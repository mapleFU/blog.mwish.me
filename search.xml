<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Strict Alias and Type Punning</title>
      <link href="/2023/12/30/Strict-Alias-and-Type-Punning/"/>
      <url>/2023/12/30/Strict-Alias-and-Type-Punning/</url>
      
        <content type="html"><![CDATA[<p>最近在看代码的时候老感觉自己的基础不够扎实，加上最近比较摸鱼，于是想灌灌水。事情的起因是早上看到社区的一个优化：<a href="https://github.com/apache/arrow/pull/39397">https://github.com/apache/arrow/pull/39397</a></p><p>这个优化的修改大概是这样的：</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">  // Read definition and repetition levels. Also return the number of definition levels</span><br><span class="line">  // and number of values to read. This function is called before reading values.</span><br><span class="line">  void ReadLevels(int64_t batch_size, int16_t* def_levels, int16_t* rep_levels,</span><br><span class="line">                  int64_t* num_def_levels, int64_t* values_to_read) &#123;</span><br><span class="line">    batch_size =</span><br><span class="line">        std::min(batch_size, this-&gt;num_buffered_values_ - this-&gt;num_decoded_values_);</span><br><span class="line">    // If the field is required and non-repeated, there are no definition levels</span><br><span class="line">    if (this-&gt;max_def_level_ &gt; 0 &amp;&amp; def_levels != nullptr) &#123;</span><br><span class="line">      *num_def_levels = this-&gt;ReadDefinitionLevels(batch_size, def_levels);</span><br><span class="line">      // TODO(wesm): this tallying of values-to-decode can be performed with better</span><br><span class="line">      // cache-efficiency if fused with the level decoding.</span><br><span class="line"><span class="deletion">-      for (int64_t i = 0; i &lt; *num_def_levels; ++i) &#123;</span></span><br><span class="line"><span class="deletion">-        if (def_levels[i] == this-&gt;max_def_level_) &#123;</span></span><br><span class="line"><span class="deletion">-          ++(*values_to_read);</span></span><br><span class="line"><span class="deletion">-        &#125;</span></span><br><span class="line"><span class="deletion">-      &#125;</span></span><br><span class="line"><span class="addition">+ *values_to_read +=</span></span><br><span class="line"><span class="addition">+          std::count(def_levels, def_levels + *num_def_levels, this-&gt;max_def_level_);</span></span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      // Required field, read all values</span><br><span class="line">      *values_to_read = batch_size;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>实际上，这个地方 <code>std::count</code> 比循环效率高吗？否，虽然我们可以认为 <code>std::count</code> 和循环大概可以产生等价的代码，那么是什么东西让这样效果好一点呢？答案是编译器无法确定 <code>num_def_levels</code>, <code>values_to_read</code> 是不是一个东西，在循环中：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (def_levels[i] == <span class="keyword">this</span>-&gt;max_def_level_) &#123;</span><br><span class="line">  (*values_to_read);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>会生成下面的代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">0xc0c2f0 &lt;ReadLevels()+96&gt; inc %rdx</span><br><span class="line">0xc0c2f3 &lt;ReadLevels()+99&gt; cmp %rax,%rdx</span><br><span class="line">0xc0c2f6 &lt;ReadLevels()+102&gt; jge 0xc0c30c &lt;ReadLevels()+124&gt;</span><br><span class="line">0xc0c2f8 &lt;ReadLevels()+104&gt; cmp %cx,(%r14,%rdx,2)</span><br><span class="line">0xc0c2fd &lt;ReadLevels()+109&gt; jne 0xc0c2f0 &lt;ReadLevels()+96&gt;</span><br><span class="line">0xc0c2ff &lt;ReadLevels()+111&gt; incq 0x0(%rbp)</span><br><span class="line">0xc0c303 &lt;ReadLevels()+115&gt; mov (%rbx),%rax</span><br><span class="line">0xc0c306 &lt;ReadLevels()+118&gt; jmp 0xc0c2f0 &lt;ReadLevels()+96&gt;</span><br></pre></td></tr></table></figure><p>这段很简单的代码在循环中反而显得判断很多余。根据我们之前介绍的内容，编译器可以很好的优化这种场景，甚至做一些向量化的优化。</p><p>这里我们会了解到的部分就是 strict aliasing，这部分的 cppreference 可以见：<a href="https://en.cppreference.com/w/cpp/language/object#Strict_aliasing">https://en.cppreference.com/w/cpp/language/object#Strict_aliasing</a> 。Strict Aliasing 大概就是，什么之后能够判断变量（想象循环里的 <code>def_levels</code>, <code>max_def_level_</code> , <code>values_to_read</code> ）指向不同的区域。</p><p>那么，根据我们上面的 cppreference （也可以参考博文 <a href="https://zhuanlan.zhihu.com/p/595286568">https://zhuanlan.zhihu.com/p/595286568</a> ）。类型上大家都是 <code>int64_t</code>，并不好判断两边不是同一个 alias！</p><h2 id="杂余"><a href="#杂余" class="headerlink" title="杂余"></a>杂余</h2><h3 id="告诉编译器好好工作"><a href="#告诉编译器好好工作" class="headerlink" title="告诉编译器好好工作"></a>告诉编译器好好工作</h3><p>本 patch 的 solving 用了个很简单的方法：直接把变量拷出来！你两个本地内存你能飞到哪去呢？</p><p>除此之外，这里还提到了很多方法</p><ol><li>RESTRICT</li><li><a href="https://en.cppreference.com/w/cpp/language/attributes/assume">https://en.cppreference.com/w/cpp/language/attributes/assume</a> </li><li><code>gnu::pure</code></li><li>…</li></ol><p>这些方法主要是告诉编译器好好干活不要胡思乱想！具体可以参考这个系列：<a href="https://developers.redhat.com/blog/2020/06/02/the-joys-and-perils-of-c-and-c-aliasing-part-1#">https://developers.redhat.com/blog/2020/06/02/the-joys-and-perils-of-c-and-c-aliasing-part-1#</a></p><h3 id="Strict-Aliasing-和-UB"><a href="#Strict-Aliasing-和-UB" class="headerlink" title="Strict Aliasing 和 UB"></a>Strict Aliasing 和 UB</h3><p>在 Strict Aliasing 的情况下，这里其实很容易写出一些相关的 ub: </p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">foo</span><span class="params">( <span class="type">float</span> *f, <span class="type">int</span> *i )</span> </span>&#123; </span><br><span class="line">    *i = <span class="number">1</span>;               </span><br><span class="line">    *f = <span class="number">0.f</span>;            </span><br><span class="line">   </span><br><span class="line">   <span class="keyword">return</span> *i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> x = <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    std::cout &lt;&lt; x &lt;&lt; <span class="string">&quot;\n&quot;</span>;   <span class="comment">// Expect 0，Output 0</span></span><br><span class="line">    x = <span class="built_in">foo</span>((<span class="type">float</span>*)(&amp;x), &amp;x);</span><br><span class="line">    std::cout &lt;&lt; x &lt;&lt; <span class="string">&quot;\n&quot;</span>;   <span class="comment">// Expect 0, But Output 1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>函数 <code>foo( float *f, int *i )</code>，编译器根据 strict aliasing rule 会认为 <code>*f</code> 和 <code>*i</code> 指向不同的内存区域，并以此进行优化，但实际上指向了相同的内存区域，因此产生了错误的结果。</p></blockquote><p>嘛这个虽然 <code>-fno-strict-aliasing</code> 可以阻止一些错误，但是实际也可以参考 Type Punning</p><h2 id="Type-Punning"><a href="#Type-Punning" class="headerlink" title="Type Punning"></a>Type Punning</h2><p>最早看 LevelDB 代码的时候，发现它从 buffer 中读取整数走了一个 memcpy。这个我当时还没理解，后来才知道是 Type Punning 的玄机。我们可以介绍一下 Strict Aliasing 之类的允许的类型转化和一些奇怪的问题。</p><blockquote><p>Whenever an attempt is made to read or modify the stored value of an object of type <code>DynamicType</code> through a glvalue of type <code>AliasedType</code>, the behavior is undefined unless one of the following is true:</p><ul><li><code>AliasedType</code> and <code>DynamicType</code> are <a href="https://en.cppreference.com/w/cpp/language/implicit_conversion#Similar_types">similar</a>.</li><li><code>AliasedType</code> is the (possibly <a href="https://en.cppreference.com/w/cpp/language/cv">cv</a>-qualified) signed or unsigned variant of <code>DynamicType</code>.</li><li><code>AliasedType</code> is <a href="https://en.cppreference.com/w/cpp/types/byte"><code>std::byte</code></a>,(since C++17) char, or unsigned char: this permits examination of the <a href="https://en.cppreference.com/w/cpp/language/object#Object_representation_and_value_representation">object representation</a> of any object as an array of bytes.</li></ul></blockquote><p>此外，还有下面的图：比如说 int32_t 的 object representation 可能很多，但转成同样位数的 float，却可能是 cb，因为它可能有些 value representation 是没有的！</p><p><img src="https://image.mwish.me/blog-image/9C554F6D-AEC1-4758-A462-3B3D75F0ABCC.png" alt="9C554F6D-AEC1-4758-A462-3B3D75F0ABCC"></p><p>这里具体也可以参考 <a href="https://www.youtube.com/watch?v=_qzMpk-22cc&amp;ab_channel=CppCon">https://www.youtube.com/watch?v=_qzMpk-22cc&amp;ab_channel=CppCon</a></p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li>Type punning in modern C++ - Timur Doumler - CppCon 2019 <a href="https://www.youtube.com/watch?v=_qzMpk-22cc&amp;ab_channel=CppCon">https://www.youtube.com/watch?v=_qzMpk-22cc&amp;ab_channel=CppCon</a></li><li>严格别名（Strict Aliasing）规则是什么，编译器为什么不做我想做的事？ - Atled的文章 - 知乎<br><a href="https://zhuanlan.zhihu.com/p/595286568">https://zhuanlan.zhihu.com/p/595286568</a></li><li><a href="https://developers.redhat.com/blog/2020/06/02/the-joys-and-perils-of-c-and-c-aliasing-part-1#">https://developers.redhat.com/blog/2020/06/02/the-joys-and-perils-of-c-and-c-aliasing-part-1#</a></li><li><a href="https://gist.github.com/shafik/848ae25ee209f698763cffee272a58f8">https://gist.github.com/shafik/848ae25ee209f698763cffee272a58f8</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Compiler Optimizations: Power, Limits, Auto-vetorize</title>
      <link href="/2023/12/10/Compiler-Optimizations-Power-Limits-Auto-vetorize/"/>
      <url>/2023/12/10/Compiler-Optimizations-Power-Limits-Auto-vetorize/</url>
      
        <content type="html"><![CDATA[<p>本文是系列文章的第三篇，前两篇文章：</p><ul><li><strong>x86 and SIMD programming Part0: Background</strong> <a href="https://blog.mwish.me/2022/11/05/x86-and-SIMD-programming/">https://blog.mwish.me/2022/11/05/x86-and-SIMD-programming/</a></li><li>Part0.5: <a href="https://blog.mwish.me/2023/11/15/Fast-Scalar-Code-and-Compiler/">https://blog.mwish.me/2023/11/15/Fast-Scalar-Code-and-Compiler/</a></li></ul><p>本篇其实还没到 Part 1，估计算是 0.8 了。本篇文章会介绍编译器能够做的一些优化和优化的限制，然后介绍 LLVM 的 Auto-vectorize。下一期会开始介绍 AVX2。</p><p>在 part-0.5 中，我们介绍了使用手写 Fast-Scalar 代码的例子和代码。实际上，在 llvm 需要复现类似的测试结果，需要关掉 LLVM Auto-vectorize，因为后者可能会帮助生成一些相似的代码。这就是编译器的魅力。但是你会发现，开不开对于浮点数都是没有区别的，我们之后会介绍，浮点数的计算因为受到精度之类的东西的影响，在没有 <code>-ffast-math</code> 的情况下，很多优化浮点数是不让做的。（说个和本题无关的，昨天看 patch 的时候竟然发现 C++20 之前 unsigned 整数转 signed 是<strong>实现定义</strong>的…而且实现定义和 ub 还不是一回事，这个震撼我心了）</p><p>这篇的主要材料来源于 Matt Godbolt 的博客和 Ethz / CMU 的课件. 本文本来11月就该写完了，因为我加班加的有点烦，中间摆烂了很长一阵子，这两天回家缓了缓才觉得应该干活了。拖了很久实在不好意思…</p><h2 id="编译器的优化和限制"><a href="#编译器的优化和限制" class="headerlink" title="编译器的优化和限制"></a>编译器的优化和限制</h2><p>编译器能够进行很多有效的优化，但是其中也有很多限制。「意识」到编译器能够进行的优化有助于我们写出快速的代码，同时，也让我们不至于因为性能搞得代码看上去特别搓。</p><p>简单的说，我个人总结就是：</p><ul><li>编译器会尝试替换昂贵的操作</li><li>编译器知道的比较多就能更好作出优化（参考 LTO、PGO）</li></ul><p>具体可见： <a href="https://dl.acm.org/doi/10.1145/3371595.3372264">https://dl.acm.org/doi/10.1145/3371595.3372264</a></p><p>有个比较好玩的，作者写的关于 LTO 的话：</p><blockquote><p>Despite being a relatively established technology (I used LTCG in the early 2000s on the original Xbox), I’ve been surprised how few projects use LTO. In part this may be because programmers unintentionally rely on undefined behavior that becomes apparent only when the compiler gets more visibility: I know I’ve been guilty of this.</p></blockquote><p>只能说 Godbolt 中肯。function call 通常是阻碍优化的部分，这个可能包括的部分有很多，你得知道函数是不是 <code>pure</code> 的，参数是否是 <code>const</code> 的，会不会修改你的参数。里面是否有原子操作之类的东西，会有那种禁止你 ordering 的东西。inline 之类的。这方面有 LTO 的话会方便很多（毕竟你自己优化能优化到哪去呢？）</p><p>这里还是建议直接看原帖，原帖重要部分是给了几个优化的实际例子，我还是比较建议通读完的，这里还有个重点是浮点数：</p><blockquote><p>This does rely on the fact that separating the totals into individual subtotals and then summing at the end is equivalent to adding them in the order the program specified. For integers, this is trivially true; but for floating-point data types this is not the case. Floating point operations are not associative: (a+b)+c is not the same as a+(b+c), as—among other things—the precision of the result of an addition depends on the relative magnitude of the two inputs.</p></blockquote><p>浮点数的操作都和很多东西相关，不开 <code>-ffast-math</code> 之类的其实不好优化的。因为编译器还是<strong>在不修改程序的语义下进行优化</strong>的。</p><p>文章中还有几个比较重要的部分：</p><ul><li>乘法、除法的优化</li><li>de-virtualization (用好 <code>final</code> ) ，这个也可见博客 [4] ( <a href="https://quuxplusone.github.io/blog/2021/02/15/devirtualization/">https://quuxplusone.github.io/blog/2021/02/15/devirtualization/</a>  )</li></ul><p>当然，乱优化浮点数可能会产生非预期的结果，比如 NaN 的处理可能会产生一些非预期的行为。</p><p>此外，影响优化的一点包括 memory alias:</p><p><img src="https://image.mwish.me/blog-image/5232900845989570722.png" alt="img"></p><p>这种不确定 alias 的情况下，可能不是特别好优化，可能编译器会加上一些 flag 或者 Runtime Flag，但我理解有来自用户的先验知识，能够帮助编译器没有负担的产生更快的代码。</p><p><img src="https://image.mwish.me/blog-image/1919209245906864678.png" alt="img"></p><p>当然，你有一些宏可以用上，这里可能也可以帮助你来展开循环，比如 <code>#pragma ivdep</code></p><p><img src="https://image.mwish.me/blog-image/147086212116536191.png" alt="img"></p><h2 id="LLVM-Auto-Vectorization"><a href="#LLVM-Auto-Vectorization" class="headerlink" title="LLVM Auto-Vectorization"></a>LLVM Auto-Vectorization</h2><p>15-721 的课件有一张比较有意思的图，但这张图实际上是错误的，编译器在这方面其实还是蛮聪明的：</p><p><img src="https://image.mwish.me/blog-image/3046202342352512391.png" alt="img"></p><p>LLVM 有一种 Runtime checks of pointers 的能力，它会编码一个 Runtime 的 checking，如下。</p><p><a href="https://llvm.org/docs/Vectorizers.html#runtime-checks-of-pointers">https://llvm.org/docs/Vectorizers.html#runtime-checks-of-pointers</a></p><p>我希望我们能回忆起来上一节的优化内容，上一节里面我们展示了一个手动的对非向量化代码的优化：<a href="https://blog.mwish.me/2023/11/15/Fast-Scalar-Code-and-Compiler/#Parquet-BYTE-STREAM-SPLIT-%E5%8A%A0%E9%80%9F">https://blog.mwish.me/2023/11/15/Fast-Scalar-Code-and-Compiler/#Parquet-BYTE-STREAM-SPLIT-%E5%8A%A0%E9%80%9F</a></p><p>我们可以看到上述优化的代码的一些思路：</p><ol><li>拆分计算，把 vectorize 的计算拆分成为一组计算 Load 一大组 —&gt; 对这组数据进行计算 —&gt; Store 内存</li><li>如果是 SIMD 或者利用指令级并行，那么计算出某个核心的计算逻辑对应的 port 数，然后去并行执行它们</li><li>上述操作如果是在 TP 点查操作中其实不一定划得来，因为没几个操作跟你并行，即使是 TableScan -&gt; Filter 这种也是。但是可能 AP 这种 workload 本身就有一大批数据需要计算的，所以可以拆分成这样每个 batch 批量执行的计算。这个批量大小和 CPU、Port、访存操作有关。如果输入数 % batchSize 还有剩余的话，可能会需要接一个 non-vectorize 的 epilogue</li></ol><p>比较有趣的事，LLVM 自动向量化会尝试产生一个类似下列的结构：</p><ul><li>Vectorize Body</li><li>Vector Epilogue</li><li>Scalar Epilogue</li></ul><p><img src="https://image.mwish.me/blog-image/1492060510279710289.png" alt="img"></p><p>LLVM 会按照上述内容来优化。知道这个之后，我们去看看 LLVM 官方的 Vectorize 文档：<a href="https://llvm.org/docs/Vectorizers.html#features">https://llvm.org/docs/Vectorizers.html#features</a></p><p>下列的代码是可以 vectorize 的</p><ul><li>Loops with unknown trip count</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">bar</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span>* B, <span class="type">float</span> K, <span class="type">int</span> start, <span class="type">int</span> end)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = start; i &lt; end; ++i)    </span><br><span class="line">        A[i] *= B[i] + K;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Reductions</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">foo</span><span class="params">(<span class="type">int</span> *A, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="type">unsigned</span> sum = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line">    sum += A[i] + <span class="number">5</span>;</span><br><span class="line">  <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里如果是 Reductions ，那么 add, xor 之类的操作，它会抽出一个 vectorize 组（类似 <code>unsigned[dop] sum</code> )，然后在上面操作的时候，避免操作同一个值。注意这里对浮点数是不能这样操作的（除非开了 <code>-ffast-math</code>）</p><ul><li>Inductions</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">bar</span><span class="params">(<span class="type">float</span> *A, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line">    A[i] = i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种能向量化（好像很合理）</p><ul><li>If Conversion</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">foo</span><span class="params">(<span class="type">int</span> *A, <span class="type">int</span> *B, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="type">unsigned</span> sum = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line">    <span class="keyword">if</span> (A[i] &gt; B[i])</span><br><span class="line">      sum += A[i] + <span class="number">5</span>;</span><br><span class="line">  <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>control flow in the innermost loop 这里可以 vectorize，这里可以参考博客：<a href="https://sbaziotis.com/performance/a-beginners-guide-to-vectorization-by-hand-part-3.html">https://sbaziotis.com/performance/a-beginners-guide-to-vectorization-by-hand-part-3.html</a></p><ul><li>Pointer Induction Variables</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">baz</span><span class="params">(<span class="type">int</span> *A, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> std::<span class="built_in">accumulate</span>(A, A + n, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对指针和标准库能很好处理</p><ul><li>Reverse Iterators</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo</span><span class="params">(<span class="type">int</span> *A, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = n; i &gt; <span class="number">0</span>; --i)</span><br><span class="line">    A[i] +=<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对反向操作很好处理(跟 rsy 聊的时候他还告诉我 reverse 方向的 prefetch 可能不如正向的 prefetch，学到很多）</p><ul><li>Scatter / Gatter</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo</span><span class="params">(<span class="type">int</span> * A, <span class="type">int</span> * B, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">intptr_t</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line">    A[i] += B[i * <span class="number">4</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>-mllvm -force-vector-width=#</code> 的情况下这里才会开启，因为它可能发现 cost 划不来</p><ul><li><a href="https://llvm.org/docs/Vectorizers.html#vectorization-of-mixed-types">https://llvm.org/docs/Vectorizers.html#vectorization-of-mixed-types</a></li></ul><p>多种类型的混合会根据代价来估计</p><ul><li>Partial unrolling during vectorization</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">foo</span><span class="params">(<span class="type">int</span> *A, <span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="type">unsigned</span> sum = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line">    sum += A[i];</span><br><span class="line">  <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个长得和前面 Reduction 很像，但这里是说，会按照 port 的数量，来拆分并行度。</p><p>这些只是我选了想记住的一部分，需要知道具体细节可以浏览原来的文档。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>Matt Godbolt 的 C++ Optimizations <a href="https://dl.acm.org/doi/10.1145/3371595.3372264">https://dl.acm.org/doi/10.1145/3371595.3372264</a> 和大佬的翻译 <a href="https://fuzhe1989.github.io/2020/01/22/optimizations-in-cpp-compilers/">https://fuzhe1989.github.io/2020/01/22/optimizations-in-cpp-compilers/</a> . 这一篇的介绍非常好</li><li>Ethz Fastcode 05: <a href="https://acl.inf.ethz.ch/teaching/fastcode/2023/slides/05-compiler-limitations.pdf">https://acl.inf.ethz.ch/teaching/fastcode/2023/slides/05-compiler-limitations.pdf</a></li><li>CMU 15-721 2023 <a href="https://15721.courses.cs.cmu.edu/spring2023/slides/08-vectorization.pdf">https://15721.courses.cs.cmu.edu/spring2023/slides/08-vectorization.pdf</a></li><li><a href="https://quuxplusone.github.io/blog/2021/02/15/devirtualization/">https://quuxplusone.github.io/blog/2021/02/15/devirtualization/</a> Author 的去虚拟化博客</li><li><a href="https://llvm.org/docs/Vectorizers.html#features">https://llvm.org/docs/Vectorizers.html#features</a> LLVM Vectorize</li><li><a href="https://sbaziotis.com/">https://sbaziotis.com/</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Fast Scalar Code and Compiler</title>
      <link href="/2023/11/15/Fast-Scalar-Code-and-Compiler/"/>
      <url>/2023/11/15/Fast-Scalar-Code-and-Compiler/</url>
      
        <content type="html"><![CDATA[<p>上一期( <a href="https://blog.mwish.me/2022/11/05/x86-and-SIMD-programming/">https://blog.mwish.me/2022/11/05/x86-and-SIMD-programming/</a> ) 介绍了 x86 和 SIMD 的背景，同时介绍了 x86 Skylake 的架构。这文章写了都整整一年了（我也太摆烂了），所以我们还是需要回顾一下。x86 CPU 上面通过 decode 代码，把 x86 CISC 指令转化为 RISC 的 micro-arch 的指令。SuperScalar 的指令被解析后，里面有一组 Port 来执行对应的代码。这样我们的 CPU 可以 OoO 的执行。理论上给定一组代码和 Port 甚至可以算出一个代码执行的上限。</p><p><img src="https://image.mwish.me/blog-image/2216018380123463140.png" alt="img"></p><p>当然上面这里说的还是一个理论的上限值，实际上在上篇文章中，我们还了解了如何衡量一个应用是 bounded by CPU 还是访存。</p><p>在访问内存上，有 L1 — L2 — L3 的 Cache。这里 L1 在每个 CPU 上，L3 则可能涉及一些共享。笔者这里并不做特别细的介绍是因为这块并不属于 ISA，而是 microarch 之类或者实现上应该管的一部分。Prefetch 本身也和高性能的代码相关，但是这个更多只能用来解释。</p><p>这一节我们介绍的是如何写出高性能的 “scalar” 代码，说是 scalar 主要是因为在这里我们不会用到 SIMD 的指令。取而代之的是如何利用 superscalar 之类的性质，写出高性能的 Scalar Code。我们首先会介绍从 fastcode 的代码和生产的代码来分析这块的性能。下一节也会介绍 LLVM 的 Auto-vectorize 和 编译器的优化。</p><h2 id="Fast-Scalar-Code"><a href="#Fast-Scalar-Code" class="headerlink" title="Fast Scalar Code"></a>Fast Scalar Code</h2><p>代码本身可能和 code 执行的汇编数量、访问的负载之类的东西有关。根据我们上篇文章的知识，指令的延迟、吞吐都是不一样的。此外，我们还知道了所谓 Super Scalar 的大致语义。那么，尽管不同架构代码可能 Port 之类的数量会有不同，但是这对我们写出快的 scalar 代码是有指导意义的。</p><p>关于乱序如下面所述</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t2 = t0 + t1</span><br><span class="line">t5 = t4 * t3</span><br><span class="line">t6 = t2 + t5</span><br></pre></td></tr></table></figure><p>那么 这里 (1) (2) 行的其实可以串行执行。考虑到 Memory Model，Store Load 可能会有一些影响，但是很多东西也走不到 Memory ( 比如看这个链接 <a href="https://stackoverflow.com/questions/29722676/atomic-operations-on-superscalar-processor">https://stackoverflow.com/questions/29722676/atomic-operations-on-superscalar-processor</a> ，实际上一些 Atomic 操作的时候，CPU 也仿佛不是 Super Scalar 的了）</p><p><img src="https://image.mwish.me/blog-image/8601113935312402029.png" alt="img"></p><p>课程举了个 Sample 来介绍如何写 fast scalar 的代码，sample 如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">template <span class="operator">&lt;</span>typename ArrowType, typename Op<span class="operator">&gt;</span></span><br><span class="line">void BenchmarkOp(benchmark::State<span class="operator">&amp;</span> state) &#123;</span><br><span class="line">  <span class="keyword">using</span> CType <span class="operator">=</span> typename ArrowType::c_type;</span><br><span class="line">  auto rand <span class="operator">=</span> random::RandomArrayGenerator(kSeed);</span><br><span class="line">  auto valueArray <span class="operator">=</span> std::static_pointer_cast<span class="operator">&lt;</span>NumericArray<span class="operator">&lt;</span>ArrowType<span class="operator">&gt;&gt;</span>(rand.Numeric<span class="operator">&lt;</span>ArrowType<span class="operator">&gt;</span>(<span class="number">4096</span> <span class="operator">*</span> <span class="number">16</span>, <span class="number">0</span>, <span class="number">114514</span>));</span><br><span class="line">  int64_t length <span class="operator">=</span> valueArray<span class="operator">-</span><span class="operator">&gt;</span>length();</span><br><span class="line">  auto <span class="keyword">values</span> <span class="operator">=</span> valueArray<span class="operator">-</span><span class="operator">&gt;</span>raw_values();</span><br><span class="line">  <span class="keyword">for</span> (auto s : state) &#123;</span><br><span class="line">    CType sum <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (int64_t i <span class="operator">=</span> <span class="number">0</span>; i <span class="operator">&lt;</span> length; i<span class="operator">+</span><span class="operator">+</span>) &#123;</span><br><span class="line">      sum <span class="operator">=</span> Op::<span class="keyword">call</span>(sum, <span class="keyword">values</span>[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    benchmark::DoNotOptimize(sum);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个代码执行如下图所示，可以说是 Scalar Code:</p><p><img src="https://image.mwish.me/blog-image/4813239862219650588.png" alt="img"></p><p><img src="https://image.mwish.me/blog-image/7962189767674737933.png" alt="img"></p><p>这里的 sequential op 导致流水线并行没有被很好的利用上，都是线性执行这些代码。下面这里提供了 <code>unroll2</code> 的实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> ArrowType, <span class="keyword">typename</span> Op&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BenchmarkOp2</span><span class="params">(benchmark::State&amp; state)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">using</span> CType = <span class="keyword">typename</span> ArrowType::c_type;</span><br><span class="line">  <span class="keyword">auto</span> rand = random::<span class="built_in">RandomArrayGenerator</span>(kSeed);</span><br><span class="line">  <span class="keyword">auto</span> valueArray = std::static_pointer_cast&lt;NumericArray&lt;ArrowType&gt;&gt;(rand.<span class="built_in">Numeric</span>&lt;ArrowType&gt;(<span class="number">4096</span> * <span class="number">16</span>, <span class="number">0</span>, <span class="number">114514</span>));</span><br><span class="line">  <span class="type">int64_t</span> length = valueArray-&gt;<span class="built_in">length</span>();</span><br><span class="line">  <span class="keyword">auto</span> values = valueArray-&gt;<span class="built_in">raw_values</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> s : state) &#123;</span><br><span class="line">    CType sum = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int64_t</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (; i &lt; length; i += <span class="number">2</span>) &#123;</span><br><span class="line">      sum = Op::<span class="built_in">call</span>(Op::<span class="built_in">call</span>(sum, values[i]), values[i + <span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (i &lt; length) &#123;</span><br><span class="line">      sum = Op::<span class="built_in">call</span>(sum, values[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    benchmark::<span class="built_in">DoNotOptimize</span>(sum);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的操作相当于把原先循环中一次改成了两个 OP，那么这个会怎么样呢？答案是没怎么变化。</p><p><img src="https://image.mwish.me/blog-image/4911952986514956094.png" alt="img"></p><p>接下来展示 Separate Accumulators 的版本：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> ArrowType, <span class="keyword">typename</span> Op&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BenchmarkOp2SA</span><span class="params">(benchmark::State&amp; state)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">using</span> CType = <span class="keyword">typename</span> ArrowType::c_type;</span><br><span class="line">  <span class="keyword">auto</span> rand = random::<span class="built_in">RandomArrayGenerator</span>(kSeed);</span><br><span class="line">  <span class="keyword">auto</span> valueArray = std::static_pointer_cast&lt;NumericArray&lt;ArrowType&gt;&gt;(rand.<span class="built_in">Numeric</span>&lt;ArrowType&gt;(<span class="number">4096</span> * <span class="number">16</span>, <span class="number">0</span>, <span class="number">114514</span>));</span><br><span class="line">  <span class="type">int64_t</span> length = valueArray-&gt;<span class="built_in">length</span>();</span><br><span class="line">  <span class="keyword">auto</span> values = valueArray-&gt;<span class="built_in">raw_values</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> s : state) &#123;</span><br><span class="line">    CType sum0 = <span class="number">0</span>;</span><br><span class="line">    CType sum1 = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int64_t</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (; i &lt; length; i += <span class="number">2</span>) &#123;</span><br><span class="line">        sum0 = Op::<span class="built_in">call</span>(sum0, values[i]);</span><br><span class="line">        sum1 += Op::<span class="built_in">call</span>(sum1, values[i + <span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (i &lt; length) &#123;</span><br><span class="line">      sum0 = Op::<span class="built_in">call</span>(sum0, values[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    benchmark::<span class="built_in">DoNotOptimize</span>(Op::<span class="built_in">call</span>(sum0, sum1));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://image.mwish.me/blog-image/2057821884675391120.png" alt="img"></p><p>这里可以得到一定的提升，但是肯定不会超过性能上限。此外，对于浮点数来说，这样的操作可能会<strong>略微变更对应的结果</strong>。</p><p>本质上，这里可以算出来一个并行度，然后来优化对应的操作：</p><p><img src="https://image.mwish.me/blog-image/7144858499665429034.png" alt="img"></p><p>当然，这段其实是个理论分析，某种程度上感觉至少我在 LLVM17 开 O3 编译器会帮忙做很多事情，除了浮点数都会优化到差不多的性能，感兴趣的也可以拿我们上面的代码去跑一下，感受一下这块的具体内容。</p><h2 id="Parquet-BYTE-STREAM-SPLIT-加速"><a href="#Parquet-BYTE-STREAM-SPLIT-加速" class="headerlink" title="Parquet BYTE_STREAM_SPLIT 加速"></a>Parquet BYTE_STREAM_SPLIT 加速</h2><p>下面这里我们再以 BYTE_STREAM_SPLIT 为类型，分析一下 Scalar 代码怎么提速。这是 Parquet 标准中一种浮点类型的无损浮点 Encoding。它要结合压缩来使用。它的算法大概是：</p><ul><li>对于 k Bytes 的 n 个浮点数拆成 k 个 n bytes 的 Stream</li><li>第一个 k Bytes 的浮点数，内容第一位写在第一 Byte；第二位写在第二个 Stream 的第一 byte ，以此类推</li></ul><p>如果你觉得上面不清晰，可以直接看原文：<a href="https://github.com/apache/parquet-format/blob/master/Encodings.md#byte-stream-split-byte_stream_split--9">https://github.com/apache/parquet-format/blob/master/Encodings.md#byte-stream-split-byte_stream_split--9</a></p><p>这块原先的代码非常好懂：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Encoding: 对于每个数值，直接写 k 个 Stream 的 Byte</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ByteStreamSplitEncodeScalar</span><span class="params">(<span class="type">const</span> <span class="type">uint8_t</span>* raw_values, <span class="type">const</span> <span class="type">int64_t</span> num_values,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 <span class="type">uint8_t</span>* output_buffer_raw)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">constexpr</span> <span class="type">size_t</span> kNumStreams = <span class="built_in">sizeof</span>(T);</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0U</span>; i &lt; num_values; ++i) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> j = <span class="number">0U</span>; j &lt; kNumStreams; ++j) &#123;</span><br><span class="line">      <span class="type">const</span> <span class="type">uint8_t</span> byte_in_value = raw_values[i * kNumStreams + j];</span><br><span class="line">      output_buffer_raw[j * num_values + i] = byte_in_value;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Encoding: 对于每个数值，直接从 k 个 Stream 的 Byte 中读取</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ByteStreamSplitDecodeScalar</span><span class="params">(<span class="type">const</span> <span class="type">uint8_t</span>* data, <span class="type">int64_t</span> num_values, <span class="type">int64_t</span> stride,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 T* out)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">constexpr</span> <span class="type">size_t</span> kNumStreams = <span class="built_in">sizeof</span>(T);</span><br><span class="line">  <span class="keyword">auto</span> output_buffer_raw = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">uint8_t</span>*&gt;(out);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int64_t</span> i = <span class="number">0</span>; i &lt; num_values; ++i) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> b = <span class="number">0</span>; b &lt; kNumStreams; ++b) &#123;</span><br><span class="line">      <span class="type">const</span> <span class="type">size_t</span> byte_index = b * stride + i;</span><br><span class="line">      output_buffer_raw[i * kNumStreams + b] = data[byte_index];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码在 CPU 上和内存上其实都并不高效。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Epilog</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> stream = <span class="number">0</span>; stream &lt; width; ++stream) &#123;</span><br><span class="line">  <span class="type">uint8_t</span>* dest = dest_streams[stream];</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int64_t</span> i = <span class="number">0</span>; i &lt; nvalues; ++i) &#123;</span><br><span class="line">    dest[i] = src[stream + i * width];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Epilog</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> stream = <span class="number">0</span>; stream &lt; width; ++stream) &#123;</span><br><span class="line">  <span class="type">const</span> <span class="type">uint8_t</span>* src = src_streams[stream];</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int64_t</span> i = <span class="number">0</span>; i &lt; nvalues; ++i) &#123;</span><br><span class="line">    dest[stream + i * width] = src[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>新的算法在末端会至少以单个 “STREAM” 为单位去读写，避免一些逐个 Value 访问 Stream 的时候把 Cache 搞进来又搞出去</p><p>当然这里不止是这套逻辑，这里把 Encoding 的逻辑拆成了下面的逻辑：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Scalar implementations</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">DoSplitStreams</span><span class="params">(<span class="type">const</span> <span class="type">uint8_t</span>* src, <span class="type">int</span> width, <span class="type">int64_t</span> nvalues,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">uint8_t</span>** dest_streams)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Value empirically chosen to provide the best performance on the author&#x27;s machine</span></span><br><span class="line">  <span class="keyword">constexpr</span> <span class="type">int</span> kBlockSize = <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (nvalues &gt;= kBlockSize) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> stream = <span class="number">0</span>; stream &lt; width; ++stream) &#123;</span><br><span class="line">      <span class="type">uint8_t</span>* dest = dest_streams[stream];</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; kBlockSize; i += <span class="number">8</span>) &#123;</span><br><span class="line">        <span class="type">uint64_t</span> a = src[stream + i * width];</span><br><span class="line">        <span class="type">uint64_t</span> b = src[stream + (i + <span class="number">1</span>) * width];</span><br><span class="line">        <span class="type">uint64_t</span> c = src[stream + (i + <span class="number">2</span>) * width];</span><br><span class="line">        <span class="type">uint64_t</span> d = src[stream + (i + <span class="number">3</span>) * width];</span><br><span class="line">        <span class="type">uint64_t</span> e = src[stream + (i + <span class="number">4</span>) * width];</span><br><span class="line">        <span class="type">uint64_t</span> f = src[stream + (i + <span class="number">5</span>) * width];</span><br><span class="line">        <span class="type">uint64_t</span> g = src[stream + (i + <span class="number">6</span>) * width];</span><br><span class="line">        <span class="type">uint64_t</span> h = src[stream + (i + <span class="number">7</span>) * width];</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> ARROW_LITTLE_ENDIAN</span></span><br><span class="line">        <span class="type">uint64_t</span> r = a | (b &lt;&lt; <span class="number">8</span>) | (c &lt;&lt; <span class="number">16</span>) | (d &lt;&lt; <span class="number">24</span>) | (e &lt;&lt; <span class="number">32</span>) | (f &lt;&lt; <span class="number">40</span>) |</span><br><span class="line">                     (g &lt;&lt; <span class="number">48</span>) | (h &lt;&lt; <span class="number">56</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">        <span class="type">uint64_t</span> r = (a &lt;&lt; <span class="number">56</span>) | (b &lt;&lt; <span class="number">48</span>) | (c &lt;&lt; <span class="number">40</span>) | (d &lt;&lt; <span class="number">32</span>) | (e &lt;&lt; <span class="number">24</span>) |</span><br><span class="line">                     (f &lt;&lt; <span class="number">16</span>) | (g &lt;&lt; <span class="number">8</span>) | h;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">        arrow::util::<span class="built_in">SafeStore</span>(&amp;dest[i], r);</span><br><span class="line">      &#125;</span><br><span class="line">      dest_streams[stream] += kBlockSize;</span><br><span class="line">    &#125;</span><br><span class="line">    src += width * kBlockSize;</span><br><span class="line">    nvalues -= kBlockSize;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Epilog</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> stream = <span class="number">0</span>; stream &lt; width; ++stream) &#123;</span><br><span class="line">    <span class="type">uint8_t</span>* dest = dest_streams[stream];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int64_t</span> i = <span class="number">0</span>; i &lt; nvalues; ++i) &#123;</span><br><span class="line">      dest[i] = src[stream + i * width];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>对于每个 Block，Block Size 会是 8 的倍数</li><li>Block 内，这里会 8 个一组，把 8 个浮点数的 Byte 写到一个 Stream 里面</li></ul><p>这里就是本节介绍的操作方式，可以看到，这里有几个 Trick:</p><ol><li>分离访存操作和 CPU 操作</li><li>对于同质大量计算，高效的处理所有值</li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://github.com/apache/arrow/pull/38529">https://github.com/apache/arrow/pull/38529</a></li><li>LLVM Auto-Vectorize <a href="https://llvm.org/docs/Vectorizers.html">https://llvm.org/docs/Vectorizers.html</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>CIDR&#39;23: Analyzing and Comparing Lakehouse Storage Systems</title>
      <link href="/2023/11/05/CIDR-23-Analyzing-and-Comparing-Lakehouse-Storage-Systems/"/>
      <url>/2023/11/05/CIDR-23-Analyzing-and-Comparing-Lakehouse-Storage-Systems/</url>
      
        <content type="html"><![CDATA[<p>Analyzing and Comparing Lakehouse Storage Systems 发布于 CIDR’23。作者包括了 UCB, Stanford，还有著名的 Mesos / Spark 的作者 Matei 和他的导师 Ion Stoica。本文分析了 DataBricks、Hudi、Iceberg 几大系统的存储，并且划分了下面的几个问题：</p><ol><li>Coordinator transaction</li><li>Store metadata</li><li>Query Metadata</li><li>Handle Update (CoW, MoR. etc…)</li></ol><p>每个问题的选择都会带来一定的 trade-off，本文也用 LHBench ( <a href="https://github.com/lhbench/lhbench">https://github.com/lhbench/lhbench</a> ) 来对比了这些 Lakehouse。</p><p>我们之前的博客可以见：</p><ol><li><a href="https://blog.mwish.me/2023/03/19/Apache-Iceberg-and-changes-above-Hive/">https://blog.mwish.me/2023/03/19/Apache-Iceberg-and-changes-above-Hive/</a></li><li><a href="https://blog.mwish.me/2022/05/01/Delta-Lake-Lakehouse/">https://blog.mwish.me/2022/05/01/Delta-Lake-Lakehouse/</a></li></ol><p>根据我们自己的理解和论文的理解，Lakehouse 虽然产品定义是一个商业概念，但是技术上，它总的来说是一个 Meta 层 — Storage 层的概念，Raynold Xin 有一个 Talk 的 PPT 做的很好，我就直接抠出来了：</p><p><img src="https://image.mwish.me/blog-image/9015916313194020933.png" alt="img"></p><p>这里可以看到，虽然 Lakehouse 是个商业概念，但是这些点还是比较清晰的：</p><ol><li>（对外）依赖 Open Format 和比较定义好的存储（比如 Object Store）<ol><li>Object Store and Lakehouse: High latency</li><li>对外: (weak) Consistency gurantee</li></ol></li><li>一定程度上的数据 / 元数据处理. 支持一些简单的 ACID 语义（这块的 ACID 语义其实没有传统的关系型数据库定义的那么清晰）</li></ol><p>知道这个概念之后我们再来看这篇论文提出的几个点：</p><ol><li>如何协调事务。这里涉及读写 — 写写的关系。<ol><li>上层事务永远下层的（对象）存储：有的地方如果考虑写 S3 或者对象存储当作事务，可能会考虑使用对象存储的 Put-if-absent 语义 （有的不支持的可能额外依赖一个外部系统）</li><li>用额外的存储系统，比如像 Hive MetaStore（或许还包括 FDB？）. 相对来说，这里提交延迟（不考虑 LIST，那又是另一个问题了）会低一些，但本身也会这个系统有一定的影响</li></ol></li><li>如何存储 metadata. (For Pruning, etc.)<ol><li>把数据存到额外的表上（Google Bigmeta?)</li><li>放到 Transaction Log 上</li><li>放到额外的服务去（FDB？）</li></ol></li><li>如何查询 Metadata<ol><li>Delta Lake 和 Hudi 可以用系统的 Parallel Job 来查询 Metadata，在大表的时候并行 Planing，加速，但这个对小表来说可能会增大 latency</li><li>Iceberg 现在是单线程查询</li><li>（但我理解这几个特么的都可以并行吧，标准在那人是活人）</li></ol></li><li>如何高效处理 Record 级别的更新。这里因为 Lakehouse 本身处理大批数据，本身有很多批量加载数据的逻辑，比如 SQL Merge 这种。不同系统可能有 Copy-on-write 或者 Merge-on-read 等方式</li></ol><p>论文里面还提到一些比较好玩的东西，很符合我的直觉</p><blockquote><p>On the one hand, organizations use lakehouse systems to ingest and organize very large datasets—for example, the largest Delta Lake tables span well into the hundreds of petabytes, consist of billions of files, and are updated with hundreds of terabytes of ingested data per day [21]. On the other hand, the data warehouse capabilities of lakehouse systems are encouraging organizations to load and manage smaller datasets in them too, in order to combine these with the latest data from their ingest pipelines and build a single management system for all data. For example, most of the CPU-hours on Databricks are used to process tables smaller than 1 TB, and query durations across all tables range from sub-second to hours.</p></blockquote><p>论文中对 Lakehouse 拆分剖析如下：</p><p><img src="https://image.mwish.me/blog-image/8009400306733372816.png" alt="img"></p><p>文章后面有一些 benchmark，但我觉得没啥意思，就不看了，你妈的这些 benchmark 比较在做过的人眼里完全没任何价值。</p><h2 id="Transaction-Coordination"><a href="#Transaction-Coordination" class="headerlink" title="Transaction Coordination"></a>Transaction Coordination</h2><ul><li>支持单表事务，但是对多标事务支持可能不是特别好，同事事务支持的语义不完全相同（见 Table1 的 Isolation Levels）</li><li>Delta Lake 使用对象存储的事务。对于 S3 这种不支持 conditional-write 的，Delta Lake 使用 Dynamo 来做协调（Lance 和 arrow-rs 的 object-store 也支持同样的语义）。我个人觉得，这套方案的本质是依赖事务性 CAS Logging 和 Lakehouse 本身的低提交频率（或者即使提交数据多，在他们的场景也倾向于是大 SQL作业提交大批量数据，而不是TP的高tps小事务）</li><li>Hudi/Iceberg HMS/Zk/Dynamo 实现的表锁。论文因为有 Delta 的人，还小小的抹黑了一下提到他们有因为这个造成脏写的问题（Hive: Fix concurrent transactions overwriting commits by adding hive lock heartbeats. <a href="https://github.com/apache/iceberg/pull/5036">https://github.com/apache/iceberg/pull/5036</a> )。但我觉得属于半尬黑了，本质原因还是依赖外部系统做一个存储层的 fencing 是比较难的，退一万步说，我觉得你 Delta 依赖 Dynamo 在 S3 上操作还比人家有优越感了么。当然依赖少确实是有优势的就是了，本质也是 trade-off。</li></ul><p>这几个产品本身都是用 OCC 的协议（insite: 冲突可能会比较小？），但是提供了不同的语义（又要开始吹自己了）：</p><ul><li>Iceberg 和 Hudi 都会保证读的时候来自 start snapshot，提交的时候和已经提交的事务没有写写冲突，所以这块的隔离级别是 SI</li><li>Delta 默认会保证（当然 Iceberg 也有这个能力）更新的时候没有 SI会遇到的 anti-dependency ( <a href="https://blog.mwish.me/2020/11/14/%E4%BA%8B%E5%8A%A1-%E5%8D%8F%E8%AE%AE%E5%92%8C%E9%9A%94%E7%A6%BB/">https://blog.mwish.me/2020/11/14/%E4%BA%8B%E5%8A%A1-%E5%8D%8F%E8%AE%AE%E5%92%8C%E9%9A%94%E7%A6%BB/</a> 比如只剩一个用户，然后两个事务都是 `IF(exist) then -1 and …`` 这种，用这种方式来支持 Serializable（当然这块读可能不完全按照定义，一个读仍然可能读到不满足时序的数据）。Delta 甚至可以开启读的时候也做检查的限制，来达到 Strict Serializable</li></ul><h2 id="Metadata-Management"><a href="#Metadata-Management" class="headerlink" title="Metadata Management"></a>Metadata Management</h2><p>S3 之类的 LIST 本身限制 1000 个文件，LIST 一个大目录延迟高，可能还要手写循环或者递归，还是比较菜的。为了突破这种限制，几个 Lakehouse 都支持把 Metadata 外存，论文这里把外存分成了 Tabular 和 Hierachical 两种方式：</p><ul><li>Delta Lake 和 Hudi 把元数据存储在 metadata table（Hudi） ， Transaction Log Checkpoint（Delta 存储 JSON / Parquet ）。这两种系统元数据提交是直接写日志然后周期性 Merge-On-Read 合并到表中（本质上有点像 Lakehouse 搞从 CDC 中导入数据的 Pattern？）</li><li>Iceberg 直接存成层次的文件</li></ul><h2 id="Data-Update-Strategies"><a href="#Data-Update-Strategies" class="headerlink" title="Data Update Strategies"></a>Data Update Strategies</h2><p>分为 COW 和 MOR。但是根据我个人的观察，比较困难的其实还是更新 / 宽表更新单列 这类的处理，有的地方可能会写 opLog，有的地方会产生一个 Primary Key 然后覆盖 PK，有的地方会更新宽表的时候 CoW 单列。 </p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.montecarlodata.com/impact-2021-the-data-lakehouse/">https://www.montecarlodata.com/impact-2021-the-data-lakehouse/</a> Reynold Xin 在 21 年的 Talk。我觉得先看这个再看 VLDB的 LakeHouse Paper 比较好，毕竟主创自己的意思肯定更清晰一些</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>SIGMOD&#39;14: Morsel-Driven Parallelism</title>
      <link href="/2023/11/03/SIGMOD-14-Morsel-Driven-Parallelism/"/>
      <url>/2023/11/03/SIGMOD-14-Morsel-Driven-Parallelism/</url>
      
        <content type="html"><![CDATA[<p>本文由 TUM 发表于 SIGMOD’14. 在前一篇文章中提到，VLDB’11 的时候，TUM 引入了 LLVM Codegen 和 Data Centric 的 Push-based Execution。在那篇文章中，介绍的是从一个 Volcano Model 转化成一个 Push-based exec 的 Plan，并没有介绍怎么在里面处理并发，生成的东西可以理解成是串行执行的</p><p>本论文可以视作上一篇论文的后续，即在 “data centric” 的执行下，怎么去根据数据来做查询切分/并发。在这套架构下，数据被切分成 Morsel 然后被 CPU 线程调度执行（论文其实没那么细介绍 TableScan?）。此外，文章也考虑了一些现代 CPU 的特性，比如 NUMA。Morsel 因为是data-centric 的，所以执行这点还比较自然（实际上某种意义上说，tp 数据库很多地方没 TPC 之类的东西还不太好做）。这里允许把输入数据切分成 Morsels，根据机器的执行状况来定义 DOP (degree of parallelism）而不用在 Plan 之类的地方写死，由 Runtime 来做动态的调度甚至变更执行期的 DOP（当然，可能有一些 colocate-join 之类的不知道要不要特殊处理）。</p><p>在新硬件上，本文考虑了新的 NUMA 硬件。NUMA 可能会有多个不对等的 Memory Controller，文章的 Point 很有意思：(这里考虑的主要是 locality 部分）</p><blockquote><p>In essence, the computer has become a network in itself as the access costs of data items varies depending on which chip the data and the accessing thread are located. Therefore, many-core parallelization needs to take RAM and cache hierarchies into account. In particular, the NUMA division of the RAM has to be considered carefully to ensure that threads work (mostly) on NUMA-local data.</p></blockquote><p>在一般数据库中，算子内部的并行可能需要一个 Exchange Operator 来切分计算，并需要一个 Optimizer 或者什么阶段定死的。这篇论文称其为 plan-driven 的并发调度。而相对的，本文提出了一种 Morsel Driven 的调度，下图是三个 Join 执行的情况：</p><p><img src="https://image.mwish.me/blog-image/8319243476576150900.png" alt="img"></p><p>在这个系统上，线程<strong>固定数量并绑核</strong>。</p><p>Morsel Driven 的调度相对来说需要一个半全局的状态，数据从输入拿到一份内存，然后丢给输出的 Buffer。虽然这里是全局的状态(也允许 work-stealing)，但是本身来说因为调度会考虑 locality，所以认为这块的 locality 相当好。当然这里 Operator 的实现也要进行一些改造来适配 Morsel。</p><p>本论文的内容大概包括：</p><ol><li>Morsel-driven 的查询执行框架</li><li>适配 Morsel 执行框架的并行算子实现</li><li>NUMA 特性的利用探讨</li></ol><h2 id="Morsel-Driven-Execution"><a href="#Morsel-Driven-Execution" class="headerlink" title="Morsel-Driven Execution"></a>Morsel-Driven Execution</h2><p>Figure2 展示了一个多表读取 -&gt; Join 的执行流程：</p><p><img src="https://image.mwish.me/blog-image/4704972240403201565.png" alt="img"></p><p>执行方式在前一篇论文里提到，这里不再赘述（值得一提的是，HyPer 这里也使用了 vectorize 的策略）</p><p>论文引入了组件 QEProject (Query Engine Project?)，把 Pipeline 转化为 dispatcher (用 Velox 类似的话说，是分给不同的 Driver 来执行？）在论文的执行中：</p><ol><li>Probe 只有在 build 完成之后才能开始执行。</li><li>每个 Pipeline 里面 QEProject 会切分等大的输入，当然这个可能造成输出大小不等大。</li><li>Dop 的上限受系统线程的限制来防止对应的抢占。</li></ol><p><img src="https://image.mwish.me/blog-image/2837544159723451720.png" alt="img"></p><p>这里在 Scan 的时候会相当于有一个抢占，此外我们再看 Figure 3，考虑到本文这里因为并发，那么 hash build 的时候，如果由 Scan 线程直接插入的话，这里会有一部分的内存的问题：读写共享区域，甚至是 Hash Table 的扩容。于是这部分会把 Scan-&gt;Build 分成两个阶段：</p><ol><li>在 Scan 阶段，数据从数据源 fetch 出来然后把 Filter 之后的数据<strong>推到 NUMA-Aware 的存储区域（在某个 NUMA 中来避免过多的同步、抢占开销）</strong>。如上图的 Storage Area 所示。这种情况下如果有 skew 的话，需要继续调度（在 DOP 小于切分的情况下），如红色执行流所示。</li><li>等 Scan -&gt; Filter 完成后，这里会切换到 Hash Build Phase。因为 Scan 已经完成（并 Staging），这里会预先申请好 Hash Table。这里会完成并发插入的流程。此外因为会有并发插入，所以 TUM 作者把这个 Hash Table 弄成 Lock-free 的了。后文有介绍 HashTable 的实现</li></ol><p>在两个 Scan 都够早晚 Hash Table 之后，这里就会构建 Probe Pipeline。</p><p><img src="https://image.mwish.me/blog-image/1842822139066825291.png" alt="img"></p><p>相对 volcano, 这些执行线程可能不用预先分配 dop，但是需要同步读写一些全局的（或者 numa 有关的）状态信息，因为这点，所以状态处理变得很重要。</p><h2 id="Dispatcher-Scheduling-Parallel-Pipeline-Tasks"><a href="#Dispatcher-Scheduling-Parallel-Pipeline-Tasks" class="headerlink" title="Dispatcher: Scheduling Parallel Pipeline Tasks"></a>Dispatcher: Scheduling Parallel Pipeline Tasks</h2><p>如前文所说，HyPer Pipeline 调度的时候采用了 TPC 模型。那么在调度的时候，自己这个任务 Morsel 执行完了（Morsel Boundary）可能就要处理别的代码了。这里的 Dispatcher 并不是一个线程，而是一个逻辑的概念。</p><p>这里它预期的目标是：</p><ol><li>有一定的 Locality，把任务<strong>尽量分配</strong>给本核心</li><li>能把线程资源尽量跑满（这里应该没有 Latency 相关的，因此应该考虑 Bandwidth 或者本文说的并发度就行？不过后文也有介绍一些优先级调度有关的东西。）</li><li>在 Locality 的情况下，避免过度 Skew。</li></ol><p>下图是 Dispatcher 的逻辑概念图。可以看到：</p><ol><li>Dispatcher 维护了逻辑的 (Pending) Pipeline Job 和对应 Pipeline Job 上的 <Core, Morsel>。同时这里挂的是能够执行的（.i.e Build 完之前 Probe 的任务不能挂上去）</li><li>这个框架也能包含 Intra-query 并行，比如例子中两个 Hash Build 的 Scan 都能够被加入这个队列。<ol><li>作者认为这块其实用处不是很大。因为这样估摸着你本身异构的任务也不是很多，大家不同的话，执行起来也比较容易 skew，同时这里还会影响 cache (我觉得即影响 icache 也影响 dcache)。所以感觉这个作用不是特别大。</li></ol></li></ol><p><img src="https://image.mwish.me/blog-image/1251129381962944340.png" alt="img"></p><p>在论文写作时，HyPer 并没有什么内部优先级的概念，每个查询优先级相同。（他们说 Priority 当时已经在开发了，感觉这套也已经是比较成熟的东西了）。每个 NUMA 这里也会有相关的 List ，来协助调度。当本 core 没啥 Morsel 的时候，这也会做成 work-stealing 的（作者认为这块非常不频繁），work-stealing 之后，数据丢在执行线程的 Core 上。</p><p>Dispatcher 这东西实现成额外线程也不好，所以 Dispatcher 实际上是一套静态的 code，由 worker thread 在 Morsel Boundary 执行。这里还允许 query canceling，因为 dispatcher 是个全局状态，在全局状态设置就特么行了。</p><h3 id="Morsel-Size"><a href="#Morsel-Size" class="headerlink" title="Morsel Size"></a>Morsel Size</h3><p>论文提到了个很好玩的东西：</p><blockquote><p>there is no performance penalty if a morsel does not fit into cache.</p></blockquote><p>Morsel 只是论文拆分任务的单元，和 Vectorize Batch Size 有关但并不绝对相关，一个 Morsel 甚至可以分成多个 Batch 来执行并大于 Cache-Size。所以 Morsel 大小就变成了调度的单元（当然潜台词是 Morsel 肯定要不比 Vectorize Batch 小，哈哈…）：</p><ol><li>Morsel 小会导致多次调度，影响全局调度器，增加同步次数</li><li>Morsel 大会导致 skew</li></ol><p><img src="https://image.mwish.me/blog-image/1572924691635908096.png" alt="img"></p><h2 id="Parallel-Operator-Details"><a href="#Parallel-Operator-Details" class="headerlink" title="Parallel Operator Details"></a>Parallel Operator Details</h2><p>如果需要在 Morsel 上高效执行，那么 Operator 本身也需要是一个高效的并发执行算子，它也要能接收 Batch 的数据。论文介绍了 Hash Join / Partition (Scan) / Grouping / Agg / Sorting 的对应的实现。这些实现可能是互相相关的，比如 Hash Join 本身可能和 Partition 会有关系（一些行为依赖 Scan 提供 Join 的两表的性质），会根据切分来高效的推进 Scan。</p><h3 id="Hash-Join"><a href="#Hash-Join" class="headerlink" title="Hash Join"></a>Hash Join</h3><p><img src="https://image.mwish.me/blog-image/1663940936737561721.png" alt="img"></p><p>这里 Hash Join 有几个 Point:</p><ol><li>对于哈希表，用了分离链接的方式来做 lock-free hashing。因为预先知道大小，所以能做比较好的 hash。<ol><li>利用了指针 48bits 的 trick。指针存着一个<strong>类似 1bit 的 Bloom Filter</strong> 的东西，来做一个快速 filtering。</li><li>作者认为这种方式相对 radix Join 来说有着不错的 cache locality</li></ol></li><li>这里使用 2M 的 Page 来做哈希表。这里作者认为，申请大页之后，这里会由第一个插入的线程触发真实的内存分配，这个时候，NUMA 页面会有一定的亲和度。之后插入可能也是这个线程<ol><li>笔者认为，光看这一段比较牵强，但是如果数据有很好的 Hash Partition 特性，而且和哈希表哈希方式对齐的话，可能会有一定的 locality，后面文章也提到了数据的 Partition。而在读阶段，因为是只读的，所以哈希表在 l2 cache 里就可以保证一定的高性能。</li></ol></li></ol><blockquote><p>Modern operating systems do not eagerly allocate the memory immediately, but only when a particular page is ﬁrst written to. This has two positive effects. First, there is no need to manually initialize the hash table to zero in an additional phase. Second, the table is adaptively distributed over the NUMA nodes, because the pages will be located on the same NUMA node as the thread that has ﬁrst written to that page. If many threads build the hash table, it will be pseudorandomly interleaved over all nodes. In case only threads from a single NUMA node construct the hash table, it will be located on that node – which is exactly as desired.</p></blockquote><h3 id="Partition-the-input"><a href="#Partition-the-input" class="headerlink" title="Partition the input"></a>Partition the input</h3><p>这里希望根据 <code>Hash(attrs)</code>，并选择尽量重要的（比如和 Join 有关的方式）来调度。这样能利用上一些 co-locate Join 等方式，并且能够让数据分布很均匀。</p><p>当然，作者认为这里<strong>只是一个 Hint</strong>，因为 Morsel 本身也有 work-stealing 的能力。</p><blockquote><p>It should be stressed that this co-location scheme is beneﬁcial but not decisive for the high performance of morsel-driven execution, as NUMA-locality is, in either case, guaranteed for table scans, and after the ﬁrst pipeline that materializes results NUMA locally.</p></blockquote><h3 id="Grouping-Aggregation"><a href="#Grouping-Aggregation" class="headerlink" title="Grouping/Aggregation"></a>Grouping/Aggregation</h3><p><img src="https://image.mwish.me/blog-image/6961668421561371144.png" alt="img"></p><p>这里类似 Map-Reduce 的 Shuffle 的模式，先本地做 Hash Partition（维护 thread local hash table，而不是 Join 的那种）。在 Hash Parititon （ht）重，如果满了，就 Spill 到额外的区域内（当然我猜这里也可以 Agg 直接做）。</p><p>然后在阶段二由不同线程 fetch。每个线程负责收集某个 Partition 的数据，当他收集完所有输入 Partition 的时候，会直接 Push 对应的输出给下游的 Operator （这个 Phase 不是个 Blocking 的）。</p><p>这里原理特别像 Shuffle。</p><h3 id="Sorting"><a href="#Sorting" class="headerlink" title="Sorting"></a>Sorting</h3><p><img src="https://image.mwish.me/blog-image/2400864754718694597.png" alt="img"></p><p>Local Sorting -&gt; Merge</p><h2 id="Other-cases-and-Blogs"><a href="#Other-cases-and-Blogs" class="headerlink" title="Other cases and Blogs"></a>Other cases and Blogs</h2><h3 id="Datafusion"><a href="#Datafusion" class="headerlink" title="Datafusion"></a>Datafusion</h3><p>Datafusion 自身是一个 pull-based Morsel Driven Execution 的执行模型，它的参考文档如下：</p><ol><li>Tustvold 写的 RFC <a href="https://docs.google.com/document/d/1txX60thXn1tQO1ENNT8rwfU3cXLofa7ZccnvP4jD6AA/edit?pli=1#heading=h.3iwlbn2gzs29">https://docs.google.com/document/d/1txX60thXn1tQO1ENNT8rwfU3cXLofa7ZccnvP4jD6AA/edit?pli=1#heading=h.3iwlbn2gzs29</a></li><li>一些相关的讨论：<ol><li><a href="https://github.com/apache/arrow-datafusion/issues/7000">https://github.com/apache/arrow-datafusion/issues/7000</a></li><li><a href="https://github.com/apache/arrow-datafusion/issues/7001">https://github.com/apache/arrow-datafusion/issues/7001</a></li></ol></li></ol><p>Alamb 提到一些比较有意思的思考：( <a href="https://github.com/apache/arrow-datafusion/issues/7001#issuecomment-1666569951">https://github.com/apache/arrow-datafusion/issues/7001#issuecomment-1666569951</a> )</p><blockquote><p>The <strong>claimed</strong> benefits of morsel driven parallelism of the classic approach are:</p><ol><li>Better NUMA / cache locality</li><li>Near linear scaling (so if you double core count to 32 to 64 expect to see a linear 2x speed up)</li><li>Better runtime optimization by scaling up/down cores, but I think this is less important in the real world (as you most often run out of memory long before you run out of CPU)</li></ol><p>Basically, I think it is totally reasonable for DataFusion to scale linearly to high core counts — like 128 / 256. I just need to prove that is the case and I suspect it will take some finagling with the current Repartitioning code</p></blockquote><p>(3) 是个比较额外的点。就算引入 Spill 之类的东西感觉还是会对内存造成一定的影响性。</p><h3 id="DuckDB"><a href="#DuckDB" class="headerlink" title="DuckDB"></a>DuckDB</h3><p><a href="https://github.com/duckdb/duckdb/pull/991">https://github.com/duckdb/duckdb/pull/991</a></p><p>这里提到会把 Morsel 切分成 100 vector，不知道新的版本是啥样子的</p><h3 id="TiFlash"><a href="#TiFlash" class="headerlink" title="TiFlash"></a>TiFlash</h3><p>依靠 Exchange 算子来做并行。见 <a href="http://fuzhe1989.github.io/2022/04/17/tiflash-executor-thread-model/">http://fuzhe1989.github.io/2022/04/17/tiflash-executor-thread-model/</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>VLDB&#39;11: Efficiently Compiling Efficient Query Plans for Modern Hardware</title>
      <link href="/2023/10/29/VLDB-11-Efficiently-Compiling-Efficient-Query-Plans-for-Modern-Hardware/"/>
      <url>/2023/10/29/VLDB-11-Efficiently-Compiling-Efficient-Query-Plans-for-Modern-Hardware/</url>
      
        <content type="html"><![CDATA[<p>在日新月异的db领域看一篇年代较早的论文有一些思路，要么是其实领域发展的没有那么快，比如大家搞了很多 btree 新结构的文章，但是感觉做 BTR 还是完全无法绕开 IBM的ARIES几件套，Ｇ.Gotez 的文章。要么就是给日渐复杂的模型找一个基本的出处。我刚翻15-721 的时候看他聊到 Vectorize 直接给我上 SIMD 了，心想这和 Monet/X100 的论文思路还是有区别的。不过仔细想想，可能 Vectorize 除开指令和数据有更好的局部性、避免哦了更多的 Volcano 这类的框架开销之外能够利用上的优化。</p><p>这篇论文由 TUM 在 11 年发表在 VLDB 上。本文主要贡献是 Codegen + 支持 codegen 的 Pipeline。现如今作为 ap 大内卷时代，这两项技术都在 DuckDB、ClickHouse、Velox 和无数分析数据库上跑着了。不是所有数据库都做了 Codegen，但是大家通常会实现一套 Pipeline 来做高效的调度和执行。但比较有意思的是，本文却是反过来的，为了 Codegen 而实现了 Pipeline。</p><p>从这个角度来看，在 codegen 的原点，作者的需求是：</p><ol><li>希望直接生成 Monet/X100 的论文中那种 optimal 的代码。因为是直接生成的 Typed 代码，所以也避免了框架的开销</li><li>本身 codegen 如果从上层去 pull 的执行的话，作者认为其中还是会有很多 branching 的开销的。作者认为，避免这种开销的方式就是以数据为中心实现 execution。把多个 operator 按照性质组织成 Pipeline，来进行以数据为中心的执行。</li></ol><p>当然，作者还举了个比较好玩的例子，在实现 Scan 的时候，如果有一些压缩之类的上下文，或者这样的处理方式，per-tuple 的执行可能 book-keeping 的开销会很大（感觉按他说法甚至类似于搞 streaming 解压了，不过看大部分实现可能不会这样做，都是 Page 解压然后再 Page 上读数据。但是传统 btr 在 Page 上处理 iterator 上下文也是有一定开销的）。</p><p><img src="https://image.mwish.me/blog-image/7123140944280875689.png" alt="img"></p><p>作者对 vectorize 当时的看法是：</p><blockquote><p>This materialization has other advantages like allowing for vectorized operations [2], but in general the lack of pipelining is very unfortunate as it consumes more memory bandwidth.</p><p>As shown in Figure 1, still does not reach the speed of hand-written code.</p></blockquote><p>(即本身对 memory bandwidth 依赖比较重。这个可以有一些工程优化，我保留态度)</p><p>关于为什么要做 Push-based 这套，作者的观点是：</p><ol><li>Data centric &gt; Operator centric，来保证数据 keep 在 register 中。</li><li>作者认为 pull-based execution 依赖 function call，同时，它需要提供一个 <code>next()</code> 的调用，这种调用很保持数据在寄存器中。</li><li>数据被 LLVM 转成 Native Code</li></ol><p>此外，虽然文章的 1-4 节，作者介绍的都是 per-tuple 的执行，但是在文章的第五节，作为优化项目，这里也允许框架使用 Batch 的执行来利用 SIMD 等方式来优化。</p><h2 id="执行模型"><a href="#执行模型" class="headerlink" title="执行模型"></a>执行模型</h2><p>作者首先定义了:</p><ul><li>Pipeline-breaker: 对于给定的输入，如果会从寄存器丢到内存里，这就是 pipeline breaker. 这里视把数据 spill 到内存中为一个 pipeline-breaking op</li><li>Full Pipeline breaker: 需要输入端 Materialize 所有的 input</li></ul><p>关于这里的寄存器概念定义，可以查看：</p><blockquote><p>LLVM hides the problem of register allocation by offering an unbounded number of registers (albeit in Single Static Assignment form).</p></blockquote><p>在这里，数据流成为了：</p><blockquote><p>data is always pushed from one pipeline-breaker into another pipeline-breaker</p></blockquote><p>在这里做一个讨论，作者认为 pull-based execution 不太适合保持 Tuple 在寄存器中，这是为什么呢？这里和培神交流了下，对于 pull 可能把函数写成下面的样子：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Optional<span class="operator">&lt;</span>Nullable<span class="operator">&lt;</span>T<span class="operator">&gt;&gt;</span> next();</span><br><span class="line">bool next(Nullable<span class="operator">&lt;</span>T<span class="operator">&gt;</span><span class="operator">*</span>);</span><br></pre></td></tr></table></figure><p>对于 1/2 来说，其实都很难保证数据在寄存器中：</p><ol><li><a href="https://wiki.osdev.org/System_V_ABI">https://wiki.osdev.org/System_V_ABI</a> 可能最多保证 64B 的返回可以在寄存器中。这样对于 Schema 稍微复杂一点的 Tuple</li><li><a href="https://www.reddit.com/r/cpp/comments/ilujab/it_turns_out_stdtuple_is_not_a_zerocost/?rdt=58548">https://www.reddit.com/r/cpp/comments/ilujab/it_turns_out_stdtuple_is_not_a_zerocost/?rdt=58548</a></li></ol><p>（当然，某种意义上，我觉得对于 Batch Exec 这里也不是那么重要。可能 Batch Exec 希望的是个类似的东西，就是数据全部在 L1 Cache 里头。ClickHouse 和 DuckDB 相对来说都觉得这块的流控之类的更加好做，而不是简单的 keep 数据在寄存器中。）</p><p>下面展示了一个带子查询的 SQL 和基本的执行计划：</p><p><img src="https://image.mwish.me/blog-image/4066494792601214913.png" alt="img"></p><p>这里 Figure2 -&gt; Figure3 左侧其实是比较好懂的。这里需要两次 Join，然后有一个的输入来自于子查询末端的 Group By 和 R3，另一份的输入来自于 R1 Selection 和 Join 的结果。左右关系可能来自优化器的估计（Hash Join 中，Build 侧可能希望小一些，来让内存的开销小一点）</p><p>上述的代码会被（逻辑上）处理成 Figure4 的样子。注意这里还是考虑的是串行处理的代码，对应从 Root 节点 pull 的代码结构。这样的代码在执行的时候会划分成下面四个 pipeline 的部分：</p><ol><li>从 R1 中读数据，然后 materialize (去 build)</li><li>R2 中读取 -&gt; Filter -&gt; Materialize ( Hash Agg )</li><li>从 Hash Aggregate 中再构建 Build 阶段的 Table</li><li>从 R3 推上来，先 Join (3) 再 Join (1) 的结果。这部分 Join 的处理还是很有意思的。</li></ol><p><img src="https://image.mwish.me/blog-image/7800869277960209727.png" alt="img"></p><p>编译出这样的代码是有难度的，尤其是考虑可能插入一些并发操作的时候。同时需要处理 Join 这样的结构。所有算子可以准备下面的逻辑结构：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">produce(); <span class="operator">/</span><span class="operator">/</span> 声明操作，要求你可以产生数据了</span><br><span class="line">consume(attr, data); <span class="operator">/</span><span class="operator">/</span> 表示收到了(某些 attr 的) 数据</span><br></pre></td></tr></table></figure><p>显然，我们之前看过 Acero 的代码，它也有类似的结构。</p><p><img src="https://image.mwish.me/blog-image/3440688350487090750.png" alt="img"></p><p>这里注意 Join 的 Consume 的结构。</p><h2 id="Code-Generation"><a href="#Code-Generation" class="headerlink" title="Code Generation"></a>Code Generation</h2><p><img src="https://image.mwish.me/blog-image/6313517831374343862.png" alt="img"></p><p>作者使用 LLVM 连接 C++ 代码，并不适用直接生成汇编的方式，如图6，C++的“齿轮”是预编译的；只有用于组合它们的LLVM“链条”是动态生成的。这样可以实现非常低的查询编译时间。直接编译 C++ 代码则要耗费数秒的时间。</p><p>有些代码比如 Sort 之类的相对复杂，LLVM 这里是用胶水把它们连接起来。然后主要编写 C++ 代码。</p><blockquote><p>While staying in LLVM, we can keep the tuples in CPU registers all the time, which is about as fast as we can expect to be. When calling an external function all registers have to be spilled to memory, which is somewhat expensive. In absolute terms it is very cheap, of course, as the registers will be spilled on the stack, which is usually in cache, but if this is done millions of times it becomes noticeable.</p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ATC&#39;19: EROFS</title>
      <link href="/2023/10/22/ATC-19-EROFS/"/>
      <url>/2023/10/22/ATC-19-EROFS/</url>
      
        <content type="html"><![CDATA[<p>之前看到培神在群里转华为贡献的 EROFS 可能进安卓主线并作为默认只读文件系统，不仅对这一贡献比较感兴趣，遂把论文拉出来读了一遍。文章作者来自华为和 SJTU iPads，内容还是比较清晰的，描述了它们怎么优化只读文件系统的，它们的贡献大概有：</p><ol><li>利用 LZ4 来把输入块压缩成<strong>固定大小的块输出</strong> BLOCK 存储在块存储设备上</li><li>利用巧妙的技巧，来优化解压缩的开销。作者认为这块的开销有两个方面：文件大小的放大、解压缩需要的的内存开销（见后文图）<ol><li>文章把 compressed block 分成了两种模式：cached io 和 in-place io。</li><li>用多种方法来优化解压缩，包括直接把用户内存映射到解压缩对应的 Page、跳过不需要解压缩的多余数据</li></ol></li></ol><p>本文只代表 19 ATC 发表的状况，听说 2023 年 Linux 主线代码和这个有点变化，而且作者目前还在维护这套系统。感兴趣的可以翻翻 maillist 来得知最新的情况。</p><h2 id="背景和相关系统介绍"><a href="#背景和相关系统介绍" class="headerlink" title="背景和相关系统介绍"></a>背景和相关系统介绍</h2><p>EROFS 是一个<strong>只读的压缩文件系统</strong>。而安卓本身代码也使用了 Linux Kernel 部分的一些代码[3]. 本身 Linux 上很多地方就是放只读文件的，比如系统的 <code>/system</code> 之类的 read-only space. 那么根据论文的作者所说，实际上安卓的系统文件大小本身是挺大的，在 android 9 上面增长到了 1.9 GB。如下图</p><p>（Sparse Image 和 Raw Image 是镜像的不同格式，见 [4] ）</p><p><img src="https://image.mwish.me/blog-image/5632958259247473078.png" alt="img"></p><ol><li>Btrfs 这种 fs 对压缩并没有那么友好，它会把数据切分成多个 128KB 的 Chunk，然后独立压缩，把这些数据存放在不同的 Extent 中，这些 Extent 的位置会存放在一个 Btree 索引上。需要读取的时候这里需要 decompress 整个 column chunk. 然后去处理. Btrfs 是可以更新的，但是更新和重写整个 chunk 差不多了，还要额外更新一下 index。</li><li>而 SquashFs 是一个已存在的压缩只读文件系统，但是这个系统会带来不少 overhead，有的是设计层面的，有的是实现层面的，见下图：</li></ol><p><img src="https://image.mwish.me/blog-image/1637353494132474512.png" alt="img"></p><p>Squashfs 支持配置<strong>输入 block-size</strong>，然后把这些压缩到输出然后分配到磁盘的 Block 上。也支持配置一些算法。在 Squashfs 上，也需要一些元数据（比如压缩前后的映射）。压缩后的大小存储在 inode 中的列表上。</p><p>从文章的实验角度看，这些设备的压缩率其实是很高的。这导致：</p><ol><li>每次会多读一些磁盘 IO 的数据（这个是设计角度导致的，比如压缩后的块和磁盘 size 不对齐）</li><li>解压缩需要申请 uncompressed 的块大小的临时内存。本来盘大小就小于内存了，你这资源开销更大了…这些内存在现在还没多大内存的机器上操作还会加剧 swapping。</li></ol><p>作者认为，Squashfs 设计有下列核心问题：</p><ol><li>Fixed-sized input compression: 这种方式对小 io 带来了比较大的读放大和内存放大，如果全要读倒还好，但是对于小 io，比方说要读取第一个 block，然后磁盘上可能没对齐的 BLOCK 都给读了，然后又要准备解压缩空间，因为你也不知道这些东西每个用户层面的读要的数据在哪块. 当配置成 4KB 的输入块的时候，上述问题会被改善，但是压缩的 batch-size 又太小了，导致白压缩了。</li><li>数据拷贝的开销。这部分上面的图写的非常清晰，这里读的 buffer-&gt;解压块 -&gt; 用户内存。每部分都引入了一定的开销。这部分我感觉一定程度上也是实现问题了。不知道 block-size 和设计感觉和这个的影响没有那么直接。主要是工程化的时候怎么在内核上支持这些需求。在实现上的时候，squashfs 实现如下<ol><li>拿到 compressed block 的数量</li><li>给每个 compressed block 申请内存。然后 issue io 把它们读起来。这里可能会有个 io page 池，这个池是预先申请的，给 io 对应的需求使用</li><li>拷贝到 temp input buffer，这里需要一个连续的空间，然后解压到 temp output buffer. 作者认为，这里的主要瓶颈还是 memory access 而不是 CPU</li><li>给用户的 page cache 拷贝</li></ol></li></ol><p>作者认为，优化空间在于：</p><ol><li>减少 io</li><li>减少内存申请</li></ol><h2 id="EROFS"><a href="#EROFS" class="headerlink" title="EROFS"></a>EROFS</h2><h3 id="Fixed-size-output-compression"><a href="#Fixed-size-output-compression" class="headerlink" title="Fixed-size output compression"></a>Fixed-size output compression</h3><p>作者认为，一部分问题来源于 Fixed-size input 的不够 flexible，所以他们使用的策略是 fixed-sized output (这块其实我也没有百分百被说服，因为感觉是有 trade-off 的，在同样压缩率的情况下，这里保证了对下层 block 的 io 是对齐的，但是本身 decompress 中的各种放大还是存在的。）</p><p><img src="https://image.mwish.me/blog-image/2120385008114742494.png" alt="img"></p><p>具体方法上，EROFS 采用了 LZ4 的方式，在 <code>&#123;输入大小到达 1MB, 输出大小到达4k&#125;</code> 两个条件任意满足一个就会切下面的 BLOCK。如果是输入大小为1MB可能也会准备一个 4K 的块。这个增加了压缩率的上限（毕竟原来128KB一压）。2(c) 就是压缩的一个图例。作者认为这样有如下有点：</p><ol><li>最大压缩率更好（我认为这个取决于输入吧 orz）</li><li>在解压缩的时候，io 控制的比较好。作者也通过一些 hack 的方式让解压缩尽量解压少的空间<ol><li>作者认为只有对应的压缩数据会被解压，我觉得没差把。我感觉一个隐含条件就是这堆东西压缩率很高，压缩率低的条件下文章提到的很多东西都比较扯。。。这样对于小碎读有一定优化，比如小碎读最多引入两个 Physical Page IO. (<strong>不过看文章领悟了一下，应该这里 fs 层也是 Page-Level IO</strong>，原则上 fs 上层读一个 Page 下头确实最多读两个物理 Page）。</li></ol></li><li>使得后文提到的 in-place compression 成为可能。</li></ol><h3 id="Input-Buffer-Handling-Cached-I-O-and-io-place-I-O"><a href="#Input-Buffer-Handling-Cached-I-O-and-io-place-I-O" class="headerlink" title="Input Buffer Handling: Cached I/O and io-place I/O"></a>Input Buffer Handling: Cached I/O and io-place I/O</h3><p><img src="https://image.mwish.me/blog-image/8349381289810421741.png" alt="img"></p><ol><li>Cached I/O: 如果要 partial read 某个 block<ol><li>使用一块 inode 区域来存储状态，数据被 fetch 到一个额外的 page cache 中。</li><li>作者认为这种小块读可能是连续的，所以可能会 cache 一会儿，后面读到了后面的区段可以避免反复解压（这段有点抽象，可以看后面的 decompression 一节）。</li></ol></li><li>In-place I/O: 比较 hack，包含一些核心优化，给一些需要 decompressed 的 Page 准备的。这里认为大块读不会被反复请求，所以把 page 放到<strong>连续的解压缩 Buffer 的尾部</strong></li></ol><p>（这段有点抽象，可以看后面的 decompression 一节，配合理解）</p><h3 id="Decompression"><a href="#Decompression" class="headerlink" title="Decompression"></a>Decompression</h3><p><img src="https://image.mwish.me/blog-image/8833660903331583403.png" alt="img"></p><p>如上图，假设现在用户需要 D4/D6 ，这里需要看看 Cache-IO 怎么处理</p><p><img src="https://image.mwish.me/blog-image/5182527977773199469.png" alt="img"></p><p>如上 (b)，这里 EROFS 只需要 D3 D4，所以它：</p><ol><li>发起两个 Page 的物理 io</li><li>准备一些 temporary page 给 D0-D2，因为 和 需要 mapping 的 Page 不一样，这些暂时不需要，然后直接解压，然后 D3 D4 解压的用 <code>vmap</code> 映射好丢给用户层</li></ol><p>如果是 in-place I/O，<strong>那么如同 (d)</strong>，这里 C0 会被放到尾部，然后直接解压完。</p><p>这里还有几个工程优化：</p><ol><li>小页面用 Per-CPU buffer decompression。因为很多小页面解压，EROFS 禁止了切换（在第五节介绍的）然后切成 per-cpu 的小页面解压，这里再解压缩页面小于 4个 page 的时候才会使用，例如 3(c). 当然这里也需要拷贝出去了</li><li>Rolling decompression: 为了避免不需要的内存申请太多，这里会每个 CPU 准备 16 个 Physical Pages，然后滚动 decompress</li></ol><p><img src="https://image.mwish.me/blog-image/4188107683917911099.png" alt="img"></p><p>此外，如果当 figure5 这种场景出现的时候，也会使用临时的 Per-cpu页面。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.usenix.org/system/files/atc19-gao.pdf">https://www.usenix.org/system/files/atc19-gao.pdf</a></li><li><a href="https://www.usenix.org/conference/atc19/presentation/gao">https://www.usenix.org/conference/atc19/presentation/gao</a> (Presentation)</li><li><a href="https://www.androidauthority.com/android-linux-784964/">https://www.androidauthority.com/android-linux-784964/</a></li><li><a href="https://wiki.archlinux.org/title/sparse_file">https://wiki.archlinux.org/title/sparse_file</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>VLDB&#39;23: Query Partition in Napa</title>
      <link href="/2023/09/08/VLDB-23-Query-Partition-in-Napa/"/>
      <url>/2023/09/08/VLDB-23-Query-Partition-in-Napa/</url>
      
        <content type="html"><![CDATA[<p>Google 在 VLDB’21 年发表了 Napa 的论文： Napa: Powering Scalable Data Warehousing with Robust Query Performance at Google。Napa 本身定位是一个对 MV 支持很好的数仓，它用 LSM 来存储对应的内容，读查询通常是 Scan 和 Multi-key Lookup（下面是 Multi-key Lookup 的一个例子，感觉是很 ads 的需求）。</p><p>在查询延时上，Napa 的需求比较高，通常它需要在压秒级的时间内完成一些查询。在数据上，Napa 有数百个 databases，其中有数千个 Table 和 MV.有些表大小甚至到达了几 PB。这些表也会被上游流系统很频繁的更新。用户希望数据有一定的实时性。为了满足这个需求，Napa 实现了 LSM-Tree 和基于 LSM 的 MV 维护引擎。</p><p><img src="https://image.mwish.me/blog-image/5678331180122730692.png" alt="img"></p><p>上述 Figure1 例子中，Napa 以 <code>K1, K2, K3</code> 为主键，并按照 <code>K..</code> 排序。这里主要需求是对这一组查询（<code>K1, K2</code> 的前缀 key）采取并行查询，通过打大并发降低对应的延迟。</p><p>这里有一些比较重要的部分：</p><ol><li>Query-specific partition: 根据查询生成对应的并发度和 Partition，来 match 对应的 SLO</li><li>Evenness: Partition 需要能够处理 skew 的情况，e.g. Figure1 中 <code>&lt;K1 = 1, K2 = 20&gt;</code> 数据可能有几百 GB</li><li>Progressiveness: 这个有点类似 Planner(但我其实不太懂，我理解是有点像，但也可能根本不一样)。算出一个 Perfect 的 Partition 是很费时间的，只要算出来预估差不多满足 SLO 需求就可以停手去执行了。所以这个算法是渐进式的。</li></ol><p>在本论文之前也有很多 database partition 的需求，包括 write-time partition(主动 partition, compaction, snowflake 风格的 micro-partition) 和查询并行. 作者认为这里解决的问题不完全一样（但我觉得肯定可以整合到一起），假如用 Partition 的方式解决并行问题的话：</p><ol><li>Partition Unit 小的话， Metadata 维护开销很大，访问 metadata 的 latency 会增加</li><li>Partition Unit 大的话，如果按照 Partition 来并行的话，可能读数据的 latency 下不去</li></ol><p>论文中实验也表明，用太细的东西做 plan 的话，这部分 planning 开销也会升高。这部分 Napa 和 Btree 结合起来了，它的 LSM Sorted Run 本身是个 DataBlocks + Btree (看着像是用 Btree 组织了一组 SST，类似 Kudu 的 Block 存储，会根据 Btree 来组织，见 <a href="https://github.com/apache/kudu/blob/master/docs/design-docs/tablet.md#handling-mutations-against-on-disk-files">https://github.com/apache/kudu/blob/master/docs/design-docs/tablet.md#handling-mutations-against-on-disk-files</a> 。RocksDB 的 Index 也大概是这种方式组织的)，每层有一些统计信息，越上面越粗略。Napa 通过这种方式来做切分。如果 Btree 上层节点足够了就用上层的，上层切不出来或者不够详细就要访问 Btree 下层。(之前在 bg 好像搞过类似的，不过它这里好处还是 immutable + 和统计结合)</p><h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a><strong>相关工作</strong></h2><p>并行处理的主要工作基本上是并行化 SQL + SIMD 模型来查询。早期的批处理工作类似 Map Reduce 一个 idea 就是切分输入并并行。</p><p>在数据库迁移到云上或者做大规模处理的时候，流行的方式是对 Key 做 {Hash/Range} Partition。这种方式也允许用户做 Collocate Join，并且能够尽量避免 distributed transaction （ For OLTP workloads, graph-based [6, 20] and skew-aware [19] partitioning approaches have been developed to minimize the number of distributed transactions. ）。这种方式倾向于写时维护 Partition（废话，TP 分布式事务或者多走了一轮开销大是这样的）</p><p>在查询的时候做 Partition 没有那么直接的工作，比较接近的工作是 database cracking。本作准备用 RL 糊屎来解决不同用户的输入。</p><h2 id="Napa"><a href="#Napa" class="headerlink" title="Napa"></a><strong>Napa</strong></h2><p>Napa 吹了一下自己系统几个需求：</p><ol><li>Robust Query Performance: 亚秒级响应，adhoc 查询</li><li>System Flexibility: Napa 的性能三角，允许拿钱之类的换 freshness</li><li>High-throughput Data Ingestion: Napa 会有很大的写入量</li></ol><p>Napa 的每个 Delta Set 相当于 LSM 的 Sorted Run，它们会被组织成 btree。每个 Delta 的 Btree 内部是没有 MVCC 的（不像 RocksDB 可能会把同一份数据 Duplicate 不同时间戳的多次操作）。为了支持 Statistics 的需求，这里会设计每层的 Statistics，父亲级别 Agg 子层级的统计信息。</p><h2 id="建模"><a href="#建模" class="headerlink" title="建模"></a><strong>建模</strong></h2><h3 id="LSM"><a href="#LSM" class="headerlink" title="LSM"></a><strong>LSM</strong></h3><p>在 napa 中，每个文件是 immutable 的，在 napa 的设计中叫做 Delta。对应格式是一个 btree，对应 napa 中的一个时间范围，<strong>和文件的 indexes</strong>。Napa 采用了 Tiered Compaction 的形式（话说之前看 G.Goetz 的简历上说他现在还在维护 napa 的 compaction），它时间戳和 Compaction 逻辑维护形式<strong>有点类似于 ClickHouse</strong>，文件落到 Napa 的时候拿到一个统一的时间戳（<code>[T1, T1]</code>)，Compaction 的时候产生新的时间戳 Range(<code>[T1, T3]</code>)。</p><p>当 Table 存在 unique key 或者 primary key 的时候，这里需要做读的时候 dedup (类似 Hudi MOR）。Napa 似乎不会对系统做假定(类似 Hudi 不假定前面是 MOR 还是 COW？）。</p><p>作者认为 LSM 增加了 Query Partition 的复杂度。主要还是因为它不是 btr 那样单层的模型，一个 key 可能存在多处。这也给查询 evenness 的估计带来了一定的复杂度。最后一点是，不同层的 Sorted Run 可能因为数据分布不同，在它们上面 Plan Partition 的难度也不同。</p><h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><p><img src="https://image.mwish.me/blog-image/4965052238396183469.png" alt="img"></p><p>Napa 有一些单机的 scan worker ：</p><ul><li>能够执行：Selection, projection, partial (local) agg</li><li>输出可以是别的 downstream，可能会被 full agg, sort, join 之类的消费对应的计算</li></ul><p>Napa 的查询优化器会尽量按照 PK 把用户的 Predicates 做成前缀（感觉有 pk 的表大家都这么搞的，但是这里有点类似 PG，<code>&lt;pk1, pk2...&gt;</code> 里面，即使只有 <code>pk2 == ...</code>, 它也会尝试构建 Prefix），在上述查询中有下列的 transform。</p><p><img src="https://image.mwish.me/blog-image/2987111351221671228.png" alt="img"></p><p>在做 Partition 的时候，因为 filter selectivity 的不同，scan worker 配置的资源不一样，所以查询的时候 partition 的情况也不同（这里大概可以理解成，论文里的 size 是原始数据的大小，应该不是 filter 之后的大小）。所以最佳的 partition unit size 可能从 10MB - 1GB。此外还有个问题是查询的 skew。Napa 对于 <code>&lt;c, d&gt;</code> 这种表，当 <code>d = d3</code> 的时候，构建的前缀可能覆盖了整张表的大部分空间（那你就别这么搞啊…）这也表明，Partition 规划需要是渐进式的，能够防止构建的粒度过细。</p><p>Napa 认为 write-time partition 并不好处理这种 case，主要原因还是它：</p><ol><li>写的时候切的太细的话或者太粗的话，读者需求都不一定完全满足。毕竟都是 adhoc query 和不同的资源在到处飘</li><li>Hash Cluster 之类的情况不太能处理 skew 或者 <code>d = d3</code> 这种查询。可能导致 Partition 规划的开销高，算起来还因为 Partition skew 性能不太好。</li></ol><p>然后 G+ 的人不装了，扯了这么久才介绍自己的需求:</p><blockquote><p>Note by this example, we have established that partitioning is highly specific to query under consideration and existing writetime partitioning is inadequate for workloads with a wide spectrum of query workloads</p></blockquote><p>总之 G+ 的人是想要在 PROGRESSIVE PARTITIONING 中发掘 Partition 的需求，渐渐发现「Plan Partition 快、查询也满足 SLO」的真相</p><h2 id="Progressive-Parititoning"><a href="#Progressive-Parititoning" class="headerlink" title="Progressive Parititoning"></a>Progressive Parititoning</h2><p>那么，Napa 已经有：</p><ol><li>每个 Delta 有一个 B-tree, 维护指向每个 PAX layout Block 的 size 等 Statistics</li><li>一定数量的 scan workers, 和从 workers + QoS 可以推断的目标 Partition 数量 P</li><li>margin ratio: theta, 用于控制衡量 Partition 的结果，表明预估的大小和实际分片大小可能的偏差。算法的预期是随着运行让这个误差尽量小。满足预期的时候，算法推出</li></ol><p>算法的预期是：</p><ul><li>给定查询 Q，算法能够切分 D 组 Deltas 成为 P 个 key-range Partition, error margin 对应是 theta</li><li>预期大小 == 根据 Btree Indices 的大小和 combine-key 来推断</li></ul><p>Figure 4-5 演示了算法工作的流程。Figure 4 展示了有四个 Delta 的表中，当 P = 2 的时候，查询 K1-K8 时候的切分。在 Figure4 可以看到，Delta#1 查询 btree 深度更大，而 Delta#2 更早停下了。因为算法认为达到了 error margin ratio。当然这个算法也可以往下切，<strong>你可以理解成这里的访问是一个 stack 或者 wave，认为某个地方可以切细，就可以访问子节点</strong>。</p><p>Figure 5 展示了具体切分的效果，这里如果按照估计，总大小上限是 70，假如按照 Figure 5，算法在 K4-K5 之间切分，那么根据算法可以算出每个 Partition 的 min-max 大小。如 Figure5.</p><p><img src="https://image.mwish.me/blog-image/9198748789641734866.png" alt="img"></p><p><img src="https://image.mwish.me/blog-image/648885662659901694.png" alt="img"></p><p>Margin Ratio 可以按照 <code>(Max - Min ) * 2 /  (Max + Min)</code> 来计算。如果两个 Partition 比率合理，那么 theta 被视为足够好了，否则算法会访问 btree 的深层来捞统计信息。比如把 <code>[K4, K8]</code> 索引再探深一层（Napa 称这种操作为 Drill Down）</p><p>Drill Down 只是部分的</p><blockquote><p>Note that we only need to drill down entries contributing to the error margin. The other entries are kept in the working set (called the set) without matching entry drill down.</p></blockquote><p>但我不知道这个 Contribute 是怎么判定的。。。Margin Ratio 大小合适度又是怎么判定的。。。这些都会在算法细节部分介绍！未完待续！</p><h3 id="算法细节"><a href="#算法细节" class="headerlink" title="算法细节"></a>算法细节</h3><p>假定 Delta 为 <script type="math/tex">\{1, ..., D\}</script>，第 i 个查询为 <script type="math/tex">d_{i}</script>。给定查询 Q， <script type="math/tex">d_{i}</script>中满足要求的条目称为 mathing entry set <script type="math/tex">E_{i}</script>. 那么在查询中也可以找到一组满足要求的 <script type="math/tex">\{E_{1}, E_{2}, ..., E_{D}\}</script>。对于每个 B-tree 节点，这里可以找到子条目 <script type="math/tex">e_{i}</script>和 <script type="math/tex">e_{i+1}</script>，每个条目的 size 等级于自己子部分内容的 size 和。它的统计信息可以简化为 <code>e = &lt;start, end, size, level, block&gt;</code>，<code>[start, end)</code> 代表 key-range. <code>level</code> 代表可以 dive 的层数（我理解层数应该是 hidden 的，不用存，只是个抽象?），<code>e.block</code> 是 child index block 的数量。</p><p>算法会逐渐推进，从一个 (virtual) root entry 扩展开来，每次到一层可以更新一批 matching entry set，相当于通过 IO （和部分 CPU 与维护成本）来提供更精细的统计。这里提供的内容基本上是 <strong>maximum size estimate</strong>。这个精细化的过程就是 DrillDown：</p><p><img src="https://image.mwish.me/blog-image/3125270644515696735.png" alt="img"></p><p>DrillDown 本身可能引入 IO（老实说我感觉 btr 这个东西本身就很容易缓存，但是这种大规模查询可能缓存命中率也做不到很高，具体得测测或者结合 RocksDB Index 的经验看看）。所以这里可能会 Batch 访问下层来优化（说实话我真不懂这了。。。虽然我看着懂他的意思，但是脑部不出为啥要这么写）</p><h4 id="Split-point-candidates"><a href="#Split-point-candidates" class="headerlink" title="Split point candidates"></a>Split point candidates</h4><p>下面是到一组 Entry Sets  <script type="math/tex">\{E_{1}, E_{2}, ..., E_{D}\}</script>里面寻找<strong>所有的 bonadry-key</strong> <script type="math/tex">\{k_{1}, k_{2}, ..., k_{m}\}</script>和对应的 cumulative 大小和<script type="math/tex">\{c_{1}, c_{2}, ..., c_{m}\}</script>. 这里希望这里面的切分能够尽量均匀. 在这里 <script type="math/tex">k_{i}</script>和下一个 key 中间的某个 key 被称为 i split point candidate 。选作中间某个 key 是一个 <strong>short-key 优化</strong>（类似处理 min-max 过长时候的优化<strong>）。</strong></p><p><script type="math/tex">c_{i}</script>实现上有点类似 DP，会选取&lt;从零到这个这个key 的 size可能的最小&gt;和&lt;从零到这个这个key 的 size可能的最大&gt;。这个说法有点抽象，截图论文了</p><p><img src="https://image.mwish.me/blog-image/6275015760304340221.png" alt="img"></p><p>下面是具体的参数：</p><p><img src="https://image.mwish.me/blog-image/2872769688922876604.png" alt="img"></p><p>通过这个粗糙的计算 size 和错误率。这个问题等价于在所有 m 个 key 中切出 P 个 Paritition（P-1 个 split point）。</p><p>下面是找到具体的 split point。本质上是一个 uniform partition 算法。算法的目标是，给定<script type="math/tex">\{c_{1}, c_{2}, ..., c_{m}\}</script>计算<script type="math/tex">\{s_{1}, s_{2}, ..., s_{p-1}\}</script>.因为这里有一个总大小（相当于最后一个 <script type="math/tex">c_{m}</script>的 max），所以根据总大小能推断出每个 Partition 的推荐大小。然后扫出一组 Partition，他这里算法我没看懂，复杂度如下</p><p><img src="https://image.mwish.me/blog-image/1296285521936491971.png" alt="img"></p><p>然后这里再次计算 <script type="math/tex">\{s_{1}, s_{2}, ..., s_{p-1}\}</script> 是否足够好了，下面挑选出对应的不合法集合：</p><p><img src="https://image.mwish.me/blog-image/1850538063534972728.png" alt="img"></p><p>这里根据不合法的集合尝试找到需要 dive 的 entry</p><p><img src="https://image.mwish.me/blog-image/6739283094117746993.png" alt="img"></p><p>可以看到，entry 是针对 key 而言的，这里可以针对 key 找到一组对应的需要切的 entry，然后尝试切一下。（论文描述了两种切分方法）</p><p><img src="https://image.mwish.me/blog-image/210579796710822954.png" alt="img"></p><p>组合起来算法如下：</p><p><img src="https://image.mwish.me/blog-image/140444377129215087.png" alt="img"></p><p>工程上这里有一些优化：</p><ol><li>允许用户设置 dop，但是每个 dop 有最小大小限制，用户可能瞎几把设，不能搞太细</li><li>允许根据 Scan 的 size 来估计，而不是根据 dop 来估计。因为可能 scan size 对于查询估计来说是个更好的东西</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>翻译: It’s not always obvious when tail-call optimization is allowed</title>
      <link href="/2023/09/05/It%E2%80%99s-not-always-obvious-when-tail-call-optimization-is-allowed/"/>
      <url>/2023/09/05/It%E2%80%99s-not-always-obvious-when-tail-call-optimization-is-allowed/</url>
      
        <content type="html"><![CDATA[<p>原文链接：<a href="https://quuxplusone.github.io/blog/2021/01/09/tail-call-optimization/">https://quuxplusone.github.io/blog/2021/01/09/tail-call-optimization/</a></p><p>翻译许可：</p><p><img src="https://image.mwish.me/blog-image/311401252216574504.png" alt="img"></p><p>我最初本文作为 <a href="https://quuxplusone.github.io/blog/2019/08/02/the-tough-guide-to-cpp-acronyms/">“A C++ acronym glossary”</a> (2019-08-02) 中的一部分编写，但决定最好将其单独列出来放到一个博客中。</p><p>“TCO”代表“tail call optimization”。 这是一种编译器优化，它将代码中的函数调用（通常会向栈上 push frame）并将其转换为 jump 指令（不会将新的 frame push 到栈上）。 只有 <code>return bar()</code> 这样在函数为尾部发生调用的时候，编译器可能会采用这种优化： 编译器说：“看，我知道 <code>bar</code> 执行完就返回给调用者，就是 <code>return bar()</code> 的这个函数了，让我们直接在本函数的 <code>caller</code> 处调用 <code>bar()</code>”！</p><p>Tail call optimization 通常可以用于 <code>return bar()</code> 这种形式，但不能用于 <code>return bar()+1</code>。</p><p>在 C++ 中，编程者很难准确地弄清楚哪里允许发生 TCO。 主要原因是 non-trivial destructors:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo1</span><span class="params">()</span> </span>&#123; <span class="built_in">bar</span>(); &#125;  <span class="comment">// tail call</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo2</span><span class="params">()</span> </span>&#123; <span class="function">std::lock_guard <span class="title">lk</span><span class="params">(m)</span></span>; <span class="built_in">bar</span>(); &#125;  <span class="comment">// not a tail call</span></span><br></pre></td></tr></table></figure><p>这也包含 temporary objects 的析构：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">bar</span><span class="params">(std::string_view)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo1</span><span class="params">()</span> </span>&#123; <span class="built_in">bar</span>(<span class="string">&quot;hello&quot;</span>); &#125;  <span class="comment">// tail call</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo2</span><span class="params">()</span> </span>&#123; <span class="built_in">bar</span>(<span class="string">&quot;hello&quot;</span>s); &#125;  <span class="comment">// not a tail call</span></span><br></pre></td></tr></table></figure><p>但即使这里所有东西都是 trivially destructible 的，您也可能因为需要 stack pointer 或其他东西，导致阻止发生 TCO 。<a href="https://godbolt.org/z/vcY3v9">https://godbolt.org/z/vcY3v9</a> ：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">bar</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">escape</span><span class="params">(<span class="type">const</span> <span class="type">int</span>&amp;)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo1</span><span class="params">()</span> </span>&#123; <span class="built_in">escape</span>(<span class="number">42</span>); <span class="built_in">bar</span>(); &#125;  <span class="comment">// tail-call on GCC and MSVC</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">foo2</span><span class="params">()</span> </span>&#123; <span class="type">const</span> <span class="type">int</span> i = <span class="number">42</span>; <span class="built_in">escape</span>(i); <span class="built_in">bar</span>(); &#125;  <span class="comment">// not a tail-call</span></span><br></pre></td></tr></table></figure><p>有趣的是，在上面的示例中，GCC 和 MSVC 为 <code>foo1</code> 生成 <code>jmp bar</code>，但 Clang 和 ICC 没有该优化。</p><p><img src="https://image.mwish.me/blog-image/9002952926214148686.png" alt="img"></p><p>您可能会合理地问为什么我们不能对 <code>foo2</code> 进行相同的优化。 我认为原因是 C++ 保证每个变量（在其生命周期内）都有一个唯一的地址。 如果我们要像这样实现 <code>bar</code>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> *addr_of_i;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">escape</span><span class="params">(<span class="type">const</span> <span class="type">int</span>&amp; i)</span> </span>&#123;</span><br><span class="line">    addr_of_i = &amp;i;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">bar</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> j;</span><br><span class="line">    <span class="built_in">assert</span>(&amp;j != addr_of_i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么程序可以判断该实现是否（不符合规定）将 <code>j</code> 放入与 <code>i</code> 相同的内存位置。 然而，没有规则规定 <code>j</code>不能与 <code>42</code> 生成的临时对象共享内存位置，因为该临时对象的生命周期与 <code>j</code> 的生命周期不重叠。</p><p>一个实现是否执行 TCO 是可以观察到的，因为从某种意义上说，tail-recursive 函数在使用 TCO 时可能使用 <code>O(1)</code> 的栈空间，但在不使用 TCO 时使用 O(n) 的栈空间——因此，当递归足够深时，会“爆破堆栈” （stack overflow）。 然而，C++ 的抽象机实际上并没有任何「爆破堆栈」的概念。 C++ 程序没有一致的方法来检测或处理该情况。</p><blockquote><p>原文：However, C++’s abstract machine doesn’t really have any notion of blowing the stack. There’s no conforming way for a C++ program to detect that condition or deal with it.  不确定翻译对了…</p></blockquote><p>因此，足够偏执的 C++ 代码合作者将避免非常深的递归。 执行此操作的一种技术是手动进行 tail-recursion optimization：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">gcd</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (x == <span class="number">0</span>) <span class="keyword">return</span> y;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">gcd</span>(y % x, x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>改写为:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">gcd</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> </span>&#123;</span><br><span class="line">top:</span><br><span class="line">    <span class="keyword">if</span> (x == <span class="number">0</span>) <span class="keyword">return</span> y;</span><br><span class="line">    std::<span class="built_in">tie</span>(x, y) = std::<span class="built_in">tuple</span>(y % x, x);</span><br><span class="line">    <span class="keyword">goto</span> top;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>并改写成</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">gcd</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (x != <span class="number">0</span>) &#123;</span><br><span class="line">        std::<span class="built_in">tie</span>(x, y) = std::<span class="built_in">tuple</span>(y % x, x);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行最后一步通常非常重要，这不仅因为这种方式（ <a href="https://en.wikipedia.org/wiki/Structured_programming">https://en.wikipedia.org/wiki/Structured_programming</a> ）使代码更易读，还因为 goto 是极少数阻止将函数标记为 constexpr 的 C++ 结构之一 （见 <a href="https://stackoverflow.com/questions/45266577/why-disallow-goto-in-constexpr-functions">https://stackoverflow.com/questions/45266577/why-disallow-goto-in-constexpr-functions</a> ）。 如果您希望函数为 constexpr（无论出于何种原因），则必须避免 goto。 这是 C++ 在风格上固执己见的罕见情况。</p><p>(如果你没有见过 <code>tie = tuple</code> trick , 你可能会喜欢我在 CppCon 2020 上的演讲 <a href="https://www.youtube.com/watch?v=OJzmWqCCZaM">“Back to Basics: Algebraic Data Types.”</a>.)</p><p><em>Posted 2021-01-09</em></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Arrow util: File &amp; FileSystem</title>
      <link href="/2023/08/21/Arrow-util-File-FileSystem/"/>
      <url>/2023/08/21/Arrow-util-File-FileSystem/</url>
      
        <content type="html"><![CDATA[<p>FileSystem 可以看作 Arrow 的数据访问层（不太像 fs，而是一个虚拟的文件系统）。只不过它兼容的不是 POSIX 语义，而是自己在上面封了一套各种接口。具体可以看：</p><ul><li><a href="https://arrow.apache.org/docs/cpp/api/filesystem.html">https://arrow.apache.org/docs/cpp/api/filesystem.html</a></li><li><a href="https://arrow.apache.org/docs/cpp/api/io.html">https://arrow.apache.org/docs/cpp/api/io.html</a></li></ul><p>相关目录在：</p><ul><li><code>cpp/src/io/interface.h</code>: 包含 file 本身部分接口、IO 的接口和所有的接口</li><li><code>cpp/src/io/file.h</code>: 包含 file 本身部分接口、IO 的接口和所有的接口</li><li><code>cpp/src/arrow/filesystem</code>: 包含 fs 部分实现和所有的接口<ul><li><code>hdfs.h</code> 下有个 <code>arrow::io::FileSystem</code>，这不是一套东西.</li></ul></li></ul><h2 id="FileSystem"><a href="#FileSystem" class="headerlink" title="FileSystem"></a>FileSystem</h2><p>FileSystem 这层抽象能够辨别出一个类似文件的语义，它的概念没有下层到 FS/VFS/Node 这样的层面。我个人理解，它对应的语义是：文件/目录 的 带规则的 List / Open / Delete / Create / GetInfo，其中还包含 Copy / Move(Rename) 这样的语义。同时提供了一些 async 或者类似 Batch 的接口。</p><p>FileSystem 这里有一些下面的子类：</p><blockquote><p>Subclassed by <a href="https://arrow.apache.org/docs/cpp/api/filesystem.html#classarrow_1_1fs_1_1_gcs_file_system">arrow::fs::GcsFileSystem</a>, <a href="https://arrow.apache.org/docs/cpp/api/filesystem.html#classarrow_1_1fs_1_1_hadoop_file_system">arrow::fs::HadoopFileSystem</a>, arrow::fs::internal::MockFileSystem, <a href="https://arrow.apache.org/docs/cpp/api/filesystem.html#classarrow_1_1fs_1_1_local_file_system">arrow::fs::LocalFileSystem</a>, <a href="https://arrow.apache.org/docs/cpp/api/filesystem.html#classarrow_1_1fs_1_1_s3_file_system">arrow::fs::S3FileSystem</a>, arrow::fs::SlowFileSystem, <a href="https://arrow.apache.org/docs/cpp/api/filesystem.html#classarrow_1_1fs_1_1_sub_tree_file_system">arrow::fs::SubTreeFileSystem</a></p></blockquote><p>Local, S3, GCS, Hadoop 这几个虽然各有各的优化，但是一看名字你就懂他们是些啥。我们额外解释一下几个别的 FS:</p><ul><li><code>SlowFileSystem</code> 注入延时，是给测试用的，见下文：</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \brief A FileSystem implementation that delegates to another</span></span><br><span class="line"><span class="comment">/// implementation but inserts latencies at various points.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ARROW_EXPORT</span> SlowFileSystem : <span class="keyword">public</span> FileSystem &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">SlowFileSystem</span>(std::shared_ptr&lt;FileSystem&gt; base_fs,</span><br><span class="line">                 std::shared_ptr&lt;io::LatencyGenerator&gt; latencies);</span><br><span class="line">  <span class="built_in">SlowFileSystem</span>(std::shared_ptr&lt;FileSystem&gt; base_fs, <span class="type">double</span> average_latency);</span><br><span class="line">  <span class="built_in">SlowFileSystem</span>(std::shared_ptr&lt;FileSystem&gt; base_fs, <span class="type">double</span> average_latency,</span><br><span class="line">                 <span class="type">int32_t</span> seed);</span><br></pre></td></tr></table></figure><ul><li><code>MockFIleSystem</code>: 把所有内容持有在内存中的 FileSystem，应该是给测试用的</li><li><code>SubTreeFileSystem</code>: 感觉像是某个 base filesystem，给一个子路径的 “SubTree” 文件系统</li></ul><p>这里 arrow 内部还支持了一套统一的 URL 系统，然后从 URL 系统中 load 出来对应的 path。比如 <code>gcs://</code>, 内容是 <code>FileSystemFromUri</code>. 需要注意的是本地文件是 <code>file://</code> 这类的前缀。</p><p>话说到这里，每个文件系统还有一些文件和路径的概念，Arrow 是怎么映射这些文件和路径的呢？Arrow FileSystem 定义了 <code>NormalizeFilePath</code>，专门处理一些 Windows Path / SubTreeSystem 之类的路径之类的内容，来给路径的逻辑做了统一的处理</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Result&lt;std::string&gt; <span class="title">SubTreeFileSystem::NormalizePath</span><span class="params">(std::string path)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> real_path, <span class="built_in">PrependBase</span>(path));</span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> normalized, base_fs_-&gt;<span class="built_in">NormalizePath</span>(real_path));</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">StripBase</span>(std::<span class="built_in">move</span>(normalized));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是在介绍 FileSystem 之前，我们先介绍一下系统运行的上下文。</p><h3 id="IOContext-and-Executor"><a href="#IOContext-and-Executor" class="headerlink" title="IOContext and Executor"></a>IOContext and Executor</h3><p>IOContext 是 Parquet 文件读取的「上下文」。因为 arrow 用的 C++17 没有标准的 async 模型，所以这里基本上还是用 IO 线程池包装了同步的接口。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// EXPERIMENTAL: options provider for IO tasks</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Includes an Executor (which will be used to execute asynchronous reads),</span></span><br><span class="line"><span class="comment">/// a MemoryPool (which will be used to allocate buffers when zero copy reads</span></span><br><span class="line"><span class="comment">/// are not possible), and an external id (in case the executor receives tasks from</span></span><br><span class="line"><span class="comment">/// multiple sources and must distinguish tasks associated with this IOContext).</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ARROW_EXPORT</span> IOContext &#123;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  MemoryPool* pool_;</span><br><span class="line">  ::arrow::internal::Executor* executor_;</span><br><span class="line">  <span class="type">int64_t</span> external_id_;</span><br><span class="line">  StopToken stop_token_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>别的都很好理解，<code>external_id_</code> 是一个类似 IOTag 的东西。我看它这里没有做很细的 tag，就基于 id 判断一下。这里它把 <code>SubmitIO</code> 包装成异步的了</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span>... SubmitArgs&gt;</span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">SubmitIO</span><span class="params">(IOContext io_context, SubmitArgs&amp;&amp;... submit_args)</span></span></span><br><span class="line"><span class="function">    -&gt; <span class="title">decltype</span><span class="params">(std::declval&lt;::arrow::internal::Executor*&gt;()-&gt;Submit(submit_args...))</span> </span>&#123;</span><br><span class="line">  ::arrow::internal::TaskHints hints;</span><br><span class="line">  hints.external_id = io_context.<span class="built_in">external_id</span>();</span><br><span class="line">  <span class="keyword">return</span> io_context.<span class="built_in">executor</span>()-&gt;<span class="built_in">Submit</span>(hints, io_context.<span class="built_in">stop_token</span>(),</span><br><span class="line">                                       std::forward&lt;SubmitArgs&gt;(submit_args)...);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里具体提交 IO 的时候还有一些 TaskHint，但是好像没有什么人真的用了这一套。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Hints about a task that may be used by an Executor.</span></span><br><span class="line"><span class="comment">// They are ignored by the provided ThreadPool implementation.</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">TaskHints</span> &#123;</span><br><span class="line">  <span class="comment">// The lower, the more urgent</span></span><br><span class="line">  <span class="type">int32_t</span> priority = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// The IO transfer size in bytes</span></span><br><span class="line">  <span class="type">int64_t</span> io_size = <span class="number">-1</span>;</span><br><span class="line">  <span class="comment">// The approximate CPU cost in number of instructions</span></span><br><span class="line">  <span class="type">int64_t</span> cpu_cost = <span class="number">-1</span>;</span><br><span class="line">  <span class="comment">// An application-specific ID</span></span><br><span class="line">  <span class="type">int64_t</span> external_id = <span class="number">-1</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>关于 Executor，这里可以当成 IO 线程的包装器接口：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ARROW_EXPORT</span> Executor &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">using</span> StopCallback = internal::FnOnce&lt;<span class="built_in">void</span>(<span class="type">const</span> Status&amp;)&gt;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">Executor</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Spawn a fire-and-forget task.</span></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Function&gt;</span><br><span class="line">  <span class="function">Status <span class="title">Spawn</span><span class="params">(...)</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Transfers a future to this executor.  Any continuations added to the</span></span><br><span class="line">  <span class="comment">// returned future will run in this executor.  Otherwise they would run</span></span><br><span class="line">  <span class="comment">// on the same thread that called MarkFinished.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// This is necessary when (for example) an I/O task is completing a future.</span></span><br><span class="line">  <span class="comment">// The continuations of that future should run on the CPU thread pool keeping</span></span><br><span class="line">  <span class="comment">// CPU heavy work off the I/O thread pool.  So the I/O task should transfer</span></span><br><span class="line">  <span class="comment">// the future to the CPU executor before returning.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// By default this method will only transfer if the future is not already completed.  If</span></span><br><span class="line">  <span class="comment">// the future is already completed then any callback would be run synchronously and so</span></span><br><span class="line">  <span class="comment">// no transfer is typically necessary.  However, in cases where you want to force a</span></span><br><span class="line">  <span class="comment">// transfer (e.g. to help the scheduler break up units of work across multiple cores)</span></span><br><span class="line">  <span class="comment">// then you can override this behavior with `always_transfer`.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Transfer 完成的是一个这样的逻辑，比方说用户的线程是一个 IO 线程，那么可能这里会访问的时候不太希望是在</span></span><br><span class="line">  <span class="comment">// CPU Thread 去接受. 当然 Transfer 对于已经完成的 Future 可能会有点奇怪, 因为它实现是直接挂 callback</span></span><br><span class="line">  <span class="comment">// 的.</span></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="function">Future&lt;T&gt; <span class="title">Transfer</span><span class="params">(Future&lt;T&gt; future)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Overload of Transfer which will always schedule callbacks on new threads even if the</span></span><br><span class="line">  <span class="comment">// future is finished when the callback is added.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// This can be useful in cases where you want to ensure parallelism</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// 强制 Transfer 操作.</span></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="function">Future&lt;T&gt; <span class="title">TransferAlways</span><span class="params">(Future&lt;T&gt; future)</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Return the level of parallelism (the number of tasks that may be executed</span></span><br><span class="line">  <span class="comment">// concurrently).  This may be an approximate number.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">int</span> <span class="title">GetCapacity</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Return true if the thread from which this function is called is owned by this</span></span><br><span class="line">  <span class="comment">// Executor. Returns false if this Executor does not support this property.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">OwnsThisThread</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="literal">false</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Return true if this is the current executor being called</span></span><br><span class="line">  <span class="comment">// n.b. this defaults to just calling OwnsThisThread</span></span><br><span class="line">  <span class="comment">// unless the threadpool is disabled</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">IsCurrentExecutor</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">OwnsThisThread</span>(); &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// \brief An interface to represent something with a custom destructor</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// \see KeepAlive</span></span><br><span class="line">  <span class="keyword">class</span> <span class="title class_">ARROW_EXPORT</span> Resource &#123;</span><br><span class="line">   <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">virtual</span> ~<span class="built_in">Resource</span>() = <span class="keyword">default</span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Keep a resource alive until all executor threads have terminated</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// Executors may have static storage duration.  In particular, the CPU and I/O</span></span><br><span class="line">  <span class="comment">/// executors are currently implemented this way.  These threads may access other</span></span><br><span class="line">  <span class="comment">/// objects with static storage duration such as the OpenTelemetry runtime context</span></span><br><span class="line">  <span class="comment">/// the default memory pool, or other static executors.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// The order in which these objects are destroyed is difficult to control.  In order</span></span><br><span class="line">  <span class="comment">/// to ensure those objects remain alive until all threads have finished those objects</span></span><br><span class="line">  <span class="comment">/// should be wrapped in a Resource object and passed into this method.  The given</span></span><br><span class="line">  <span class="comment">/// shared_ptr will be kept alive until all threads have finished their worker loops.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">KeepAlive</span><span class="params">(std::shared_ptr&lt;Resource&gt; resource)</span></span>;</span><br><span class="line">  </span><br><span class="line"> <span class="keyword">protected</span>:</span><br><span class="line">  <span class="comment">// Subclassing API</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">SpawnReal</span><span class="params">(TaskHints hints, FnOnce&lt;<span class="type">void</span>()&gt; task, StopToken,</span></span></span><br><span class="line"><span class="params"><span class="function">                           StopCallback&amp;&amp;)</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这部分接口其实都相对比较好理解.</p><p>先介绍几个比较好理解的接口：</p><ol><li><code>KeepAlive</code>: 生命周期 Ordering 维护器</li><li><code>OwnsThisThread()</code> 这部分实现很有意思，<code>ThreadPool</code> 实现这个的时候套了一层 <code>threadlocal</code>，我们可以看看</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">thread_local</span> ThreadPool* current_thread_pool_ = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">ThreadPool::OwnsThisThread</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> current_thread_pool_ == <span class="keyword">this</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ThreadPool::LaunchWorkersUnlocked</span><span class="params">(<span class="type">int</span> threads)</span> </span>&#123;</span><br><span class="line">  std::shared_ptr&lt;State&gt; state = sp_state_;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; threads; i++) &#123;</span><br><span class="line">    state_-&gt;workers_.<span class="built_in">emplace_back</span>();</span><br><span class="line">    <span class="keyword">auto</span> it = --(state_-&gt;workers_.<span class="built_in">end</span>());</span><br><span class="line">    *it = std::<span class="built_in">thread</span>([<span class="keyword">this</span>, state, it] &#123;</span><br><span class="line">      current_thread_pool_ = <span class="keyword">this</span>;</span><br><span class="line">      <span class="built_in">WorkerLoop</span>(state, it);</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以直接看看 <code>Transfer</code> 的实现，这段处理的比较有意思</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> FT = Future&lt;T&gt;, <span class="keyword">typename</span> FTSync = <span class="keyword">typename</span> FT::SyncType&gt;</span><br><span class="line">Future&lt;T&gt; <span class="built_in">DoTransfer</span>(Future&lt;T&gt; future, <span class="type">bool</span> always_transfer = <span class="literal">false</span>) &#123;</span><br><span class="line">  <span class="keyword">auto</span> transferred = Future&lt;T&gt;::<span class="built_in">Make</span>();</span><br><span class="line">  <span class="keyword">if</span> (always_transfer) &#123;</span><br><span class="line">    CallbackOptions callback_options = CallbackOptions::<span class="built_in">Defaults</span>();</span><br><span class="line">    callback_options.should_schedule = ShouldSchedule::Always;</span><br><span class="line">    callback_options.executor = <span class="keyword">this</span>;</span><br><span class="line">    <span class="keyword">auto</span> sync_callback = [transferred](<span class="type">const</span> FTSync&amp; result) <span class="keyword">mutable</span> &#123;</span><br><span class="line">      transferred.<span class="built_in">MarkFinished</span>(result);</span><br><span class="line">    &#125;;</span><br><span class="line">    future.<span class="built_in">AddCallback</span>(sync_callback, callback_options);</span><br><span class="line">    <span class="keyword">return</span> transferred;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// We could use AddCallback&#x27;s ShouldSchedule::IfUnfinished but we can save a bit of</span></span><br><span class="line">  <span class="comment">// work by doing the test here.</span></span><br><span class="line">  <span class="keyword">auto</span> callback = [<span class="keyword">this</span>, transferred](<span class="type">const</span> FTSync&amp; result) <span class="keyword">mutable</span> &#123;</span><br><span class="line">    <span class="keyword">auto</span> spawn_status =</span><br><span class="line">        <span class="built_in">Spawn</span>([transferred, result]() <span class="keyword">mutable</span> &#123; transferred.<span class="built_in">MarkFinished</span>(result); &#125;);</span><br><span class="line">    <span class="keyword">if</span> (!spawn_status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">      transferred.<span class="built_in">MarkFinished</span>(spawn_status);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="keyword">auto</span> callback_factory = [&amp;callback]() &#123; <span class="keyword">return</span> callback; &#125;;</span><br><span class="line">  <span class="keyword">if</span> (future.<span class="built_in">TryAddCallback</span>(callback_factory)) &#123;</span><br><span class="line">    <span class="keyword">return</span> transferred;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// If the future is already finished and we aren&#x27;t going to force spawn a thread</span></span><br><span class="line">  <span class="comment">// then we don&#x27;t need to add another layer of callback and can return the original</span></span><br><span class="line">  <span class="comment">// future</span></span><br><span class="line">  <span class="keyword">return</span> future;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码很清晰：</p><ol><li>如果是 <code>always_transfer</code>，那么就可以创建一个 callback，直接挂过去</li><li>否则，尝试开一个 transfer &amp; callback 的 thread, 尝试 async 去 MarkFinish. 如果 Future 已经 finish 了，这部分逻辑倒是很好解决了。</li></ol><h3 id="文件系统的接口"><a href="#文件系统的接口" class="headerlink" title="文件系统的接口"></a>文件系统的接口</h3><p>这里有些比较好玩的，首先看 <code>FileSystem</code> 这个基类</p><h4 id="List-文件"><a href="#List-文件" class="headerlink" title="List 文件"></a>List 文件</h4><p>这里会有一些对 Stream Open 的支持，可以打开 File 之类的操作，和根据 FileSelector 去 List 的操作：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Get info for the given target.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Any symlink is automatically dereferenced, recursively.</span></span><br><span class="line"><span class="comment">/// A nonexistent or unreachable file returns an Ok status and</span></span><br><span class="line"><span class="comment">/// has a FileType of value NotFound.  An error status indicates</span></span><br><span class="line"><span class="comment">/// a truly exceptional condition (low-level I/O error, etc.).</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Result&lt;FileInfo&gt; <span class="title">GetFileInfo</span><span class="params">(<span class="type">const</span> std::string&amp; path)</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="comment">/// Same, for many targets at once.</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Result&lt;FileInfoVector&gt; <span class="title">GetFileInfo</span><span class="params">(<span class="type">const</span> std::vector&lt;std::string&gt;&amp; paths)</span></span>;</span><br><span class="line"><span class="comment">/// Same, according to a selector.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// The selector&#x27;s base directory will not be part of the results, even if</span></span><br><span class="line"><span class="comment">/// it exists.</span></span><br><span class="line"><span class="comment">/// If it doesn&#x27;t exist, see `FileSelector::allow_not_found`.</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Result&lt;FileInfoVector&gt; <span class="title">GetFileInfo</span><span class="params">(<span class="type">const</span> FileSelector&amp; select)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Async version of GetFileInfo</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Future&lt;FileInfoVector&gt; <span class="title">GetFileInfoAsync</span><span class="params">(<span class="type">const</span> std::vector&lt;std::string&gt;&amp; paths)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Streaming async version of GetFileInfo</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// The returned generator is not async-reentrant, i.e. you need to wait for</span></span><br><span class="line"><span class="comment">/// the returned future to complete before calling the generator again.</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> FileInfoGenerator <span class="title">GetFileInfoGenerator</span><span class="params">(<span class="type">const</span> FileSelector&amp; select)</span></span>;</span><br></pre></td></tr></table></figure><p>这里观察到有一个 <code>FileSelector</code> 接口，实际上这里也会支持一些过滤规则，然后尽量下推</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \brief File selector for filesystem APIs</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ARROW_EXPORT</span> FileSelector &#123;</span><br><span class="line">  <span class="comment">/// The directory in which to select files.</span></span><br><span class="line">  <span class="comment">/// If the path exists but doesn&#x27;t point to a directory, this should be an error.</span></span><br><span class="line">  std::string base_dir;</span><br><span class="line">  <span class="comment">/// The behavior if `base_dir` isn&#x27;t found in the filesystem.  If false,</span></span><br><span class="line">  <span class="comment">/// an error is returned.  If true, an empty selection is returned.</span></span><br><span class="line">  <span class="type">bool</span> allow_not_found;</span><br><span class="line">  <span class="comment">/// Whether to recurse into subdirectories.</span></span><br><span class="line">  <span class="type">bool</span> recursive;</span><br><span class="line">  <span class="comment">/// The maximum number of subdirectories to recurse into.</span></span><br><span class="line">  <span class="type">int32_t</span> max_recursion;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">FileSelector</span>() : <span class="built_in">allow_not_found</span>(<span class="literal">false</span>), <span class="built_in">recursive</span>(<span class="literal">false</span>), <span class="built_in">max_recursion</span>(INT32_MAX) &#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="Dir-Operations"><a href="#Dir-Operations" class="headerlink" title="Dir Operations"></a>Dir Operations</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Create a directory and subdirectories.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// This function succeeds if the directory already exists.</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">CreateDir</span><span class="params">(<span class="type">const</span> std::string&amp; path, <span class="type">bool</span> recursive = <span class="literal">true</span>)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Delete a directory and its contents, recursively.</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">DeleteDir</span><span class="params">(<span class="type">const</span> std::string&amp; path)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Delete a directory&#x27;s contents, recursively.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Like DeleteDir, but doesn&#x27;t delete the directory itself.</span></span><br><span class="line"><span class="comment">/// Passing an empty path (&quot;&quot; or &quot;/&quot;) is disallowed, see DeleteRootDirContents.</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">DeleteDirContents</span><span class="params">(<span class="type">const</span> std::string&amp; path,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 <span class="type">bool</span> missing_dir_ok = <span class="literal">false</span>)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Async version of DeleteDirContents.</span></span><br><span class="line"><span class="keyword">virtual</span> Future&lt;&gt; <span class="built_in">DeleteDirContentsAsync</span>(<span class="type">const</span> std::string&amp; path,</span><br><span class="line">                                        <span class="type">bool</span> missing_dir_ok = <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/// EXPERIMENTAL: Delete the root directory&#x27;s contents, recursively.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Implementations may decide to raise an error if this operation is</span></span><br><span class="line"><span class="comment">/// too dangerous.</span></span><br><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> may decide to remove this if it&#x27;s deemed not useful</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">DeleteRootDirContents</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br></pre></td></tr></table></figure><h3 id="File-and-Stream-Operations"><a href="#File-and-Stream-Operations" class="headerlink" title="File and Stream Operations"></a>File and Stream Operations</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Delete a file.</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">DeleteFile</span><span class="params">(<span class="type">const</span> std::string&amp; path)</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="comment">/// Delete many files.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// The default implementation issues individual delete operations in sequence.</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">DeleteFiles</span><span class="params">(<span class="type">const</span> std::vector&lt;std::string&gt;&amp; paths)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Move / rename a file or directory.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// If the destination exists:</span></span><br><span class="line"><span class="comment">/// - if it is a non-empty directory, an error is returned</span></span><br><span class="line"><span class="comment">/// - otherwise, if it has the same type as the source, it is replaced</span></span><br><span class="line"><span class="comment">/// - otherwise, behavior is unspecified (implementation-dependent).</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">Move</span><span class="params">(<span class="type">const</span> std::string&amp; src, <span class="type">const</span> std::string&amp; dest)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Copy a file.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// If the destination exists and is a directory, an error is returned.</span></span><br><span class="line"><span class="comment">/// Otherwise, it is replaced.</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Status <span class="title">CopyFile</span><span class="params">(<span class="type">const</span> std::string&amp; src, <span class="type">const</span> std::string&amp; dest)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Open an input stream for sequential reading.</span></span><br><span class="line"><span class="keyword">virtual</span> Result&lt;std::shared_ptr&lt;io::InputStream&gt;&gt; <span class="built_in">OpenInputStream</span>(</span><br><span class="line">    <span class="type">const</span> std::string&amp; path) = <span class="number">0</span>;</span><br><span class="line"><span class="comment">/// Open an input stream for sequential reading.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// This override assumes the given FileInfo validly represents the file&#x27;s</span></span><br><span class="line"><span class="comment">/// characteristics, and may optimize access depending on them (for example</span></span><br><span class="line"><span class="comment">/// avoid querying the file size or its existence).</span></span><br><span class="line"><span class="keyword">virtual</span> Result&lt;std::shared_ptr&lt;io::InputStream&gt;&gt; <span class="built_in">OpenInputStream</span>(<span class="type">const</span> FileInfo&amp; info);</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Open an input file for random access reading.</span></span><br><span class="line"><span class="keyword">virtual</span> Result&lt;std::shared_ptr&lt;io::RandomAccessFile&gt;&gt; <span class="built_in">OpenInputFile</span>(</span><br><span class="line">    <span class="type">const</span> std::string&amp; path) = <span class="number">0</span>;</span><br><span class="line"><span class="comment">/// Open an input file for random access reading.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// This override assumes the given FileInfo validly represents the file&#x27;s</span></span><br><span class="line"><span class="comment">/// characteristics, and may optimize access depending on them (for example</span></span><br><span class="line"><span class="comment">/// avoid querying the file size or its existence).</span></span><br><span class="line"><span class="keyword">virtual</span> Result&lt;std::shared_ptr&lt;io::RandomAccessFile&gt;&gt; <span class="built_in">OpenInputFile</span>(</span><br><span class="line">    <span class="type">const</span> FileInfo&amp; info);</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Async version of OpenInputStream</span></span><br><span class="line"><span class="keyword">virtual</span> Future&lt;std::shared_ptr&lt;io::InputStream&gt;&gt; <span class="built_in">OpenInputStreamAsync</span>(</span><br><span class="line">    <span class="type">const</span> std::string&amp; path);</span><br><span class="line"><span class="comment">/// Async version of OpenInputStream</span></span><br><span class="line"><span class="keyword">virtual</span> Future&lt;std::shared_ptr&lt;io::InputStream&gt;&gt; <span class="built_in">OpenInputStreamAsync</span>(</span><br><span class="line">    <span class="type">const</span> FileInfo&amp; info);</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Async version of OpenInputFile</span></span><br><span class="line"><span class="keyword">virtual</span> Future&lt;std::shared_ptr&lt;io::RandomAccessFile&gt;&gt; <span class="built_in">OpenInputFileAsync</span>(</span><br><span class="line">    <span class="type">const</span> std::string&amp; path);</span><br><span class="line"><span class="comment">/// Async version of OpenInputFile</span></span><br><span class="line"><span class="keyword">virtual</span> Future&lt;std::shared_ptr&lt;io::RandomAccessFile&gt;&gt; <span class="built_in">OpenInputFileAsync</span>(</span><br><span class="line">    <span class="type">const</span> FileInfo&amp; info);</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Open an output stream for sequential writing.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// If the target already exists, existing data is truncated.</span></span><br><span class="line"><span class="keyword">virtual</span> Result&lt;std::shared_ptr&lt;io::OutputStream&gt;&gt; <span class="built_in">OpenOutputStream</span>(</span><br><span class="line">    <span class="type">const</span> std::string&amp; path,</span><br><span class="line">    <span class="type">const</span> std::shared_ptr&lt;<span class="type">const</span> KeyValueMetadata&gt;&amp; metadata) = <span class="number">0</span>;</span><br><span class="line">Result&lt;std::shared_ptr&lt;io::OutputStream&gt;&gt; <span class="built_in">OpenOutputStream</span>(<span class="type">const</span> std::string&amp; path);</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Open an output stream for appending.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// If the target doesn&#x27;t exist, a new empty file is created.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Note: some filesystem implementations do not support efficient appending</span></span><br><span class="line"><span class="comment">/// to an existing file, in which case this method will return NotImplemented.</span></span><br><span class="line"><span class="comment">/// Consider writing to multiple files (using e.g. the dataset layer) instead.</span></span><br><span class="line"><span class="keyword">virtual</span> Result&lt;std::shared_ptr&lt;io::OutputStream&gt;&gt; <span class="built_in">OpenAppendStream</span>(</span><br><span class="line">    <span class="type">const</span> std::string&amp; path,</span><br><span class="line">    <span class="type">const</span> std::shared_ptr&lt;<span class="type">const</span> KeyValueMetadata&gt;&amp; metadata) = <span class="number">0</span>;</span><br><span class="line">Result&lt;std::shared_ptr&lt;io::OutputStream&gt;&gt; <span class="built_in">OpenAppendStream</span>(<span class="type">const</span> std::string&amp; path);</span><br></pre></td></tr></table></figure><p>这里它打开文件，本身都是 Sync 或者 Async 的，而打开后的接口，可能有不同的 Sync Async 模型。根据我个人的理解，这个可能是个开发者责任制。比如某个接口在非关键路径上不是 async，就没有开发者愿意改它，然后这玩意就都是 Sync 的了。反正 Sync 是第一需要支持的东西。然后需要注意的是，似乎 <code>FileSystem</code> 这套接口使用的时候会尽量保证是 hold by <code>shared_ptr</code> 的。</p><p>Async 的实现目前也比较直接，应该是默认实现是包一套 <code>SubmitIO</code>，然后内部实现可以在继承的时候允许自己去做一些 hack. 这里举例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DeferredFunc&gt;</span><br><span class="line"><span class="function"><span class="keyword">auto</span> <span class="title">FileSystemDefer</span><span class="params">(FileSystem* fs, <span class="type">bool</span> synchronous, DeferredFunc&amp;&amp; func)</span></span></span><br><span class="line"><span class="function">    -&gt; <span class="title">decltype</span><span class="params">(DeferNotOk(</span></span></span><br><span class="line"><span class="params"><span class="function">        fs-&gt;io_context().executor()-&gt;Submit(func, std::shared_ptr&lt;FileSystem&gt;&#123;&#125;)))</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> self = fs-&gt;<span class="built_in">shared_from_this</span>();</span><br><span class="line">  <span class="keyword">if</span> (synchronous) &#123;</span><br><span class="line">    <span class="keyword">return</span> std::forward&lt;DeferredFunc&gt;(func)(std::<span class="built_in">move</span>(self));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">DeferNotOk</span>(io::internal::<span class="built_in">SubmitIO</span>(</span><br><span class="line">      fs-&gt;<span class="built_in">io_context</span>(), std::forward&lt;DeferredFunc&gt;(func), std::<span class="built_in">move</span>(self)));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace</span></span><br><span class="line"></span><br><span class="line">Future&lt;std::shared_ptr&lt;io::InputStream&gt;&gt; FileSystem::<span class="built_in">OpenInputStreamAsync</span>(</span><br><span class="line">    <span class="type">const</span> std::string&amp; path) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">FileSystemDefer</span>(</span><br><span class="line">      <span class="keyword">this</span>, default_async_is_sync_,</span><br><span class="line">      [path](std::shared_ptr&lt;FileSystem&gt; self) &#123; <span class="keyword">return</span> self-&gt;<span class="built_in">OpenInputStream</span>(path); &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>为什么 OpenFile 需要是 async 的呢？举例子就是 S3 的 Open:</p><p>这里 <code>Init</code> 本身会发出一个 HeadObject，所以可能需要尽量在对应的异步线程里打开</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A RandomAccessFile that reads from a S3 object</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ObjectInputFile</span> <span class="keyword">final</span> : <span class="keyword">public</span> io::RandomAccessFile &#123;</span><br><span class="line">  <span class="function">Status <span class="title">Init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Issue a HEAD Object to get the content-length and ensure any</span></span><br><span class="line">    <span class="comment">// errors (e.g. file not found) don&#x27;t wait until the first Read() call.</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;;  </span><br></pre></td></tr></table></figure><h2 id="File"><a href="#File" class="headerlink" title="File"></a>File</h2><p>File 有好几个接口，这些代码本身是非常清晰的。这里接口类似 concept，每个地方是一个</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">FileIterface(Close, CloseAsync, Abort, Tell. 这里特殊说一下 CloseAsync, 因为可能文件读取也要释放一些资源的)</span><br><span class="line">Seekable(Seek)</span><br><span class="line">Writable(Write, Flush. Write 可以传入 non-owned buffer, 也可以丢个 shared_ptr&lt;Buffer&gt; 进来来避免拷贝)</span><br><span class="line">Readable(Read. Read 可以拷贝到用户的 Buffer, 也可以返回一个 shared_ptr&lt;Buffer&gt;)</span><br><span class="line">OutputStream: FileIterface</span><br><span class="line">InputStream: FileIterface, Readable (Advance, Peak, supports_zero_copy, ReadMetadata, ReadMetadataAsync)</span><br><span class="line">RandomAccessFile: InputStream, Seekable (GetStream, GetSize, ReadAt, ReadAsync, ReadManyAsync, WillNeed)</span><br><span class="line">WritableFile: OutputStream (WriteAt)</span><br><span class="line">ReadWriteFileInterface: RandomAccessFile, WritableFile</span><br></pre></td></tr></table></figure><p>这个部分注意一下 async 的实现即可。我们首先关注一下 S3 的 <code>CloseAsync</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">Future&lt;&gt; <span class="built_in">CloseAsync</span>() <span class="keyword">override</span> &#123;</span><br><span class="line">   <span class="keyword">if</span> (closed_) <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> (current_part_) &#123;</span><br><span class="line">     <span class="comment">// Upload last part</span></span><br><span class="line">     <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">CommitCurrentPart</span>());</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// S3 mandates at least one part, upload an empty one if necessary</span></span><br><span class="line">   <span class="keyword">if</span> (part_number_ == <span class="number">1</span>) &#123;</span><br><span class="line">     <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">UploadPart</span>(<span class="string">&quot;&quot;</span>, <span class="number">0</span>));</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Wait for in-progress uploads to finish (if async writes are enabled)</span></span><br><span class="line">   <span class="keyword">return</span> <span class="built_in">FlushAsync</span>().<span class="built_in">Then</span>([<span class="keyword">this</span>]() &#123;</span><br><span class="line">     <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> client_lock, holder_-&gt;<span class="built_in">Lock</span>());</span><br><span class="line"></span><br><span class="line">     <span class="comment">// At this point, all part uploads have finished successfully</span></span><br><span class="line">     <span class="built_in">DCHECK_GT</span>(part_number_, <span class="number">1</span>);</span><br><span class="line">     <span class="built_in">DCHECK_EQ</span>(upload_state_-&gt;completed_parts.<span class="built_in">size</span>(),</span><br><span class="line">               <span class="built_in">static_cast</span>&lt;<span class="type">size_t</span>&gt;(part_number_ - <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">     S3Model::CompletedMultipartUpload completed_upload;</span><br><span class="line">     completed_upload.<span class="built_in">SetParts</span>(upload_state_-&gt;completed_parts);</span><br><span class="line">     S3Model::CompleteMultipartUploadRequest req;</span><br><span class="line">     req.<span class="built_in">SetBucket</span>(<span class="built_in">ToAwsString</span>(path_.bucket));</span><br><span class="line">     req.<span class="built_in">SetKey</span>(<span class="built_in">ToAwsString</span>(path_.key));</span><br><span class="line">     req.<span class="built_in">SetUploadId</span>(upload_id_);</span><br><span class="line">     req.<span class="built_in">SetMultipartUpload</span>(std::<span class="built_in">move</span>(completed_upload));</span><br><span class="line"></span><br><span class="line">     <span class="keyword">auto</span> outcome =</span><br><span class="line">         client_lock.<span class="built_in">Move</span>()-&gt;<span class="built_in">CompleteMultipartUploadWithErrorFixup</span>(std::<span class="built_in">move</span>(req));</span><br><span class="line">     <span class="keyword">if</span> (!outcome.<span class="built_in">IsSuccess</span>()) &#123;</span><br><span class="line">       <span class="keyword">return</span> <span class="built_in">ErrorToStatus</span>(</span><br><span class="line">           std::forward_as_tuple(<span class="string">&quot;When completing multiple part upload for key &#x27;&quot;</span>,</span><br><span class="line">                                 path_.key, <span class="string">&quot;&#x27; in bucket &#x27;&quot;</span>, path_.bucket, <span class="string">&quot;&#x27;: &quot;</span>),</span><br><span class="line">           <span class="string">&quot;CompleteMultipartUpload&quot;</span>, outcome.<span class="built_in">GetError</span>());</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     holder_ = <span class="literal">nullptr</span>;</span><br><span class="line">     closed_ = <span class="literal">true</span>;</span><br><span class="line">     <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">   &#125;);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>这里因为完成的时候还得 <code>Flush</code> 然后发个 <code>Complete</code> 请求，所以很适合作为一个 Async。</p><p>对于 <code>RandomAccessFile::ReadAt</code> 来说，默认实现是个很挫的实现…，比如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Result&lt;<span class="type">int64_t</span>&gt; <span class="title">RandomAccessFile::ReadAt</span><span class="params">(<span class="type">int64_t</span> position, <span class="type">int64_t</span> nbytes, <span class="type">void</span>* out)</span> </span>&#123;</span><br><span class="line">  <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(interface_impl_-&gt;lock_)</span></span>;</span><br><span class="line">  <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">Seek</span>(position));</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">Read</span>(nbytes, out);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Result&lt;std::shared_ptr&lt;Buffer&gt;&gt; RandomAccessFile::<span class="built_in">ReadAt</span>(<span class="type">int64_t</span> position,</span><br><span class="line">                                                         <span class="type">int64_t</span> nbytes) &#123;</span><br><span class="line">  <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(interface_impl_-&gt;lock_)</span></span>;</span><br><span class="line">  <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">Seek</span>(position));</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">Read</span>(nbytes);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>File</code> 系还有几个 Concurrency Wrapper，但在 Release 编译的时候其实是不上锁的( Concurrency Wrapper 实现了。当然，系统如果支持这样，可以做一些相对好的操作。HDFS 这样有的 client 不支持 pread 的可以走这套，但是如果走 pread 肯定可以有更好的性能.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A RandomAccessFile that reads from a S3 object</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ObjectInputFile</span> <span class="keyword">final</span> : <span class="keyword">public</span> io::RandomAccessFile;</span><br></pre></td></tr></table></figure><p>这里就实现了不带锁的 pread，来加速对应的操作。</p><h4 id="Buffered-and-Memory-Layer"><a href="#Buffered-and-Memory-Layer" class="headerlink" title="Buffered and Memory Layer"></a>Buffered and Memory Layer</h4><p>Buffered 是 arrow 包装的一套 Buffer IO 系统，我觉得有点类似 Rust 标准库的那套 Buffer IO，然后也包装了一些 Arrow 特有的逻辑。读取的</p><p><code>BufferedOutputStream</code> 和 <code>BufferedInputStream</code> 是 Buffered IO 的实现，分别把输入输出 Buffer 化。</p><p><code>src/arrow/io/memory.h</code> 有一些用 Memory 中的 <code>Buffer</code> 或者别的东西当成输入或者输出的工具，可以在测试之类的代码很方便的使用。</p><h3 id="Transform"><a href="#Transform" class="headerlink" title="Transform"></a>Transform</h3><p><code>TransformInputStream</code> 允许用户给 inputStream 读 bytes 的时候定制一个 <code>transform</code> 函数</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ARROW_EXPORT</span> TransformInputStream : <span class="keyword">public</span> InputStream &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">using</span> TransformFunc =</span><br><span class="line">      std::function&lt;Result&lt;std::shared_ptr&lt;Buffer&gt;&gt;(<span class="type">const</span> std::shared_ptr&lt;Buffer&gt;&amp;)&gt;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>感觉这个得定义一个有状态的函数，比如说那种 utf8 parsing 的时候返回的 buf 肯定不一定是完整的 buf 了…</p><h3 id="Memory-Caching-Layer"><a href="#Memory-Caching-Layer" class="headerlink" title="Memory Caching Layer"></a>Memory Caching Layer</h3><p><code>src/arrow/io/caching.h</code> 处理了预读、缓存、IO合并的逻辑。<code>ReadRangeCache</code> 会预读并且缓存数据，它有两种形式：</p><ol><li>Lazy: 等待用户的读，来触发 IO</li><li>Default: 把所有 IO 发出去</li></ol><p>上面两种接口都会发送 IO 合并，然后读一个大块的时候 IO 发出去之后会缓存</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">ARROW_EXPORT</span> CacheOptions &#123;</span><br><span class="line">  <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">double</span> kDefaultIdealBandwidthUtilizationFrac = <span class="number">0.9</span>;</span><br><span class="line">  <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">int64_t</span> kDefaultMaxIdealRequestSizeMib = <span class="number">64</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief The maximum distance in bytes between two consecutive</span></span><br><span class="line">  <span class="comment">///   ranges; beyond this value, ranges are not combined</span></span><br><span class="line">  <span class="type">int64_t</span> hole_size_limit;</span><br><span class="line">  <span class="comment">/// \brief The maximum size in bytes of a combined range; if</span></span><br><span class="line">  <span class="comment">///   combining two consecutive ranges would produce a range of a</span></span><br><span class="line">  <span class="comment">///   size greater than this, they are not combined</span></span><br><span class="line">  <span class="type">int64_t</span> range_size_limit;</span><br><span class="line">  <span class="comment">/// \brief A lazy cache does not perform any I/O until requested.</span></span><br><span class="line">  <span class="type">bool</span> lazy;</span><br><span class="line">  <span class="comment">/// \brief The maximum number of ranges to be prefetched. This is only used</span></span><br><span class="line">  <span class="comment">///   for lazy cache to asynchronously read some ranges after reading the target range.</span></span><br><span class="line">  <span class="type">int64_t</span> prefetch_limit = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="type">bool</span> <span class="keyword">operator</span>==(<span class="type">const</span> CacheOptions&amp; other) <span class="type">const</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> hole_size_limit == other.hole_size_limit &amp;&amp;</span><br><span class="line">           range_size_limit == other.range_size_limit &amp;&amp; lazy == other.lazy &amp;&amp;</span><br><span class="line">           prefetch_limit == other.prefetch_limit;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Construct CacheOptions from network storage metrics (e.g. S3).</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// \param[in] time_to_first_byte_millis Seek-time or Time-To-First-Byte (TTFB) in</span></span><br><span class="line">  <span class="comment">///   milliseconds, also called call setup latency of a new S3 request.</span></span><br><span class="line">  <span class="comment">///   The value is a positive integer.</span></span><br><span class="line">  <span class="comment">/// \param[in] transfer_bandwidth_mib_per_sec Data transfer Bandwidth (BW) in MiB/sec.</span></span><br><span class="line">  <span class="comment">///   The value is a positive integer.</span></span><br><span class="line">  <span class="comment">/// \param[in] ideal_bandwidth_utilization_frac Transfer bandwidth utilization fraction</span></span><br><span class="line">  <span class="comment">///   (per connection) to maximize the net data load.</span></span><br><span class="line">  <span class="comment">///   The value is a positive double precision number less than 1.</span></span><br><span class="line">  <span class="comment">/// \param[in] max_ideal_request_size_mib The maximum single data request size (in MiB)</span></span><br><span class="line">  <span class="comment">///   to maximize the net data load.</span></span><br><span class="line">  <span class="comment">///   The value is a positive integer.</span></span><br><span class="line">  <span class="comment">/// \return A new instance of CacheOptions.</span></span><br><span class="line">  <span class="function"><span class="type">static</span> CacheOptions <span class="title">MakeFromNetworkMetrics</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">int64_t</span> time_to_first_byte_millis, <span class="type">int64_t</span> transfer_bandwidth_mib_per_sec,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">double</span> ideal_bandwidth_utilization_frac = kDefaultIdealBandwidthUtilizationFrac,</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">int64_t</span> max_ideal_request_size_mib = kDefaultMaxIdealRequestSizeMib)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> CacheOptions <span class="title">Defaults</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">static</span> CacheOptions <span class="title">LazyDefaults</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里比较新颖的一个地方是 <code>MakeFromNetworkMetrics</code>, 根据网络状况生成对应的 IO 状况.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Arrow Acero Framework</title>
      <link href="/2023/08/03/Arrow-Acero-Framework/"/>
      <url>/2023/08/03/Arrow-Acero-Framework/</url>
      
        <content type="html"><![CDATA[<p>Acero 是一个 「Streaming」 的处理引擎。这个 Streaming 有点类似 Monet/X100 意义上的：</p><ol><li>最早 Monet 他们弄的是整个全部物化，每个按照自己的大 Batch 做执行</li><li>后来发现这样物化的开销过高，所以弄成了 Batch Exec</li></ol><p>Acero 在 Arrow 中也是这样的存在，它是一个 Push-Based Executor，目前还不支持 Pipeline Executor 之类的形式。 也不支持 Sort Merge Join 和 Sort Agg。基本上支持的算子都在下面了。这也导致了一个现象：</p><ul><li>SortBy, TopK 算子在 Acero 里面是结合 Sink 算子来实现的</li></ul><p><img src="https://image.mwish.me/blog-image/415664007430259013.png" alt="img"></p><p>Acero 相当于一个串联 Dataset (读/写)，Function 的工具，产生需要的数据或者 Table。它并没有什么优化器，类似 Velox，对接的是外层的 Substrait[1] , dplyr [2] 接口。</p><p>我们会从 Declaration，Plan ，Node 层开始介绍 Acero 的结构。</p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>文档的这一节介绍了 Acero 的结构（ <a href="https://arrow.apache.org/docs/cpp/streaming_execution.html#architecture-overview">https://arrow.apache.org/docs/cpp/streaming_execution.html#architecture-overview</a> ）</p><p>暂时无法在飞书文档外展示此内容</p><ol><li><code>ExecPlan</code> 可以从 <code>Declaration</code> 中创建，作为一些语法糖. <code>ExecPlan</code> 不仅是一个</li><li><code>ExecNode</code> 是一个 Acero 中的基本控制单元，并且可以加入 <code>ExecNodeOptions</code>。各种类型的 ExecNode 构造函数不对外公开，但是可以走 <code>ExecFactoryRegistry</code> 创建。</li><li>数据通过 ExecBatch 来推送，这个东西也是个泛用类型的玩意</li></ol><p>Acero 大部分实现是做在 Compute 上的，Acero 主要做的是串起 Dataset 和 Compute，这里还有张不错的图：</p><p><img src="https://image.mwish.me/blog-image/7708173130236331652.png" alt="img"></p><p>这里创建 ExecNode 的时候，类似 <code>CallFunction</code>, 也可以通过名称来创建，e.g. <a href="https://arrow.apache.org/docs/cpp/streaming_execution.html#constructing-execnode-using-options">https://arrow.apache.org/docs/cpp/streaming_execution.html#constructing-execnode-using-options</a></p><p>Plan 是一个 ExecNode 的组合。它相当于整个执行的 Plan，而不是类似 <code>PhysicalPlanNode</code> 这种 <code>ExecNode</code> 对应的单个节点的结构。它也有一些执行的上下文 （<code>ExecContext</code> 和 <code>QueryOptions</code>）. </p><p>ExecBatch 是对应的传递的单元，它代码比较简单。这里它代码引入了 <code>SelectionVector</code>，但是实现并没有用上 selection vector。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// The values representing positional arguments to be passed to a kernel&#x27;s</span></span><br><span class="line"><span class="comment">/// exec function for processing.</span></span><br><span class="line">std::vector&lt;Datum&gt; values;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// SV, 实际上是没有用上的</span></span><br><span class="line">std::shared_ptr&lt;SelectionVector&gt; selection_vector;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// DataBatch 内的 Guarantee. 这里的抽象比较有意思, 因为它可能倾向于</span></span><br><span class="line"><span class="comment">/// 里面来自同一个 RowGroup 或者啥的. 所以对上方吐出的数据会有一个 gurantee.</span></span><br><span class="line">Expression guarantee = <span class="built_in">literal</span>(<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/// values 里面每个的长度(可能会有 constants, 这里它抽象和 Velox 的)</span></span><br><span class="line"><span class="type">int64_t</span> length = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// 这里允许并行读取多个文件然后 unordered 吐出去，这个 index 表示 Order 相关的部分。</span></span><br><span class="line"><span class="type">int64_t</span> index = kUnsequencedIndex;</span><br></pre></td></tr></table></figure><p><img src="https://image.mwish.me/blog-image/3457402530082094772.png" alt="img"></p><p>上面是 ExecBatch 的官图。Acero 里的 <code>Node</code> 工厂如代码所示：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \brief An extensible registry for factories of ExecNodes</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ARROW_ACERO_EXPORT</span> ExecFactoryRegistry &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">using</span> Factory = std::function&lt;<span class="built_in">Result</span>&lt;ExecNode*&gt;(ExecPlan*, std::vector&lt;ExecNode*&gt;,</span><br><span class="line">                                                  <span class="type">const</span> ExecNodeOptions&amp;)&gt;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">ExecFactoryRegistry</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Get the named factory from this registry</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// will raise if factory_name is not found</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Result&lt;Factory&gt; <span class="title">GetFactory</span><span class="params">(<span class="type">const</span> std::string&amp; factory_name)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Add a factory to this registry with the provided name</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// will raise if factory_name is already in the registry</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">AddFactory</span><span class="params">(std::string factory_name, Factory factory)</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// The default registry, which includes built-in factories.</span></span><br><span class="line"><span class="function">ARROW_ACERO_EXPORT</span></span><br><span class="line"><span class="function">ExecFactoryRegistry* <span class="title">default_exec_factory_registry</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// \brief Construct an ExecNode using the named factory</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> Result&lt;ExecNode*&gt; <span class="title">MakeExecNode</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::string&amp; factory_name, ExecPlan* plan, std::vector&lt;ExecNode*&gt; inputs,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> ExecNodeOptions&amp; options,</span></span></span><br><span class="line"><span class="params"><span class="function">    ExecFactoryRegistry* registry = default_exec_factory_registry())</span> </span>&#123;</span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> factory, registry-&gt;<span class="built_in">GetFactory</span>(factory_name));</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">factory</span>(plan, std::<span class="built_in">move</span>(inputs), options);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里需要注意，<code>Node</code> 的关系基本上是 <code>ExecNode</code> 自己维护的，<code>Plan</code> 会去驱动整个执行。<code>MakeExecNode</code> 的时候，这里会 <code>emplace_back</code> 对应的节点。然后在 Build 的阶段拓扑排序。</p><p>节点有不同的类型，这里我们简单的抽象：</p><ul><li>TableSource / Scan: 类似 “scan” 之类的接口，提供数据源。这里一部分代码实现在 Dataset 那套接口下面</li><li>Project: 很正常的 Project，在有的地方 Project 并不会是一个 Node，而是作为属性丢给各个算子自己，而不是搞出一个 Project。不过我感觉这块开销也不是很大</li><li>Filter: 给出对应的过滤逻辑，走 Compute::Filter</li><li>Sink: 计算的结果，OrderBy TopK 之类的算子目前是在 Sink 上面实现的，这有点奇怪。</li></ul><p>在 Node 节点串起来之后，我们需要 Care 一下 Pipeline 的控制流. 在 Acero 内部有两个 Scheduler:</p><ol><li>AsyncScheduler</li><li>TaskScheduler</li></ol><p>AsyncScheduler 有点类似 Pipeline 的根结点，它会把 “scan” 之类最底端的 Node 推进去，然后 ScanNode 可能会调用通知下一层节点，来通信下一层信息。TaskScheduler 是专门给 Join 这种准备的，它会类似 ForkJoin，在线程组上执行多个任务。（不过 TaskScheduler 代码我没完全看懂）</p><h2 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h2><p>我们在这里介绍 <code>ExecPlan</code> 和 <code>ExecNode</code> 两层，尽可能介绍一下</p><h3 id="Future"><a href="#Future" class="headerlink" title="Future"></a>Future</h3><p>首先我们需要介绍一下 arrow 的 <code>Future</code>，它实现了一套简单的 Future，实际上这是一个支持添加 Callback 的 <code>shared_future</code>，Arrow 用这个共享的 Future 来支持了 push-based 的语核。这里可以看 <code>Future</code> 作 <code>Future&lt;Result&lt;T&gt;&gt;</code>, 它对 <code>Status</code> 等类型做了很好的支持。</p><p>这套东西实现在：<a href="https://arrow.apache.org/docs/cpp/api/async.html">https://arrow.apache.org/docs/cpp/api/async.html</a> 。这套代码是比较正常的 Future 代码，关注接口就行了。实现等我看一圈 C++ Templates 再来啃吧 XD</p><p>在这里，Future 本身作为 shared_future, 所以可以这样</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Result&lt;Table&gt; <span class="title">blockingOp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">   <span class="keyword">auto</span> future = plan-&gt;<span class="built_in">GetFuture</span>()</span><br><span class="line">   future.<span class="built_in">Wait</span>();  <span class="comment">// &lt;-- 转换成阻塞操作，不影响内部的执行</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Future 可以添加 <code>Callback</code> 和 <code>Then</code>.</p><ol><li><code>AddCallback</code> 加入 Callback, Callback 是处理完本 <code>Future</code> 之后执行的一个或者多个回调函数。这里如果对一个 Finished Future 调用 Callback，那么可能会直接调用这个函数（傻了吧，就地 Callback）。为了解决这个问题，这里提供了 <code>TryAddCallback</code> 接口，如果执行完了，这里会不执行这个<ol><li>Callback 可以绑定对应的 <code>options</code> ，其中可以带上对应的 Executor。这里实现的时候，就允许你这个地方执行对应的逻辑。也有一些逻辑决定是否调度对应的 Future，类似 Folly 中的 <code>via</code></li></ol></li><li><code>Then</code> 类似 <code>Callback</code>, 但是本身产生一个 <code>future</code>。它现在会当成 Callback 实现，不会在 <code>Callback</code> 执行完之后被调度，而是当成一个普通的 Callback。</li></ol><p>我们可以简单看几个 Future 的使用例子（而不是看代码）：</p><p>Case 1: All</p><p>这里关键点是用 Callback 实现，然后处理错误，返回一个新的 Future。然后所有 Future 结束在新的 Future 里面 <code>MarkFinished</code></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">Future&lt;std::vector&lt;Result&lt;T&gt;&gt;&gt; <span class="built_in">All</span>(std::vector&lt;Future&lt;T&gt;&gt; futures) &#123;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">State</span> &#123;</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">State</span><span class="params">(std::vector&lt;Future&lt;T&gt;&gt; f)</span></span></span><br><span class="line"><span class="function">        : futures(std::move(f)), n_remaining(futures.size()) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">    std::vector&lt;Future&lt;T&gt;&gt; futures;</span><br><span class="line">    std::atomic&lt;<span class="type">size_t</span>&gt; n_remaining;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (futures.<span class="built_in">size</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> &#123;std::vector&lt;Result&lt;T&gt;&gt;&#123;&#125;&#125;;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> state = std::<span class="built_in">make_shared</span>&lt;State&gt;(std::<span class="built_in">move</span>(futures));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> out = Future&lt;std::vector&lt;Result&lt;T&gt;&gt;&gt;::<span class="built_in">Make</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">const</span> Future&lt;T&gt;&amp; future : state-&gt;futures) &#123;</span><br><span class="line">    future.<span class="built_in">AddCallback</span>([state, out](<span class="type">const</span> Result&lt;T&gt;&amp;) <span class="keyword">mutable</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (state-&gt;n_remaining.<span class="built_in">fetch_sub</span>(<span class="number">1</span>) != <span class="number">1</span>) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">      std::vector&lt;Result&lt;T&gt;&gt; <span class="built_in">results</span>(state-&gt;futures.<span class="built_in">size</span>());</span><br><span class="line">      <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; results.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">        results[i] = state-&gt;futures[i].<span class="built_in">result</span>();</span><br><span class="line">      &#125;</span><br><span class="line">      out.<span class="built_in">MarkFinished</span>(std::<span class="built_in">move</span>(results));</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> out;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Case2: CountRows:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> FragmentGenerator = AsyncGenerator&lt;std::shared_ptr&lt;Fragment&gt;&gt;;</span><br><span class="line"></span><br><span class="line"><span class="function">Result&lt;FragmentGenerator&gt; <span class="title">AsyncScanner::GetFragments</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="comment">// TODO(ARROW-8163): Async fragment scanning will return AsyncGenerator&lt;Fragment&gt;</span></span><br><span class="line">  <span class="comment">// here. Current iterator based versions are all fast &amp; sync so we will just ToVector</span></span><br><span class="line">  <span class="comment">// it</span></span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> fragments_it, dataset_-&gt;<span class="built_in">GetFragments</span>(scan_options_-&gt;filter));</span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> fragments_vec, fragments_it.<span class="built_in">ToVector</span>());</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">MakeVectorGenerator</span>(std::<span class="built_in">move</span>(fragments_vec));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Future&lt;<span class="type">int64_t</span>&gt; <span class="title">AsyncScanner::CountRowsAsync</span><span class="params">(Executor* executor)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> fragment_gen, <span class="built_in">GetFragments</span>());</span><br><span class="line"></span><br><span class="line">  <span class="function">compute::ExecContext <span class="title">exec_context</span><span class="params">(scan_options_-&gt;pool, executor)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> plan, acero::ExecPlan::<span class="built_in">Make</span>(exec_context));</span><br><span class="line">  <span class="comment">// Drop projection since we only need to count rows</span></span><br><span class="line">  <span class="type">const</span> <span class="keyword">auto</span> options = std::<span class="built_in">make_shared</span>&lt;ScanOptions&gt;(*scan_options_);</span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> empty_projection,</span><br><span class="line">                        ProjectionDescr::<span class="built_in">FromNames</span>(std::<span class="built_in">vector</span>&lt;std::string&gt;(),</span><br><span class="line">                                                   *scan_options_-&gt;dataset_schema));</span><br><span class="line">  <span class="built_in">SetProjection</span>(options.<span class="built_in">get</span>(), empty_projection);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> total = std::make_shared&lt;std::atomic&lt;<span class="type">int64_t</span>&gt;&gt;(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  fragment_gen = <span class="built_in">MakeMappedGenerator</span>(</span><br><span class="line">      std::<span class="built_in">move</span>(fragment_gen),</span><br><span class="line">      [options, total](<span class="type">const</span> std::shared_ptr&lt;Fragment&gt;&amp; fragment) &#123;</span><br><span class="line">        <span class="keyword">return</span> fragment-&gt;<span class="built_in">CountRows</span>(options-&gt;filter, options)</span><br><span class="line">            .<span class="built_in">Then</span>([options, total, fragment](std::optional&lt;<span class="type">int64_t</span>&gt; fast_count) <span class="keyword">mutable</span></span><br><span class="line">                  -&gt; std::shared_ptr&lt;Fragment&gt; &#123;</span><br><span class="line">              <span class="keyword">if</span> (fast_count) &#123;</span><br><span class="line">                <span class="comment">// fast path: got row count directly; skip scanning this fragment</span></span><br><span class="line">                (*total) += *fast_count;</span><br><span class="line">                <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;InMemoryFragment&gt;(options-&gt;dataset_schema,</span><br><span class="line">                                                          RecordBatchVector&#123;&#125;);</span><br><span class="line">              &#125;</span><br><span class="line"></span><br><span class="line">              <span class="comment">// slow path: actually filter this fragment&#x27;s batches</span></span><br><span class="line">              <span class="keyword">return</span> std::<span class="built_in">move</span>(fragment);</span><br><span class="line">            &#125;);</span><br><span class="line">      &#125;);</span><br><span class="line"></span><br><span class="line">  acero::Declaration count_plan = acero::Declaration::<span class="built_in">Sequence</span>(</span><br><span class="line">      &#123;&#123;<span class="string">&quot;scan&quot;</span>,</span><br><span class="line">        ScanNodeOptions&#123;std::<span class="built_in">make_shared</span>&lt;FragmentDataset&gt;(scan_options_-&gt;dataset_schema,</span><br><span class="line">                                                          std::<span class="built_in">move</span>(fragment_gen)),</span><br><span class="line">                        options&#125;&#125;,</span><br><span class="line">       &#123;<span class="string">&quot;project&quot;</span>, acero::ProjectNodeOptions&#123;&#123;options-&gt;filter&#125;, &#123;<span class="string">&quot;mask&quot;</span>&#125;&#125;&#125;,</span><br><span class="line">       &#123;<span class="string">&quot;aggregate&quot;</span>, acero::AggregateNodeOptions&#123;&#123;compute::Aggregate&#123;</span><br><span class="line">                         <span class="string">&quot;sum&quot;</span>, <span class="literal">nullptr</span>, <span class="string">&quot;mask&quot;</span>, <span class="string">&quot;selected_count&quot;</span>&#125;&#125;&#125;&#125;&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> acero::<span class="built_in">DeclarationToBatchesAsync</span>(std::<span class="built_in">move</span>(count_plan), exec_context)</span><br><span class="line">      .<span class="built_in">Then</span>([total](<span class="type">const</span> RecordBatchVector&amp; batches) -&gt; Result&lt;<span class="type">int64_t</span>&gt; &#123;</span><br><span class="line">        <span class="built_in">DCHECK_EQ</span>(<span class="number">1</span>, batches.<span class="built_in">size</span>());</span><br><span class="line">        <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(std::shared_ptr&lt;Scalar&gt; count_scalar,</span><br><span class="line">                              batches[<span class="number">0</span>]-&gt;<span class="built_in">column</span>(<span class="number">0</span>)-&gt;<span class="built_in">GetScalar</span>(<span class="number">0</span>));</span><br><span class="line">        <span class="keyword">return</span> total-&gt;<span class="built_in">load</span>() +</span><br><span class="line">               <span class="built_in">static_cast</span>&lt;<span class="type">int64_t</span>&gt;(</span><br><span class="line">                   ::arrow::internal::<span class="built_in">checked_pointer_cast</span>&lt;UInt64Scalar&gt;(count_scalar)</span><br><span class="line">                       -&gt;value);</span><br><span class="line">      &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个 <code>Then</code> 用的还挺有趣</p><h3 id="Plan"><a href="#Plan" class="headerlink" title="Plan"></a>Plan</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ARROW_ACERO_EXPORT</span> ExecPlan : <span class="keyword">public</span> std::enable_shared_from_this&lt;ExecPlan&gt; &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// This allows operators to rely on signed 16-bit indices</span></span><br><span class="line">  <span class="type">static</span> <span class="type">const</span> <span class="type">uint32_t</span> kMaxBatchSize = <span class="number">1</span> &lt;&lt; <span class="number">15</span>;</span><br><span class="line">  <span class="keyword">using</span> NodeVector = std::vector&lt;ExecNode*&gt;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">ExecPlan</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">QueryContext* <span class="title">query_context</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief retrieve the nodes in the plan</span></span><br><span class="line">  <span class="function"><span class="type">const</span> NodeVector&amp; <span class="title">nodes</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">ExecNode* <span class="title">AddNode</span><span class="params">(std::unique_ptr&lt;ExecNode&gt; node)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Node, <span class="keyword">typename</span>... Args&gt;</span><br><span class="line">  <span class="function">Node* <span class="title">EmplaceNode</span><span class="params">(Args&amp;&amp;... args)</span> </span>&#123;</span><br><span class="line">    std::unique_ptr&lt;Node&gt; node&#123;<span class="keyword">new</span> Node&#123;std::forward&lt;Args&gt;(args)...&#125;&#125;;</span><br><span class="line">    <span class="keyword">auto</span> out = node.<span class="built_in">get</span>();</span><br><span class="line">    <span class="built_in">AddNode</span>(std::<span class="built_in">move</span>(node));</span><br><span class="line">    <span class="keyword">return</span> out;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">Status <span class="title">Validate</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Start producing on all nodes</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// Nodes are started in reverse topological order, such that any node</span></span><br><span class="line">  <span class="comment">/// is started before all of its inputs.</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">StartProducing</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Stop producing on all nodes</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// Triggers all sources to stop producing new data.  In order to cleanly stop the plan</span></span><br><span class="line">  <span class="comment">/// will continue to run any tasks that are already in progress.  The caller should</span></span><br><span class="line">  <span class="comment">/// still wait for `finished` to complete before destroying the plan.</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">StopProducing</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief A future which will be marked finished when all tasks have finished.</span></span><br><span class="line">  Future&lt;&gt; <span class="built_in">finished</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Return whether the plan has non-empty metadata</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">HasMetadata</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Return the plan&#x27;s attached metadata</span></span><br><span class="line">  <span class="function">std::shared_ptr&lt;<span class="type">const</span> KeyValueMetadata&gt; <span class="title">metadata</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">std::string <span class="title">ToString</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>上面这段代码生命周期管理还是非常好理解的：</p><ol><li><code>StartProducing</code>: 开始产生数据</li><li><code>StopProducing</code>: 停止产生 <strong>source 数据</strong>。</li></ol><h3 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ARROW_ACERO_EXPORT</span> ExecNode &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">using</span> NodeVector = std::vector&lt;ExecNode*&gt;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">ExecNode</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">const</span> <span class="type">char</span>* <span class="title">kind_name</span><span class="params">()</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The number of inputs expected by this node</span></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">num_inputs</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(inputs_.<span class="built_in">size</span>()); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// This node&#x27;s predecessors in the exec plan</span></span><br><span class="line">  <span class="function"><span class="type">const</span> NodeVector&amp; <span class="title">inputs</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> inputs_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// True if the plan has no output schema (is a sink)</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">is_sink</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> !output_schema_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Labels identifying the function of each input.</span></span><br><span class="line">  <span class="function"><span class="type">const</span> std::vector&lt;std::string&gt;&amp; <span class="title">input_labels</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> input_labels_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// This node&#x27;s successor in the exec plan</span></span><br><span class="line">  <span class="function"><span class="type">const</span> ExecNode* <span class="title">output</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> output_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// The datatypes for batches produced by this node</span></span><br><span class="line">  <span class="function"><span class="type">const</span> std::shared_ptr&lt;Schema&gt;&amp; <span class="title">output_schema</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> output_schema_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// This node&#x27;s exec plan</span></span><br><span class="line">  <span class="function">ExecPlan* <span class="title">plan</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> plan_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief An optional label, for display and debugging</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// There is no guarantee that this value is non-empty or unique.</span></span><br><span class="line">  <span class="function"><span class="type">const</span> std::string&amp; <span class="title">label</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> label_; &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">SetLabel</span><span class="params">(std::string label)</span> </span>&#123; label_ = std::<span class="built_in">move</span>(label); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Validate</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief the ordering of the output batches</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">const</span> Ordering&amp; <span class="title">ordering</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// Transfer input batch to ExecNode</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// A node will typically perform some kind of operation on the batch</span></span><br><span class="line">  <span class="comment">/// and then call InputReceived on its outputs with the result.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// Other nodes may need to accumulate some number of inputs before any</span></span><br><span class="line">  <span class="comment">/// output can be produced.  These nodes will add the batch to some kind</span></span><br><span class="line">  <span class="comment">/// of in-memory accumulation queue and return.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">InputReceived</span><span class="params">(ExecNode* input, ExecBatch batch)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// Mark the inputs finished after the given number of batches.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This may be called before all inputs are received.  This simply fixes</span></span><br><span class="line">  <span class="comment">/// the total number of incoming batches for an input, so that the ExecNode</span></span><br><span class="line">  <span class="comment">/// knows when it has received all input, regardless of order.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">InputFinished</span><span class="params">(ExecNode* input, <span class="type">int</span> total_batches)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Perform any needed initialization</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This hook performs any actions in between creation of ExecPlan and the call to</span></span><br><span class="line">  <span class="comment">/// StartProducing. An example could be Bloom filter pushdown. The order of ExecNodes</span></span><br><span class="line">  <span class="comment">/// that executes this method is undefined, but the calls are made synchronously.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// At this point a node can rely on all inputs &amp; outputs (and the input schemas)</span></span><br><span class="line">  <span class="comment">/// being well defined.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Init</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Start producing</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This must only be called once.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This is typically called automatically by ExecPlan::StartProducing().</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">StartProducing</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Pause producing temporarily</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// \param output Pointer to the output that is full</span></span><br><span class="line">  <span class="comment">/// \param counter Counter used to sequence calls to pause/resume</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This call is a hint that an output node is currently not willing</span></span><br><span class="line">  <span class="comment">/// to receive data.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This may be called any number of times.</span></span><br><span class="line">  <span class="comment">/// However, the node is still free to produce data (which may be difficult</span></span><br><span class="line">  <span class="comment">/// to prevent anyway if data is produced using multiple threads).</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">PauseProducing</span><span class="params">(ExecNode* output, <span class="type">int32_t</span> counter)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Resume producing after a temporary pause</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// \param output Pointer to the output that is now free</span></span><br><span class="line">  <span class="comment">/// \param counter Counter used to sequence calls to pause/resume</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This call is a hint that an output node is willing to receive data again.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This may be called any number of times.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">ResumeProducing</span><span class="params">(ExecNode* output, <span class="type">int32_t</span> counter)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Stop producing new data</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// If this node is a source then the source should stop generating data</span></span><br><span class="line">  <span class="comment">/// as quickly as possible.  If this node is not a source then there is typically</span></span><br><span class="line">  <span class="comment">/// nothing that needs to be done although a node may choose to start ignoring incoming</span></span><br><span class="line">  <span class="comment">/// data.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This method will be called when an error occurs in the plan</span></span><br><span class="line">  <span class="comment">/// This method may also be called by the user if they wish to end a plan early</span></span><br><span class="line">  <span class="comment">/// Finally, this method may be called if a node determines it no longer needs any more</span></span><br><span class="line">  <span class="comment">/// input (for example, a limit node).</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This method may be called multiple times.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This is not a pause.  There will be no way to start the source again after this has</span></span><br><span class="line">  <span class="comment">/// been called.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">StopProducing</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">std::string <span class="title">ToString</span><span class="params">(<span class="type">int</span> indent = <span class="number">0</span>)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">protected</span>:</span><br><span class="line">  <span class="built_in">ExecNode</span>(ExecPlan* plan, NodeVector inputs, std::vector&lt;std::string&gt; input_labels,</span><br><span class="line">           std::shared_ptr&lt;Schema&gt; output_schema);</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">StopProducingImpl</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// Provide extra info to include in the string representation.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> std::string <span class="title">ToStringExtra</span><span class="params">(<span class="type">int</span> indent = <span class="number">0</span>)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  std::atomic&lt;<span class="type">bool</span>&gt; stopped_;</span><br><span class="line">  ExecPlan* plan_;</span><br><span class="line">  std::string label_;</span><br><span class="line"></span><br><span class="line">  NodeVector inputs_;</span><br><span class="line">  std::vector&lt;std::string&gt; input_labels_;</span><br><span class="line"></span><br><span class="line">  std::shared_ptr&lt;Schema&gt; output_schema_;</span><br><span class="line">  ExecNode* output_ = NULLPTR;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这块代码还是比较清晰的，而且考虑了 <code>Pause</code> <code>Resume</code> 等操作的并行性（这里给操作带上了一个外部的 Counter，由外部维护操作的序号，来做定序，没有幂等的需求）。哎我真觉得这个代码非常清晰了。</p><p>暂时无法在飞书文档外展示此内容</p><h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><p><code>TaskScheduler</code> 的代码我没看懂，因此只看 AsyncScheduler 就行。</p><p>这块的代码还是比较奇葩的，<code>AsyncTaskScheduler</code> 会有几个相关的类型：</p><ol><li><code>AsyncTaskScheduler</code></li><li><code>AsyncTaskSchedulerImpl</code>: 具体实现</li><li><code>ThrottledAsyncTaskScheduler</code>: 限流的 Task Scheduler</li><li><code>AsyncTaskGroup</code>: 这个是个比较奇怪的东西，比方说 Scan 的时候，这里会要原本的文件活着，所以成为一个小的调度组。<code>AsyncTaskGroupImpl</code> 是它的一个实现。</li></ol><p>这里简单看一下这里的创建方式就行：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Construct a scheduler</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// \param initial_task The initial task which is responsible for adding</span></span><br><span class="line"><span class="comment">///        the first subtasks to the scheduler.</span></span><br><span class="line"><span class="comment">/// \param abort_callback A callback that will be triggered immediately after a task</span></span><br><span class="line"><span class="comment">///        fails while other tasks may still be running.  Nothing needs to be done here,</span></span><br><span class="line"><span class="comment">///        when a task fails the scheduler will stop accepting new tasks and eventually</span></span><br><span class="line"><span class="comment">///        return the error.  However, this callback can be used to more quickly end</span></span><br><span class="line"><span class="comment">///        long running tasks that have already been submitted.  Defaults to doing</span></span><br><span class="line"><span class="comment">///        nothing.</span></span><br><span class="line"><span class="comment">/// \param stop_token An optional stop token that will allow cancellation of the</span></span><br><span class="line"><span class="comment">///        scheduler.  This will be checked before each task is submitted and, in the</span></span><br><span class="line"><span class="comment">///        event of a cancellation, the scheduler will enter an aborted state. This is</span></span><br><span class="line"><span class="comment">///        a graceful cancellation and submitted tasks will still complete.</span></span><br><span class="line"><span class="comment">/// \return A future that will be completed when the initial task and all subtasks have</span></span><br><span class="line"><span class="comment">///         finished.</span></span><br><span class="line"><span class="type">static</span> Future&lt;&gt; <span class="built_in">Make</span>(</span><br><span class="line">    FnOnce&lt;<span class="built_in">Status</span>(AsyncTaskScheduler*)&gt; initial_task,</span><br><span class="line">    FnOnce&lt;<span class="built_in">void</span>(<span class="type">const</span> Status&amp;)&gt; abort_callback = [](<span class="type">const</span> Status&amp;) &#123;&#125;,</span><br><span class="line">    StopToken stop_token = StopToken::<span class="built_in">Unstoppable</span>());</span><br></pre></td></tr></table></figure><p>注意 Scan 的时候怎么使用的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Future&lt;&gt; <span class="built_in">AddScanTasks</span>(<span class="type">const</span> std::shared_ptr&lt;FragmentScanner&gt;&amp; fragment_scanner) &#123;</span><br><span class="line">  scan_state-&gt;fragment_scanner = fragment_scanner;</span><br><span class="line">  ScanState* state_view = scan_state.<span class="built_in">get</span>();</span><br><span class="line">  Future&lt;&gt; list_and_scan_done = Future&lt;&gt;::<span class="built_in">Make</span>();</span><br><span class="line">  <span class="comment">// Finish callback keeps the scan state alive until all scan tasks done</span></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">StateHolder</span> &#123;</span><br><span class="line">    <span class="function">Status <span class="title">operator</span><span class="params">()</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      list_and_scan_done.<span class="built_in">MarkFinished</span>();</span><br><span class="line">      <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    Future&lt;&gt; list_and_scan_done;</span><br><span class="line">    std::unique_ptr&lt;ScanState&gt; scan_state;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  std::unique_ptr&lt;util::AsyncTaskGroup&gt; scan_tasks = util::AsyncTaskGroup::<span class="built_in">Make</span>(</span><br><span class="line">      node-&gt;batches_throttle_.<span class="built_in">get</span>(),</span><br><span class="line">      StateHolder&#123;list_and_scan_done, std::<span class="built_in">move</span>(scan_state)&#125;);</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; fragment_scanner-&gt;<span class="built_in">NumBatches</span>(); i++) &#123;</span><br><span class="line">    node-&gt;num_batches_.<span class="built_in">fetch_add</span>(<span class="number">1</span>);</span><br><span class="line">    scan_tasks-&gt;<span class="built_in">AddTask</span>(std::<span class="built_in">make_unique</span>&lt;ScanBatchTask&gt;(node, state_view, i));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// The &quot;list fragments&quot; task doesn&#x27;t actually end until the fragments are</span></span><br><span class="line">  <span class="comment">// all scanned.  This allows us to enforce fragment readahead.</span></span><br><span class="line">  <span class="keyword">return</span> list_and_scan_done;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里 <code>scan_state</code> 在 <code>StateHolder</code> 中维护。并且做了 dtor callback。</p><h2 id="Node-Implementions"><a href="#Node-Implementions" class="headerlink" title="Node Implementions"></a>Node Implementions</h2><h3 id="Scan"><a href="#Scan" class="headerlink" title="Scan"></a>Scan</h3><p>ScanNode 采取 Push 的策略。并且可能有一些 Backpressure. 这部分代码可以见于 <code>arrow/dataset/scanner.cc</code></p><p>这里大概逻辑是把 Parquet FileFragment 弄成 Scanner，然后弄成 AsyncRecordBatchGenerator，吐出 RecordBatch</p><h4 id="Unordered-Generator"><a href="#Unordered-Generator" class="headerlink" title="Unordered Generator"></a>Unordered Generator</h4><p>这里会在文件产生的 RecordBatch 上标注一个序，但是不手动定序。</p><h4 id="Ordered-Generator"><a href="#Ordered-Generator" class="headerlink" title="Ordered Generator"></a>Ordered Generator</h4><p>构建在 Unordered Generator 上，排序的 BatchGen</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://substrait.io/">https://substrait.io/</a></li><li><a href="https://dplyr.tidyverse.org/">https://dplyr.tidyverse.org/</a></li><li><a href="https://arrow.apache.org/docs/cpp/streaming_execution.html">https://arrow.apache.org/docs/cpp/streaming_execution.html</a></li><li><a href="https://arrow.apache.org/docs/dev/cpp/streaming_execution.html">https://arrow.apache.org/docs/dev/cpp/streaming_execution.html</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>arrow dataset</title>
      <link href="/2023/07/23/Arrow-Dataset/"/>
      <url>/2023/07/23/Arrow-Dataset/</url>
      
        <content type="html"><![CDATA[<p>Dataset 是 Arrow 中泛化处理 <code>&#123;某种 fs 上, 某种 format&#125;</code> 的多个文件的抽象。在读取文件的时候，通常会有多个数据集合，吐出同一种 Schema。</p><p>有数据集合，那么自然就有单个文件，Dataset 抽象出了 Fragment 的概念。每个 Fragment 对应的范围可以是文件，也可以是 “文件的一部分” ( e.g.: Csv 文件的一定行数，Parquet 文件中的1个 RowGroup）。对于 Fragment 来说，Fragment 的 Schema 可能和数据的 Schema 会有一点区别，Dataset 会在这一层做 Schema Evolution (但是 Arrow 目前，至少 13.0 还不支持 Parquet upcast，只支持少读几列或者多读几列不存在的这种<strong>类似 Project 和包括 Projection</strong> 的搞法），将多部分 Fragment 的 Schema 转化为 Dataset 的 Schema 的逻辑由 <code>FragmentEvolutionStrategy</code> 处理。</p><p>Dataset 有 Discovery 的能力（<code>DatasetFactory</code>）。这部分我觉得有点怪，比如说，它能给定一个目录，然后把这个目录当成 Hive 分区那种方式处理( <code>key=value</code>)。不知道这个算不算一个实用功能，因为在我看来，这块总觉得是应该丢给 Meta 系统来处理的。</p><p>Dataset 可以用来看 Schema 然后 Scan，产生一个对应的 Scanner 对象（有 Scanner，里面持有 FragmentScanner）。产生对应的 RecordBatch。不过我看好像还没有针对 Iceberg 之类的处理的逻辑。在 Scan 的时候，这里会有一定的预读策略，不过这几块的逻辑基本是给 Acero 准备的，有的地方策略看起来还是挺奇怪的，比如基本是一个 push-based 的模型，不断 push 具体的内容。</p><p>此外，对于 Scan 来说可以指定对应策略，比如 Prefetch 的属性、是否要求 Scan 出来的数据满足 Ordering，e.g.:</p><p><img src="https://image.mwish.me/blog-image/whiteboard_exported_image.png" alt="whiteboard_exported_image"></p><p>目前在一种 DataSet 里面，有的 Dataset 只能处理一种 Format （Parquet、CSV…）的数据，它们可以靠 <code>UnionDataset</code> 连接起来处理。而 FileSystem 上的内容则靠 <code>FileSystemDataset</code>。之后我们会了解这些东西是怎么组合起来的。</p><p>上面的 Dataset 部分和 Acero 是交融的，Dataset 可以利用 Acero 的部分来 Scan，而 Acero 又借助了 Fragments:</p><p><img src="https://image.mwish.me/blog-image/whiteboard_exported_image-2.png" alt="whiteboard_exported_image-2"></p><p>Arrow 还允许写 Dataset，它提供了：</p><ol><li>DatasetWriter</li><li>SinkNode</li></ol><p>这里组织和之前差不多，不过老实说我感觉 Arrow 对写这块没那么熟悉，所以写链路上感觉打磨的不是很多。</p><h2 id="Fragment"><a href="#Fragment" class="headerlink" title="Fragment"></a>Fragment</h2><p>Fragment 是 Dataset 的「一部分」抽象为一个子单元，可能会有一些 Partition 约束</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ARROW_DS_EXPORT</span> <span class="title">Fragment</span> :</span> public <span class="built_in">std</span>::enable_shared_from_this&lt;Fragment&gt; &#123;</span><br><span class="line"> public:</span><br><span class="line">  <span class="comment">/// \brief An expression that represents no known partition information</span></span><br><span class="line">  <span class="type">static</span> <span class="type">const</span> compute::Expression kNoPartitionInformation;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Return the physical schema of the Fragment.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// The physical schema is also called the writer schema.</span></span><br><span class="line">  <span class="comment">/// This method is blocking and may suffer from high latency filesystem.</span></span><br><span class="line">  <span class="comment">/// The schema is cached after being read once, or may be specified at construction.</span></span><br><span class="line">  Result&lt;<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Schema&gt;&gt; ReadPhysicalSchema();</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// An asynchronous version of Scan</span></span><br><span class="line">  virtual Result&lt;RecordBatchGenerator&gt; <span class="title function_">ScanBatchesAsync</span><span class="params">(</span></span><br><span class="line"><span class="params">      <span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;ScanOptions&gt;&amp; options)</span> = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Inspect a fragment to learn basic information</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This will be called before a scan and a fragment should attach whatever</span></span><br><span class="line">  <span class="comment">/// information will be needed to figure out an evolution strategy.  This information</span></span><br><span class="line">  <span class="comment">/// will then be passed to the call to BeginScan</span></span><br><span class="line">  virtual Future&lt;<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;InspectedFragment&gt;&gt; InspectFragment(</span><br><span class="line">      <span class="type">const</span> FragmentScanOptions* format_options, compute::ExecContext* exec_context);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Start a scan operation</span></span><br><span class="line">  virtual Future&lt;<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;FragmentScanner&gt;&gt; BeginScan(</span><br><span class="line">      <span class="type">const</span> FragmentScanRequest&amp; request, <span class="type">const</span> InspectedFragment&amp; inspected_fragment,</span><br><span class="line">      <span class="type">const</span> FragmentScanOptions* format_options, compute::ExecContext* exec_context);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Count the number of rows in this fragment matching the filter using metadata</span></span><br><span class="line">  <span class="comment">/// only. That is, this method may perform I/O, but will not load data.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// If this is not possible, resolve with an empty optional. The fragment can perform</span></span><br><span class="line">  <span class="comment">/// I/O (e.g. to read metadata) before it deciding whether it can satisfy the request.</span></span><br><span class="line">  virtual Future&lt;<span class="built_in">std</span>::optional&lt;<span class="type">int64_t</span>&gt;&gt; CountRows(</span><br><span class="line">      compute::Expression predicate, <span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;ScanOptions&gt;&amp; options);</span><br><span class="line"></span><br><span class="line">  virtual <span class="built_in">std</span>::<span class="built_in">string</span> <span class="title function_">type_name</span><span class="params">()</span> <span class="type">const</span> = <span class="number">0</span>;</span><br><span class="line">  virtual <span class="built_in">std</span>::<span class="built_in">string</span> <span class="title function_">ToString</span><span class="params">()</span> <span class="type">const</span> &#123; <span class="keyword">return</span> type_name(); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief An expression which evaluates to true for all data viewed by this</span></span><br><span class="line">  <span class="comment">/// Fragment.</span></span><br><span class="line">  <span class="type">const</span> compute::Expression&amp; <span class="title function_">partition_expression</span><span class="params">()</span> <span class="type">const</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这部分逻辑比较简单。</p><ol><li><code>FragmentScanOptions</code> 是一套多态接口，允许你自己定义</li><li><code>InspectFragments</code> 会允许你去 Inspect 对应的内容</li><li><code>CountRow</code> 会尝试（注意，这个不一定真的返回）告诉你有多少行，它会做成 Best Effort + 准确的。比如它读 Parquet，如果发现自己某个 Expression 没法判断是否满足，就会快速熔断，返回 <code>std::nullopt</code>.</li></ol><h3 id="FileFragment"><a href="#FileFragment" class="headerlink" title="FileFragment"></a>FileFragment</h3><p>主要的 Fragment 是 FileFragment，是在某种 fs 上，给定某个 Schema 读取，有着 Format 的固定单元。FileFragment 对应某种文件格式，但是不一定对应一个文件。比如 Parquet 的 FileFragment 就可能对应 File 下的一到数个 RowGroup。</p><p>这里面包装了如下的类型：</p><ul><li>FileSource :  <code>((fileName, fs) or (input buffer), compression..)</code>, 允许用户在上面打开一个 <code>RandomAccessFile</code> 或者 <code>InputStream</code> (老实说我觉得 InputStream 比较自然…不过 OSS 这种做 RandomAccess 的话要包一堆 pread 之类的语义，也不是不行）</li><li>FileFormat : 相当于 <code>FileFragment</code> 的工厂，包装了一些 Fragment 的接口，然后根据 <code>FileSource</code> 之类的创建 FileFragment，和<strong>所有</strong> Fragment 上的接口. 这里感觉不会创建 RowGroup 上的 Fragment。FileFormat 对每个文件类型需要实现一遍子类。此外，每一种 Format 工厂上还有一个 <code>FragmentScanOptions</code>，<strong>作为默认的 Scan 配置</strong>。这种 Format 作为工厂的配置代码没啥奇特的，不过作为框架代码还是可以拿来抄的</li></ul><ol><li><p>在 FileFormat 下有多种 Format，比如 Csv, Ipc, Json, Parquet。作为 Dataset 的抽象。</p></li><li><p><code>FileFragment</code> == <code>FileSource + FileFormat</code>. 包装了一个 <code>FileFormat</code> 和 <code>FileSource</code>，完成对应的需求。</p></li></ol><p>我们以 ParquetFileFragment 和 ParquetFileFormat 为例</p><ol><li><code>ParquetFileFragment</code>: 包括 <code>SchemaManifest</code>、文件的 <code>metadata_</code>，此外还有一些 Partition Guarantee Expression、RowGroup 裁剪表达式的内容</li><li><code>ParquetFileFormat</code>: 包装了上层的一个奇怪的 ReaderOptions，和 default config</li></ol><p>在 Format 层实现的：</p><ul><li>IsSupport: 看一下 Footer，查看一下文件使用的版本呀编码呀自己是否支持</li><li><code>GetReader</code> / <code>GetReaderAsync</code>: 打开 Reader</li><li>读取 Schema</li><li>读取的时候做 Schema Projection (这里包含把外部读取的 Schema 映射到内部，可以看 <code>InferColumnProjection</code>, 我觉得这块写的怪怪的，甚至还有检查 duplicate fields name 的）</li></ul><p>在 <code>ParquetFileFragment</code> 层，默认会「打开 Footer，然后包含所有的 RowGroup」，然后外层用户可以：</p><ol><li>下推 Filter，这里会把每个 RowGroup 的信息抽出来，抽成一个 Expression，然后看这个 Expression &amp;&amp; 用户传入的 Filter 如果一定是 False 的话，那么可以尝试裁剪掉</li><li>允许 Subset，取这里的一小部分</li><li>在打开 Scanner 的时候 (<code>ParquetFileFormat::GetReaderAsync</code>)，才会打开 InputStream ( <code>FileSource::open</code>)</li></ol><p>我们可以简单看一下 Filter 的代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">Result&lt;<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;&gt; ParquetFileFragment::FilterRowGroups(</span><br><span class="line">    compute::Expression predicate) &#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt; row_groups;</span><br><span class="line">  ARROW_ASSIGN_OR_RAISE(<span class="keyword">auto</span> expressions, TestRowGroups(<span class="built_in">std</span>::move(predicate)));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> lock = physical_schema_mutex_.Lock();</span><br><span class="line">  DCHECK(expressions.empty() || (expressions.size() == row_groups_-&gt;size()));</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; expressions.size(); i++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (expressions[i].IsSatisfiable()) &#123;</span><br><span class="line">      row_groups.push_back(row_groups_-&gt;at(i));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> row_groups;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Result&lt;<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;compute::Expression&gt;&gt; ParquetFileFragment::TestRowGroups(</span><br><span class="line">    compute::Expression predicate) &#123;</span><br><span class="line">  <span class="keyword">auto</span> lock = physical_schema_mutex_.Lock();</span><br><span class="line"></span><br><span class="line">  DCHECK_NE(metadata_, nullptr);</span><br><span class="line">  ARROW_ASSIGN_OR_RAISE(</span><br><span class="line">      predicate, SimplifyWithGuarantee(<span class="built_in">std</span>::move(predicate), partition_expression_));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!predicate.IsSatisfiable()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;compute::Expression&gt;&#123;&#125;;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">const</span> FieldRef&amp; ref : FieldsInExpression(predicate)) &#123;</span><br><span class="line">    ARROW_ASSIGN_OR_RAISE(<span class="keyword">auto</span> match, ref.FindOneOrNone(*physical_schema_));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (match.empty()) <span class="keyword">continue</span>;</span><br><span class="line">    <span class="keyword">if</span> (statistics_expressions_complete_[match[<span class="number">0</span>]]) <span class="keyword">continue</span>;</span><br><span class="line">    statistics_expressions_complete_[match[<span class="number">0</span>]] = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> SchemaField&amp; schema_field = manifest_-&gt;schema_fields[match[<span class="number">0</span>]];</span><br><span class="line">    <span class="type">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> row_group : *row_groups_) &#123;</span><br><span class="line">      <span class="keyword">auto</span> row_group_metadata = metadata_-&gt;RowGroup(row_group);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">auto</span> minmax =</span><br><span class="line">              ColumnChunkStatisticsAsExpression(schema_field, *row_group_metadata)) &#123;</span><br><span class="line">        FoldingAnd(&amp;statistics_expressions_[i], <span class="built_in">std</span>::move(*minmax));</span><br><span class="line">        ARROW_ASSIGN_OR_RAISE(statistics_expressions_[i],</span><br><span class="line">                              statistics_expressions_[i].Bind(*physical_schema_));</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      ++i;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;compute::Expression&gt; <span class="title function_">row_groups</span><span class="params">(row_groups_-&gt;size())</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; row_groups_-&gt;size(); ++i) &#123;</span><br><span class="line">    ARROW_ASSIGN_OR_RAISE(<span class="keyword">auto</span> row_group_predicate,</span><br><span class="line">                          SimplifyWithGuarantee(predicate, statistics_expressions_[i]));</span><br><span class="line">    row_groups[i] = <span class="built_in">std</span>::move(row_group_predicate);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> row_groups;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>(我感觉这块虽然没问题，但是 Column As Expr 看着有点别扭，而且这种模式在搞 BloomFilter 的时候，就不是很方便了。之后看看 Velox 和 Impala 之类的是怎么搞 Column Filter 的，比方说你其实有点不那么好把 BF 抽出来作为一个表达式然后放这里（其实也不是不行））</p><p>这里取 Subset 的时候，相当于 <code>FileMetadata</code> 和 <code>SchemaManifest</code> 这几个东西会传过去，不会重复 Reopen footer.</p><h3 id="FileWriter"><a href="#FileWriter" class="headerlink" title="FileWriter"></a>FileWriter</h3><p><code>FileWriter</code> 包装了不同 Format 文件的写接口，可以给 SinkNode 来写入数据，不过我觉得写的很简单也很挫，随便看看就行了。</p><h3 id="上层操作"><a href="#上层操作" class="headerlink" title="上层操作"></a>上层操作</h3><p><code>FragmentEvolutionStrategy</code> 在上层处理了一些 Evolution</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \brief Rules for converting the dataset schema to and from fragment schemas</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ARROW_DS_EXPORT</span> <span class="title">FragmentEvolutionStrategy</span> &#123;</span></span><br><span class="line"> public:</span><br><span class="line">  <span class="comment">/// This instance will only be destroyed when all scan operations for the</span></span><br><span class="line">  <span class="comment">/// fragment have completed.</span></span><br><span class="line">  virtual ~FragmentEvolutionStrategy() = <span class="keyword">default</span>;</span><br><span class="line">  <span class="comment">/// \brief A guarantee that applies to all batches of this fragment</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// For example, if a fragment is missing one of the fields in the dataset</span></span><br><span class="line">  <span class="comment">/// schema then a typical evolution strategy is to set that field to null.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// So if the column at index 3 is missing then the guarantee is</span></span><br><span class="line">  <span class="comment">/// FieldRef(3) == null</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// Individual field guarantees should be AND&#x27;d together and returned</span></span><br><span class="line">  <span class="comment">/// as a single expression.</span></span><br><span class="line">  virtual Result&lt;compute::Expression&gt; <span class="title function_">GetGuarantee</span><span class="params">(</span></span><br><span class="line"><span class="params">      <span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;FieldPath&gt;&amp; dataset_schema_selection)</span> <span class="type">const</span> = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Return a fragment schema selection given a dataset schema selection</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// For example, if the user wants fields 2 &amp; 4 of the dataset schema and</span></span><br><span class="line">  <span class="comment">/// in this fragment the field 2 is missing and the field 4 is at index 1 then</span></span><br><span class="line">  <span class="comment">/// this should return &#123;1&#125;</span></span><br><span class="line">  virtual Result&lt;<span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;FragmentSelection&gt;&gt; DevolveSelection(</span><br><span class="line">      <span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;FieldPath&gt;&amp; dataset_schema_selection) <span class="type">const</span> = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Return a filter expression bound to the fragment schema given</span></span><br><span class="line">  <span class="comment">///        a filter expression bound to the dataset schema</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// The dataset scan filter will first be simplified by the guarantee returned</span></span><br><span class="line">  <span class="comment">/// by GetGuarantee.  This means an evolution that only handles dropping or casting</span></span><br><span class="line">  <span class="comment">/// fields doesn&#x27;t need to do anything here except return the given filter.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// On the other hand, an evolution that is doing some kind of aliasing will likely</span></span><br><span class="line">  <span class="comment">/// need to convert field references in the filter to the aliased field references</span></span><br><span class="line">  <span class="comment">/// where appropriate.</span></span><br><span class="line">  virtual Result&lt;compute::Expression&gt; <span class="title function_">DevolveFilter</span><span class="params">(</span></span><br><span class="line"><span class="params">      <span class="type">const</span> compute::Expression&amp; filter)</span> <span class="type">const</span> = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Convert a batch from the fragment schema to the dataset schema</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// Typically this involves casting columns from the data type stored on disk</span></span><br><span class="line">  <span class="comment">/// to the data type of the dataset schema.  For example, this fragment might</span></span><br><span class="line">  <span class="comment">/// have columns stored as int32 and the dataset schema might have int64 for</span></span><br><span class="line">  <span class="comment">/// the column.  In this case we should cast the column from int32 to int64.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// Note: A fragment may perform this cast as the data is read from disk.  In</span></span><br><span class="line">  <span class="comment">/// that case a cast might not be needed.</span></span><br><span class="line">  virtual Result&lt;compute::ExecBatch&gt; <span class="title function_">EvolveBatch</span><span class="params">(</span></span><br><span class="line"><span class="params">      <span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;RecordBatch&gt;&amp; batch,</span></span><br><span class="line"><span class="params">      <span class="type">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;FieldPath&gt;&amp; dataset_selection,</span></span><br><span class="line"><span class="params">      <span class="type">const</span> FragmentSelection&amp; selection)</span> <span class="type">const</span> = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Return a string description of this strategy</span></span><br><span class="line">  virtual <span class="built_in">std</span>::<span class="built_in">string</span> <span class="title function_">ToString</span><span class="params">()</span> <span class="type">const</span> = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>每个 Fragment 在文件级别会有一些 Guarantee，表达：</p><p>比如这个 Fragment 如果 Field 少了一个，那么整体还是可读的，但是这个 Batch 可能会有一些 Gurantee。比如读取 <code>&lt;a: int, b:int, c:int&gt;</code> 三列，文件只有 <code>&lt;a: int, b:int&gt;</code>，那么 c 可以补齐，这个时候会有一些 <code>EvolveBatch</code>(把 Batch 补齐)，或者 <code>Gurantee</code>(保证 <code>c == null</code> ) 的操作，给上面提供一些处理的帮助。这个 <code>DevolveFilter</code> 能够把对应的 Filter 补成对应的，或者补充一些别的重新映射之类的操作（比如  <code>&lt;a: int, c:int, b:int&gt;</code> ). 这部分方便做 Resolve.</p><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>Dataset 是 Fragment 的集合，表现为一组可以被 arrow 捞出来处理的整体，这些 Fragment 可能按照一些分区规则之类的方式被排序。Dataset 可以处理的逻辑有：</p><ol><li>ProjectSchema: 允许 Dataset 上套一层 Project，Project 甚至可以是一些表达式</li><li>产生 Scan 对象</li></ol><p>这么说来这套东西还是挺简单的是不…并不是，我们可以看看这套类型是怎么组合的:</p><p><img src="https://image.mwish.me/blog-image/whiteboard_exported_image-3.png" alt="whiteboard_exported_image-3"></p><p><code>DatasetFactory</code> 可以帮助构造不同类型的 <code>Dataset</code>，实际上这里主要目的是 List 出对应的目录然后构建到一起。</p><p>实际上，这里面大概逻辑是：</p><ol><li>用户可以用 <code>FileSystemDatasetFactory</code> 之类的，指定对应的 S3 或者 Local 等目录，List Plan 到对应的文件</li><li>构建出一组 FileSystemDataset，然后用 Union 连接到一起</li><li>拿到对应的 Fragment，然后允许对 Fragment 打开 + 预读。可以创建 <code>FragmentDataset</code> 然后丢给 Acero</li><li>用 Acero 之类的 Scanner 去做对应的 Scan</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Distributed Transaction in DynamoDB</title>
      <link href="/2023/07/15/Distributed-Transaction-in-DynamoDB/"/>
      <url>/2023/07/15/Distributed-Transaction-in-DynamoDB/</url>
      
        <content type="html"><![CDATA[<p>DynamoDB 是一个 Dynamo 之后亚马逊主要推进的一个 K-V 型产品，定位上是一个强一致、多租户的 key-value 存储。DynamoDB 产品做的比较早，但是论文发布在 ATC’22 上 [1] 。</p><p>ATC’23 的论文 Distributed Transactions at Scale in Amazon DynamoDB 介绍了 DynamoDB 是怎么支持高性能的分布式事务的，本来我是比较期待他们整什么特别好的活，但实际上看前三节的时候有一种「感觉不如 ByteGraph…事务…」的感觉。本文前几节讲述了 DynamoDB 事务的负载和实现，它的负载主要是一个 Point Get 或者多行事务读，单row/多row Update 之类类似 RocksDB 但没有 Iterator 的场景（还有一个操作是 <code>condition ? op1 : op2</code> 这种类似 RocksDB Merge 的场景），和在这种场景下，如何不依赖 MVCC 和锁服务、依靠本地时间戳实现 OCC 事务。本文的重点在第四节，描述了在这种特定负载下，如何通过 Thomas Rule 之类的方式来做 OCC Reorder。</p><p>笔者看完觉得亮点在第四节，虽然看着有一点失望，但是无疑本文能帮我一定程度上 recap 之前做的分布式事务，也方便看看，它为什么这么做，特定领域的优化有没有前途。和语义化处理事务的一些实现逻辑。</p><p>在论文里，他们的描述如下（首先需要了解他们是一个 primary key-value 的模型）：</p><ul><li>事务相对于维护成 session，只是在单个单个请求里面提交（天啊这不是我们 bg 的梗吗）</li><li>采用乐观事务来实现（用户真的不会有意见吗）</li><li>对非事务操作（Get / Put）、1PC 等场景有特定优化，让事务逻辑尽量不影响它们。同时这些操作也不会 break 事务操作的逻辑</li><li>不用 MVCC，事务本地直接更新。作者觉得多版本开放在存储上太复杂了（感觉甚至包括用 write intent 这种形式），所以做了一个单版本的事务（我本人对这个不置可否，因为感觉它们没有 scan 负载，所以可以尽量做简单）</li><li>用事务的 start-ts 来做时间戳，时间戳从亚马逊的单独的服务上处理（类似 TrueTime，但是看论文描述说是会有点偏差的，估计就是 NTP 矫正有时间偏差有个 lower-bound 的时钟？）</li></ul><p>(题外话，在 ByteGraph 论文里面重点描述了这种场景下 Retry 可能带来的问题，但是 DynamoDB 好像没强调这个，他们只强调了写请求会带上一个 client id，感觉没有深究，不知道是他们没做还是什么情况，如下图）</p><p><img src="https://image.mwish.me/blog-image/998926934240291277.png" alt="img"></p><h2 id="DynamoDB-Interfaces"><a href="#DynamoDB-Interfaces" class="headerlink" title="DynamoDB Interfaces"></a>DynamoDB Interfaces</h2><p>DynamoDB 提供了操作 Table 或者 Index 的抽象 . 下面是它开放的非事务 API: </p><p><img src="https://image.mwish.me/blog-image/6696684328966579519.png" alt="img"></p><p>对于事务 API，我们可以列出来然后看看具体代码的写法（确实有点像 RocksDB）</p><p><img src="https://image.mwish.me/blog-image/7121389673865386713.png" alt="img"></p><ul><li>它的 <code>TransactGetItems</code> 维护的是一个类似 SI 的语义（ RC 应该直接走读接口就行）</li><li>写操作会<strong>保证自己是幂等</strong>的，具体而言它允许用户带上一个 client-id，然后保证10min的窗口内这里是会检查是否重复的（但是论文没有强调这块具体的实现，有点像是在内存或者存储上维护了一个 Purge Window，因为这里比较恶心的情况是 client-id 和 txn-id 逻辑不一定在一起，除非它做了什么特殊的保证操作或者在节点内存上跟着事务一起维护了这个窗口，我感觉都能做但是就有点麻烦。难道是用这个生成 transaction-id…?）</li></ul><p><img src="https://image.mwish.me/blog-image/6182433940045300901.png" alt="img"></p><p>上面的逻辑描述了 DynamoDB 先 Check，满足的话就去更新并且创建订单（总觉得这个组织还是比较平坦的，不知道允许不允许复杂一点的逻辑结构，看了下文档感觉不太建议用户这么搞，估计就是个简单的 check + merge）</p><h2 id="Transaction-Execution-Basics"><a href="#Transaction-Execution-Basics" class="headerlink" title="Transaction Execution: Basics"></a>Transaction Execution: Basics</h2><p>这节介绍了 DynamoDB 的事务执行，之所以叫 Basic 是因为这节介绍的是大概的框架，而没有介绍 OCC 相关的核心优化。</p><p><img src="https://image.mwish.me/blog-image/6547853856850566784.png" alt="img"></p><p>在鉴权等操作之后，事务请求（不包括非事务请求）都会被发给 Transaction Coordinator。Transaction Coordinator 是一个无状态的节点，任何一个 Transaction Coordinator 都可以充当一个事务的 coordinator。</p><p>在 coordinator 上，事务会被 assign 一个 start-ts （使用 AWS time-sync service [3]，一个 NTP 池）作为事务操作的 ts，然后要求按照 ts 做 ordering。这里比较 trick，因为它这里不依赖 TrueTime、Lock 而且做的还是 OCC，我觉得这段还是得比较谨慎的判断 corner case 的…</p><h3 id="Write-Transaction-Protocols"><a href="#Write-Transaction-Protocols" class="headerlink" title="Write Transaction Protocols"></a>Write Transaction Protocols</h3><p>这里的协议是个 2PC:</p><p><img src="https://image.mwish.me/blog-image/4742757250468458028.png" alt="img"></p><ol><li>Prepare</li><li>Commit / Cancel</li><li>(post) 去 Ledger 记录事务的 FIN 信息<ol><li>这里面，对于 DynamoDB，每个 row (或者说 item) 有一个 <code>&#123;timestamp(commit时更新), update-txn-id(prepare时更新,commit清理)&#125;</code> 的标记, 作为事务更新的标记，这里有一点需要注意：</li></ol></li></ol><ul><li>对于一般的数据库，这种一般是插入一条边，带上自己的 ts/txn-id 作为锁，然后等 commit 阶段这条记录变得对外部事务可见。可能旧的 row 会带上 end-ts。当然也有一些系统是 implicit 完成这个约束的，比如构建在 kv 系统上的 Percolator</li><li>对于 DynamoDB，这一组标记仅仅是一个 update-locking，在 Prepare 阶段在旧的数据上标记这个 row 的锁被占用了，并且在 commit 阶段可以做检查（commit 阶段的检查应该和重试之类的也有关系，一般分布式事务可能需要有一个 background resolve 之类的后台清理之类的流程），<strong>这组「锁」在事务提交之后，它认为 txn-id 就可以 discard 了。</strong></li></ul><p><img src="https://image.mwish.me/blog-image/5160409351946106530.png" alt="img"></p><p>Coordinator 上正常链路的操作还是很简单的。Prepare 正常链路的协议如下：</p><p><img src="https://image.mwish.me/blog-image/3483436806349992495.png" alt="img"></p><p>这里注意到几个地方：</p><ul><li>只有通过了 check 才能推进</li><li>如果现在操作被另一个事务(<code>tx</code>)占有了，时间戳比 tx 小直接就返回了，但是比更新大还是会失败，因为这上面有 <code>ongoing</code></li><li>因为删除一条记录这个物理记录就会不存在了，这个会维护 <code>partition</code> 上的 <code>maxDeleteTimeStamp</code>。然后如果插入的时间戳小于 <code>maxDeleteTimestamp</code>，表示可能和对这条边的删除冲突，所以不得推进。（这里 bytegraph 主要是靠 lock 来维护的，然后 binlog 需要维护一个 delete set）</li><li>如果遇到冲突或者失败，这里就会 cancel 自己（感觉在高冲突场景下，这个要么得优化要么得甩锅给用户）</li><li>需要在节点上提交成功再返回，感觉没有做 async commit</li><li>感觉它们没有描述一个事务表，在 coordinator 上好像也没有存储，这个感觉是对他们来说算得上独特的地方，因为这样感觉就不好确定事务最终的状态或者所有 participants 了。这个后面有讲 Ledger。</li></ul><p><img src="https://image.mwish.me/blog-image/6510681213383560754.png" alt="img"></p><p>Commit 阶段，比较有趣的是它会做一个 <code>item.ongoing == commit-txn</code> 的检查，这个和后面几节介绍的 recover 有关。</p><p>题外话，我觉得这里很重要一部分是 Merge 操作的原子性和读写集。这里看了下官方文档：</p><blockquote><p>You can’t target the same item with multiple operations within the same transaction. For example, you can’t perform a <code>ConditionCheck</code> and also an <code>Update</code> action on the same item in the same transaction.</p></blockquote><p>我总觉得 <code>condition</code> 的 item 也得上个写标记。</p><h3 id="Naive-Read-Transaction-Protocol"><a href="#Naive-Read-Transaction-Protocol" class="headerlink" title="(Naive) Read Transaction Protocol"></a>(Naive) Read Transaction Protocol</h3><p>DynamoDB 不想和 TS Protocol 一样维护一个 read-ts 标记。所以才用了两阶段读（类似 Hekaton OCC 那套）：</p><ol><li>Phase1: 查看读的 item 是否都没有 on-going 事务，如果有的话，返回失败，否则记录 item LSN</li><li>Phase2: 读完之后再次检查 LSN 有没有变更</li></ol><p>这个实际上过于 Naive 了，所以第四节会讲这部分怎么进行优化。（妈的又引入了一个 LSN 的概念，你用 ts 会死？）</p><h3 id="Recovery"><a href="#Recovery" class="headerlink" title="Recovery"></a>Recovery</h3><p>因为 Paxos 协议，所以 Participant Failed 是很好处理的，但是 Coordinator Failed 可能会丢失事务执行的上下文（Percolator 类的协议会有 Primary 存储对应事务的上下文，DynamoDB 没有说，这个可以节省一轮提交时候的 rpc，但是感觉对 resolve 来说会有一定负担）。这里有个后台 scanner 去扫没完成的事务，然后尝试交给一个新的 Coordinator 来 Resolve。</p><p>论文提到 transaction 可以并行 resolve，没啥问题，但是比较恶心的是，如果你去 resolve:</p><ul><li>你怎么定义这个 txn 是 abort 还是 commit 呢？</li><li>你怎么找到所有的 participants 呢？</li></ul><p>这里它们没有 async commit，但是也不能看到一个 abort 一个，要不然最终状态又问题，但论文提到了 <strong>Ledger 来存储事务的状态</strong>。（论文里没有提到它是不是同步写 Ledger，不过我觉得应该是，这样 resolve 的时候可以找到所有的 Participants，然后再去 resolve）</p><p>Ledger 本身是 DynamoDB 上一个特殊的表，用这个来处理相关的事务逻辑，Storage 节点也会主动把没完成的事务上报，然后提醒上面主动清理（BG 也有这套逻辑，害，感觉他们做的没啥啊 XD）</p><h2 id="Adapting-timestamp-ordering-for-key-value-operations"><a href="#Adapting-timestamp-ordering-for-key-value-operations" class="headerlink" title="Adapting timestamp ordering for key-value operations"></a>Adapting timestamp ordering for key-value operations</h2><p>DynamoDB 区分出了 Delete / Partial Update / Insert / Upsert(Put) 之类的语义（里面有些没直接说，但是大致是这个意思）。然后应用了一些 OCC 上的经典 Rules，同时把非事务的操作也囊括进来了（很难避免事务和非事务操作在某些方面上的冲突）</p><h3 id="PointGet-始终会成功"><a href="#PointGet-始终会成功" class="headerlink" title="PointGet 始终会成功"></a>PointGet 始终会成功</h3><p>读保证 RC 语义即可，可以看做它的时间戳：</p><ul><li>大于等于已经提交的事务</li><li>小于 Prepare 的事务</li></ul><p>反正 Point Get，在这个 Partial Order 的系统没有什么要和别人同步的。这个不会走 txn coordinator，直接路由到 Storage Node 就行了。</p><h3 id="Single-Put-可以直接写没有-Prepare-的-row"><a href="#Single-Put-可以直接写没有-Prepare-的-row" class="headerlink" title="Single Put 可以直接写没有 Prepare 的 row"></a>Single Put 可以直接写没有 Prepare 的 row</h3><p>首先注意这里不会走 coordinator 节点，直接路由给 Storage。</p><p>这里单点的直接写是可以的，发现没有 Prepare 的 row 的时候，可以直接写入（Delete/Update/Put…）。如果是 checked-write 的话就不太行，这里论文也没太仔细论证，我感觉这个时间戳还是比较复杂的，类似 PolarDB-X 设计上的 1PC 的流程了</p><h3 id="Single-Put-可以直接-Buffer-写没有-Prepare-的-row"><a href="#Single-Put-可以直接-Buffer-写没有-Prepare-的-row" class="headerlink" title="Single Put 可以直接 Buffer 写没有 Prepare 的 row"></a>Single Put 可以直接 Buffer 写没有 Prepare 的 row</h3><p>对于有 Prepare 的 row，这里可能会 Buffer 写请求然后分配一个 Later Timestamp。</p><p>这里它们还提了一个 further optimization:</p><ul><li>如果是 unconditional Put/Delete，这里可以直接覆盖然后返回成功，之前的事务成功与否都不可见（类似 Thomas Rule 了，不同的区别是，Thomas Rule 可能要处理 Cascade Abort，但对于 DynamoDB，这类 1PC 操作既然做了就是一定成功的，不过我觉得这套东西实现的时候还是挺恶心的，估计不好查问题）。</li></ul><h3 id="对于最新写入是覆盖写的操作，旧时间戳的事务写可以认为与它无冲突"><a href="#对于最新写入是覆盖写的操作，旧时间戳的事务写可以认为与它无冲突" class="headerlink" title="对于最新写入是覆盖写的操作，旧时间戳的事务写可以认为与它无冲突"></a>对于最新写入是覆盖写的操作，旧时间戳的事务写可以认为与它无冲突</h3><p>这个比较好理解，和上面一条原则差不多。但我觉得搞得太复杂了，对于 checked-write 这类 Merge 操作那你也要算上，这个本身时间顺序就从一个 ts 全序变成一坨 start-ts 和 arrive-ts 很混乱的东西了。</p><h3 id="多条写同一-row-的-Put-Delete-事务可以-batch-prepare"><a href="#多条写同一-row-的-Put-Delete-事务可以-batch-prepare" class="headerlink" title="多条写同一 row 的 Put/Delete 事务可以 batch prepare"></a>多条写同一 row 的 Put/Delete 事务可以 batch prepare</h3><p>这条我没读太懂，这怎么敢的…把 Prepared 变成一组 <code>vector</code>?然后提交的时候更新记录，从 vector 移除自己？</p><p>如果是 partial update，那么需要全序，否则可以并行 prepare。</p><p>我还是那个问题，你 checked-update 要排序怎么办。。。感觉我就没理解这个 check 的语义…如果 check 的语义就是检查元数据的话倒是没问题，但是这个包括检查数据，估计要么走写协议，要么走读协议，不然看着非常别扭。</p><h3 id="Read-可以不用走-OCC-的两轮流程"><a href="#Read-可以不用走-OCC-的两轮流程" class="headerlink" title="Read 可以不用走 OCC 的两轮流程"></a>Read 可以不用走 OCC 的两轮流程</h3><blockquote><p>This GetItemWithTimestamp operation returns the latest value of the item if its last write timestamp is earlier than the given read timestamp and if any prepared transactions have later timestamps, and otherwise rejects the request.</p></blockquote><p>这部分概念简单，但是有一个分布式系统时间戳回退的问题，这部分有点像 TiDB 的 async-commit 提到的读水位维护。要求后续更新 row 不能低于这个 Max-Row-Read-Ts。</p><p>题外话，这傻逼文章之前还说不想维护 read-ts，这下全回来了。</p><h3 id="写同一个-Partition-的事务可以走-1PC"><a href="#写同一个-Partition-的事务可以走-1PC" class="headerlink" title="写同一个 Partition 的事务可以走 1PC"></a>写同一个 Partition 的事务可以走 1PC</h3><p>废话。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文描述了 DynamoDB 的分布式事务处理，亮点是相关的语义，但笔者觉得：</p><ol><li>它缺少 scan 的场景，在 scan 场景下，DynamoDB 的读处理将变成一堆废物。不过反过来想，如果没有 Scan 支持，那我们也不一定需要做一个 MVCC 的系统</li><li>特定语义的区分。根据 Update 区分为不同语义和区分为是否是事务写，来做一些特定的事务优化。这些优化不是通用的，而且可能 break 系统 invariant，但是可能确实能优化一些特定场景。</li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li>Amazon DynamoDB: A Scalable, Predictably Performant, and Fully Managed NoSQL Database Service <a href="https://www.usenix.org/conference/atc22/presentation/elhemali">https://www.usenix.org/conference/atc22/presentation/elhemali</a></li><li>DynamoDB 事务相关的文档 <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html#transaction-conflict-handling">https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/transaction-apis.html#transaction-conflict-handling</a></li><li>AWS Time Sync <a href="https://aws.amazon.com/cn/about-aws/whats-new/2022/11/amazon-time-sync-internet-public-ntp-service/">https://aws.amazon.com/cn/about-aws/whats-new/2022/11/amazon-time-sync-internet-public-ntp-service/</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>arrow expression</title>
      <link href="/2023/07/06/arrow-expression/"/>
      <url>/2023/07/06/arrow-expression/</url>
      
        <content type="html"><![CDATA[<p>Expression，顾名思义，是 arrow 中计算的表达式。这里可以通过 Substrait 来构建 Plan 或者单机的表达式。</p><h2 id="Glance"><a href="#Glance" class="headerlink" title="Glance"></a>Glance</h2><p>在 Arrow 中，Expression 可以分为下面几种可能的形式：</p><ul><li>Call<ul><li>Function + Args 的包装，分为 Bounded / Unbounded 的类型</li></ul></li><li>Parameter ( <code>A reference to a single (potentially nested) field of the input Datum.</code>)<ul><li>Arrow 或者 Input 中 Field 的包装，分为 Bounded / Unbounded</li><li>可以通过 <code>FieldRef</code> 之类的来构建。用户大部分时候只走 <code>field_ref</code>，但底下实现还是个 <code>Parameter</code></li></ul></li><li>Literal: 正常的 Literal, 包含 Null。实际上由 <code>Datum</code> (我们在介绍 Compute 的时候讲过) 实现</li></ul><p>上面这几套接口在 Expression 中表现为比较有趣的形式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// An unbound expression which maps a single Datum to another Datum.</span></span><br><span class="line"><span class="comment">/// An expression is one of</span></span><br><span class="line"><span class="comment">/// - A literal Datum.</span></span><br><span class="line"><span class="comment">/// - A reference to a single (potentially nested) field of the input Datum.</span></span><br><span class="line"><span class="comment">/// - A call to a compute function, with arguments specified by other Expressions.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ARROW_EXPORT</span> Expression &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">is_valid</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> impl_ != NULLPTR; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// Access a Call or return nullptr if this expression is not a call</span></span><br><span class="line">  <span class="function"><span class="type">const</span> Call* <span class="title">call</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="comment">/// Access a Datum or return nullptr if this expression is not a literal</span></span><br><span class="line">  <span class="function"><span class="type">const</span> Datum* <span class="title">literal</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="comment">/// Access a FieldRef or return nullptr if this expression is not a field_ref</span></span><br><span class="line">  <span class="function"><span class="type">const</span> FieldRef* <span class="title">field_ref</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">Parameter</span> &#123;</span><br><span class="line">    FieldRef ref;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// post-bind properties</span></span><br><span class="line">    TypeHolder type;</span><br><span class="line">    ::arrow::internal::SmallVector&lt;<span class="type">int</span>, <span class="number">2</span>&gt; indices;</span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="function"><span class="type">const</span> Parameter* <span class="title">parameter</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  </span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">using</span> Impl = std::variant&lt;Datum, Parameter, Call&gt;;</span><br><span class="line">  std::shared_ptr&lt;Impl&gt; impl_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里的使用方式很有意思，类似 enum:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> call = expr-&gt;<span class="built_in">call</span>();</span><br><span class="line"><span class="keyword">if</span> (call == <span class="literal">nullptr</span>) <span class="keyword">return</span>;</span><br></pre></td></tr></table></figure><p><code>Datum</code> 作为 <code>literal</code> 我们之前就已经介绍过了（囧）</p><p>它自己还有整个 Expression 的类型 (<code>Type</code>)，然后此外，整个 <code>Expression</code> 还有对应的 Hash 和 Equal 的方法，用来组一些比较。我们之后会看到这些方法</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::string <span class="title">ToString</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Equals</span><span class="params">(<span class="type">const</span> Expression&amp; other)</span> <span class="type">const</span></span>;</span><br><span class="line"><span class="function"><span class="type">size_t</span> <span class="title">hash</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Hash</span> &#123;</span><br><span class="line">  <span class="function"><span class="type">size_t</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> Expression&amp; expr)</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> expr.<span class="built_in">hash</span>(); &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>此外，这里还有一些特殊的属性，需要额外提供一下：</p><ol><li><code>IsBound</code>:<ol><li><strong>这个后面讲，有点复杂</strong></li></ol></li><li><code>IsScalar</code> （需要注意的是，在这里，complex type 之类的也算是 scalar）<ol><li>对于 <code>Datum</code> 来说，Datum 包含的是否是 Scalar (它还能包含 Array Table RecordBatch ChunkedArray 之类的)</li><li>对于 FieldRef，这里…啥都行！</li><li><code>Call</code>: all argument <code>IsScalar</code>, and function type is <code>SCALAR</code>.</li></ol></li></ol><h2 id="FieldRef-and-Parameter"><a href="#FieldRef-and-Parameter" class="headerlink" title="FieldRef and Parameter"></a>FieldRef and Parameter</h2><p><code>FieldRef</code> 是个很奇怪的东西，表示对某个 Field 的引用，它本身也可以是：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Unlike FieldPath (which exclusively uses indices of child fields), FieldRef may</span></span><br><span class="line"><span class="comment">/// reference a field by name. It is intended to replace parameters like `int field_index`</span></span><br><span class="line"><span class="comment">/// and `const std::string&amp; field_name`; it can be implicitly constructed from either a</span></span><br><span class="line"><span class="comment">/// field index or a name.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Nested fields can be referenced as well. Given</span></span><br><span class="line"><span class="comment">///     schema(&#123;field(&quot;a&quot;, struct_(&#123;field(&quot;n&quot;, null())&#125;)), field(&quot;b&quot;, int32())&#125;)</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// the following all indicate the nested field named &quot;n&quot;:</span></span><br><span class="line"><span class="comment">///     FieldRef ref1(0, 0);</span></span><br><span class="line"><span class="comment">///     FieldRef ref2(&quot;a&quot;, 0);</span></span><br><span class="line"><span class="comment">///     FieldRef ref3(&quot;a&quot;, &quot;n&quot;);</span></span><br><span class="line"><span class="comment">///     FieldRef ref4(0, &quot;n&quot;);</span></span><br><span class="line"><span class="comment">///     ARROW_ASSIGN_OR_RAISE(FieldRef ref5,</span></span><br><span class="line"><span class="comment">///                           FieldRef::FromDotPath(&quot;.a[0]&quot;));</span></span><br></pre></td></tr></table></figure><p>他可以表示的路径如上所述, 这里可以用名字表示。那么实际上内部用 <code>FieldPath</code> 是最好的，但是这里 xjb 糊了一套，用户 Bind 的时候要传个 Schema 进来，然后用这个 Schema 来 Bind，Bind 完里面还是原来那个 <code>&quot;a.b.c&quot;</code>，只是绑定了一些类型。</p><p>在 Bind 的时候，注意到这些 Post Bind，类型是在 Bind 之后绑定的（还是个 <code>TypeHolder</code> 呢，呵呵）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Parameter</span> &#123;</span><br><span class="line">  FieldRef ref;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// post-bind properties</span></span><br><span class="line">  TypeHolder type;</span><br><span class="line">  ::arrow::internal::SmallVector&lt;<span class="type">int</span>, <span class="number">2</span>&gt; indices;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="Call"><a href="#Call" class="headerlink" title="Call"></a>Call</h2><p>Call 表示一个 fn call.</p><p>如果是 <code>Call</code>, 这里会有对应的参数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Call</span> &#123;</span><br><span class="line">  std::string function_name;</span><br><span class="line">  std::vector&lt;Expression&gt; arguments;</span><br><span class="line">  std::shared_ptr&lt;FunctionOptions&gt; options;</span><br><span class="line">  <span class="comment">// Cached hash value</span></span><br><span class="line">  <span class="type">size_t</span> hash;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// post-Bind properties:</span></span><br><span class="line">  std::shared_ptr&lt;Function&gt; function;</span><br><span class="line">  <span class="type">const</span> Kernel* kernel = NULLPTR;</span><br><span class="line">  std::shared_ptr&lt;KernelState&gt; kernel_state;</span><br><span class="line">  TypeHolder type;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">ComputeHash</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里可以通过 <code>function</code> 来判断是否做 binding。这里的含义还是比较清晰的，Expression 的主要内容还是在这个地方应该是最重要的一个类型。<code>+</code> <code>-</code> 之类的，本身有 <code>add</code> 之类的 Function ( 在之前的 compute 模块介绍过 )。而 <code>Expression</code> 层会组织成:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Call(function_name=&quot;Add&quot;, arguments=&#123;field_ref(&quot;a.b&quot;), literal(1000)&#125;)</span><br></pre></td></tr></table></figure><p>这样的形式，在 <code>Bind</code> 以后，这里会绑定到 <code>Function</code> 和对应的 <code>kernel</code> 执行器上。</p><p>这里还提供了 <code>and</code>, <code>or</code> 之类的东西给用户，非常有意思:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">project</span><span class="params">(std::vector&lt;Expression&gt; values,</span></span></span><br><span class="line"><span class="params"><span class="function">                                std::vector&lt;std::string&gt; names)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">equal</span><span class="params">(Expression lhs, Expression rhs)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">not_equal</span><span class="params">(Expression lhs, Expression rhs)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">less</span><span class="params">(Expression lhs, Expression rhs)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">less_equal</span><span class="params">(Expression lhs, Expression rhs)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">greater</span><span class="params">(Expression lhs, Expression rhs)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">greater_equal</span><span class="params">(Expression lhs, Expression rhs)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">is_null</span><span class="params">(Expression lhs, <span class="type">bool</span> nan_is_null = <span class="literal">false</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">is_valid</span><span class="params">(Expression lhs)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">and_</span><span class="params">(Expression lhs, Expression rhs)</span></span>;</span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">and_</span><span class="params">(<span class="type">const</span> std::vector&lt;Expression&gt;&amp;)</span></span>;</span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">or_</span><span class="params">(Expression lhs, Expression rhs)</span></span>;</span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">or_</span><span class="params">(<span class="type">const</span> std::vector&lt;Expression&gt;&amp;)</span></span>;</span><br><span class="line"><span class="function">ARROW_EXPORT Expression <span class="title">not_</span><span class="params">(Expression operand)</span></span>;</span><br></pre></td></tr></table></figure><p>比较有意思的是 <code>project</code>，会产生一个新的 <code>struct</code> 类型。</p><h3 id="Bind"><a href="#Bind" class="headerlink" title="Bind"></a>Bind</h3><p>对 Expression 的 Bind 会比较复杂. 这里可能做的事情有：</p><ol><li>Bind 所有的子成员，然后进入 <code>BindNonRecursive</code></li><li>拿到所有 arguments 的类型</li><li>根据 Name 和参数去找到对应的 <code>Function</code> , <code>Kernel</code>，这里先找完全匹配的 （ <code>`DispatchExact</code>）<ol><li>如果找到正好匹配的，就用这个</li><li>如果有 <code>insert_implicit_casts</code>，就会尝试修改类型<ol><li>对于 Literal，找到 Literal 的最小类型（eg: 如果是 <code>Datum(int32(8))</code>, 可以改成 <code>Datum(int8(8))</code></li><li>尝试去 <code>DispatchBest</code>，然后如果有不一样的，<ol><li>如果是 <code>field_ref</code>，直接用目标类型</li><li>如果是 <code>field_ref</code> 或者 <code>call</code>，插入一个 Cast</li></ol></li></ol></li></ol></li><li>初始化 <code>KernelContext</code> 和 <code>KernelState</code></li></ol><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>表达式的很大一部分逻辑在于对表达式进行处理。下面列举了一组相关的 API。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Weak canonicalization which establishes guarantees for subsequent passes. Even</span></span><br><span class="line"><span class="comment">/// equivalent Expressions may result in different canonicalized expressions.</span></span><br><span class="line"><span class="comment">/// TODO this could be a strong canonicalization</span></span><br><span class="line"><span class="function">ARROW_EXPORT</span></span><br><span class="line"><span class="function">Result&lt;Expression&gt; <span class="title">Canonicalize</span><span class="params">(Expression, ExecContext* = NULLPTR)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Simplify Expressions based on literal arguments (for example, add(null, x) will always</span></span><br><span class="line"><span class="comment">/// be null so replace the call with a null literal). Includes early evaluation of all</span></span><br><span class="line"><span class="comment">/// calls whose arguments are entirely literal.</span></span><br><span class="line"><span class="function">ARROW_EXPORT</span></span><br><span class="line"><span class="function">Result&lt;Expression&gt; <span class="title">FoldConstants</span><span class="params">(Expression)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Simplify Expressions by replacing with known values of the fields which it references.</span></span><br><span class="line"><span class="function">ARROW_EXPORT</span></span><br><span class="line"><span class="function">Result&lt;Expression&gt; <span class="title">ReplaceFieldsWithKnownValues</span><span class="params">(<span class="type">const</span> KnownFieldValues&amp; known_values,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                Expression)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Simplify an expression by replacing subexpressions based on a guarantee:</span></span><br><span class="line"><span class="comment">/// a boolean expression which is guaranteed to evaluate to `true`. For example, this is</span></span><br><span class="line"><span class="comment">/// used to remove redundant function calls from a filter expression or to replace a</span></span><br><span class="line"><span class="comment">/// reference to a constant-value field with a literal.</span></span><br><span class="line"><span class="function">ARROW_EXPORT</span></span><br><span class="line"><span class="function">Result&lt;Expression&gt; <span class="title">SimplifyWithGuarantee</span><span class="params">(Expression,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         <span class="type">const</span> Expression&amp; guaranteed_true_predicate)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Replace all named field refs (e.g. &quot;x&quot; or &quot;x.y&quot;) with field paths (e.g. [0] or [1,3])</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// This isn&#x27;t usually needed and does not offer any simplification by itself.  However,</span></span><br><span class="line"><span class="comment">/// it can be useful to normalize an expression to paths to make it simpler to work with.</span></span><br><span class="line"><span class="function">ARROW_EXPORT Result&lt;Expression&gt; <span class="title">RemoveNamedRefs</span><span class="params">(Expression expression)</span></span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="tools"><a href="#tools" class="headerlink" title="tools"></a>tools</h4><p><code>arrow/compute/util.h</code> 等地方提供了一组靠谱的工具，最典型的是一个 tree visitor:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Modify an Expression with pre-order and post-order visitation.</span></span><br><span class="line"><span class="comment">/// `pre` will be invoked on each Expression. `pre` will visit Calls before their</span></span><br><span class="line"><span class="comment">/// arguments, `post_call` will visit Calls (and no other Expressions) after their</span></span><br><span class="line"><span class="comment">/// arguments. Visitors should return the Identical expression to indicate no change; this</span></span><br><span class="line"><span class="comment">/// will prevent unnecessary construction in the common case where a modification is not</span></span><br><span class="line"><span class="comment">/// possible/necessary/...</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// If an argument was modified, `post_call` visits a reconstructed Call with the modified</span></span><br><span class="line"><span class="comment">/// arguments but also receives a pointer to the unmodified Expression as a second</span></span><br><span class="line"><span class="comment">/// argument. If no arguments were modified the unmodified Expression* will be nullptr.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> PreVisit, <span class="keyword">typename</span> PostVisitCall&gt;</span><br><span class="line"><span class="function">Result&lt;Expression&gt; <span class="title">ModifyExpression</span><span class="params">(Expression expr, <span class="type">const</span> PreVisit&amp; pre,</span></span></span><br><span class="line"><span class="params"><span class="function">                                    <span class="type">const</span> PostVisitCall&amp; post_call)</span></span>;</span><br></pre></td></tr></table></figure><p>这个能够被用来扫 + 更新整个 tree.</p><h4 id="Canonicalize"><a href="#Canonicalize" class="headerlink" title="Canonicalize"></a>Canonicalize</h4><p>尝试把表达式处理成长得差不多的情况。</p><p>e.g: 对<strong>同样的</strong>可交换操作的处理</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">((a + b) + 2) + 3</span><br></pre></td></tr></table></figure><p>这里发现是同样的操作，就会尝试整理，然后做成便于 constant folding 的形式。这里也会有 <code>field_ref</code>, <code>literal</code> , <code>null literal</code> 位置的关系。</p><p>e.g.: 对比较的处理</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a &gt; 3</span><br><span class="line">3 &lt; a</span><br></pre></td></tr></table></figure><p>这里会被处理成一样的形式。</p><h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h3><p>这里还有 Constant Folding，抽出 Key-Values 等形式。其实这个表达式相对来说还是太 trivial 了，做个入门还行，难一点还是别看这个了。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>schedule: Mesos</title>
      <link href="/2023/07/01/schedule-Mesos-and-Yarn/"/>
      <url>/2023/07/01/schedule-Mesos-and-Yarn/</url>
      
        <content type="html"><![CDATA[<p>在之前博客中，我们介绍了 MapReduce 和 Spark 的框架，这两个的程序类型都是 Batch Job，batch job 这里会被分配到对应的机器上，由一个类似 master 的节点来调度或者监控它的执行。</p><p>对于小的任务来说，细粒度的调度是比较难控制的，从一些 Morsel Driven 的调度到 Scylladb 和 RocksDB 的一些例子，看着都很难，而且智能是在负载上、核心或者线程池上切分，做一些细粒度的调度，OS 下面也有一些调度相关的，比如非常经典的 CFS 调度。对于 Batch Job 来说，问题其实有那么点类似 OS （包括后来 Google 和 Meta 的场景，可能都类似一个分布式的 OS，对数据中心大量机器进行高效的调度和分配）。这里有一些区别是，任务可能会有一些先验的预期之类的。</p><p>我们讨论的 Mesos 是一些平台的前身，但同时，Mesos 也被捐献到 Apache 中，和 Yarn 类似的，广泛的进行一些 Hadoop 系 Batch Job 甚至小一些的任务的调度，并管理 MPI、Hadoop 等计算框架。Mesos 的论文发表于 NSDI’11，可以看到论文比较早，论文主要的点在于：</p><ol><li>出现的时候，主要取代的是静态分片的集群</li><li>2级调度，来允许用户自己编写调度框架，Mesos 管理资源和调度框架交互。这样不能保证全局最优的调度，但是提供了 scability</li><li>基于两级调度设计的 api<ol><li>有一些亲和度甚至是必要条件有关的考量</li><li>资源量对于应用/框架不够的时候，怎么处理</li><li>任务是否能够被 kill</li><li>对于资源占有了，但是没跑起来这种会死锁的情况，怎么处理</li></ol></li><li>定义任务的平均执行时间和执行时间的分布，Mesos 的对应处理</li></ol><p>这里我们也<strong>只介绍「框架」相关的，其实尽量避免介绍具体的策略</strong>，感觉策略要到 queuing theory 或者 DRF 的论文可以介绍一下。</p><h2 id="两级调度"><a href="#两级调度" class="headerlink" title="两级调度"></a><strong>两级调度</strong></h2><p>需求：Hadoop, MPI 等多个集群共享资源，而每部分可能会有自己的调度器。把所有的调度器整合到全局在工程上比较重（当然也可以，但是那要求中心化的调度 + 可能会比较粗糙的调度算法 + 不好复用框架自己的代码，因为每个框架可能对调度的需求不一样，然后人家写啥你写啥，如果卡顿一下搞得 master 卡住了就更是灾难了）。此外，这里需求还有 HA。</p><p>此外，对于那种同一组资源的多个集群，Mesos 甚至能给你拆两组 scheduler 然后自己跑在上头管，提供了很多方便搞事的方法。</p><p>综上，Mesos 没有选择中心化的调度，而是选择了两级调度：</p><p><img src="https://image.mwish.me/blog-image/7264590773996925814.png" alt="img"></p><p>这里 Mesos 可以给调度器提供资源，然后调度器决定具体 task 的运行，这中间有很多细节：，但是大致框架如下：</p><ol><li>Mesos 决定把多少资源给用户(resource offer)</li><li>调度器可以拒绝这些资源或者开跑，关切这里的具体调度</li></ol><h3 id="架构和例子"><a href="#架构和例子" class="headerlink" title="架构和例子"></a><strong>架构和例子</strong></h3><p>Mesos 的架构如 Figure 2，下面是个论文的的 Mesos 例子：</p><p><img src="https://image.mwish.me/blog-image/3859067561288897201.png" alt="img"></p><p>Mesos 会运行：</p><ul><li>Executor: 承载具体的 Task 的运行</li><li>Scheduler: 核心的调度器。本身是一个轻状态，会有 backup 和 failover</li></ul><p>Figure3 展示了对应的流程：</p><ol><li>Slave 1: 汇报自身的资源</li><li>Master 1: 决定提供给 Framework 1，然后告诉它对应的资源描述</li><li>Framework 1: 调度后发两个 Tasks，每个 Task 也有对应的资源描述</li><li>任务被派发给对应的 executor</li></ol><p>（这里考虑到机制上还有任务的 rit，failover 之类的问题，不过我感觉，因为大部分计算重复计算了也没什么问题，然后本身 master 是个弱状态的节点，所以这块相对可以比 tp 的 master，比如 hbase， 处理的粗糙一些）</p><p>那么上面这张图是个最简单的情况，实际上是有很多细节的，包括 corner case 和下面一些信息：</p><ul><li>为了在接口上比较 clean，框架可以 Reject 资源，比如说 Mesos 给的资源不够的时候 Reject、不满足需求也可以 Reject。本身提供了一个 Reject 的可能，然后这个请求本身要走一轮 RPC，为了提前优化掉 RPC，框架可以编写 Filter，让 Mesos Scheduler 测提前过滤，包括设置 ip 白名单这种操作<ul><li>Mesos 认为 Filter 不是必须的，只是节省 rpc，当很多小的 task 的时候，直接 delay scheduling (攒着一些 slave 信息再发）的效果贼好，这种情况下没 Filter 性能也不错</li><li>Mesos 在论文写作的时候支持两种 filter:<ul><li>只支持 Set 中的 Executor 节点</li><li>提供支援的时候，至少需要 R 的资源</li><li>原则上，其他 Filter 也能支持（rnm，那你还写这么多？）</li></ul></li></ul></li><li>在写这篇论文的时候，Scheduler 的调度算法是 min-max fair sharing 的调度，当然一段时间之后，他们就搞了 DRF. 如果都是短作业，然后一个 10% share 的框架可能需要等待 10% 的执行时间，但是如果有一些大 task，这里调度会受到一些影响。Mesos 允许 revoke(kill) 对应的 task，然后给应用一个 grace period 来清楚对应的 task。当然有一些 Job，比如 MPI 这种 dependency 比较复杂的，也可以通过 guaranteed allocation 来<strong>申请一定的资源</strong>，这种情况下，在这个框架申请的资源在 guaranteed allocation 之下的时候，Mesos 可能就不太会去 kill 它了（可以看作是一个低水位）</li><li>论文写作的时候，isolation 还没啥好的机制，掠过不讲。</li><li>在申请资源的时候，回到上述步骤，这里在 (3) Scheduler 收到框架信息的时候，Mesos 才会把资源占用计算给它（感觉这个在处理挂掉的 Framework 的时候有一点乐观，可能极端情况资源会发出去几份？虽然我觉得计算层面挂掉问题不严重，不过跨几个系统处理问题终归有些麻烦）。实际上如果框架很久不返回，Mesos 会 rescind 回收相关的资源，然后允许把这些资源调度给别的框架）</li><li>关于 Failover:<ul><li>如果 Mesos Master fail 了，那么允许拉起。这里还运行了一个 zk</li><li>如果 Mesos Executor 挂了或者任务 crash 了，可以交给 Framework 处理</li><li>如果 Framework 挂了，Mesos 允许用户在 Framework 测注册一组，允许从顶上去</li></ul></li></ul><p><img src="https://image.mwish.me/blog-image/2418121716793468253.png" alt="img"></p><p>这里 Scheduler Callback 是用户调度器，Executor 是对应的执行器。Callback 是被 Mesos 执行的操作，Action 是主动对 Mesos 执行的操作。</p><h2 id="Mesos-的行为和优化"><a href="#Mesos-的行为和优化" class="headerlink" title="Mesos 的行为和优化"></a>Mesos 的行为和优化</h2><p>这里对 Mesos 的行为进行了建模：</p><ul><li>Framework ramp-up time: 一个 framework 调度到 task 的时间</li><li>Job completion time: one-job per framework 的情况下的调度时间</li><li>System utilization: 集群利用率</li></ul><p>这里考虑到的调度和计算任务相关的一些性质：</p><ul><li>Elastic: 是否和 MapReduce / Dryad 这样能调整对应的并发。这并不是说调整任务 dop 这种，而是说可能可以分开来 task 完了就停止了，比如对应的 MPI 就不能直接具备这个能力(rigid)</li><li>对资源要求的 mandatory 或者 preferred<ul><li>Mandatory: 强制的要求，比如要在有 GPU 的机器上执行</li><li>Preferred: 要求，只是调度亲和性这种逻辑。</li></ul></li><li>暂时假设 mandatory resources 不会超过 guaranteed share，防止出现死锁的情况（TBD: 话说一般的调度框架是怎么处理死锁的呢？）</li><li>暂时分成 slot-based 的 min-max share</li></ul><h3 id="Homogeneous-Tasks"><a href="#Homogeneous-Tasks" class="headerlink" title="Homogeneous Tasks"></a>Homogeneous Tasks</h3><blockquote><p>We consider a cluster with <strong>n</strong> slots and a framework, f, that is entitled to <strong>k</strong> slots. For the purpose of this analysis, we consider two distributions of the task durations: constant (i.e., all tasks have the same length) and exponential. Let the mean task duration be <strong>T,</strong> and assume that framework f runs a job which requires βkT total computation time. That is, when the framework has k slots, it takes its job βT time to ﬁnish.</p></blockquote><p><img src="https://image.mwish.me/blog-image/8249790567283055499.png" alt="img"></p><ul><li>对于 Ramp-up time, 如果分布是 constant，那么 T 的时间基本上都会调度到。如果是指数分布的，那么可能会有 Tlnk 的期望时间.</li><li>对于 Job completion time, Elastic 这里比较简单，Rigid 里面要拿到所有资源才能开始</li><li>利用率同上</li></ul><h3 id="Preference"><a href="#Preference" class="headerlink" title="Preference"></a>Preference</h3><p>在引入 Perference 的时候，内容会发生一些改变。当每集群 prefer 都够用的时候肯定没问题，出现抢占的时候，这里可能会用类似彩票调度的方式来分配。</p><h3 id="Heterogeneous-Tasks"><a href="#Heterogeneous-Tasks" class="headerlink" title="Heterogeneous Tasks"></a>Heterogeneous Tasks</h3><p>这里主要指的是大 task 和 小 task 都有的场景。</p><blockquote><p>Such heterogeneous workloads can hurt frameworks with short tasks. In the worst case, all nodes required by a short job might be ﬁlled with long tasks, so the job may need to wait a long time (relative to its execution time) to acquire resources.</p><p>In particular, we can associate a maximum task duration with some of the resources on each node, after which tasks running on those resources are killed. These time limits can be exposed to the frameworks in resource offers, allowing them to choose whether to use these resources. This scheme is similar to the common policy of having a separate queue for short jobs in HPC clusters.</p></blockquote><h2 id="References"><a href="#References" class="headerlink" title="References"></a><strong>References</strong></h2><ol><li>集群调度系统的演进 - 邵明岐的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/51790388">https://zhuanlan.zhihu.com/p/51790388</a></li><li>号称了解mesos双层调度的你，先来回答下面这五个问题！ - 网易数帆的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/49429953">https://zhuanlan.zhihu.com/p/49429953</a></li><li>让你彻底搞明白YARN资源分配 - 斜杠代码日记的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/335881182">https://zhuanlan.zhihu.com/p/335881182</a></li><li>久经沙场的集群管理系统调研：Borg, Twine, Protean, Mesos, YARN and K8S - Peter的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/388355341">https://zhuanlan.zhihu.com/p/388355341</a></li><li>Hadoop YARN：调度性能优化实践 - 美团技术团队的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/76697106">https://zhuanlan.zhihu.com/p/76697106</a></li><li><a href="https://draveness.me/papers-mesos/">https://draveness.me/papers-mesos/</a></li><li><a href="https://draveness.me/system-design-scheduler/">https://draveness.me/system-design-scheduler/</a></li><li><a href="https://blog.mwish.me/2022/05/29/Scheduling-Blog-Overview/">https://blog.mwish.me/2022/05/29/Scheduling-Blog-Overview/</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Snowflake: Streaming and Change in Table</title>
      <link href="/2023/06/22/Snowflake-Streaming-and-Change-in-Table/"/>
      <url>/2023/06/22/Snowflake-Streaming-and-Change-in-Table/</url>
      
        <content type="html"><![CDATA[<p>What’s the Difference? Incremental Processing with Change Queries in Snowflake 是发表在 SIGMOD’23 上的论文。描述了 Snowflake 内部的增量计算场景。这个部分有点类似 Streaming 或者说什么，Snowflake 可以在表或者 MV 的对象上开启 <code>STREAM</code>， Stream 内会包含 Snowflake 产生的类似 CDC 的数据 <code>CHANGES</code>，然后，Snowflake 本身能够根据 Time Travel 的功能来跑出 <code>STREAM</code> 上的 <code>CHANGES</code>，下游会消费这个 <code>CHANGES</code>，来用增量构建 diff。Snowflake 声称这套代码已经跑三年了，另外，这套论文的第一作者是 MillWheel 的作者。什么刘式家族。</p><p>Streaming System 和 Batch 的大乱斗有悠久的历史了，作者认为这其中的区别在于：</p><ul><li>Batch 需要处理整套输入来产生输出</li><li><p>Streaming 处理的是「增量」</p><p>* 可能会做一个 Partition，单个 key 的处理在 Partition 内是按行操作、序列化的</p></li></ul><p>Snowflake 做了下面的概念区分：</p><ul><li>Tables: 每个时间点内，表的完整状态</li><li>Stream: changes to a dataset over time, 表示 Tables 上发生的「变更」（类似 Redo Log 流？但是是更上层的概念）</li></ul><p>Snowflake 倾向于「用户可以直接查询 CHANGES」的方式，并且认为有这样的 Usecases:</p><ul><li>Event Queuing: 给 SQL 一个 message queue 的语义</li><li>Notifications: 论文认为消费 <code>CHANGES</code> 表，相对来说资源开销会小很多</li><li><strong>Incremental View Maintenance(IVM)</strong>: 给上层实现增量 MV 维护提供比较好的工具</li><li>Flexible Change transformation: 消费 CHANGES 的时候，有的用户只关注一部分，并且这种 CHANGES 走 SQL 的话也算有优势</li></ul><p>Snowflake 提供了下面的语义：</p><ul><li>CHANGES：对表或者增量 mv 的变更</li><li>STREAM: 对表或者增量 mv 的变更流，包含很多 CHANGES 和时间戳，需要消费来推进。</li></ul><h2 id="Semantics"><a href="#Semantics" class="headerlink" title="Semantics"></a>Semantics</h2><p>Snowflake 把表构建为一个 TVR 模型(time-varying relations), 并构建了一个 Table + Redo Log 的模型，<strong>来捕获 SQL 中发生的 INSERT, UPDATE, DELETE 操作</strong>。在这里，Snowflake 先抽象成了 Delete + Insert 的模型。下面是论文中用到的 SQL 和时序，后面会不断回来看这个的：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>:<span class="number">00</span>&gt; SELECT * FROM people;</span><br><span class="line">+----+-------+</span><br><span class="line">| id | name  |</span><br><span class="line">+----+-------+</span><br><span class="line">| <span class="number">1</span>  | Jeff  | </span><br><span class="line">| <span class="number">2</span>  | Donny |</span><br><span class="line">+----+-------+</span><br><span class="line"></span><br><span class="line">(Listing <span class="number">1</span>. Example table with two rows)</span><br></pre></td></tr></table></figure><p>下面是论文中的操作序列：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12</span>:<span class="number">01</span>&gt; INSERT INTO people <span class="title function_ invoke__">VALUES</span> (<span class="number">3</span>, <span class="symbol">&#x27;Walter</span>&#x27;), (<span class="number">4</span>, <span class="symbol">&#x27;Maud</span>&#x27;), (<span class="number">5</span>, <span class="symbol">&#x27;Uli</span>&#x27;);</span><br><span class="line"></span><br><span class="line"><span class="number">12</span>:<span class="number">02</span> &gt; UPDATE people SET name = <span class="symbol">&#x27;Jeffrey</span> &#x27; WHERE id = <span class="number">1</span>; </span><br><span class="line"><span class="number">12</span>:<span class="number">03</span> &gt; UPDATE people SET name = <span class="symbol">&#x27;Maude</span> &#x27; WHERE id = <span class="number">4</span>;</span><br><span class="line"><span class="number">12</span>:<span class="number">04</span> &gt; DELETE FROM people WHERE id <span class="title function_ invoke__">in</span> (<span class="number">2</span>, <span class="number">5</span>); </span><br><span class="line"></span><br><span class="line">(Listing <span class="number">2</span>. Mutations to the table from Listing <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>查询结果是：</p><p><img src="https://image.mwish.me/blog-image/2034055683243599966.png" alt="img"></p><p>那么，这里逻辑上的 Redo Log 如下所示（这并不代表最终产生的 CHANGES）：</p><p><img src="https://image.mwish.me/blog-image/2295336572436247647.png" alt="img"></p><p>这种抽象对 Table 或者 MV 都有用，还是比较通用的，当然这里可能是说，<strong>需要在删除和插入的时候都带上完整的行记录</strong>，对于宽表来说还是有点大的。不过这年头我还是觉得简单就是好，大力出奇迹就行，优化什么的等客户有需求再说吧。</p><h3 id="CHANGES-quries"><a href="#CHANGES-quries" class="headerlink" title="CHANGES quries"></a>CHANGES quries</h3><p>CHANGES query 是 snowflake 的一种查询 CHANGES 的查询，支持 SQL。Snowflake 早就支持了 Time Travel，用户可以指定 START 和 END 的时间戳，如果不指定 END 就是查询 START 到现在的数据，当然，除了时间戳，用户还可以使用 <code>STREAM</code> 对象来查询。</p><p>如之前 Listing 3 所描述的，在 CHANGES 查询的结果中，有一些 metadata columns：</p><ul><li><code>$ACTION</code>: CHANGES 是 INSERT 还是 DELETE</li><li><code>$ISUPDATE</code>: 对于 UPDATE，它在 CHANGES 中会变成 INSERT + DELETE. 在这种场景下 <code>$ISUPDATE = true</code></li><li><code>$ROW_ID</code>: 这个就非常有意思了。表示 Row 的 Unique Id，后面会介绍这个字段是怎么构成的</li></ul><p>其实 (1) (3) 还比较好理解（但是需要细分一下 ROW_ID 是怎么构成的），此外 Snowflake 还支持查询 <code>INFORMATION</code>，表示 <code>CHANGES</code> 的元信息。下面介绍 Snowflake 的区分处理方式，Snowflake 目前支持两种 CHANGES 格式，这里都可以表示为类似 Redo Log 的形式：</p><ul><li>Append Only: 表示<strong>数据第一次插入表</strong>的日志，可能来自 INSERT, Merge, COPY 或者 Snowpipe(file-based) / Snowpipe Streaming(row-based)。UPDATE/Truncate/Delete 其实在这里都不会被记录。下面展示了在 Snowflake 查询 Listing 2 的 APPEND_ONLY 数据</li></ul><p><img src="https://image.mwish.me/blog-image/2778464309866266745.png" alt="img"></p><ul><li>Minimum-delta: <strong>在指定的时间段或者 STREAM 变更内</strong>的 INSERT/UPDATE/DELETE等写 操作<strong>最小DELETE/INSERT集合</strong>（即合并重复操作）。这种操作相对于物理变化其实好处比较多，比方说用户跑了个 Merge 请求或者内部跑了个 Compaction，你 dedup 一下用户/下游幸福多了。</li></ul><p><img src="https://image.mwish.me/blog-image/1456419358256344730.png" alt="img"></p><p>这里可以对比 Listing 3，可以看到对 id 4 的重复操作都被折叠掉了，对同一个对象( id 5 )的 INSERT - DELETE 也没了（可以拉上去对比一下）。</p><p>在这里，Snowflake 做了个比较有意思的评论：在审计场景中，所有记录都要是可见而不能被折叠，不过目前大部分用户觉得凑合着用就行，之后可能会把所有 CHANGES 都暴露出去。</p><p>这里有个问题是，delta 信息可能比 Insert 全一些，为啥还需要 minimum-delta </p><h3 id="CHANGES-queries-on-Views"><a href="#CHANGES-queries-on-Views" class="headerlink" title="CHANGES queries on Views"></a>CHANGES queries on Views</h3><p>之前例子中的 CHANGES 都是对表的，下面有一个比较恶心的：对 View 的 CHANGES.</p><ul><li>Append-only CHANGES<ul><li>Monotonicity: 这里定义了 Monotonicity, 即插入一条数据是否保证最终的插入，例子是 Anti-Join，可能表 A 插入一条数据，Anti-Join 的 MV 会减少一条数据。这里认为不是很方便的直接计算到 append-only changes，所以这里只允许 append-only changes 提供给 monotonic query(mv)</li><li>Repeated inserts: 有一个例子是同一条边被插入 - 删除 - 插入 ，第二次插入是否要被包含。这里认为不需要包含，它认为这样会让实现更简单一些（哪里更简单了呢）</li></ul></li><li>Minimum-delta CHANGES<ul><li>Excluded Columns: 对于 Filter 条件来说，Base 被 Filter 掉的或者是根本和 mv 没关系的列，MV 不会再出现这样的 CHANGES</li><li>Update coercion: 对于 Excluded -&gt; INLUDED 的请求（比如 UPDATE），这里会将上游的 Update 变成 CHANGES 中的 INSERT</li></ul></li></ul><p>接着举例子：</p><p><img src="https://image.mwish.me/blog-image/6727086490095305434.png" alt="img"></p><p>Oid 是 id 的 foreign key, 下面创建一个 inner join 的 mv:</p><p><img src="https://image.mwish.me/blog-image/3745451790993126611.png" alt="img"></p><p>下面描述了一些变更操作：</p><p><img src="https://image.mwish.me/blog-image/1947515212853200859.png" alt="img"></p><ul><li>这里比较好玩，第一个 SQL 相当于最终 mv 的一个 UPDATE，产生了 DELETE + INSERT</li><li>第二个 UPDATE 在 Base 表是一个 UPDATE，但是它导致 mv Join 变更了，相当于 Delete + Insert</li><li>第三个更新 <code>desc</code> 列归属于 excluded column，所以没一点影响</li><li>第四个 DELETE 会导致 mv 两条 Delete (感觉它的 fk 不是强约束，总觉得在 db 这种数据很难删）</li></ul><h3 id="STREAM-Objects"><a href="#STREAM-Objects" class="headerlink" title="STREAM Objects"></a>STREAM Objects</h3><p>CHANGES 是一个比较好用的工具，而 STREAM 则是 CHANGES 和表的状态维护。能够完成存储状态和容错等功能。我们列举 STREAM 的逻辑：</p><ul><li>表(persistent or view) 级别，对应一个 schema-level catalog object ，绑定于 source view (表或者 mv)</li><li>STREAM 的状态叫 frontier，代表 CHANGES 被消费完的一个时间点（类似 ckpt?）</li><li>Stream 可以被 consume:<ul><li>被查询的时候，STREAM 生成 frontier 到现在的应用</li><li>DML 操作 STREAM 的时候，STREAM 会在 DML 的事务中被处理（原子性），当事务 COMMIT 的时候，推进 STREAM。</li></ul></li><li>一个表可以创建多个 STREAM</li><li>STREAM 支持 show initial rows，在 STREAM 被第一次消费的时候，它的数据包含表的数据（我猜是全部都是 INSERT 的形式）。这个让整个 STREAM 构成一个能恢复整个表的 redo log 流</li></ul><p>下面展示了 Listing 1/2 的 STREAM</p><p><img src="https://image.mwish.me/blog-image/644682537778375200.png" alt="img"></p><p><img src="https://image.mwish.me/blog-image/2376649931720618126.png" alt="img"></p><p>（这里 idea 还是挺明显的）</p><p>作者认为，STREAM 引入的存储开销比较小，相对的只需要存储 frontier，所以作者觉得 STREAM 可以随便开，当然论文也提到了，STREAM 本身和表的 retention policy 有关，这里认为 STREAM 本身也依赖表的 Retention 策略，如果下游某个时间戳的表 GC 了，那么这里会表示文件再也捞不到了，所以 STREAM Stale 了。当然 Snowflake 本身有一定的 Time Travel 机制和 Retention 相关的，它允许维护、延长一段时间的 Retention，直到这个数据真的 Retire 了。</p><h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>Snowflake 希望能够尽量复用以前的组建和机制、也减少客户的负担（废话）。这里要求：</p><ul><li>给 Storage Layer 增加 Row-Level Metadata</li><li>Query differentiation framework to Rewrite query</li><li>Integrate STREAM with Transaction system</li></ul><p>这里，论文总结了一下 Snowflake 的架构，然后介绍了一下它们是怎么实现 STREAM 的。</p><h3 id="Table-Metadata"><a href="#Table-Metadata" class="headerlink" title="Table Metadata"></a>Table Metadata</h3><p>Snowflake 的表在数据上由多个 micro-partition 组成，他们是大小不一的数据文件，以 z-ordering 之类的形式来组织，存储在 Blob Storage 上，元数据存储在一个 FoundationDB 集群上（妈的现在 fdb 的贡献者全是 sfc-gh 家族了，迫真占领社区）。Snowflake 有一个 table version，来表示 Table 的状态：</p><ul><li>System Timestamp</li><li>Set of micro-parititons</li><li>Partition-level statistics</li></ul><p>而表的状态也类似连续的 Redo Logs:</p><ul><li>INSERT 等操作插入新的 micro-partitions</li><li>DML 的操作的 Micro-partition 级别，比如 CoW 那种就是 Delete / Insert；或者干脆直接删了<ul><li>上述都走 Transaction 提交操作</li></ul></li><li>如果超过 Retention，去回收数据</li></ul><p>表的版本和查询的版本直接关联，metadata system 首先会拿到时间错对应的 table version, 拿到对应的 micro partitions</p><h3 id="Query-Differentiation"><a href="#Query-Differentiation" class="headerlink" title="Query Differentiation"></a>Query Differentiation</h3><h4 id="查询的模型"><a href="#查询的模型" class="headerlink" title="查询的模型"></a>查询的模型</h4><p>这里的技巧在于，把查询改写为增量 mv 的查询我原封不动贴一下论文的模型：</p><blockquote><p>given that we want the CHANGES of a query 𝑄 over an interval 𝐼, we say we differentiate 𝑄 to obtain the derivative of 𝑄 , Δ 𝐼𝑄 , which varies over 𝐼.</p></blockquote><p>这里会根据上面几部分来改写查询，下面是数学部分，我只能看懂大概（悲），大概是 Join / Filter / Project / Agg 拆分成增量的形式。</p><p><img src="https://image.mwish.me/blog-image/3032945505873821696.png" alt="img"></p><p>当然，等量代换完成之后，就涉及到代价的问题了：</p><ul><li>Inner Join 之类的代换可能性能及户都会有优化</li><li>Agg 之类的，如果大部分 key 被修改了，性能可能会一坨</li></ul><p>所以这里丢给 Cost-based Optimizer 去自己评估了。</p><h4 id="Change-Tracking"><a href="#Change-Tracking" class="headerlink" title="Change Tracking"></a>Change Tracking</h4><p>Snowflake 会在 TableScan Operator 处理增量，它需要在 TableScan 捞出 changes。这里会利用行上的 metadata 来处理，Snowflake 给行上启用了 properties:</p><ul><li>A unique id. Stable across updates (还记得 min-delta 上的嘛）</li><li>Whether the row was inserted into the current micro-partition or was copied in from another.This information makes it trivial to produce append-only changes. （行的来源，但我觉得这个在 Compaction 之后计算很蛋疼啊，包括 insert + compaction，你总不能每一行去 traverse version chain 吧，迫真 MVCC，不过它也处理了这个问题）</li></ul><p>这两块我觉得存储开销肯定还小，因为列存一压很多东西就没了，但是我觉得这套框架和别的合起来还是有问题的。当然，这里肯定会有重复（redundent delta），于是 query rewriter 会在上面区分这个查询是否会产生 delta，如果可能有 delta 就属于 redundant-delta properties，给你嗯加一个 consolidation 去去重。Snowflake 发现大部分 CHANGE QUERY 只有 一堆INSERT 或者 一堆 DELETE，所以它提供了不少 Plan Shapes:</p><ul><li>MINIMIZE</li><li>ADDED_ONLY</li><li>REMOVED_ONLY</li></ul><p>考虑到这个，在 planning 的时候，这里会找到 INSERTED micro-partitions 和 DELETED micro-partitions(这个对 Compaction 也生效），然后进行下面的 Plan，那个 UNION 就很精髓，Minimization 看下面计算的性质。这里还有个 <code>ISUPDATE</code> 计算，我们一会儿讲。</p><p><img src="https://image.mwish.me/blog-image/8580455075483302732.png" alt="img"></p><p>对于 Added 来说，这里会找到：</p><ol><li>所有 Added Partition，包括 Compaction 产生的</li><li>扫描所有记录，只有行来源不来自于别的文件的才会被记入</li></ol><p>这个算法也是比较简洁的</p><p><img src="https://image.mwish.me/blog-image/2504297451855509654.png" alt="img"></p><p>在元信息上，关于 ACTION 的计算是很简单的，ISUPDATE 的计算会是最终合并的（而不是中间的操作），总的说它只看起止。</p><p>比较重要的是 <code>$ROW_ID</code>，这个东西设置了可能就没那么好改了：</p><ol><li>可以是有含义的语义，但是可能会对系统未来的 evaluation 造成兼容性负担（也不那么会把？）</li><li>可以是没有含义的语义，比如 Hashing Columns。因为这里也希望 TableScan 之类的时候，不会对 Shuffle 之类的内容造成太大的负担</li><li>Our row IDs are a cryptographic hash of the change tracking columns, which ensures uniqueness to a very high probability.（比如 geohash 或者类似的？猜测和 row 还有 partition 有关）</li></ol><p>这里还有个问题是，上面作为 base 表的，那么作为传下去或者 mv 的呢？这里的处理方式是：</p><ol><li>Filter / Project 不改变 row-id</li><li>Group By 根据 Group-by Agg Keys 来做 row-id</li><li>UNION ALL 在同一张表的 Filter 的时候，可能相对复杂一些</li></ol><p>Snowflake 说他们没遇到什么 corner case，什么绿皮暴力搞法大力出奇迹。</p><h3 id="Stream-Transactions"><a href="#Stream-Transactions" class="headerlink" title="Stream Transactions"></a>Stream Transactions</h3><p><img src="https://image.mwish.me/blog-image/7468682257460978131.png" alt="img"></p><p>在 STREAM 被查询的时候，这里会尝试消费，消费的时候会满足原子性。</p><ol><li>如果设计单个 Table，那会很简单，但是多个 table，会比较蛋疼，因为 snowflake 好像没有全局时间戳。这里 frontier 会检测多个 base table 的版本，来保证 STREAM 内部不会有冲突</li><li>STREAM 本身代表过去的时间戳，所以它自己要存时间戳，这里也会有个 last updated 的物理时间戳</li><li>在消费 STREAM 可能会有事务，所以一个 STREAM 可能不能被多个客户端消费</li><li>Staleness 会根据 Retention 来维护</li></ol><h2 id="USAGE-AND-PERFORMANCE-ANALYSIS"><a href="#USAGE-AND-PERFORMANCE-ANALYSIS" class="headerlink" title="USAGE AND PERFORMANCE ANALYSIS"></a>USAGE AND PERFORMANCE ANALYSIS</h2><p><img src="https://image.mwish.me/blog-image/1423177542917606780.png" alt="img"></p><p><img src="https://image.mwish.me/blog-image/4745081897764211093.png" alt="img"></p><p><img src="https://image.mwish.me/blog-image/3412166040666676318.png" alt="img"></p><h2 id="批话环节"><a href="#批话环节" class="headerlink" title="批话环节"></a>批话环节</h2><p>这篇文章描述的内容还是很朴素的，我当时以为有啥大招，但是还是硬扫。这块难度应该不在存储上，对查询改写、优化器甚至上游调度开销会比较高。而且很多东西还是 Open Problem。期待厂商还是能把这套机制和 Live Table 之类的结合起来，或者提供一些 Streaming 的算子，抽象出一个更高效的框架。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark: RDD design</title>
      <link href="/2023/06/21/Spark-RDD-design/"/>
      <url>/2023/06/21/Spark-RDD-design/</url>
      
        <content type="html"><![CDATA[<p>以 2023 年的视角来看，MapReduce 是个过度力大砖飞的软件，它强调强制的 2个 Stage （一些其他第三方之类的方案会有别的 Stage），然后 Stage 中间 Sort + 落 HDFS 文件来做 Shuffle，靠 Reducer Pull 来传输数据。这样的计算流很固定、性能比较低效，但是相对来说确实是个力大砖飞的方案。</p><p>Spark 之前，首先是微软在 SCOPE 系统和 DryadLinq 之类的地方做出了贡献，包括 DAG 一样的计算流、（类）SQL 的支持，但是 Spark 确实是开源社区很早掏出来的，并且在今天已经茁壮成长为了 DataBricks 这样的巨大公司和拥有了庞大的周边生态，可见这套东西打法还是很重要。Spark 支持的对象有 DataSet/DataFrame 和 SQL 甚至 Streaming / ML 等多个目标的庞大系统。不过我们会在之后的内容中提到 Spark SQL 甚至 DataFrame，我们今天只涉及 Spark 论文中提出的 RDD。</p><h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>Spark 最初版本整个在 Scala 上编写，它提供的抽象是 RDD。在论文写作的时候，它只做一些 Batch Exec 的计算，并且论文中提到的优势场景包括 iterative algorithms (eg: 图计算，ML 的训练) 和 interactive data mining tools(给同一份数据发多次 adhoc query). 同时，RDD 的目标是<strong>尽量用上内存</strong>(利用上内存并不难，但是 MPI 可能需要知道对应机器的位置，此外还需要能够从故障或者 worker failover 中恢复出来)、利用 Intermediate result。</p><p>相对于 MPI, Pregel 等系统，Spark RDD 构建的是一种<strong>粗粒度的抽象</strong>，它：</p><ul><li>类似 Fp，本身是 immutable 的</li><li>描述计算过程，同时也有一些相对 internal 的东西， 比如 Partition。也允许有 <code>persist</code> (持久化) 和 <code>cache</code> (缓存/物化结果并尽量在内存)</li><li>Parallel：因为 RDD 只描述计算过程，同时一些 Map 累的计算流程通常是相同的，所以允许 Parallel 的去执行。当然也可以根据 partition 之类的东西来决定这部分的描述</li><li>Fault Tolerant: 这个 FT 名字有点抽象，并不是和 TP Workload 一样的 FT，而是和 MapReduce 那种没算完或者挂了，就去重新 Exec 对应的任务</li></ul><p>上面的部分其实有点抽象。不过后面都会讲。论文先举了两个 RDD 的例子：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lines = spark.textFile(<span class="string">&quot;hdfs://...&quot;</span>) </span><br><span class="line">errors = lines.filter(_.startsWith(<span class="string">&quot;ERROR&quot;</span>))</span><br><span class="line">errors.persist()</span><br><span class="line">errors.count()</span><br><span class="line"></span><br><span class="line">errors.filter(_.contains(<span class="string">&quot;MySQL&quot;</span>)).count()</span><br></pre></td></tr></table></figure><p>这里的计算流程可以如下所示：可以看到 RDD 要么来自文件输入（<code>lines</code>） 要么来自对之前 RDD 的 transformation。</p><p><img src="https://image.mwish.me/blog-image/image-20230619195027384.png" alt="image-20230619195027384"></p><p>文章也对比了 Spark 和 Distributed Memory 的优势（不过我个人认为 RDD 和 Distributed Memory 完全不是一套东西，也用在不同的场景，我现在觉得 Distributed Memory 是 “Internal”）下面的表格吹了很多有点，但我觉得主要区别还是：</p><ul><li>Spark 自己维护了 lineage，表述数据的构造和血缘关系</li><li>声明式需要某种计算 vs 具体实现对应的计算</li><li>RDD 在内存不够的时候也可以 downgrade 成类似 MapReduce 那种模式（利用 Spill 和 Shuffle）</li></ul><p>别的都是虚头巴脑的，感觉扯来扯去浪费时间。</p><p><img src="https://image.mwish.me/blog-image/0CAF7F90-40E2-474C-A42C-19B76FF70AB1.png" alt="0CAF7F90-40E2-474C-A42C-19B76FF70AB1"></p><p>这里论文还描述了一下不适合 RDD 不适合 Streaming 或者小亮多次更新的应用，看见 DataBricks 的 Live Table，我陷入了沉思。嘛，技术是发展的，Delta-IO 提供的数据湖本身也是一种绕弯弯的方案吧。</p><h3 id="Spark-Programming-Interface"><a href="#Spark-Programming-Interface" class="headerlink" title="Spark Programming Interface"></a>Spark Programming Interface</h3><p>Spark 的 Cluster 模式如链接所述：<a href="https://spark.apache.org/docs/latest/cluster-overview.html">https://spark.apache.org/docs/latest/cluster-overview.html</a> 。本身把 worker 部署的时候部署在机器或者容器上，有 standalone, Yarn/Mesos 调度, Kubernetes 模式。这里有几个（全宇宙都一样的）模型：</p><p><img src="https://image.mwish.me/blog-image/cluster-overview.png" alt="cluster-overview"></p><p><img src="https://image.mwish.me/blog-image/image-20230620221329414.png" alt="image-20230620221329414"></p><p>用户可以用 Scala 编写 RDD，RDD 是带类型的对象 <code>RDD[T]</code>, 对 RDD 操作分为 <code>transformation</code> 和 <code>action</code>，里面内容其实非常好理解（我感觉一些带副作用的在这里反而显得有点怪）：</p><p><img src="https://image.mwish.me/blog-image/EBF3B6DA-0602-4995-B618-93751F38FD6C.png" alt="EBF3B6DA-0602-4995-B618-93751F38FD6C"></p><p> 这里会显得有点混乱，但是其实很简单，首先这些功能差不多都是函数式或者 db 类似的原语. 这里有几个值得注意的：</p><ul><li><code>join</code> <code>union</code> <code>cogroup</code> <code>crossProduct</code>: 令人熟悉的数据库老朋友</li><li><code>sort</code>: 懂得都懂（其实类型上 sort 还没有，我感觉类似会有个 properties 的东西在里面？）</li><li><code>partitionBy</code>: 需要注意的是，这里指定的是类似「物理执行」的属性，这点感觉其实对性能之类的相对来说比较重要，举个例子，比如本身可能走 shuffle 的计算，在 Partition 之后就不一定要走 Shuffle 了。</li></ul><p>论文这里提供了一个 <code>PageRank</code> 的例子，其实 MR 之类的都会在这介绍 PageRank，什么公共靶场. 这里需要注意的是，它把 <code>links</code> 给 <code>cache</code> 下来了，然后在每一步都可以用这个基本的 RDD，而不需要重新计算。这里有个 Python 的例子：<a href="https://github.com/apache/spark/blob/master/examples/src/main/python/pagerank.py">https://github.com/apache/spark/blob/master/examples/src/main/python/pagerank.py</a> （注意 <code>cache</code> 和迭代）</p><p><img src="https://image.mwish.me/blog-image/image-20230620225708643.png" alt="image-20230620225708643"></p><p>需要注意的是，作者认为这里 links 很大，所以没有去 <code>broadcast</code> 它，这里也提到，如果负载比较明确，可以去 <code>partition</code> 一把：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">links = spark.textFile(...).map(...).partitionBy(myPartFunc).persist()</span><br></pre></td></tr></table></figure><p>对的，其实 Spark RDD 还带了一组比较物理性质的操作：</p><p><img src="https://image.mwish.me/blog-image/0D7ADA36-5AD3-482E-B1BC-21766A1C686B.png" alt="0D7ADA36-5AD3-482E-B1BC-21766A1C686B"></p><p>Spark 的操作可以指定 <code>numPartition</code> 和对应的 <code>partitioner</code>, 甚至去 <code>repartition</code>，不过这里需要注意 <code>partition</code> 本身不生成 RDD （ <code>repartition</code> 肯定会）。它有：</p><ul><li>List Partition</li><li>Hash Partition</li><li>Range Partition</li></ul><p>上面几种，具体还是看业务了。<code>cache</code> / <code>presist</code> 本身是个 lazy 的操作，会在执行的时候才处理，<strong>Cache / Persist 的对象是 RDD 的结果</strong></p><h2 id="RDD-的组成"><a href="#RDD-的组成" class="headerlink" title="RDD 的组成"></a>RDD 的组成</h2><p>作者在这里认为，RDD 包含：</p><ul><li>Partitions</li><li>Dependencies (对应的数据源)</li><li>Compute Function</li><li>Metadata About Schema</li></ul><p>我个人觉得其实有点像数据库的 Physical Plan 一类的东西（或许 Spark SQL 的论文会告诉我有什么区别）。</p><p>关于 RDD，几个要关注的操作是：</p><ul><li>dependency and shuffle</li><li>plan 构建</li><li>cache / persist</li></ul><p>我们先讲 dependency &amp; shuffle. 也是 Spark 的核心之一。</p><h3 id="Dependency-and-Shuffle"><a href="#Dependency-and-Shuffle" class="headerlink" title="Dependency and Shuffle"></a>Dependency and Shuffle</h3><p><img src="https://image.mwish.me/blog-image/14AC10E6-1CB9-40C2-AAAC-2CA613DAF85B.png" alt="14AC10E6-1CB9-40C2-AAAC-2CA613DAF85B"></p><p>Spark 会根据操作类型来判断是否要 Shuffle，这里的判断方式其实看上面，意外很简单，它把 Spark 区分为 Narrow Dependencies 和 Wide Dependencies:</p><ul><li>Narrow Dependencies: where each <strong>partition</strong> of the parent RDD is used by at most one <strong>partition</strong> of the child RDD</li><li>Wide Dependencies: wide dependencies, where multiple child partitions may depend on it.</li></ul><p>这里我特地贴原文，因为它含义还是比较清晰的，因为这里一对一 和多对一的单位是 <strong>RDD中的 Partition</strong> ！</p><ul><li>OneToOne、ManyToOne 之类的关系显然肯定是 Narrow Dependencies</li><li>多对一参照 Partition，co-locate Join 这种可能会是 Narrow Dependencies!</li></ul><p>我们下面区分到 Shuffle 的实现，Shuffle 在 MapReduce 中也能见到，它是一个部分整个写过去，另一部分整个读的操作。这个操作还是相当重的，而且可能涉及排序。这里考虑分成 Shuffle Write 和 Shuffle Read 的阶段，写的时候可能走排序或者 Hash + Agg，读的时候可能还需要再走一个类似多路归并的操作。</p><p><img src="https://image.mwish.me/blog-image/BC2A9E92-563A-4D1D-8647-7336690F0C24.png" alt="BC2A9E92-563A-4D1D-8647-7336690F0C24"></p><p>在 VLDB‘20 上，LinkedIn 的工程师提供了一个 Spark Shuffle 的方案，Spark 3.2 的时候被 Merge 进去了。之后写篇单独文章介绍这个 Shuffle 的流程好了。</p><h3 id="Stage"><a href="#Stage" class="headerlink" title="Stage"></a>Stage</h3><p><img src="https://image.mwish.me/blog-image/C0F5047D-EBFA-4C60-9265-16E8822B489B.png" alt="C0F5047D-EBFA-4C60-9265-16E8822B489B"></p><p>Spark 会按照 Wide Dependencies 拆分成多个 Stage，Stage 内并行执行（有点类似 Push-based Execution Engine？）</p><p><img src="https://image.mwish.me/blog-image/63816205-6672-4A0D-8A47-E3AD07D1A28D.png" alt="63816205-6672-4A0D-8A47-E3AD07D1A28D"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文关注 Spark 计算和 Shuffle，省略了内存管理、代码生成等部分，因为我感觉这些东西要么我们之前讲过更现代的方案，要么 Photon 自己做了，没必要在意这么老论文是怎么 codegen 、内存管理的。</p><p>Spark 感觉论文里也提出了力大砖飞的方式。此外，对于 Shuffle 等地方的优化，本文也只是提到，没有深入（入门阶段先 move-fast 先扫一遍，之后懂得多了再补回来吧）。关于各个 transform，其实本来应该大有可以讲的地方，不过目前点到为止算了。</p><p>Spark 还有一套比较大的杀手锏是 Adaptive Query Execution，它能根据大小来动态调整执行的资源，来处理大数据场景的 skew，这是个比较重要的优化，但本文也略过了，实在深感惭愧。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><p>Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing</p></li><li><p>VLDB’20  Magnet: 领英Spark Shuffle解决方案 - Sovnlo的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/397391514">https://zhuanlan.zhihu.com/p/397391514</a></p></li><li><p>关于Spark 3.2.0 push-based shuffle - 斜杠代码日记的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/443752106">https://zhuanlan.zhihu.com/p/443752106</a></p></li><li><p>大数据处理框架Apache Spark设计与实现(<a href="https://book.douban.com/subject/35140409/">https://book.douban.com/subject/35140409/</a>)  许利杰、方亚芬 / 电子工业出版社</p></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Parallel Data Processing with MapReduce: A Survey</title>
      <link href="/2023/06/14/Parallel-Data-Processing-with-MapReduce-A-Survey/"/>
      <url>/2023/06/14/Parallel-Data-Processing-with-MapReduce-A-Survey/</url>
      
        <content type="html"><![CDATA[<p>上次写 MapReduce 的文章还是在很久之前，记得大四下学期毕业写 6.824 的时候写的：<a href="https://blog.mwish.me/2020/01/28/MapReduce-%E7%AE%80%E8%AF%BB/">https://blog.mwish.me/2020/01/28/MapReduce-%E7%AE%80%E8%AF%BB/</a> 。谁知道这门课都改名叫 6.8540 了。</p><p>Parallel Data Processing with MapReduce: A Survey 这篇 SIGMOD‘11 的论文在 MapReduce 发表几年后总结了一下 MapReduce 的优劣。我们会带着这篇论文的 Point 去看看一些后续的分布式计算。</p><p>MR 在 04 年推出的时候算是组了一堆垃圾机器，然后拼凑的一个满足 Google 搜索等计算需求的系统，Scalable 上其实问题没那么大（不讨论具体算子的话），但是 performance 和 efficiency 上可能没那么尽人意，毕竟三副本写、落盘等方式在 2023 年好时代的软件工程师看来其实是优点让人困惑的。不过事实证明，这套东西受到了很多人的欢迎。虽然大部分人觉得这套东西其实是一个历史的退步，MapReduce -&gt; Hadoop 这套东西也慢慢被后来的东西取代了，但是这中间出现的很多名词和概念还是有延续性的，毕竟如果讨论到分布式计算的各种算子， Shuffle / Sort 这些东西的优化其实也可能是根据这些最早的概念一步步来的。包括一些 Push/Pull 之类的讨论，和论文提出的一些远见，感觉概念还是有延续性的。在看 Spark RDD 之前我们还是先来回顾一下古老的 MapReduce 吧。</p><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p><img src="https://image.mwish.me/blog-image/5038885A-E1C0-404D-8CF7-7332A7477439.png" alt="5038885A-E1C0-404D-8CF7-7332A7477439"></p><p>MapReduce 的架构很简单：</p><ol><li>把程序（可能以 Binary 等方式）分布到 Mapper / Reducer 上，编写 Map 和 Reduce 函数</li><li>程序分为 Map 和 Reduce 两个 Stage，数据 Stage 都读取并落到 GFS 上，为了容错写三副本，读也走 GFS (HDFS) 来读取</li><li>Map Stage 的分布和 Input Block 还有 Map 的机器有关。Block 被分配给 Mapper，执行尽量无状态的 Map 函数，然后可能会走一个本地排序来做一下 Map-Key 的 Group By。最后走一个 optional 的 <code>Combiner</code> （类似 Map 端预 Reduce 或者别的逻辑）来提前减少数据量 I/O 带宽<ol><li>Map Stage 的结果存放在 <strong>本地或者多副本的存储上</strong>，然后按照 Reduce Task 的数量做一个 Partition，这里 Partition 成 R 份，通常是 <code>hash(key) mod R</code> 的形式。这里可能会有一个 Buffer 和 Spill-size，处理的时候内存装不下可以 Spill 文件或者合并</li><li>可能会有一个 shuffle 的流程，在 Map 写下去之前，会走 Hash Shuffle 或者 Sort Shuffle，把数据排序一遍写入，避免 Reduce 阶段打开过多的 Reader，和加速下游 Reducer 读取数据。</li></ol></li><li>在Map Stage 任务执行完之前，Reduce Stage 不能工作. 这里其实可以有一些更 flexible 的模型，比如 Mapper 直接把数据 push 到 Reducer，但是这样 Reducer 挂了事情可能就会变麻烦了，所以可以落一次盘</li><li>在 Reduce 阶段，<strong>一般一条 Record 只会发给一个 Reducer</strong> (Recall: JOIN). Reducer 以 <strong>Pull</strong> 模式去走 IPC 拉数据。这里有个类似 External Merge Sort 的方式来读取 — Merge 数据，因为需要读取多份奇怪的数据。最后把 Reduce 结果输出到 HDFS。在原论文中，Reducer 拉到数据需要排序一遍。</li><li>Stage 内 Task 和机器数量可以不相等，MapReduce 框架会监控看你执行的快不快。执行快的节点可以多执行几个任务，执行慢的可以设置超时然后换人跑。这也实现了对应的 Fault Tolerant 和自动的 load balance。</li><li>Hadoop 系可能有 Yarn 之类的框架，来给定对应内存的申请，然后把任务、调度和对应的任务绑定。</li></ol><p><img src="https://image.mwish.me/blog-image/09C1DE3C-5A3E-4246-97C4-A52B148A6D93.png" alt="09C1DE3C-5A3E-4246-97C4-A52B148A6D93"></p><p>MapReduce 可不可以只有一个阶段呢？比如 Filter 或者 Project 可能会只有 Map 阶段，</p><h2 id="Pros-and-cons"><a href="#Pros-and-cons" class="headerlink" title="Pros and cons"></a>Pros and cons</h2><p>首先 Stonebraker 这些做数据库的人觉得贼几把不爽，自己优化的好好的突然来一波人写了个很挫的架构然后还很受欢迎。接下来又一些博客的对线。历史其实是很清晰的，想必在座的各位都知道这二十年都经历了什么破事。</p><blockquote><p>Anderson et al also criticize that the current Hadoop system is scalable, but achieves very low eﬃciency per node, less than 5MB/s processing rates, repeating a mistake that previous studies on high-performance systems often made by “focusing on scalability but missing eﬃciency” [32]. This poor eﬃciency involves many issues such as performance, total cost of ownership(TCO) and energy. Although Hadoop won the 1st position in GraySort benchmark test for 100 TB sorting(1 trillion 100-byte records) in 2009, its winning was achieved with over 3,800 nodes [76]. MapReduce or Hadoop would not be a cheap solution if the cost for constructing and maintaining a cluster of that size was considered.</p></blockquote><p>（题外话，随着硬件发展 MotherDuck 甚至在网上发博客说大数据不存在了，意思是除了大公司的数据其他小公司的跑个单机嵌入式差不多得了。我不置可否不过也很好奇他们准备怎么赚钱）</p><p>比较有意思的是，这里抽象出了一个模型，模型有下面几点：</p><ol><li>Efficiency</li><li>Fault Tolerant</li></ol><p>这里的观点是，MR 有着很强的 Fault Tolerant，取而代之的是碎成渣的 Efficiency，因为它要很频繁的去做 Local File IO （不考虑输入端和输出端）或者作为 checkpoint。作为对比，Efficient 的代表是但是的数据库，取而代之的可能是对 Batch Job，对重任务的重试不友好。随后，作者报菜名的介绍了一下 MapReduce 的优点和缺点：</p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>(这一段我看的比较困惑，可能没做过计算是这样的)</p><ol><li>Flexible: ??? 至少你可以无视数据格式造大便</li><li>Independent of storage: 呃呃呃….这个可能是跟绑定存储的 MPP 比较的吧</li><li>Fault tolerance: 这个我还是认可的</li><li>High Scalabity: 其实我不是很懂 scalable，感觉 DOP 无脑往大切也不太好吧，但至少对一些需要并发的 Batch Job 可能确实是优势？（2023 年的机器和 2004 年已经不一样了。。。）</li></ol><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol><li>No high-level language</li><li>No schema and no index</li><li><strong>A single fixed dataflow</strong></li><li>Low efficiency<ol><li>External Sort-Merge</li><li>Materialization of intermediate results</li><li>write to distributed file system (?)</li><li>block-level restrarts</li><li>one-to-one shuffle strategy (?)</li><li>simple runtime scheduling</li></ol></li></ol><h2 id="对-MapReduce-的改进"><a href="#对-MapReduce-的改进" class="headerlink" title="对 MapReduce 的改进"></a>对 MapReduce 的改进</h2><p>这节主要介绍了（作者认为的）MapReduce 的问题，我本来蛮期待这节的，但是读着读着发现写的还是太早了，很多改进的系统都已经死了。读这节的时候，主要还是关注，在 2023 年这个节点，大数据系统是怎么克服这些问题的。</p><h3 id="High-Level-Languages"><a href="#High-Level-Languages" class="headerlink" title="High-Level Languages"></a>High-Level Languages</h3><p>微软的 SCOPE, Apache Pig, Apache Hive 都包含上层语言相关的改进，包括 Spark 的模型也支持 DataFrame 和 SQL 两种形式。这里比较著名的是微软的 SCOPE 上的 DryadLinq 和 Spark SQL。都能够把 SQL 转成<strong>自己的执行流</strong>。</p><p>我们之前介绍过 Hive，Hive 支持 Hive QL，支持 adhoc query。Hive 如果后台是 MR，它收到 SQL 会编译产生一组 Stage，然后 Stage 代表对应的 MR Job。</p><h3 id="Schema-Support"><a href="#Schema-Support" class="headerlink" title="Schema Support"></a>Schema Support</h3><p>Schema 有好几层含义，这里主要指的是 MapReduce 论文中本身处理的是纯文本或者二进制，所以过于 flexible 的问题，实际上这里的解决方式有上层提供 Schema 和提供一定的格式。实际上很多格式本身就是「大数据 / Hadoop 系」搞出来的，比如 Avro、Parquet、ORC 这几个格式都多少是从「大数据社区」孵化出来的。</p><p>关于这个，感觉 Schema Support 本身也是讨论烂了的内容了。</p><h3 id="Flexible-Data-Flow"><a href="#Flexible-Data-Flow" class="headerlink" title="Flexible Data Flow"></a>Flexible Data Flow</h3><p>Flexible Data Flow 主要在于 Map / Reduce 模型本身的优化和改进，比如一些算法本身要维护一些处理数据的状态。</p><p>一些改进，比如 Map-Reduce 要读多个输入的时候（比如 Join），可能会有一个 Map-Reduce-Merge 的模型.</p><p>不过，现在的版本宠儿是 Spark / Dryad 这样的类似 DAG 的流。通过 点（计算）和边（TCP / 内存 / 落文件这样的通信）来构成对应的计算。这些东西一起受到 Runtime 的调度。</p><h3 id="Blocking-Operations"><a href="#Blocking-Operations" class="headerlink" title="Blocking Operations"></a>Blocking Operations</h3><p>MapReduce 的计算流类似 BSP 模型，不执行完上一部就不能执行下一步，这样也不是很好处理<strong>增量的请求和 Online Processing</strong>（ Google 当时用 MapReduce 跑批，然后走 Percolator 的小 TP 请求来插入新的数据），也不支持 Streaming 这样的东西，这里也有一些对应的更新的模型。我个人感觉这里模型本质上还是说，MR 这类东西只适合跑批，需要在同样的模型上支持一些轻量的操作。</p><p>我个人感觉 Lakehouse / Delta-Lake 这种（包括 Paimon 这种 Flink Table Format）：</p><ol><li>一个通用的 Table Format，有比较适合插入的结构</li><li>一个强劲的 meta</li></ol><h3 id="I-O-Optimization"><a href="#I-O-Optimization" class="headerlink" title="I/O Optimization"></a>I/O Optimization</h3><p>Parquet / ORC 这种结构在 I/O 等 Optimize 上效果显著。</p><h3 id="Scheduling-TBD"><a href="#Scheduling-TBD" class="headerlink" title="Scheduling(TBD)"></a>Scheduling(TBD)</h3><p>调度有问题主要是 MR 论文的调度太 sb 了，这里提到了估计估算等，我感觉这里主要关注 Yarn 的调度等。这个之后专门写一篇博客吧。</p><ul><li>对任务本身的起止重试等进行估计</li><li>还有一个问题是，如果 MR 的集群是共享的，那么多租户这一个层次的调度。</li><li>如果有相似的计算，避免重复计算（共享请求）</li></ul><h3 id="Joins"><a href="#Joins" class="headerlink" title="Joins"></a>Joins</h3><p>Map Reduce 本身只支持一个 input，所以 Join 是一个在上面需要绕弯弯解决的问题。这里有几种对应的方案：</p><ol><li>Map-side Join: 实现方式类似 RDBMS 的 SMJ, 根据 key 来做 partition，然后被 Join 到一起。另一种是对应的 broadcast Join. Map-side join 一定程度上能减小对应的网络和传输开销。broadcast join 也可以在 Map 阶段搞定</li><li>Reduce-side Join: 最通用的 Join. Map 来做对应的标记，然后来做 key-equality join.</li><li>Map-Reduce-Merge: 在 Reduce 后加一个 Merge 阶段，类似 Filtering-Join-Agg 的模式</li></ol><p>我们以 Hive 为例子，Hive 会有：</p><ol><li>发生在 Shuffle / Reduce 阶段的<ol><li>Map: 读取 A, B 的数据，然后根据 Join 条件发往 Reduce（可能走 Shuffle），检测 Key 相同的，做 Join</li></ol></li><li>发生在 Map 阶段的：Map 侧完成操作<ol><li>有一个 Stage 读取小表，然后存 HashTable 到文件系统。然后任务中 Map 阶段读它，做 Join</li></ol></li><li>可以做 Bucket Map Join, Table 1 和 Table 2 的 bucket 成倍数关系可以快速 Bucket 裁剪</li><li>可能需要处理 Skew Data，特殊分配一个作业处理 Skew 的数据</li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>Hive 性能调优实战 林志煌 煮</li><li>Parallel Data Processing with MapReduce: A Survey</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ToyDB Query Parsing</title>
      <link href="/2023/06/07/ToyDB-Query-Parsing/"/>
      <url>/2023/06/07/ToyDB-Query-Parsing/</url>
      
        <content type="html"><![CDATA[<p>ToyDB 提供了手动解析的 Parser 和自己写的 Catalog 和 Planner，Catalog. 它有一个很奇怪的特点就是，大家都叫一个名字，然后从 modules 来区分。我不知道这算不算好的实践，反正给我整的有点麻。</p><p>这里我折腾了一个简单的可以玩 query 的场景：<a href="https://github.com/mapleFU/toydb">https://github.com/mapleFU/toydb</a> ，见这个项目里的 <code>test_basic_sql</code>。</p><h2 id="Catalog"><a href="#Catalog" class="headerlink" title="Catalog"></a>Catalog</h2><p>ToyDB 的 Catalog 和 Transaction 是半绑定的，Catalog 和 Transaction 都以一个 Trait 的形式提供。ToyDB 的 Catalog 只支持单个 database，不支持 DDL。系统会存储在一个 Raft Key-Value 的事务引擎上，存储内容如下：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Encodes SQL keys, using an order-preserving encoding - see kv::encoding for details. Options can</span></span><br><span class="line"><span class="comment">/// be None to get a keyspace prefix. We use table and column names directly as identifiers, to</span></span><br><span class="line"><span class="comment">/// avoid additional indirection and associated overhead. It is not possible to change names, so</span></span><br><span class="line"><span class="comment">/// this is ok. Uses Cows since we want to borrow when encoding but return owned when decoding.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// 最后一项可能由 Option 构成, Option 为空的时候, 可以拿到这个 key</span></span><br><span class="line"><span class="comment">/// 编码: 这里会把对应的对象整理成一个 Key, Table / Index / Row 存放在不同的 keyspace (类似 ns).</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// 这个基本上套了一层 foundation db 的编码系统。</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">Key</span>&lt;<span class="symbol">&#x27;a</span>&gt; &#123;</span><br><span class="line">    <span class="comment">/// A table schema key for the given table name</span></span><br><span class="line">    <span class="comment">/// tableName.</span></span><br><span class="line">    <span class="comment">/// 这个的 prefix 为 0x01</span></span><br><span class="line">    <span class="title function_ invoke__">Table</span>(<span class="type">Option</span>&lt;Cow&lt;<span class="symbol">&#x27;a</span>, <span class="type">str</span>&gt;&gt;),</span><br><span class="line">    <span class="comment">/// A key for an index entry</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// (tableName, columnName, value).</span></span><br><span class="line">    <span class="title function_ invoke__">Index</span>(Cow&lt;<span class="symbol">&#x27;a</span>, <span class="type">str</span>&gt;, Cow&lt;<span class="symbol">&#x27;a</span>, <span class="type">str</span>&gt;, <span class="type">Option</span>&lt;Cow&lt;<span class="symbol">&#x27;a</span>, Value&gt;&gt;),</span><br><span class="line">    <span class="comment">/// A key for a row identified by table name and row primary key</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// (tableName, value)</span></span><br><span class="line">    <span class="title function_ invoke__">Row</span>(Cow&lt;<span class="symbol">&#x27;a</span>, <span class="type">str</span>&gt;, <span class="type">Option</span>&lt;Cow&lt;<span class="symbol">&#x27;a</span>, Value&gt;&gt;),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对应 Trait 如下：</p><ul><li>Catalog, Schema, Column, Table: <a href="https://github.com/erikgrinaker/toydb/blob/master/src/sql/schema.rs">https://github.com/erikgrinaker/toydb/blob/master/src/sql/schema.rs</a><ul><li>Column 有基本的 <code>(name, type)</code> 支持 default, pk, nullable, unique, foreign key 甚至 index，支持上层去 validate 对应的 value，这个检查。（虽然有的地方我感觉不应该在 Column 里面支持）</li><li>Table 即 <code>&lt;name: String, columns: [Column]&gt;</code>，在单个 Table 内，只有单个 key 是主键，不支持联合主键。Index 也只支持单值的 Index，不支持联合索引</li><li>Schema 这里会访问物理层，来拿到对应的内容。</li><li>它的 Catalog 这个地方支持的是访问 Table 的接口</li><li>讨论：在 Column 支持 pk, default, unique, fk 应该不是一个合理的方案。</li></ul></li></ul><h2 id="Parsing"><a href="#Parsing" class="headerlink" title="Parsing"></a>Parsing</h2><p>这里的 Lexer 不太教科书，而是手工编写的一个识别器，我感觉用 flex 写一个没准还舒服些。</p><p>语法分析则是一个递归下降的 Parsing，语法结构如下：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Parses an SQL statement</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">parse_statement</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;ast::Statement&gt; &#123;</span><br><span class="line">    <span class="keyword">match</span> <span class="keyword">self</span>.<span class="title function_ invoke__">peek</span>()? &#123;</span><br><span class="line">        <span class="title function_ invoke__">Some</span>(Token::<span class="title function_ invoke__">Keyword</span>(Keyword::Begin)) =&gt; <span class="keyword">self</span>.<span class="title function_ invoke__">parse_transaction</span>(),</span><br><span class="line">        <span class="title function_ invoke__">Some</span>(Token::<span class="title function_ invoke__">Keyword</span>(Keyword::Commit)) =&gt; <span class="keyword">self</span>.<span class="title function_ invoke__">parse_transaction</span>(),</span><br><span class="line">        <span class="title function_ invoke__">Some</span>(Token::<span class="title function_ invoke__">Keyword</span>(Keyword::Rollback)) =&gt; <span class="keyword">self</span>.<span class="title function_ invoke__">parse_transaction</span>(),</span><br><span class="line"></span><br><span class="line">        <span class="title function_ invoke__">Some</span>(Token::<span class="title function_ invoke__">Keyword</span>(Keyword::Create)) =&gt; <span class="keyword">self</span>.<span class="title function_ invoke__">parse_ddl</span>(),</span><br><span class="line">        <span class="title function_ invoke__">Some</span>(Token::<span class="title function_ invoke__">Keyword</span>(Keyword::<span class="built_in">Drop</span>)) =&gt; <span class="keyword">self</span>.<span class="title function_ invoke__">parse_ddl</span>(),</span><br><span class="line"></span><br><span class="line">        <span class="title function_ invoke__">Some</span>(Token::<span class="title function_ invoke__">Keyword</span>(Keyword::Delete)) =&gt; <span class="keyword">self</span>.<span class="title function_ invoke__">parse_statement_delete</span>(),</span><br><span class="line">        <span class="title function_ invoke__">Some</span>(Token::<span class="title function_ invoke__">Keyword</span>(Keyword::Insert)) =&gt; <span class="keyword">self</span>.<span class="title function_ invoke__">parse_statement_insert</span>(),</span><br><span class="line">        <span class="title function_ invoke__">Some</span>(Token::<span class="title function_ invoke__">Keyword</span>(Keyword::Select)) =&gt; <span class="keyword">self</span>.<span class="title function_ invoke__">parse_statement_select</span>(),</span><br><span class="line">        <span class="title function_ invoke__">Some</span>(Token::<span class="title function_ invoke__">Keyword</span>(Keyword::Update)) =&gt; <span class="keyword">self</span>.<span class="title function_ invoke__">parse_statement_update</span>(),</span><br><span class="line"></span><br><span class="line">        <span class="title function_ invoke__">Some</span>(Token::<span class="title function_ invoke__">Keyword</span>(Keyword::Explain)) =&gt; <span class="keyword">self</span>.<span class="title function_ invoke__">parse_statement_explain</span>(),</span><br><span class="line"></span><br><span class="line">        <span class="title function_ invoke__">Some</span>(token) =&gt; <span class="title function_ invoke__">Err</span>(Error::<span class="title function_ invoke__">Parse</span>(<span class="built_in">format!</span>(<span class="string">&quot;Unexpected token &#123;&#125;&quot;</span>, token))),</span><br><span class="line">        <span class="literal">None</span> =&gt; <span class="title function_ invoke__">Err</span>(Error::<span class="title function_ invoke__">Parse</span>(<span class="string">&quot;Unexpected end of input&quot;</span>.<span class="title function_ invoke__">into</span>())),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以从这个来推断出它的结构，这段应该是按照 standard 写的，还算有参考价值。对外产生最终的结构在目录 <code>ast</code> 下头，具体是一个 <code>ast::Statement</code>.</p><p>特殊的，如果是 <code>SELECT *</code></p><h2 id="Planner"><a href="#Planner" class="headerlink" title="Planner"></a>Planner</h2><p>Planner 负责将 <code>ast::Statement</code> 转为 <code>Plan</code>. 这部分 Plan / PlanNode 本身就是可以运行的了，通过走一个可选的 Optimizer 来进行优化。</p><p>这个地方没有一个 （单独的）Binder 阶段来 resolve name，</p><h3 id="Plan-Select"><a href="#Plan-Select" class="headerlink" title="Plan Select"></a>Plan Select</h3><h4 id="Scope"><a href="#Scope" class="headerlink" title="Scope"></a>Scope</h4><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Manages names available to expressions and executors, and maps them onto columns/fields.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Scope 包含一组有序的 columns. 同时包含限定符, 表示这些东西的归属.</span></span><br><span class="line"><span class="meta">#[derive(Clone, Debug)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Scope</span> &#123;</span><br><span class="line">    <span class="comment">// If true, the scope is constant and cannot contain any variables.</span></span><br><span class="line">    constant: <span class="type">bool</span>,</span><br><span class="line">    <span class="comment">// Currently visible tables, by query name (i.e. alias or actual name).</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Table 的名称集合, 构建了 alias / table_name -&gt; Table 的映射</span></span><br><span class="line">    <span class="comment">// TODO(maple): 这个 Table 是怎么构建出来的? 具体 binding 吗?</span></span><br><span class="line">    tables: HashMap&lt;<span class="type">String</span>, Table&gt;,</span><br><span class="line">    <span class="comment">// Column labels, if any (qualified by table name when available)</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// columns 是表的 source-of-truth, 下面三个 hash 都是根据这玩意造出来的.</span></span><br><span class="line">    columns: <span class="type">Vec</span>&lt;(<span class="type">Option</span>&lt;<span class="type">String</span>&gt;, <span class="type">Option</span>&lt;<span class="type">String</span>&gt;)&gt;,</span><br><span class="line">    <span class="comment">// Qualified names to column indexes.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// qualified: 有 table-name 和 field-name 的, 这个地方 field-name 可能是一个 label.</span></span><br><span class="line">    qualified: HashMap&lt;(<span class="type">String</span>, <span class="type">String</span>), <span class="type">usize</span>&gt;,</span><br><span class="line">    <span class="comment">// Unqualified names to column indexes, if unique.</span></span><br><span class="line">    unqualified: HashMap&lt;<span class="type">String</span>, <span class="type">usize</span>&gt;,</span><br><span class="line">    <span class="comment">// Unqualified ambiguous names.</span></span><br><span class="line">    <span class="comment">// TODO(maple): ambiguous 的 name 是怎么 solving 的?</span></span><br><span class="line">    ambiguous: HashSet&lt;<span class="type">String</span>&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Expression"><a href="#Expression" class="headerlink" title="Expression"></a>Expression</h3><p>Expression 的 solving 通常不需要变更类型，字面量是什么类型使用的就是什么类型，这里支持的类型有：</p><ul><li>INTEGER: 1, 2, 3</li><li>FLOAT: 1.2</li><li>NULL</li><li>Boolean: true, false</li><li>String: <code>&#39;&#39;</code></li></ul><p>常量解析的时候，一般就用上面这些类型，然后在表达式 eval 阶段判断类型。</p><p>表达式会从 <code>Scope</code> 中捞到名字，从 <code>ast::Expression</code> 构建一个 <code>Expression</code> 它会构建：</p><ul><li>Literal: 返回 <em><code>Constant</code></em></li><li>Field: 带有来源的 fieldId 和 table.name 的名字，返回 <code>Field</code></li><li>Function：<em>很遗憾，它没有实现任何 function</em><ul><li>搜了下，function 处理中，可以参考这两个。toydb 类型处理感觉是比较简单的，function 和 ast::function 一一对应<ul><li><a href="https://www.postgresql.org/docs/current/sql-expressions.html">https://www.postgresql.org/docs/current/sql-expressions.html</a></li><li><a href="https://duckdb.org/docs/sql/functions/date">https://duckdb.org/docs/sql/functions/date</a></li></ul></li></ul></li><li><strong>Column: 这个比较重要，放后面说，这个在它的 SQL 语法不存在，属于内部生成的</strong></li><li>Operation: 从 AND OR 到加减法等等</li></ul><p>总之，这里会构建一份 Expression</p><h3 id="FromTable-TableRef-构建"><a href="#FromTable-TableRef-构建" class="headerlink" title="FromTable ( TableRef ) 构建"></a>FromTable ( TableRef ) 构建</h3><ul><li>采用</li></ul><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">build_from_clause:</span><br><span class="line">- copy 一份 root Scope</span><br><span class="line">- (对每个子成员) (使用 root Scope) build_from_item</span><br><span class="line">  - (递归基) 去 catalog 查询有没有这个名字的表, 然后走 `scope::add_table`, 返回一个 Node::Scan</span><br><span class="line">  - (Join) 去 build_from_item 左表, 然后用同一个 scope 去 build_from_item 右表</span><br><span class="line">    再用这个 scope 去 `build_expression`, 构建出 `ON ..` 的条件</span><br><span class="line">    构成一个 Node::NextLoopJoin 节点. (这里有一些关于 right join 的 hack 操作，暂不讨论)</span><br><span class="line">- 对上述的成员，构成一个 Node::NestLoopJoin 的左深树, 并递归的去 merge 这些 scope</span><br></pre></td></tr></table></figure><p>这个地方用到了 <code>build_expression</code> 来处理 <code>ON</code> 的情况，对外返回了一个新的 Scope.</p><h3 id="Where-构建"><a href="#Where-构建" class="headerlink" title="Where 构建"></a>Where 构建</h3><p>用到了 <code>build_expression</code> 来处理 <code>WHERE</code> 子表达式。同 Expression 一节</p><p>注意这里没有 subquery，所以内容应该很简单</p><h3 id="Selection-List-处理"><a href="#Selection-List-处理" class="headerlink" title="Selection-List 处理"></a>Selection-List 处理</h3><p><code>select-list</code> 如果是 empty，作者认为是全部输出（即 <code>SELECT *</code>），不懂 SQL 语法，这是真的吗？</p><h4 id="inject-hidden"><a href="#inject-hidden" class="headerlink" title="inject_hidden"></a>inject_hidden</h4><p>这里会先尝试给 select 去 <code>inject_hidden</code>，插入一些需要结果的 ast::Expr 或者 ast::Field，最后再通过 Projection 把这些字段给 Prune 掉。这个时候会利用之前说的 <code>Column</code> 字段。</p><p>这里会尝试：</p><ul><li>插入 HAVING 的内容</li><li>插入 ORDER BY 的内容</li></ul><p><code>inject_hidden</code> 插入的时候，会有两个 <code>ast::Expr</code>:</p><ul><li>Selection 的 expr 组</li><li>需要插入的 expr</li></ul><p>这个时候，大致逻辑如下：</p><ul><li>扫描 selection ，和需要插入的 expr 对比<ul><li>如果某项成员正好相等 (<code>SELECT x .. ORDER BY x</code>)，那么就标记为 <code>ast::expr::Column</code></li><li>否则，访问 expr 树，找到对应的 Column Ref，然后替换成对应的上下文，比如 <code>SELECT a .. HAVING a = 10</code> , <code>a</code> 替换为 <code>Column(0)</code></li></ul></li><li>对于没有找到相似的，全部加入 <code>selection</code>, 然后表达式替换为 <code>Column( 在 selection 中的位置)</code></li></ul><h4 id="Plan-Agg"><a href="#Plan-Agg" class="headerlink" title="Plan Agg"></a>Plan Agg</h4><p>Plan Agg 是代码里面我看的最蛋疼的一部分，这个部分结果大概是：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Aggregation aggregates</span><br><span class="line">- Projection aggregators, group-bys</span><br></pre></td></tr></table></figure><p>Eg:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">└─Aggregation: sum</span><br><span class="line">   └─ Projection: a, b + <span class="number">2</span></span><br><span class="line">       └─ Filter: a &gt; <span class="number">0</span></span><br></pre></td></tr></table></figure><p>Aggregation 前 aggregates 项是对应的，后面来自 GROUP-BY 子句</p><p>Group-BY 表达式的处理分成好几个阶段：</p><ul><li>从 Selection-List 中抽取 Aggregation<ul><li>把 Selection 中的表达式替换为对 Aggregation 的 Column-Ref, 这里相当于从 Select 里面抽出 expr. <code>exprs</code> 都是裸的 ast::expr. <code>SELECT max(a) ...</code> 抽成 ColumnRef(0) + MAX</li><li>能抽成 Field-Ref 的尽量抽取成 Field-Ref，表达形式为 <code>Column(idx)</code></li></ul></li><li>抽取 GROUP BY<ul><li>把 Selection 中的表达式替换为对 Group By 的 Column-Ref</li></ul></li><li>构建 Aggregator<ul><li>插入上面的表达式。这里会对 <code>Scope</code> 做一个 Projection，有点 hack，我还得消化一下</li></ul></li><li>再构建一个 Projection，拿到 Selection-List</li></ul><h3 id="剩余"><a href="#剩余" class="headerlink" title="剩余"></a>剩余</h3><ul><li>Build Having</li><li>Build Order</li><li>Build Offset</li><li>Build Limit</li><li>把 <code>inject_hidden</code> 插入的隐藏列 Projection 掉</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Why do InnoDB need ReadView</title>
      <link href="/2023/06/07/Why-do-we-need-ReadView/"/>
      <url>/2023/06/07/Why-do-we-need-ReadView/</url>
      
        <content type="html"><![CDATA[<p>之前其实一直不好理解为什么 InnoDB 多要了一个 ReadView，看完了某个回答（  <a href="https://www.zhihu.com/question/40514055/answer/86935747）之后，突然理解了。">https://www.zhihu.com/question/40514055/answer/86935747）之后，突然理解了。</a></p><h2 id="InnoDB-MVCC"><a href="#InnoDB-MVCC" class="headerlink" title="InnoDB MVCC"></a>InnoDB MVCC</h2><p>在系统中，有几个 txn:</p><ol><li>事务的 DB_TRX_ID，如果是读写事务的话，会在 <code>trx_sys_get_new_trx_id()</code> 分配一个递增的 <code>trx_id</code>, 我们可以简单将其视作 <code>start_trx_id</code></li><li>在事务 Commit 的时候，提交 undo 的时候，会分配 <code>txn_no</code> 给 Undo ( <code>trx_serialisation_number_get</code> -&gt; <code>trx_sys_get_new_trx_id()</code> )，这个可以看作 <code>end_ts</code></li><li>而每个读事务会在自己的 ReadView 中记录自己开始的时候看到的最大的 trx_no 为 <code>m_low_limit_no</code>。ReadView 列表按照 <code>m_low_limit_no</code></li></ol><p>InnoDB MVCC 相关的结构如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** The MVCC read view manager */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MVCC</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  Allocate and create a view.</span></span><br><span class="line"><span class="comment">  @param view   view owned by this class created for the</span></span><br><span class="line"><span class="comment">                          caller. Must be freed by calling close()</span></span><br><span class="line"><span class="comment">  @param trx    transaction creating the view */</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">view_open</span><span class="params">(ReadView *&amp;view, <span class="type">trx_t</span> *trx)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  Close a view created by the above function.</span></span><br><span class="line"><span class="comment">  @param view   view allocated by trx_open.</span></span><br><span class="line"><span class="comment">  @param own_mutex  true if caller owns trx_sys_t::mutex */</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">view_close</span><span class="params">(ReadView *&amp;view, <span class="type">bool</span> own_mutex)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  Release a view that is inactive but not closed. Caller must own</span></span><br><span class="line"><span class="comment">  the trx_sys_t::mutex.</span></span><br><span class="line"><span class="comment">  @param view   View to release */</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">view_release</span><span class="params">(ReadView *&amp;view)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Clones the oldest view and stores it in view. No need to</span></span><br><span class="line"><span class="comment">  call view_close(). The caller owns the view that is passed in.</span></span><br><span class="line"><span class="comment">  It will also move the closed views from the m_views list to the</span></span><br><span class="line"><span class="comment">  m_free list. This function is called by Purge to create it view.</span></span><br><span class="line"><span class="comment">  @param view   Preallocated view, owned by the caller */</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">clone_oldest_view</span><span class="params">(ReadView *view)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  @return the number of active views */</span></span><br><span class="line">  <span class="function">ulint <span class="title">size</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  @return true if the view is active and valid */</span></span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="type">bool</span> <span class="title">is_view_active</span><span class="params">(ReadView *view)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">ut_a</span>(view != <span class="built_in">reinterpret_cast</span>&lt;ReadView *&gt;(<span class="number">0x1</span>));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (view != <span class="literal">NULL</span> &amp;&amp; !(<span class="built_in">intptr_t</span>(view) &amp; <span class="number">0x1</span>));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  Set the view creator transaction id. Note: This shouldbe set only</span></span><br><span class="line"><span class="comment">  for views created by RW transactions. */</span></span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">set_view_creator_trx_id</span><span class="params">(ReadView *view, <span class="type">trx_id_t</span> id)</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  Validates a read view list. */</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">validate</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  Find a free view from the active list, if none found then allocate</span></span><br><span class="line"><span class="comment">  a new view. This function will also attempt to move delete marked</span></span><br><span class="line"><span class="comment">  views from the active list to the freed list.</span></span><br><span class="line"><span class="comment">  @return a view to use */</span></span><br><span class="line">  <span class="function"><span class="keyword">inline</span> ReadView *<span class="title">get_view</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">  Get the oldest view in the system. It will also move the delete</span></span><br><span class="line"><span class="comment">  marked read views from the views list to the freed list.</span></span><br><span class="line"><span class="comment">  @return oldest view if found or NULL */</span></span><br><span class="line">  <span class="function"><span class="keyword">inline</span> ReadView *<span class="title">get_oldest_view</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function">ReadView *<span class="title">get_view_created_by_trx_id</span><span class="params">(<span class="type">trx_id_t</span> trx_id)</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">/** Free views ready for reuse. */</span></span><br><span class="line">  <span class="type">view_list_t</span> m_free;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Active and closed views, the closed views will have the</span></span><br><span class="line"><span class="comment">  creator trx id set to TRX_ID_MAX */</span></span><br><span class="line">  <span class="type">view_list_t</span> m_views;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>MVCC</code> 会按照 <code>m_low_limit_no</code> 排序，一些详细的注释在 <code>read/read0read.cc</code> 里面，它还有个 free-list 避免重复的的分配（RC 之类的时候）。</p><p>而 ReadView 有着如下的结构：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ReadView</span> &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">MVCC</span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// Disable copying</span></span><br><span class="line">  <span class="built_in">ReadView</span>(<span class="type">const</span> ReadView &amp;);</span><br><span class="line">  ReadView &amp;<span class="keyword">operator</span>=(<span class="type">const</span> ReadView &amp;);</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">/** The read should not see any transaction with trx id &gt;= this</span></span><br><span class="line"><span class="comment">  value. In other words, this is the &quot;high water mark&quot;. */</span></span><br><span class="line">  <span class="type">trx_id_t</span> m_low_limit_id;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** The read should see all trx ids which are strictly</span></span><br><span class="line"><span class="comment">  smaller (&lt;) than this value.  In other words, this is the</span></span><br><span class="line"><span class="comment">  low water mark&quot;. */</span></span><br><span class="line">  <span class="type">trx_id_t</span> m_up_limit_id;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** trx id of creating transaction, set to TRX_ID_MAX for free</span></span><br><span class="line"><span class="comment">  views. */</span></span><br><span class="line">  <span class="type">trx_id_t</span> m_creator_trx_id;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Set of RW transactions that was active when this snapshot</span></span><br><span class="line"><span class="comment">  was taken */</span></span><br><span class="line">  <span class="type">ids_t</span> m_ids;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** The view does not need to see the undo logs for transactions</span></span><br><span class="line"><span class="comment">  whose transaction number is strictly smaller (&lt;) than this value:</span></span><br><span class="line"><span class="comment">  they can be removed in purge if not needed by other views */</span></span><br><span class="line">  <span class="type">trx_id_t</span> m_low_limit_no;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** AC-NL-RO transaction view that has been &quot;closed&quot;. */</span></span><br><span class="line">  <span class="type">bool</span> m_closed;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">typedef</span> <span class="title">UT_LIST_NODE_T</span><span class="params">(ReadView)</span> <span class="type">node_t</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** List of read views in trx_sys */</span></span><br><span class="line">  byte pad1[<span class="number">64</span> - <span class="built_in">sizeof</span>(<span class="type">node_t</span>)];</span><br><span class="line">  <span class="type">node_t</span> m_view_list;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>那么，我们注意到：</p><ol><li>对一个 readview, 有着 <code>m_low_limit_id</code> 和 <code>m_up_limit_id</code> 两个水位，这两个水位可以过滤掉插入的</li><li><code>m_creator_trx_id</code> 代表自身，创建的内容对自己是可见的</li><li><code>m_low_limit_no</code> 代表创建时候的最大 id。</li></ol><p>这个在 ReadView 创建的时候，可以看到具体的设置逻辑：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">Copy the transaction ids from the source vector */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ReadView::copy_trx_ids</span><span class="params">(<span class="type">const</span> <span class="type">trx_ids_t</span> &amp;trx_ids)</span> </span>&#123;</span><br><span class="line">  ulint size = trx_ids.<span class="built_in">size</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (m_creator_trx_id &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="built_in">ut_ad</span>(size &gt; <span class="number">0</span>);</span><br><span class="line">    --size;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (size == <span class="number">0</span>) &#123;</span><br><span class="line">    m_ids.<span class="built_in">clear</span>();</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  m_ids.<span class="built_in">reserve</span>(size);</span><br><span class="line">  m_ids.<span class="built_in">resize</span>(size);</span><br><span class="line"></span><br><span class="line">  <span class="type">ids_t</span>::value_type *p = m_ids.<span class="built_in">data</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Copy all the trx_ids except the creator trx id */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (m_creator_trx_id &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// 拷贝 自己之外的元素</span></span><br><span class="line">    <span class="comment">/* Note: We go through all this trouble because it is</span></span><br><span class="line"><span class="comment">    unclear whether std::vector::resize() will cause an</span></span><br><span class="line"><span class="comment">    overhead or not. We should test this extensively and</span></span><br><span class="line"><span class="comment">    if the vector to vector copy is fast enough then get</span></span><br><span class="line"><span class="comment">    rid of this code and replace it with more readable</span></span><br><span class="line"><span class="comment">    and obvious code. The code below does exactly one copy,</span></span><br><span class="line"><span class="comment">    and filters out the creator&#x27;s trx id. */</span></span><br><span class="line"></span><br><span class="line">    <span class="type">trx_ids_t</span>::const_iterator it =</span><br><span class="line">        std::<span class="built_in">lower_bound</span>(trx_ids.<span class="built_in">begin</span>(), trx_ids.<span class="built_in">end</span>(), m_creator_trx_id);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">ut_ad</span>(it != trx_ids.<span class="built_in">end</span>() &amp;&amp; *it == m_creator_trx_id);</span><br><span class="line"></span><br><span class="line">    ulint i = std::<span class="built_in">distance</span>(trx_ids.<span class="built_in">begin</span>(), it);</span><br><span class="line">    ulint n = i * <span class="built_in">sizeof</span>(<span class="type">trx_ids_t</span>::value_type);</span><br><span class="line"></span><br><span class="line">    ::<span class="built_in">memmove</span>(p, &amp;trx_ids[<span class="number">0</span>], n);</span><br><span class="line"></span><br><span class="line">    n = (trx_ids.<span class="built_in">size</span>() - i - <span class="number">1</span>) * <span class="built_in">sizeof</span>(<span class="type">trx_ids_t</span>::value_type);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">ut_ad</span>(i + (n / <span class="built_in">sizeof</span>(<span class="type">trx_ids_t</span>::value_type)) == m_ids.<span class="built_in">size</span>());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (n &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      ::<span class="built_in">memmove</span>(p + i, &amp;trx_ids[i + <span class="number">1</span>], n);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 拷贝所有的元素</span></span><br><span class="line">    ulint n = size * <span class="built_in">sizeof</span>(<span class="type">trx_ids_t</span>::value_type);</span><br><span class="line"></span><br><span class="line">    ::<span class="built_in">memmove</span>(p, &amp;trx_ids[<span class="number">0</span>], n);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  m_up_limit_id = m_ids.<span class="built_in">front</span>();</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> UNIV_DEBUG</span></span><br><span class="line">  <span class="comment">/* Assert that all transaction ids in list are active. */</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">trx_ids_t</span>::const_iterator it = trx_ids.<span class="built_in">begin</span>(); it != trx_ids.<span class="built_in">end</span>();</span><br><span class="line">       ++it) &#123;</span><br><span class="line">    <span class="type">trx_t</span> *trx = <span class="built_in">trx_get_rw_trx_by_id</span>(*it);</span><br><span class="line">    <span class="built_in">ut_ad</span>(trx != <span class="literal">NULL</span>);</span><br><span class="line">    <span class="built_in">ut_ad</span>(trx-&gt;state == TRX_STATE_ACTIVE || trx-&gt;state == TRX_STATE_PREPARED);</span><br><span class="line">  &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* UNIV_DEBUG */</span></span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">Opens a read view where exactly the transactions serialized before this</span></span><br><span class="line"><span class="comment">point in time are seen in the view.</span></span><br><span class="line"><span class="comment">@param id   Creator transaction id */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ReadView::prepare</span><span class="params">(<span class="type">trx_id_t</span> id)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">ut_ad</span>(<span class="built_in">mutex_own</span>(&amp;trx_sys-&gt;mutex));</span><br><span class="line"></span><br><span class="line">  m_creator_trx_id = id;</span><br><span class="line"></span><br><span class="line">  m_low_limit_no = m_low_limit_id = m_up_limit_id = trx_sys-&gt;max_trx_id;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!trx_sys-&gt;rw_trx_ids.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">    <span class="built_in">copy_trx_ids</span>(trx_sys-&gt;rw_trx_ids);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    m_ids.<span class="built_in">clear</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">ut_ad</span>(m_up_limit_id &lt;= m_low_limit_id);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">UT_LIST_GET_LEN</span>(trx_sys-&gt;serialisation_list) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">trx_t</span> *trx;</span><br><span class="line"></span><br><span class="line">    trx = <span class="built_in">UT_LIST_GET_FIRST</span>(trx_sys-&gt;serialisation_list);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (trx-&gt;no &lt; m_low_limit_no) &#123;</span><br><span class="line">      m_low_limit_no = trx-&gt;no;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  m_closed = <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这里的设置非常巧妙。</p><p>接下来观察到一个事实，这里是根据 <code>trx_sys-&gt;rw_trx_ids</code> 和 <code>trx_sys-&gt;max_trx_id</code> 还有 <code>m_creator_trx_id</code> 设置的：</p><ol><li><code>m_low_limit_id</code> 设置为 <code>trx_sys-&gt;max_trx_id</code> ( 即 <code>max(start-ts, end-ts)</code>)</li><li><code>m_low_limit_no</code> 设置为 <code>min(min committing-txn-id, trx_sys-&gt;max_trx_id)</code>，表示已经提交的最大事务 id 或 pending 的最小事务 id，<strong>保证不会读到提交中的数据</strong></li><li><code>m_low_limit_id</code> 和 <code>m_up_limit_id</code> 都是对应的 Running Txn Id。<code>m_up_limit_id</code> 更新为 <code>min(active-txn)</code></li></ol><p>所以在检查的时候，这里有：</p><ol><li>一条插入的边会有 <code>DB_TRX_ID</code>, 这个是 <code>start_ts</code>，<strong>最大的问题是，这玩意并不是一个</strong> <code>commit_ts</code>!</li><li>所以要根据 min-max 和 runing-txn 列表来判断它</li></ol><p>我们反过来推断一下：</p><ol><li>如果 <code>start_ts == commit_ts</code> -&gt; 并不需要一个 ReadView</li><li>如果不需要这么精细的判断，比如分布式并不知道所有 runing txn 是什么，就不需要这个</li></ol><h2 id="TiDB-CRDB"><a href="#TiDB-CRDB" class="headerlink" title="TiDB / CRDB"></a>TiDB / CRDB</h2><p>我们回过头来看 TiDB，TiDB 是一个 Percolator 的模型，显然，在这里获得所有的 txn-id 是不现实的（我怀疑会导致提交成为瓶颈，或者打爆 PD），这个时候就需要对状态未决的事务捞状态甚至等待了。CRDB 其实也差不多。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li>分布式事务中的时间戳 - Eric Fu的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/333471336">https://zhuanlan.zhihu.com/p/333471336</a></li><li><a href="http://mysql.taobao.org/monthly/2018/11/04/">http://mysql.taobao.org/monthly/2018/11/04/</a></li><li><a href="http://mysql.taobao.org/monthly/2015/04/01/">http://mysql.taobao.org/monthly/2015/04/01/</a></li><li><a href="https://leviathan.vip/2019/03/20/InnoDB%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%88%86%E6%9E%90-MVCC/">https://leviathan.vip/2019/03/20/InnoDB%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%88%86%E6%9E%90-MVCC/</a></li><li>innodb事务开启后，修改一行记录，是update执行后行版本号增加，还是在事物提交后行版本号增加？ - 郁白的回答 - 知乎 <a href="https://www.zhihu.com/question/40514055/answer/86935747">https://www.zhihu.com/question/40514055/answer/86935747</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Arrow Data System</title>
      <link href="/2023/06/01/Arrow-Data-System/"/>
      <url>/2023/06/01/Arrow-Data-System/</url>
      
        <content type="html"><![CDATA[<ol><li><p>Apache Arrow 是由 Pandas 作者 Wes McKenny 主导的一款以内存为主体，辐射到数据交换、内存计算、多格式多平台转换的库。它的大概 Idea 可以见下图，写的非常直观。</p><p><img src="https://image.mwish.me/blog-image/image.png" alt="image"></p><p>我们简单介绍一下 Arrow 的内容：</p><ol><li>一切的核心，Arrow 的内存 Columnar 结构(见官方介绍 [1] 和我之前的博客 [2])<ol><li>在这上面的 ExtensionType，支持用户定义自己的类型，包括 Tensor 这样的类型</li><li>IPC File</li></ol></li><li>数据交换上成功的工具<ol><li>Arrow JDBC Converter [3]</li><li>ADBC [4]</li><li>Arrow Flight [5] 和基于 Arrow Flight SQL [6]</li></ol></li><li>一些计算相关的 API<ol><li>向量化计算函数的 Compute [7]</li><li>Push-based Execution 的 Acero [8]</li><li>LLVM Codegen 的执行 Gandiva [9] (已经快死了)</li><li>SQL Planning 的 Datafusion [10]</li><li>分布式执行的 Ballista</li></ol></li><li>一些数据源和写入相关的 API<ol><li>FileSystem: 对文件来源的层次的 Unify [11]</li><li>Dataset API: 对某个 FileSystem 下的多个文件 / 分区 / 数据格式的抽象，也可以加上 Project, Filter 等操作 [12]</li></ol></li></ol><p>就我个人评价而言，Arrow 在每个领域中很难说得上是性能最好的，但是胜在提供了比较完善的解决方案，api 相对侵入性也不会很大。很多地方扩展性比较强，例如提供了 <code>ExtensionType</code>（可以用 <code>ExtensionType</code> 去支持机器学习需要的 Tensor 这样的类型 [16] ），也允许用户按照 API 去 Inject 自己想要的东西。Arrow Flight 总体上也是比较开放的。这些合起来的原因和方便的生态导致 Arrow 其实被较为广泛的使用了，包括 Snowflake [13] 和 Bigquery [14] 这几家都在用，开源的数据项目，像 Ray 这样的也会积极拥抱 Arrow。DuckDB 甚至给支持 Arrow 的转换写了一篇博客 [15]。</p><p>总的来说，Arrow 主要为生态开放的做了不少工作，虽然核心的性能不是最好的（参见 Velox 和诸多的大厂开放的引擎，一个比较经典的例子是 Firebolt，基于开源的引擎自己拼了一个数据仓库出来），但是因为很强的通用性和比较完善的生态，现在已经侵入了很多人的系统。</p><h2 id="Core-In-Memory-Format"><a href="#Core-In-Memory-Format" class="headerlink" title="Core: In Memory Format"></a><strong>Core: In Memory Format</strong></h2><p>关于 Arrow 的 In Memory Format，之前尝试介绍过了：</p><ol><li><a href="https://blog.mwish.me/2023/05/04/Type-and-Array-in-Columnar-System/">https://blog.mwish.me/2023/05/04/Type-and-Array-in-Columnar-System/</a></li><li><a href="https://blog.mwish.me/2022/10/04/Parquet-Part2-arrow-Parquet-code-path/">https://blog.mwish.me/2022/10/04/Parquet-Part2-arrow-Parquet-code-path/</a></li></ol><p>这个地方本身没啥好说的，值得说的都在上面的内容了</p><h3 id="IPC-Format"><a href="#IPC-Format" class="headerlink" title="IPC Format"></a><strong>IPC Format</strong></h3><p>IPC File 格式 <strong>基本等价于</strong> 内存中 Format 的 RecordBatch，这里它会尽量在 package 里面做 alignas （比较有意思和关联的 patch 看这个：<a href="https://github.com/apache/arrow/pull/35565/files">https://github.com/apache/arrow/pull/35565/files</a> ，在计算层要求输出是满足 align 的），然后让数据能够被 Zero-Copy 的解析到 Arrow 格式上。这里应该关心可能的数据和元数据</p><p>IPC Format 有两种格式：</p><ol><li>Streaming Format: Appendable，必须整个解析</li><li>Random Access: 一整个 RecordBatch 写的文件</li></ol><p>在协议上，这里允许（不定大小的）下列元素：</p><ol><li>Schema: <strong>文件或者 Stream</strong> 的 Schema（这里需要注意，ipc 既可以写在文件里，又可以为了整个流来设置）</li><li>DictionaryBatch</li><li>RecordBatch</li></ol><p>在定义的格式中，基本的元素是 Message，下面是对应的 Message Format:</p><p><img src="https://image.mwish.me/blog-image/ipc-file-format.png" alt="ipc-file-format"></p><p>这里元数据由 <code>FlatBuffer</code> 组成（ <a href="https://blog.mwish.me/2022/01/14/format-thinking/">https://blog.mwish.me/2022/01/14/format-thinking/</a> ）它的格式定义在 <a href="https://github.com/apache/arrow/blob/main/format/Message.fbs">https://github.com/apache/arrow/blob/main/format/Message.fbs</a> 中。这里包括：</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">table Message &#123;</span><br><span class="line">  version: org.apache.arrow.flatbuf.MetadataVersion;</span><br><span class="line">  header: MessageHeader;</span><br><span class="line">  bodyLength: long;</span><br><span class="line">  custom_metadata: [ KeyValue ];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h4><p><img src="https://image.mwish.me/blog-image/C9ACE6F5-A3F6-45B3-A4E6-169BFAAF96A0.png" alt="C9ACE6F5-A3F6-45B3-A4E6-169BFAAF96A0"></p><p><img src="https://image.mwish.me/blog-image/a7d9c337-14e0-44f8-8c1c-e8badd189e0d.png" alt="a7d9c337-14e0-44f8-8c1c-e8badd189e0d"></p><p>为什么之前强调了是文件/Stream的 Schema 呢，因为它本身是没有文件（内）级别的 Schema Evolution 的</p><p>比较重要的是 Record Batch Message，这里会在写文件和读取的时候都保证 alignment (8B，也可以手动指定），这里有：<a href="https://arrow.apache.org/docs/format/Columnar.html#recordbatch-message">https://arrow.apache.org/docs/format/Columnar.html#recordbatch-message</a></p><p>这部分实现的内容很像 ORC 那套格式。</p><p>同时，这部分字典格式是 INCREMENT 的（看上面的 DICTIONARY DELTA），增量的字典带来了一部分的扩展性：<a href="https://arrow.apache.org/docs/format/Columnar.html#dictionary-messages">https://arrow.apache.org/docs/format/Columnar.html#dictionary-messages</a></p><h4 id="File"><a href="#File" class="headerlink" title="File"></a>File</h4><p><img src="https://image.mwish.me/blog-image/9E626D1C-90D9-4261-80DD-761870A41306.png" alt="9E626D1C-90D9-4261-80DD-761870A41306"></p><h3 id="Extension-Type"><a href="#Extension-Type" class="headerlink" title="Extension Type"></a>Extension Type</h3><p>用户可以以 Key-Value Metadata 的形式去做 Schema 上的扩展，GeoArrow，Tensor 这些，都可以收益于Arrow 包含的扩展：<a href="https://arrow.apache.org/docs/format/Columnar.html#extension-types">https://arrow.apache.org/docs/format/Columnar.html#extension-types</a></p><h2 id="数据交换的工具"><a href="#数据交换的工具" class="headerlink" title="数据交换的工具"></a>数据交换的工具</h2><p>如果说之前的部分是内存和 Stream 层面的 kernel，那么下面来介绍数据交换。提到这部分，可能首先想起的是 IPC 层 CWI 的相关的论文 「Don’t Hold My Data Hostage – A Case For Client Protocol Redesign」。其实和文章结论比较接近，但是这部分其实比较有意思，也给用户可以科普一下 client-side 的 dirty work 和复杂度。</p><h3 id="Arrow-Flight"><a href="#Arrow-Flight" class="headerlink" title="Arrow Flight"></a>Arrow Flight</h3><p>Arrow Flight 其实是在 grpc 和 protobuf 上开了一套洞的 Arrow 传输协议。</p><p>Q: Arrow Flight 和 Arrow Streaming Format 有什么关系？</p><p>A: Arrow Flight 主要工作在传输协议和分布式上</p><p>如图，下面是 Arrow Flight 的工作模式</p><p><img src="https://image.mwish.me/blog-image/flight-request-pattern.png" alt="flight-request-pattern"></p><p>如图，Arrow Flight 允许以如下方式去捞一个 <strong>Dataset</strong>，和这篇（ <a href="https://zhuanlan.zhihu.com/p/340520316">https://zhuanlan.zhihu.com/p/340520316</a> ）有异曲同工之妙（废话，AP 做法都差不多）</p><p><img src="https://image.mwish.me/blog-image/flight-batch.png" alt="flight-batch"></p><p>在代码实现上，Flight 在 Protobuf 代码上开了个洞，尽量让他解析 Arrow 数据的时候，被 Arrow 拦截，做到实现上的 Zero-copy (众所周知，pb 本身不是为了传输大对象设计的）。</p><p>Flight 还支持一些非 gRPC 的访问，比如协议上准备兼容</p><h3 id="From-JDBC-Converter-to-Others"><a href="#From-JDBC-Converter-to-Others" class="headerlink" title="From JDBC Converter to Others"></a>From JDBC Converter to Others</h3><p>JDBC / ODBC 实际上是 90 年代起数据交换的事实标准，如果考虑到使用的话，流程如左图：</p><p><img src="https://image.mwish.me/blog-image/casting.png" alt="casting"></p><p>右图首先提供了一种 JDBC Client 的交互方式。即首先需要转一层。当然这并不能让人满意，所以接下来出现了下面的数据流</p><p><img src="https://image.mwish.me/blog-image/data.png" alt="data"></p><ol><li>ADBC: 启发自 DuckDB 作者的论文 「Don’t Hold My Data Hostage – A Case For Client Protocol Redesign」。相当于列式的 JDBC。需要注意的是，这个格式虽然比较有潜力，但是才 0.4，可能需要等他自己发展一下</li><li>Driver: 类似数据库的 Driver，能够把 Arrow 转成 JDBC / ADBC</li><li>Flight SQL Protocol: Flight 之上的 Catalog / SQL 框架。与实现大概无关，愿景是一个通用协议层</li></ol><p>说实话这套东西竞争力还挺强的，BigQuery, Snowflake, DataBricks 都或多或少用了这套东西. 主要问题还是用数据库的 JDBC Driver 或者甚至行的接口来处理还是比较菜的。需要专门的接口来 handle 这套内容。</p><h2 id="计算相关的工具"><a href="#计算相关的工具" class="headerlink" title="计算相关的工具"></a>计算相关的工具</h2><h3 id="Compute-amp-Acero"><a href="#Compute-amp-Acero" class="headerlink" title="Compute &amp; Acero"></a>Compute &amp; Acero</h3><p>在 Arrow 的核心中提供了 Arrow Compute 这样的工具，它的基本逻辑和定位见之前的博客：<a href="https://blog.mwish.me/2023/05/27/Arrow-Compute/">https://blog.mwish.me/2023/05/27/Arrow-Compute/</a></p><p>Compute 定位的是向量化的算子( Function )。</p><p>虽然 Compute 本身可能没有 Expression 的概念，但是 Arrow 为了别的地方使用，在 Compute 里面实现了 Expression。几乎所有数据库都有 Expression 相关的概念，它可以是：</p><ol><li>LiteralValue Or Datum</li><li>FieldRef of input Datum</li><li>Compute Function，Function Member 都是别的 Expression</li></ol><p><img src="https://image.mwish.me/blog-image/expressions.png" alt="expressions"></p><p>Acero 是构建在这套系统上的 Operator 层。定位上，Acero 是一个 Push-Based 的算子层，虽然代码写的不是很细，但是比较易懂：</p><p><img src="https://image.mwish.me/blog-image/acero-nodes.png" alt="acero-nodes"></p><p>这里可以根据 Declaration 生成一组对应的 ExecPlan / ExecNode，然后下层来驱动数据流的执行。</p><h4 id="Substrait"><a href="#Substrait" class="headerlink" title="Substrait"></a>Substrait</h4><p>Substrait 的定位是一个开放的 (可能被优化过的) Plan，后面可以是对应的执行器，前面产生对应的 Plan。Arrow C++ Acero 本身并不负责 Planning，只是一个执行的对应的流。</p><p><img src="https://image.mwish.me/blog-image/B1AA6B5E-808A-43C6-97CC-D165C82B13A8.png" alt="B1AA6B5E-808A-43C6-97CC-D165C82B13A8"></p><h3 id="Datafusion-Ballista"><a href="#Datafusion-Ballista" class="headerlink" title="Datafusion / Ballista"></a>Datafusion / Ballista</h3><p><img src="https://image.mwish.me/blog-image/D457D790-709D-4B27-846D-DFBDC4183DB2.png" alt="D457D790-709D-4B27-846D-DFBDC4183DB2"></p><p>SQL 和执行对应的逻辑。</p><h3 id="Gandiva"><a href="#Gandiva" class="headerlink" title="Gandiva"></a>Gandiva</h3><p>Gandiva 类似 Compute，是 Dremio 捐赠给项目的，对应的逻辑是 Codegen. 这个项目感觉差不多已经似了</p><p><img src="https://image.mwish.me/blog-image/gandiva.png" alt="gandiva"></p><h2 id="数据源和写入相关的-API"><a href="#数据源和写入相关的-API" class="headerlink" title="数据源和写入相关的 API"></a>数据源和写入相关的 API</h2><p><img src="https://image.mwish.me/blog-image/0EC24B5E-7C33-4F1D-B813-B9C4BBA65D25.png" alt="0EC24B5E-7C33-4F1D-B813-B9C4BBA65D25"></p><p>Arrow 在对应的内容上有两层</p><ol><li>FileSystem: 处理 Local, S3, HDFS 等「存储后台」的文件</li><li>DataSet: ORC/JSON/CSV 等文件是在 DataSet 层处理的，这层也使用了 FileSystem。有点像 Presto 的 Connector，可以 Filter Pushdown 和读/写</li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a><strong>References</strong></h2><ol><li>DuckDB quacks Arrow: A zero-copy data integration between Apache Arrow and DuckDB <a href="https://duckdb.org/2021/12/03/duck-arrow.html">https://duckdb.org/2021/12/03/duck-arrow.html</a></li><li><a href="https://arrow.apache.org/docs/cpp/api/tensor.html">https://arrow.apache.org/docs/cpp/api/tensor.html</a> 和 maillist 的讨论 <a href="https://lists.apache.org/thread/95ncmr4two34mxodlds7bzxvrrzmk1s6">https://lists.apache.org/thread/95ncmr4two34mxodlds7bzxvrrzmk1s6</a></li></ol></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Arrow Compute: CallFunction and Add</title>
      <link href="/2023/05/27/Arrow-Compute/"/>
      <url>/2023/05/27/Arrow-Compute/</url>
      
        <content type="html"><![CDATA[<h2 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h2><p>Arrow 包含着一些对应的 Runtime 类型的语义，可以执行一些计算相关的功能，它的上层可以是 Python 脚本直接调用 Arrow Compute，也可以是 Substrait Plan 调用 Acero。</p><p>简单来说，Arrow 这些计算可以包括 Compute 层和 Acero 层：</p><ol><li>Compute: (执行单元) Datum, Expression, Function 和 Function 层面的执行( Kernel, FunctionExecutor, KernelExecutor)</li><li>Acero: Push-Based Execution Model, ExecBatch, 调度（可能会用到 dataset 层的 api 来访问数据）</li></ol><p><strong>Datum</strong>: 一个泛用类型，可以包装 {scalar, array, chunked array, record batch, table}.  操作的输入和输出通常都是某种 <code>vector&lt;Datum&gt; -&gt; Datum</code></p><p>Function: 由<strong>一个或者数个 Kernel</strong> 组成，每个 Kernel 有操作和对应的<strong>输入/输出类型</strong>，Function 按照 Function name 注册在 <strong>FunctionRegistry</strong> 中. 在类型匹配的时候，Function 支持「挑选最佳的匹配」，并且，Function 支持 implicit cast，将一些类型完成对应的转型.</p><p>好，上面的知识你已经知道了，下面举一个弱智的例子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> i64_3 = std::<span class="built_in">make_shared</span>&lt;arrow::Int64Scalar&gt;(<span class="number">3</span>);</span><br><span class="line">arrow::Datum incremented_datum;</span><br><span class="line"></span><br><span class="line"><span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(incremented_datum,</span><br><span class="line">                      arrow::compute::<span class="built_in">CallFunction</span>(<span class="string">&quot;add&quot;</span>, &#123;int64_array_a, i64_3&#125;));</span><br><span class="line">std::shared_ptr&lt;::arrow::Array&gt; incremented_array = std::<span class="built_in">move</span>(incremented_datum).<span class="built_in">make_array</span>();</span><br><span class="line">std::cout &lt;&lt; incremented_array-&gt;<span class="built_in">ToString</span>() &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><ol><li>这里输入是一个 <code>Array</code> 和 <code>Scalar</code>，类型都是 <code>Int64</code>，输出是一个 <code>Int64Array</code></li><li>调用了 <code>arrow::compute::CallFunction</code>, 通过名称 <code>&quot;add&quot;</code> 来调用对应的函数</li><li>返回类型是一个 <code>Datum</code>，可以 get 出来是一个 Array。</li></ol><p>实际上，把 <code>Int64Scalar</code> 换成 <code>Int32Scalar</code> 也是可以通过的，因为这里的系统支持内部的转型。甚至从 Dict 转成普通类型也是可以的. Arrow Compute 指定了一个类型兼容性的表格，来处理这项任务：<a href="https://arrow.apache.org/docs/cpp/compute.html#common-numeric-type">https://arrow.apache.org/docs/cpp/compute.html#common-numeric-type</a></p><p>这里简单的推断一下这套规则，感觉 Arrow 用的是简单的类型映射写进去的，没有引入一些相对复杂一些的计算：</p><ul><li>Numeric<ul><li>Numeric 允许 Implicit Cast<ul><li>Signed integer / Unsigned integer / Floating Point 的 Common Type 是 <code>max(T1, T2)</code></li><li>(Unsigned, Signed) 的 Common Type 是 <code>larger-int(max(T1, T2))</code>. 特殊的，当其中一个类型是 64-bit 的时候，这里选择的输出类型是 int64 (而可能不是 decimal)。这代表，<code>(int64, uint64)</code> 中，u64 的大于 <code>i64::max</code> 的值会被 truncate</li></ul></li><li>Arrow 有 Decimal128 和 Decimal256</li></ul></li><li>Temporal: Date types (Date32, Date64), Time types (Time32, Time64), Timestamp, Duration, Interval.</li><li>“Binary-like”: Binary, LargeBinary, sometimes also FixedSizeBinary.</li><li>“String-like”: String, LargeString.<ul><li>这里不支持特殊的限定长度或者 char varchar 类型。而且 String / LargeString 实际上和物理 Layout 有关</li></ul></li><li>“List-like”: List, LargeList, sometimes also FixedSizeList.</li><li>“Nested”: List-likes (including FixedSizeList), Struct, Union, and related types like Map.</li></ul><p>（令我感觉很搞笑的是，这里竟然没有包括字典和 REE. <code>&#123;字典, REE&#125;</code> 允许 Implicit Cast 到）</p><blockquote><p>需要注意的是，Group Aggregation 并不能用 <code>CallFunction</code> 来调用</p></blockquote><p>Function 有几种类型，粗略的说，类型包含：</p><ol><li>Aggregators: 接收 (chunked) array / scalar，生成一个 Scalar Output Value</li><li>Grouped Aggregations: 类似 GROUP BY (col1, col2…)。接收 Hash Agg (我简单扫了一下，似乎不支持 SortMerge + Agg?)。实现上算子会类似下面所示。在这个</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">HashAggregate</span></span><br><span class="line"><span class="function">  <span class="title">grouper</span><span class="params">(hash)</span></span></span><br><span class="line"><span class="function">  <span class="title">hash_agg</span><span class="params">(agg)</span></span></span><br></pre></td></tr></table></figure><ol><li>Scalar Functions: Scalar 并不是表示这个函数是 <code>F(Scalar) -&gt; Scalar</code>，而是表示一种单射关系，从一组是参数生成另一组参数。举例为 “add”, “mul” 甚至 “abs” 这种。实际上这里种类是非常多的，不过我们这篇博客不介绍框架之外的东西。<ol><li>比较有意思的是，random number generator 这种 0 个参数的东西也被归类了这里。</li></ol></li><li>Vector Functions: 输出是类似带状态的，比如 Sort / 累积和 / Filter 这种</li></ol><p>上面的系统被组织成下面的层次：</p><ul><li>ExecNode (in Acero)</li><li>Function( 不同类型的 Function )</li><li>Kernel (同一个 Function 的不同实现)</li></ul><p>下面我们来阅读后面两项的代码组织。</p><h2 id="从-CallFunction-和-“add”-看起"><a href="#从-CallFunction-和-“add”-看起" class="headerlink" title="从 CallFunction 和 “add” 看起"></a>从 CallFunction 和 “add” 看起</h2><p>一些函数能够被 <code>CallFunction</code> 调用：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ARROW_EXPORT</span></span><br><span class="line"><span class="function">Result&lt;Datum&gt; <span class="title">CallFunction</span><span class="params">(<span class="type">const</span> std::string&amp; func_name, <span class="type">const</span> std::vector&lt;Datum&gt;&amp; args,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">const</span> FunctionOptions* options, ExecContext* ctx = NULLPTR)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ARROW_EXPORT</span></span><br><span class="line"><span class="function">Result&lt;Datum&gt; <span class="title">CallFunction</span><span class="params">(<span class="type">const</span> std::string&amp; func_name, <span class="type">const</span> std::vector&lt;Datum&gt;&amp; args,</span></span></span><br><span class="line"><span class="params"><span class="function">                           ExecContext* ctx = NULLPTR)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ARROW_EXPORT</span></span><br><span class="line"><span class="function">Result&lt;Datum&gt; <span class="title">CallFunction</span><span class="params">(<span class="type">const</span> std::string&amp; func_name, <span class="type">const</span> ExecBatch&amp; batch,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">const</span> FunctionOptions* options, ExecContext* ctx = NULLPTR)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ARROW_EXPORT</span></span><br><span class="line"><span class="function">Result&lt;Datum&gt; <span class="title">CallFunction</span><span class="params">(<span class="type">const</span> std::string&amp; func_name, <span class="type">const</span> ExecBatch&amp; batch,</span></span></span><br><span class="line"><span class="params"><span class="function">                           ExecContext* ctx = NULLPTR)</span></span>;</span><br></pre></td></tr></table></figure><p>这里除了我们之前介绍的，还有几个比较好玩的参数:</p><ol><li><code>FunctionOptions</code>: 是一个比较奇怪的东西</li><li><code>ExecBatch</code>: 基本上是 Acero 之类的传下来的，它们倾向以 Batch 模式来 Exec</li><li><code>ExecContext</code>: 执行的时候的上下文，包含了：<ol><li>MemoryPool</li><li>CPU Info ( SIMD instr 之类的）</li><li>CPU Executor</li><li>ChunkSize ( Batch Size )</li><li>Function Registry</li></ol></li></ol><p>那么，最为最开始使用的用户，我们可以自顶向下的来看看这个 CallFunction:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Result&lt;Datum&gt; <span class="title">CallFunction</span><span class="params">(<span class="type">const</span> std::string&amp; func_name, <span class="type">const</span> std::vector&lt;Datum&gt;&amp; args,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">const</span> FunctionOptions* options, ExecContext* ctx)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (ctx == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    ctx = <span class="built_in">default_exec_context</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(std::shared_ptr&lt;<span class="type">const</span> Function&gt; func,</span><br><span class="line">                        ctx-&gt;<span class="built_in">func_registry</span>()-&gt;<span class="built_in">GetFunction</span>(func_name));</span><br><span class="line">  <span class="keyword">return</span> func-&gt;<span class="built_in">Execute</span>(args, options, ctx);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="FunctionRegistry"><a href="#FunctionRegistry" class="headerlink" title="FunctionRegistry"></a>FunctionRegistry</h4><p>FunctionRegistry 的实现关系类似 Naming 的 Scope:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FunctionRegistry</span>::FunctionRegistryImpl &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  FunctionRegistryImpl* parent_;</span><br><span class="line">  std::mutex lock_;</span><br><span class="line">  std::unordered_map&lt;std::string, std::shared_ptr&lt;Function&gt;&gt; name_to_function_;</span><br><span class="line">  std::unordered_map&lt;std::string, <span class="type">const</span> FunctionOptionsType*&gt; name_to_options_type_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ol><li>内部成员实际上会有 <code>lock_</code> 的保护</li><li>有父级关系( 我看了下，arrow 内部好像没用到，感觉是给用户处理 UDF 之类的？）</li><li>允许加入成员和 alias</li></ol><p>那么，这里层次是怎么玩的呢，答案是它会按照分类来创建：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> std::unique_ptr&lt;FunctionRegistry&gt; <span class="title">CreateBuiltInRegistry</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> registry = FunctionRegistry::<span class="built_in">Make</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Register core kernels</span></span><br><span class="line">  <span class="built_in">RegisterScalarCast</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterVectorHash</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterVectorSelection</span>(registry.<span class="built_in">get</span>());</span><br><span class="line"></span><br><span class="line">  <span class="built_in">RegisterScalarOptions</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterVectorOptions</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterAggregateOptions</span>(registry.<span class="built_in">get</span>());</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> ARROW_COMPUTE</span></span><br><span class="line">  <span class="comment">// Register additional kernels</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Scalar functions</span></span><br><span class="line">  <span class="built_in">RegisterScalarArithmetic</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarBoolean</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarComparison</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarIfElse</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarNested</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarRandom</span>(registry.<span class="built_in">get</span>());  <span class="comment">// Nullary</span></span><br><span class="line">  <span class="built_in">RegisterScalarRoundArithmetic</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarSetLookup</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarStringAscii</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarStringUtf8</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarTemporalBinary</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarTemporalUnary</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarValidity</span>(registry.<span class="built_in">get</span>());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Vector functions</span></span><br><span class="line">  <span class="built_in">RegisterVectorArraySort</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterVectorCumulativeSum</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterVectorNested</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterVectorRank</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterVectorReplace</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterVectorSelectK</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterVectorSort</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterVectorRunEndEncode</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterVectorRunEndDecode</span>(registry.<span class="built_in">get</span>());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Aggregate functions</span></span><br><span class="line">  <span class="built_in">RegisterHashAggregateBasic</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarAggregateBasic</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarAggregateMode</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarAggregateQuantile</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarAggregateTDigest</span>(registry.<span class="built_in">get</span>());</span><br><span class="line">  <span class="built_in">RegisterScalarAggregateVariance</span>(registry.<span class="built_in">get</span>());</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> registry;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace internal</span></span><br><span class="line"></span><br><span class="line"><span class="function">FunctionRegistry* <span class="title">GetFunctionRegistry</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">static</span> <span class="keyword">auto</span> g_registry = internal::<span class="built_in">CreateBuiltInRegistry</span>();</span><br><span class="line">  <span class="keyword">return</span> g_registry.<span class="built_in">get</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们举几个例子，比如插入 Cast 相关的:</p><ol><li>MetaFunction 本质上是个转发器(误)</li><li>注册了一个 FunctionOption，这里绑定的是类型和对应的成员。</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">auto</span> kCastOptionsType = <span class="built_in">GetFunctionOptionsType</span>&lt;CastOptions&gt;(</span><br><span class="line">    arrow::internal::<span class="built_in">DataMember</span>(<span class="string">&quot;to_type&quot;</span>, &amp;CastOptions::to_type),</span><br><span class="line">    arrow::internal::<span class="built_in">DataMember</span>(<span class="string">&quot;allow_int_overflow&quot;</span>, &amp;CastOptions::allow_int_overflow),</span><br><span class="line">    arrow::internal::<span class="built_in">DataMember</span>(<span class="string">&quot;allow_time_truncate&quot;</span>, &amp;CastOptions::allow_time_truncate),</span><br><span class="line">    arrow::internal::<span class="built_in">DataMember</span>(<span class="string">&quot;allow_time_overflow&quot;</span>, &amp;CastOptions::allow_time_overflow),</span><br><span class="line">    arrow::internal::<span class="built_in">DataMember</span>(<span class="string">&quot;allow_decimal_truncate&quot;</span>,</span><br><span class="line">                                &amp;CastOptions::allow_decimal_truncate),</span><br><span class="line">    arrow::internal::<span class="built_in">DataMember</span>(<span class="string">&quot;allow_float_truncate&quot;</span>,</span><br><span class="line">                                &amp;CastOptions::allow_float_truncate),</span><br><span class="line">    arrow::internal::<span class="built_in">DataMember</span>(<span class="string">&quot;allow_invalid_utf8&quot;</span>, &amp;CastOptions::allow_invalid_utf8));</span><br><span class="line">&#125;  <span class="comment">// namespace</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">RegisterScalarCast</span><span class="params">(FunctionRegistry* registry)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">DCHECK_OK</span>(registry-&gt;<span class="built_in">AddFunction</span>(std::<span class="built_in">make_shared</span>&lt;CastMetaFunction&gt;()));</span><br><span class="line">  <span class="built_in">DCHECK_OK</span>(registry-&gt;<span class="built_in">AddFunctionOptionsType</span>(kCastOptionsType));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实你会对这个 FunctionType 很困惑，我也很困惑，看上去他们挫了一套反射库：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Options, <span class="keyword">typename</span>... Properties&gt;</span><br><span class="line"><span class="function"><span class="type">const</span> FunctionOptionsType* <span class="title">GetFunctionOptionsType</span><span class="params">(<span class="type">const</span> Properties&amp;... properties)</span> </span>&#123;</span><br><span class="line">  <span class="type">static</span> <span class="type">const</span> <span class="keyword">class</span> <span class="title class_">OptionsType</span> : <span class="keyword">public</span> GenericOptionsType &#123;</span><br><span class="line">   <span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">OptionsType</span><span class="params">(<span class="type">const</span> arrow::internal::PropertyTuple&lt;Properties...&gt; properties)</span></span></span><br><span class="line"><span class="function">        : properties_(properties) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">const</span> <span class="type">char</span>* <span class="title">type_name</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> Options::kTypeName; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">std::string <span class="title">Stringify</span><span class="params">(<span class="type">const</span> FunctionOptions&amp; options)</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">      <span class="type">const</span> <span class="keyword">auto</span>&amp; self = <span class="built_in">checked_cast</span>&lt;<span class="type">const</span> Options&amp;&gt;(options);</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">StringifyImpl</span>&lt;Options&gt;(self, properties_).<span class="built_in">Finish</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">Compare</span><span class="params">(<span class="type">const</span> FunctionOptions&amp; options,</span></span></span><br><span class="line"><span class="params"><span class="function">                 <span class="type">const</span> FunctionOptions&amp; other)</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">      <span class="type">const</span> <span class="keyword">auto</span>&amp; lhs = <span class="built_in">checked_cast</span>&lt;<span class="type">const</span> Options&amp;&gt;(options);</span><br><span class="line">      <span class="type">const</span> <span class="keyword">auto</span>&amp; rhs = <span class="built_in">checked_cast</span>&lt;<span class="type">const</span> Options&amp;&gt;(other);</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">CompareImpl</span>&lt;Options&gt;(lhs, rhs, properties_).equal_;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">Status <span class="title">ToStructScalar</span><span class="params">(<span class="type">const</span> FunctionOptions&amp; options,</span></span></span><br><span class="line"><span class="params"><span class="function">                          std::vector&lt;std::string&gt;* field_names,</span></span></span><br><span class="line"><span class="params"><span class="function">                          std::vector&lt;std::shared_ptr&lt;Scalar&gt;&gt;* values)</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">      <span class="type">const</span> <span class="keyword">auto</span>&amp; self = <span class="built_in">checked_cast</span>&lt;<span class="type">const</span> Options&amp;&gt;(options);</span><br><span class="line">      <span class="built_in">RETURN_NOT_OK</span>(</span><br><span class="line">          <span class="built_in">ToStructScalarImpl</span>&lt;Options&gt;(self, properties_, field_names, values).status_);</span><br><span class="line">      <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    Result&lt;std::unique_ptr&lt;FunctionOptions&gt;&gt; <span class="built_in">FromStructScalar</span>(</span><br><span class="line">        <span class="type">const</span> StructScalar&amp; scalar) <span class="type">const</span> <span class="keyword">override</span> &#123;</span><br><span class="line">      <span class="keyword">auto</span> options = std::<span class="built_in">make_unique</span>&lt;Options&gt;();</span><br><span class="line">      <span class="built_in">RETURN_NOT_OK</span>(</span><br><span class="line">          <span class="built_in">FromStructScalarImpl</span>&lt;Options&gt;(options.<span class="built_in">get</span>(), scalar, properties_).status_);</span><br><span class="line">      <span class="keyword">return</span> std::<span class="built_in">move</span>(options);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;FunctionOptions&gt; <span class="title">Copy</span><span class="params">(<span class="type">const</span> FunctionOptions&amp; options)</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">      <span class="keyword">auto</span> out = std::<span class="built_in">make_unique</span>&lt;Options&gt;();</span><br><span class="line">      <span class="built_in">CopyImpl</span>&lt;Options&gt;(out.<span class="built_in">get</span>(), <span class="built_in">checked_cast</span>&lt;<span class="type">const</span> Options&amp;&gt;(options), properties_);</span><br><span class="line">      <span class="keyword">return</span> std::<span class="built_in">move</span>(out);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span>:</span><br><span class="line">    <span class="type">const</span> arrow::internal::PropertyTuple&lt;Properties...&gt; properties_;</span><br><span class="line">  &#125; <span class="built_in">instance</span>(arrow::internal::<span class="built_in">MakeProperties</span>(properties...));</span><br><span class="line">  <span class="keyword">return</span> &amp;instance;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h4><p>然后我们来看看 <code>Function</code> 部分，以 “Add” 为例:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="function">Result&lt;Datum&gt; <span class="title">ExecuteInternal</span><span class="params">(<span class="type">const</span> Function&amp; func, std::vector&lt;Datum&gt; args,</span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="type">int64_t</span> passed_length, <span class="type">const</span> FunctionOptions* options,</span></span></span><br><span class="line"><span class="params"><span class="function">                              ExecContext* ctx)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> inputs, internal::<span class="built_in">GetFunctionArgumentTypes</span>(args));</span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> func_exec, func.<span class="built_in">GetBestExecutor</span>(inputs));</span><br><span class="line">  <span class="built_in">ARROW_RETURN_NOT_OK</span>(func_exec-&gt;<span class="built_in">Init</span>(options, ctx));</span><br><span class="line">  <span class="keyword">return</span> func_exec-&gt;<span class="built_in">Execute</span>(args, passed_length);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace</span></span><br><span class="line"></span><br><span class="line"><span class="function">Result&lt;Datum&gt; <span class="title">Function::Execute</span><span class="params">(<span class="type">const</span> std::vector&lt;Datum&gt;&amp; args,</span></span></span><br><span class="line"><span class="params"><span class="function">                                <span class="type">const</span> FunctionOptions* options, ExecContext* ctx)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">ExecuteInternal</span>(*<span class="keyword">this</span>, args, <span class="comment">/*passed_length=*/</span><span class="number">-1</span>, options, ctx);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Result&lt;Datum&gt; <span class="title">Function::Execute</span><span class="params">(<span class="type">const</span> ExecBatch&amp; batch, <span class="type">const</span> FunctionOptions* options,</span></span></span><br><span class="line"><span class="params"><span class="function">                                ExecContext* ctx)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">ExecuteInternal</span>(*<span class="keyword">this</span>, batch.values, batch.length, options, ctx);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Function 内部有一层 <code>Dispatch</code> 的流程:</p><ol><li>创建对应的 Executor，这里的 Executor 是个 <code>KernelExecutor</code> 类型</li><li>然后找到 Best 的 Kernel( <code>GetBestExecutor</code> )</li><li>包装成一个 FunctionExecutor 返回</li></ol><p>我们先来讲 <code>Kernel</code>，然后来讲对应的 Executors</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Result&lt;std::shared_ptr&lt;FunctionExecutor&gt;&gt; Function::<span class="built_in">GetBestExecutor</span>(</span><br><span class="line">    std::vector&lt;TypeHolder&gt; inputs) <span class="type">const</span> &#123;</span><br><span class="line">  std::unique_ptr&lt;detail::KernelExecutor&gt; executor;</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">kind</span>() == Function::SCALAR) &#123;</span><br><span class="line">    executor = detail::KernelExecutor::<span class="built_in">MakeScalar</span>();</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">kind</span>() == Function::VECTOR) &#123;</span><br><span class="line">    executor = detail::KernelExecutor::<span class="built_in">MakeVector</span>();</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">kind</span>() == Function::SCALAR_AGGREGATE) &#123;</span><br><span class="line">    executor = detail::KernelExecutor::<span class="built_in">MakeScalarAggregate</span>();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">NotImplemented</span>(<span class="string">&quot;Direct execution of HASH_AGGREGATE functions&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="type">const</span> Kernel* kernel, <span class="built_in">DispatchBest</span>(&amp;inputs));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> std::<span class="built_in">make_shared</span>&lt;detail::FunctionExecutorImpl&gt;(std::<span class="built_in">move</span>(inputs), kernel,</span><br><span class="line">                                                        std::<span class="built_in">move</span>(executor), *<span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Kernel-执行器和逻辑的生成"><a href="#Kernel-执行器和逻辑的生成" class="headerlink" title="Kernel 执行器和逻辑的生成"></a>Kernel 执行器和逻辑的生成</h4><p>首先，我们来介绍 Kernel 对象，Kernel 的类型稍稍有点复杂：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \brief Common initializer function for all kernel types.</span></span><br><span class="line"><span class="keyword">using</span> KernelInit = std::function&lt;Result&lt;std::unique_ptr&lt;KernelState&gt;&gt;(</span><br><span class="line">    KernelContext*, <span class="type">const</span> KernelInitArgs&amp;)&gt;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// \brief Base type for kernels. Contains the function signature and</span></span><br><span class="line"><span class="comment">/// optionally the state initialization function, along with some common</span></span><br><span class="line"><span class="comment">/// attributes</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ARROW_EXPORT</span> Kernel &#123;</span><br><span class="line">  <span class="built_in">Kernel</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">Kernel</span>(std::shared_ptr&lt;KernelSignature&gt; sig, KernelInit init)</span><br><span class="line">      : <span class="built_in">signature</span>(std::<span class="built_in">move</span>(sig)), <span class="built_in">init</span>(std::<span class="built_in">move</span>(init)) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">Kernel</span>(std::vector&lt;InputType&gt; in_types, OutputType out_type, KernelInit init)</span><br><span class="line">      : <span class="built_in">Kernel</span>(KernelSignature::<span class="built_in">Make</span>(std::<span class="built_in">move</span>(in_types), std::<span class="built_in">move</span>(out_type)),</span><br><span class="line">               std::<span class="built_in">move</span>(init)) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief The &quot;signature&quot; of the kernel containing the InputType input</span></span><br><span class="line">  <span class="comment">/// argument validators and OutputType output type resolver.</span></span><br><span class="line">  std::shared_ptr&lt;KernelSignature&gt; signature;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Create a new KernelState for invocations of this kernel, e.g. to</span></span><br><span class="line">  <span class="comment">/// set up any options or state relevant for execution.</span></span><br><span class="line">  KernelInit init;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Create a vector of new KernelState for invocations of this kernel.</span></span><br><span class="line">  <span class="function"><span class="type">static</span> Status <span class="title">InitAll</span><span class="params">(KernelContext*, <span class="type">const</span> KernelInitArgs&amp;,</span></span></span><br><span class="line"><span class="params"><span class="function">                        std::vector&lt;std::unique_ptr&lt;KernelState&gt;&gt;*)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Indicates whether execution can benefit from parallelization</span></span><br><span class="line">  <span class="comment">/// (splitting large chunks into smaller chunks and using multiple</span></span><br><span class="line">  <span class="comment">/// threads). Some kernels may not support parallel execution at</span></span><br><span class="line">  <span class="comment">/// all. Synchronization and concurrency-related issues are currently the</span></span><br><span class="line">  <span class="comment">/// responsibility of the Kernel&#x27;s implementation.</span></span><br><span class="line">  <span class="type">bool</span> parallelizable = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Indicates the level of SIMD instruction support in the host CPU is</span></span><br><span class="line">  <span class="comment">/// required to use the function. The intention is for functions to be able to</span></span><br><span class="line">  <span class="comment">/// contain multiple kernels with the same signature but different levels of SIMD,</span></span><br><span class="line">  <span class="comment">/// so that the most optimized kernel supported on a host&#x27;s processor can be chosen.</span></span><br><span class="line">  SimdLevel::type simd_level = SimdLevel::NONE;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Additional kernel-specific data</span></span><br><span class="line">  std::shared_ptr&lt;KernelState&gt; data;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>举例子是 <code>Add</code> 这个 Binary 的 Scalar Function:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> add = <span class="built_in">MakeArithmeticFunction</span>&lt;Add&gt;(<span class="string">&quot;add&quot;</span>, add_doc);</span><br><span class="line"><span class="built_in">AddDecimalBinaryKernels</span>&lt;Add&gt;(<span class="string">&quot;add&quot;</span>, add.<span class="built_in">get</span>());</span><br></pre></td></tr></table></figure><p>这里调了对应的 KernelGenerator，这里写了一套模版代码，我觉得调用起来挺方便，读起来感觉真的有点点难，首先这里有 <code>Add</code> 和 Checked 版本的 Add，他们提供是否检查的代码。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Add</span> &#123;</span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> Arg0, <span class="keyword">typename</span> Arg1&gt;</span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="keyword">constexpr</span> enable_if_floating_value&lt;T&gt; <span class="title">Call</span><span class="params">(KernelContext*, Arg0 left, Arg1 right,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                    Status*)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> left + right;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> Arg0, <span class="keyword">typename</span> Arg1&gt;</span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="keyword">constexpr</span> enable_if_unsigned_integer_value&lt;T&gt; <span class="title">Call</span><span class="params">(KernelContext*, Arg0 left,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                            Arg1 right, Status*)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> left + right;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> Arg0, <span class="keyword">typename</span> Arg1&gt;</span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="keyword">constexpr</span> enable_if_signed_integer_value&lt;T&gt; <span class="title">Call</span><span class="params">(KernelContext*, Arg0 left,</span></span></span><br><span class="line"><span class="params"><span class="function">                                                          Arg1 right, Status*)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> arrow::internal::<span class="built_in">SafeSignedAdd</span>(left, right);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> Arg0, <span class="keyword">typename</span> Arg1&gt;</span><br><span class="line">  <span class="function"><span class="type">static</span> enable_if_decimal_value&lt;T&gt; <span class="title">Call</span><span class="params">(KernelContext*, Arg0 left, Arg1 right, Status*)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> left + right;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">AddChecked</span> &#123;</span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> Arg0, <span class="keyword">typename</span> Arg1&gt;</span><br><span class="line">  <span class="function"><span class="type">static</span> enable_if_integer_value&lt;T&gt; <span class="title">Call</span><span class="params">(KernelContext*, Arg0 left, Arg1 right,</span></span></span><br><span class="line"><span class="params"><span class="function">                                         Status* st)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">static_assert</span>(std::is_same&lt;T, Arg0&gt;::value &amp;&amp; std::is_same&lt;T, Arg1&gt;::value, <span class="string">&quot;&quot;</span>);</span><br><span class="line">    T result = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">ARROW_PREDICT_FALSE</span>(<span class="built_in">AddWithOverflow</span>(left, right, &amp;result))) &#123;</span><br><span class="line">      *st = Status::<span class="built_in">Invalid</span>(<span class="string">&quot;overflow&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> Arg0, <span class="keyword">typename</span> Arg1&gt;</span><br><span class="line">  <span class="function"><span class="type">static</span> enable_if_floating_value&lt;T&gt; <span class="title">Call</span><span class="params">(KernelContext*, Arg0 left, Arg1 right,</span></span></span><br><span class="line"><span class="params"><span class="function">                                          Status*)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">static_assert</span>(std::is_same&lt;T, Arg0&gt;::value &amp;&amp; std::is_same&lt;T, Arg1&gt;::value, <span class="string">&quot;&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> left + right;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> Arg0, <span class="keyword">typename</span> Arg1&gt;</span><br><span class="line">  <span class="function"><span class="type">static</span> enable_if_decimal_value&lt;T&gt; <span class="title">Call</span><span class="params">(KernelContext*, Arg0 left, Arg1 right, Status*)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> left + right;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>有一个地方需要注意一下，虽然 Arrow 可能会在调用的时候判断，如果输入（有一个）是 NULL，那么输出 NULL。但是 Add 的时候，针对 Null 上 Undefined 的地方做加法开销也不大。我们这里看 <code>MakeArithmeticFunction&lt;Add&gt;(&quot;add&quot;, add_doc)</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里还塞了一个 FunctionDoc 进去</span></span><br><span class="line"><span class="type">const</span> FunctionDoc add_doc&#123;<span class="string">&quot;Add the arguments element-wise&quot;</span>,</span><br><span class="line">                          (<span class="string">&quot;Results will wrap around on integer overflow.\n&quot;</span></span><br><span class="line">                           <span class="string">&quot;Use function \&quot;add_checked\&quot; if you want overflow\n&quot;</span></span><br><span class="line">                           <span class="string">&quot;to return an error.&quot;</span>),</span><br><span class="line">                          &#123;<span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>&#125;&#125;;</span><br></pre></td></tr></table></figure><p>然后和：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Op, <span class="keyword">typename</span> FunctionImpl = ArithmeticFunction&gt;</span><br><span class="line">std::shared_ptr&lt;ScalarFunction&gt; <span class="built_in">MakeArithmeticFunction</span>(std::string name,</span><br><span class="line">                                                       FunctionDoc doc) &#123;</span><br><span class="line">  <span class="keyword">auto</span> func = std::<span class="built_in">make_shared</span>&lt;FunctionImpl&gt;(name, Arity::<span class="built_in">Binary</span>(), std::<span class="built_in">move</span>(doc));</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; ty : <span class="built_in">NumericTypes</span>()) &#123;</span><br><span class="line">    <span class="keyword">auto</span> exec = <span class="built_in">ArithmeticExecFromOp</span>&lt;ScalarBinaryEqualTypes, Op&gt;(ty);</span><br><span class="line">    <span class="built_in">DCHECK_OK</span>(func-&gt;<span class="built_in">AddKernel</span>(&#123;ty, ty&#125;, ty, exec));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">AddNullExec</span>(func.<span class="built_in">get</span>());</span><br><span class="line">  <span class="keyword">return</span> func;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里 <code>NumericTypes</code> 包含什么呢：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Numeric types</span></span><br><span class="line"><span class="built_in">Extend</span>(g_int_types, &amp;g_numeric_types);</span><br><span class="line"><span class="built_in">Extend</span>(g_floating_types, &amp;g_numeric_types);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Non-parametric, non-nested types. This also DOES NOT include</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// * Decimal</span></span><br><span class="line"><span class="comment">// * Fixed Size Binary</span></span><br><span class="line"><span class="comment">// * Time32</span></span><br><span class="line"><span class="comment">// * Time64</span></span><br><span class="line"><span class="comment">// * Timestamp</span></span><br><span class="line">g_primitive_types = &#123;<span class="built_in">null</span>(), <span class="built_in">boolean</span>(), <span class="built_in">date32</span>(), <span class="built_in">date64</span>()&#125;;</span><br><span class="line"><span class="built_in">Extend</span>(g_numeric_types, &amp;g_primitive_types);</span><br></pre></td></tr></table></figure><p>然后调用 <code>ArithmeticExecFromOp&lt;ScalarBinaryEqualTypes, Op&gt;(ty)</code> 产生 <code>ArrayKernelExec</code>, <code>ArithmeticExecFromOp</code> 会使用 <code>ScalarBinaryEqualTypes</code> 这个 Generator 来把动态的调用分发到静态模版上:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> ArrayKernelExec = <span class="built_in">Status</span> (*)(KernelContext*, <span class="type">const</span> ExecSpan&amp;, ExecResult*);</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">template</span> &lt;<span class="keyword">typename</span>...&gt; <span class="keyword">class</span> <span class="title class_">KernelGenerator</span>, <span class="keyword">typename</span> Op,</span><br><span class="line">          <span class="keyword">typename</span> KernelType = ArrayKernelExec, <span class="keyword">typename</span>... Args&gt;</span><br><span class="line">KernelType <span class="built_in">ArithmeticExecFromOp</span>(detail::GetTypeId get_id) &#123;</span><br><span class="line">  <span class="keyword">switch</span> (get_id.id) &#123;</span><br><span class="line">    <span class="keyword">case</span> Type::INT8:</span><br><span class="line">      <span class="keyword">return</span> KernelGenerator&lt;Int8Type, Int8Type, Op, Args...&gt;::Exec;</span><br><span class="line">    <span class="keyword">case</span> Type::UINT8:</span><br><span class="line">      <span class="keyword">return</span> KernelGenerator&lt;UInt8Type, UInt8Type, Op, Args...&gt;::Exec;</span><br><span class="line">    <span class="keyword">case</span> Type::INT16:</span><br><span class="line">      <span class="keyword">return</span> KernelGenerator&lt;Int16Type, Int16Type, Op, Args...&gt;::Exec;</span><br><span class="line">    <span class="keyword">case</span> Type::UINT16:</span><br><span class="line">      <span class="keyword">return</span> KernelGenerator&lt;UInt16Type, UInt16Type, Op, Args...&gt;::Exec;</span><br><span class="line">    <span class="keyword">case</span> Type::INT32:</span><br><span class="line">      <span class="keyword">return</span> KernelGenerator&lt;Int32Type, Int32Type, Op, Args...&gt;::Exec;</span><br><span class="line">    <span class="keyword">case</span> Type::UINT32:</span><br><span class="line">      <span class="keyword">return</span> KernelGenerator&lt;UInt32Type, UInt32Type, Op, Args...&gt;::Exec;</span><br><span class="line">    <span class="keyword">case</span> Type::DURATION:</span><br><span class="line">    <span class="keyword">case</span> Type::INT64:</span><br><span class="line">    <span class="keyword">case</span> Type::TIMESTAMP:</span><br><span class="line">      <span class="keyword">return</span> KernelGenerator&lt;Int64Type, Int64Type, Op, Args...&gt;::Exec;</span><br><span class="line">    <span class="keyword">case</span> Type::UINT64:</span><br><span class="line">      <span class="keyword">return</span> KernelGenerator&lt;UInt64Type, UInt64Type, Op, Args...&gt;::Exec;</span><br><span class="line">    <span class="keyword">case</span> Type::FLOAT:</span><br><span class="line">      <span class="keyword">return</span> KernelGenerator&lt;FloatType, FloatType, Op, Args...&gt;::Exec;</span><br><span class="line">    <span class="keyword">case</span> Type::DOUBLE:</span><br><span class="line">      <span class="keyword">return</span> KernelGenerator&lt;DoubleType, DoubleType, Op, Args...&gt;::Exec;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="built_in">DCHECK</span>(<span class="literal">false</span>);</span><br><span class="line">      <span class="keyword">return</span> FailFunctor&lt;KernelType&gt;::Exec;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>下面我们来看 Generator:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A kernel exec generator for binary kernels where both input types are the</span></span><br><span class="line"><span class="comment">// same</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> OutType, <span class="keyword">typename</span> ArgType, <span class="keyword">typename</span> Op&gt;</span><br><span class="line"><span class="keyword">using</span> ScalarBinaryEqualTypes = ScalarBinary&lt;OutType, ArgType, ArgType, Op&gt;;</span><br></pre></td></tr></table></figure><p>里面是：</p><ol><li>把输入输出的 Array 用泛型抽了迭代器出来</li><li>根据 <code>Op::Call</code> 来调用</li><li>根据一个泛型 Writer 来抽出输出，写输出的数据</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A kernel exec generator for binary functions that addresses both array and</span></span><br><span class="line"><span class="comment">// scalar inputs and dispatches input iteration and output writing to other</span></span><br><span class="line"><span class="comment">// templates</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// This template executes the operator even on the data behind null values,</span></span><br><span class="line"><span class="comment">// therefore it is generally only suitable for operators that are safe to apply</span></span><br><span class="line"><span class="comment">// even on the null slot values.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The &quot;Op&quot; functor should have the form</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// struct Op &#123;</span></span><br><span class="line"><span class="comment">//   template &lt;typename OutValue, typename Arg0Value, typename Arg1Value&gt;</span></span><br><span class="line"><span class="comment">//   static OutValue Call(KernelContext* ctx, Arg0Value arg0, Arg1Value arg1, Status* st)</span></span><br><span class="line"><span class="comment">//   &#123;</span></span><br><span class="line"><span class="comment">//     // implementation</span></span><br><span class="line"><span class="comment">//     // <span class="doctag">NOTE:</span> &quot;status&quot; should only populated with errors,</span></span><br><span class="line"><span class="comment">//     //       leave it unmodified to indicate Status::OK()</span></span><br><span class="line"><span class="comment">//   &#125;</span></span><br><span class="line"><span class="comment">// &#125;;</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> OutType, <span class="keyword">typename</span> Arg0Type, <span class="keyword">typename</span> Arg1Type, <span class="keyword">typename</span> Op&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ScalarBinary</span> &#123;</span><br><span class="line">  <span class="keyword">using</span> OutValue = <span class="keyword">typename</span> GetOutputType&lt;OutType&gt;::T;</span><br><span class="line">  <span class="keyword">using</span> Arg0Value = <span class="keyword">typename</span> GetViewType&lt;Arg0Type&gt;::T;</span><br><span class="line">  <span class="keyword">using</span> Arg1Value = <span class="keyword">typename</span> GetViewType&lt;Arg1Type&gt;::T;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> Status <span class="title">ArrayArray</span><span class="params">(KernelContext* ctx, <span class="type">const</span> ArraySpan&amp; arg0,</span></span></span><br><span class="line"><span class="params"><span class="function">                           <span class="type">const</span> ArraySpan&amp; arg1, ExecResult* out)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> Status <span class="title">ArrayScalar</span><span class="params">(KernelContext* ctx, <span class="type">const</span> ArraySpan&amp; arg0, <span class="type">const</span> Scalar&amp; arg1,</span></span></span><br><span class="line"><span class="params"><span class="function">                            ExecResult* out)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> Status <span class="title">ScalarArray</span><span class="params">(KernelContext* ctx, <span class="type">const</span> Scalar&amp; arg0, <span class="type">const</span> ArraySpan&amp; arg1,</span></span></span><br><span class="line"><span class="params"><span class="function">                            ExecResult* out)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> Status <span class="title">Exec</span><span class="params">(KernelContext* ctx, <span class="type">const</span> ExecSpan&amp; batch, ExecResult* out)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (batch[<span class="number">0</span>].<span class="built_in">is_array</span>()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (batch[<span class="number">1</span>].<span class="built_in">is_array</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">ArrayArray</span>(ctx, batch[<span class="number">0</span>].array, batch[<span class="number">1</span>].array, out);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">ArrayScalar</span>(ctx, batch[<span class="number">0</span>].array, *batch[<span class="number">1</span>].scalar, out);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (batch[<span class="number">1</span>].<span class="built_in">is_array</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">ScalarArray</span>(ctx, *batch[<span class="number">0</span>].scalar, batch[<span class="number">1</span>].array, out);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">DCHECK</span>(<span class="literal">false</span>);</span><br><span class="line">        <span class="keyword">return</span> Status::<span class="built_in">Invalid</span>(<span class="string">&quot;Should be unreachable&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>最后调用 <code>func-&gt;AddKernel(/*输入类型*/&#123;ty, ty&#125;, /*输出类型*/ty, ``/*执行callback*/``exec)</code> 来添加执行的 Kernel。</p><p>这里我们再回过头看看那个问题，Kernel 是什么：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Kernel</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// \brief Arguments to pass to an KernelInit function. A struct is used to help</span></span><br><span class="line"><span class="comment">/// avoid API breakage should the arguments passed need to be expanded.</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">KernelInitArgs</span> &#123;</span><br><span class="line">  <span class="comment">/// \brief A pointer to the kernel being initialized. The init function may</span></span><br><span class="line">  <span class="comment">/// depend on the kernel&#x27;s KernelSignature or other data contained there.</span></span><br><span class="line">  <span class="type">const</span> Kernel* kernel;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief The types of the input arguments that the kernel is</span></span><br><span class="line">  <span class="comment">/// about to be executed against.</span></span><br><span class="line">  <span class="type">const</span> std::vector&lt;TypeHolder&gt;&amp; inputs;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Opaque options specific to this kernel. May be nullptr for functions</span></span><br><span class="line">  <span class="comment">/// that do not require options.</span></span><br><span class="line">  <span class="type">const</span> FunctionOptions* options;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// \brief Common initializer function for all kernel types.</span></span><br><span class="line"><span class="keyword">using</span> KernelInit = std::function&lt;Result&lt;std::unique_ptr&lt;KernelState&gt;&gt;(</span><br><span class="line">    KernelContext*, <span class="type">const</span> KernelInitArgs&amp;)&gt;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// \brief Base type for kernels. Contains the function signature and</span></span><br><span class="line"><span class="comment">/// optionally the state initialization function, along with some common</span></span><br><span class="line"><span class="comment">/// attributes</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ARROW_EXPORT</span> Kernel &#123;</span><br><span class="line">  <span class="built_in">Kernel</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">Kernel</span>(std::shared_ptr&lt;KernelSignature&gt; sig, KernelInit init)</span><br><span class="line">      : <span class="built_in">signature</span>(std::<span class="built_in">move</span>(sig)), <span class="built_in">init</span>(std::<span class="built_in">move</span>(init)) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">Kernel</span>(std::vector&lt;InputType&gt; in_types, OutputType out_type, KernelInit init)</span><br><span class="line">      : <span class="built_in">Kernel</span>(KernelSignature::<span class="built_in">Make</span>(std::<span class="built_in">move</span>(in_types), std::<span class="built_in">move</span>(out_type)),</span><br><span class="line">               std::<span class="built_in">move</span>(init)) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief The &quot;signature&quot; of the kernel containing the InputType input</span></span><br><span class="line">  <span class="comment">/// argument validators and OutputType output type resolver.</span></span><br><span class="line">  std::shared_ptr&lt;KernelSignature&gt; signature;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Create a new KernelState for invocations of this kernel, e.g. to</span></span><br><span class="line">  <span class="comment">/// set up any options or state relevant for execution.</span></span><br><span class="line">  KernelInit init;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Create a vector of new KernelState for invocations of this kernel.</span></span><br><span class="line">  <span class="function"><span class="type">static</span> Status <span class="title">InitAll</span><span class="params">(KernelContext*, <span class="type">const</span> KernelInitArgs&amp;,</span></span></span><br><span class="line"><span class="params"><span class="function">                        std::vector&lt;std::unique_ptr&lt;KernelState&gt;&gt;*)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="type">bool</span> parallelizable = <span class="literal">true</span>;</span><br><span class="line">  SimdLevel::type simd_level = SimdLevel::NONE;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Additional kernel-specific data</span></span><br><span class="line">  std::shared_ptr&lt;KernelState&gt; data;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>Kernel 本身是一组奇怪的 api，包含 <code>KernelState</code>, 外部根据<code>KernelSignature</code> 和 <code>KernelInit</code>来调用它，我们来看 <code>ScalarKernel</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> ArrayKernelExec = <span class="built_in">Status</span> (*)(KernelContext*, <span class="type">const</span> ExecSpan&amp;, ExecResult*);</span><br><span class="line"></span><br><span class="line"><span class="comment">/// \brief Kernel data structure for implementations of ScalarFunction. In</span></span><br><span class="line"><span class="comment">/// addition to the members found in Kernel, contains the null handling</span></span><br><span class="line"><span class="comment">/// and memory pre-allocation preferences.</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ARROW_EXPORT</span> ScalarKernel : <span class="keyword">public</span> Kernel &#123;</span><br><span class="line">  <span class="built_in">ScalarKernel</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">ScalarKernel</span>(std::shared_ptr&lt;KernelSignature&gt; sig, ArrayKernelExec exec,</span><br><span class="line">               KernelInit init = NULLPTR)</span><br><span class="line">      : <span class="built_in">Kernel</span>(std::<span class="built_in">move</span>(sig), init), <span class="built_in">exec</span>(exec) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">ScalarKernel</span>(std::vector&lt;InputType&gt; in_types, OutputType out_type, ArrayKernelExec exec,</span><br><span class="line">               KernelInit init = NULLPTR)</span><br><span class="line">      : <span class="built_in">Kernel</span>(std::<span class="built_in">move</span>(in_types), std::<span class="built_in">move</span>(out_type), std::<span class="built_in">move</span>(init)), <span class="built_in">exec</span>(exec) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Perform a single invocation of this kernel. Depending on the</span></span><br><span class="line">  <span class="comment">/// implementation, it may only write into preallocated memory, while in some</span></span><br><span class="line">  <span class="comment">/// cases it will allocate its own memory. Any required state is managed</span></span><br><span class="line">  <span class="comment">/// through the KernelContext.</span></span><br><span class="line">  ArrayKernelExec exec;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Writing execution results into larger contiguous allocations</span></span><br><span class="line">  <span class="comment">/// requires that the kernel be able to write into sliced output ArrayData*,</span></span><br><span class="line">  <span class="comment">/// including sliced output validity bitmaps. Some kernel implementations may</span></span><br><span class="line">  <span class="comment">/// not be able to do this, so setting this to false disables this</span></span><br><span class="line">  <span class="comment">/// functionality.</span></span><br><span class="line">  <span class="type">bool</span> can_write_into_slices = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// For scalar functions preallocated data and intersecting arg validity</span></span><br><span class="line">  <span class="comment">// bitmaps is a reasonable default</span></span><br><span class="line">  NullHandling::type null_handling = NullHandling::INTERSECTION;</span><br><span class="line">  MemAllocation::type mem_allocation = MemAllocation::PREALLOCATE;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里比较关键的是这个 Exec，我们来看看执行侧：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ARROW_EXPORT</span> KernelExecutor &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">KernelExecutor</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// The Kernel&#x27;s `init` method must be called and any KernelState set in the</span></span><br><span class="line">  <span class="comment">/// KernelContext *before* KernelExecutor::Init is called. This is to facilitate</span></span><br><span class="line">  <span class="comment">/// the case where init may be expensive and does not need to be called again for</span></span><br><span class="line">  <span class="comment">/// each execution of the kernel, for example the same lookup table can be re-used</span></span><br><span class="line">  <span class="comment">/// for all scanned batches in a dataset filter.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Init</span><span class="params">(KernelContext*, KernelInitArgs)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// TODO(wesm): per ARROW-16819, adding ExecBatch variant so that a batch</span></span><br><span class="line">  <span class="comment">// length can be passed in for scalar functions; will have to return and</span></span><br><span class="line">  <span class="comment">// clean a bunch of things up</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Execute</span><span class="params">(<span class="type">const</span> ExecBatch&amp; batch, ExecListener* listener)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Datum <span class="title">WrapResults</span><span class="params">(<span class="type">const</span> std::vector&lt;Datum&gt;&amp; args,</span></span></span><br><span class="line"><span class="params"><span class="function">                            <span class="type">const</span> std::vector&lt;Datum&gt;&amp; outputs)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Check the actual result type against the resolved output type</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">CheckResultType</span><span class="params">(<span class="type">const</span> Datum&amp; out, <span class="type">const</span> <span class="type">char</span>* function_name)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> std::unique_ptr&lt;KernelExecutor&gt; <span class="title">MakeScalar</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">static</span> std::unique_ptr&lt;KernelExecutor&gt; <span class="title">MakeVector</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">static</span> std::unique_ptr&lt;KernelExecutor&gt; <span class="title">MakeScalarAggregate</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>最终，<code>ScalarExecutor::Execute</code> 会执行那个 <code>exec</code>，来处理对应的逻辑:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">ExecuteNonSpans</span><span class="params">(ExecListener* listener)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// ARROW-16756: Kernel is going to allocate some memory and so</span></span><br><span class="line">  <span class="comment">// for the time being we pass in an empty or partially-filled</span></span><br><span class="line">  <span class="comment">// shared_ptr&lt;ArrayData&gt; or shared_ptr&lt;Scalar&gt; to be populated</span></span><br><span class="line">  <span class="comment">// by the kernel.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// We will eventually delete the Scalar output path per</span></span><br><span class="line">  <span class="comment">// ARROW-16757.</span></span><br><span class="line">  ExecSpan input;</span><br><span class="line">  ExecResult output;</span><br><span class="line">  <span class="keyword">while</span> (span_iterator_.<span class="built_in">Next</span>(&amp;input)) &#123;</span><br><span class="line">    <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(output.value, <span class="built_in">PrepareOutput</span>(input.length));</span><br><span class="line">    <span class="built_in">DCHECK</span>(output.<span class="built_in">is_array_data</span>());</span><br><span class="line"></span><br><span class="line">    ArrayData* out_arr = output.<span class="built_in">array_data</span>().<span class="built_in">get</span>();</span><br><span class="line">    <span class="keyword">if</span> (output_type_.type-&gt;<span class="built_in">id</span>() == Type::NA) &#123;</span><br><span class="line">      out_arr-&gt;null_count = out_arr-&gt;length;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (kernel_-&gt;null_handling == NullHandling::INTERSECTION) &#123;</span><br><span class="line">      <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">PropagateNulls</span>(kernel_ctx_, input, out_arr));</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (kernel_-&gt;null_handling == NullHandling::OUTPUT_NOT_NULL) &#123;</span><br><span class="line">      out_arr-&gt;null_count = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">RETURN_NOT_OK</span>(kernel_-&gt;<span class="built_in">exec</span>(kernel_ctx_, input, &amp;output));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Output type didn&#x27;t change</span></span><br><span class="line">    <span class="built_in">DCHECK</span>(output.<span class="built_in">is_array_data</span>());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Emit a result for each chunk</span></span><br><span class="line">    <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">EmitResult</span>(std::<span class="built_in">move</span>(output.<span class="built_in">array_data</span>()), listener));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Kernel-的类型匹配"><a href="#Kernel-的类型匹配" class="headerlink" title="Kernel 的类型匹配"></a>Kernel 的类型匹配</h4><p>还有一个比较重要的是 Kernel 函数的类型匹配，这里会根据 <code>Matches</code> 来挑选对应的类型来进行匹配。我们回到 <code>ExecuteInternal</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Result&lt;Datum&gt; <span class="title">ExecuteInternal</span><span class="params">(<span class="type">const</span> Function&amp; func, std::vector&lt;Datum&gt; args,</span></span></span><br><span class="line"><span class="params"><span class="function">                              <span class="type">int64_t</span> passed_length, <span class="type">const</span> FunctionOptions* options,</span></span></span><br><span class="line"><span class="params"><span class="function">                              ExecContext* ctx)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> inputs, internal::<span class="built_in">GetFunctionArgumentTypes</span>(args));</span><br><span class="line">  <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(<span class="keyword">auto</span> func_exec, func.<span class="built_in">GetBestExecutor</span>(inputs));</span><br><span class="line">  <span class="built_in">ARROW_RETURN_NOT_OK</span>(func_exec-&gt;<span class="built_in">Init</span>(options, ctx));</span><br><span class="line">  <span class="keyword">return</span> func_exec-&gt;<span class="built_in">Execute</span>(args, passed_length);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里会:</p><ol><li><code>GetBestExecutor</code>，根据 <code>Function::DispatchBest</code> 来找到对应的 <code>Kernel</code>，然后创建 <code>FunctionExecutor</code>. <code>Dispatch</code> 默认走的是 <code>DispatchExact</code>，就是找到完全对应的输入。有的时候根据需求不同，可能会插入一些 <code>Cast</code></li><li>在 <code>func_exec-&gt;Init</code> 阶段，去 Init 需要的内容</li><li>调用 <code>func_exec-&gt;Execute</code></li></ol><p>Dispatch 的签名如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \brief Return a best-match kernel that can execute the function given the argument</span></span><br><span class="line"><span class="comment">/// types, after implicit casts are applied.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// \param[in,out] values Argument types. An element may be modified to</span></span><br><span class="line"><span class="comment">/// indicate that the returned kernel only approximately matches the input</span></span><br><span class="line"><span class="comment">/// value descriptors; callers are responsible for casting inputs to the type</span></span><br><span class="line"><span class="comment">/// required by the kernel.</span></span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Result&lt;<span class="type">const</span> Kernel*&gt; <span class="title">DispatchBest</span><span class="params">(std::vector&lt;TypeHolder&gt;* values)</span> <span class="type">const</span></span>;</span><br></pre></td></tr></table></figure><p>我们再以 Add 为例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">ArithmeticFunction</span> : ScalarFunction &#123;</span><br><span class="line">  <span class="keyword">using</span> ScalarFunction::ScalarFunction;</span><br><span class="line"></span><br><span class="line">  <span class="function">Result&lt;<span class="type">const</span> Kernel*&gt; <span class="title">DispatchBest</span><span class="params">(std::vector&lt;TypeHolder&gt;* types)</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">CheckArity</span>(types-&gt;<span class="built_in">size</span>()));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">CheckDecimals</span>(types));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">using</span> arrow::compute::detail::DispatchExactImpl;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">auto</span> kernel = <span class="built_in">DispatchExactImpl</span>(<span class="keyword">this</span>, *types)) <span class="keyword">return</span> kernel;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">EnsureDictionaryDecoded</span>(types);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Only promote types for binary functions</span></span><br><span class="line">    <span class="keyword">if</span> (types-&gt;<span class="built_in">size</span>() == <span class="number">2</span>) &#123;</span><br><span class="line">      <span class="built_in">ReplaceNullWithOtherType</span>(types);</span><br><span class="line">      TimeUnit::type finest_unit;</span><br><span class="line">      <span class="keyword">if</span> (<span class="built_in">CommonTemporalResolution</span>(types-&gt;<span class="built_in">data</span>(), types-&gt;<span class="built_in">size</span>(), &amp;finest_unit)) &#123;</span><br><span class="line">        <span class="built_in">ReplaceTemporalTypes</span>(finest_unit, types);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (TypeHolder type = <span class="built_in">CommonNumeric</span>(*types)) &#123;</span><br><span class="line">          <span class="built_in">ReplaceTypes</span>(type, types);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">auto</span> kernel = <span class="built_in">DispatchExactImpl</span>(<span class="keyword">this</span>, *types)) <span class="keyword">return</span> kernel;</span><br><span class="line">    <span class="keyword">return</span> arrow::compute::detail::<span class="built_in">NoMatchingKernel</span>(<span class="keyword">this</span>, *types);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个地方就是创建所有需要的上下文，<code>Kernel</code> 的挑选来自于</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \brief An type-checking interface to permit customizable validation rules</span></span><br><span class="line"><span class="comment">/// for use with InputType and KernelSignature. This is for scenarios where the</span></span><br><span class="line"><span class="comment">/// acceptance is not an exact type instance, such as a TIMESTAMP type for a</span></span><br><span class="line"><span class="comment">/// specific TimeUnit, but permitting any time zone.</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ARROW_EXPORT</span> TypeMatcher &#123;</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">TypeMatcher</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Return true if this matcher accepts the data type.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">Matches</span><span class="params">(<span class="type">const</span> DataType&amp; type)</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief A human-interpretable string representation of what the type</span></span><br><span class="line">  <span class="comment">/// matcher checks for, usable when printing KernelSignature or formatting</span></span><br><span class="line">  <span class="comment">/// error messages.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> std::string <span class="title">ToString</span><span class="params">()</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Return true if this TypeMatcher contains the same matching rule as</span></span><br><span class="line">  <span class="comment">/// the other. Currently depends on RTTI.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">Equals</span><span class="params">(<span class="type">const</span> TypeMatcher&amp; other)</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里也允许 <code>Output</code> 计算出对应的输出类型：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \brief Container to capture both exact and input-dependent output types.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ARROW_EXPORT</span> OutputType &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">/// \brief An enum indicating whether the value type is an invariant fixed</span></span><br><span class="line">  <span class="comment">/// value or one that&#x27;s computed by a kernel-defined resolver function.</span></span><br><span class="line">  <span class="keyword">enum</span> <span class="title class_">ResolveKind</span> &#123; FIXED, COMPUTED &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// Type resolution function. Given input types, return output type.  This</span></span><br><span class="line">  <span class="comment">/// function MAY may use the kernel state to decide the output type based on</span></span><br><span class="line">  <span class="comment">/// the FunctionOptions.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This function SHOULD _not_ be used to check for arity, that is to be</span></span><br><span class="line">  <span class="comment">/// performed one or more layers above.</span></span><br><span class="line">  <span class="keyword">using</span> Resolver = <span class="built_in">Result</span>&lt;TypeHolder&gt; (*)(KernelContext*, <span class="type">const</span> std::vector&lt;TypeHolder&gt;&amp;);</span><br></pre></td></tr></table></figure><p>在 Init 的时候逻辑如下. 这里 <code>Add</code> 对应的上下文不太多。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">KernelInit</span><span class="params">(<span class="type">const</span> FunctionOptions* options)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">CheckOptions</span>(func, options));</span><br><span class="line">  <span class="keyword">if</span> (options == NULLPTR) &#123;</span><br><span class="line">    options = func.<span class="built_in">default_options</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (kernel-&gt;init) &#123;</span><br><span class="line">    <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(state,</span><br><span class="line">                          kernel-&gt;<span class="built_in">init</span>(&amp;kernel_ctx, &#123;kernel, in_types, options&#125;));</span><br><span class="line">    kernel_ctx.<span class="built_in">SetState</span>(state.<span class="built_in">get</span>());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">RETURN_NOT_OK</span>(executor-&gt;<span class="built_in">Init</span>(&amp;kernel_ctx, &#123;kernel, in_types, options&#125;));</span><br><span class="line">  <span class="keyword">this</span>-&gt;options = options;</span><br><span class="line">  inited = <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">Init</span><span class="params">(<span class="type">const</span> FunctionOptions* options, ExecContext* exec_ctx)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (exec_ctx == NULLPTR) &#123;</span><br><span class="line">    exec_ctx = <span class="built_in">default_exec_context</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  kernel_ctx = KernelContext&#123;exec_ctx, kernel&#125;;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">KernelInit</span>(options);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇文章简单串了一下最简单的 Add 执行的流程，限于本人目前水平和篇幅，这部分不会很详细。等待本人更熟悉 Runtime 代码再扩充本文的内容。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Type and Array in Columnar System</title>
      <link href="/2023/05/04/Type-and-Array-in-Columnar-System/"/>
      <url>/2023/05/04/Type-and-Array-in-Columnar-System/</url>
      
        <content type="html"><![CDATA[<p>Type 和 Array 是 Columnar System 最底层的东西之一了。因为本身任何列存系统无时无刻都要和它们打交道。作为系统的 Building Block，存储到 Runtime 都有 Type System，同时处理的数据大部分时候都是 Columnar 的。</p><p>Type &amp; Array System 本身不是很有花头的东西，主要考量的是某个编程语言下的：</p><ol><li>直接的平坦非变长数据的实现（这是最简单的一层，可能需要关注 alignas、内存管理等）、Null 的处理、读/写的接口</li><li>String（等变长） 类型的处理</li><li>Struct / Map / Array 等变长/嵌套类型的处理<ol><li>nullable / nonnull 的逻辑的处理（这个逻辑并不简单，想象一下 <code>nullable struct&lt;list&lt;nonnull int&gt;&gt;</code>，那么怎么表示这样的结构</li></ol></li><li>Union 等数据的处理（本质上其实有点类似变长 / 嵌套结构）</li><li>各种编码的格式，比如 Dictionary / RLE 等 format。这里要考虑的是编码格式本身的抽象之类的。</li></ol><h2 id="Arrow"><a href="#Arrow" class="headerlink" title="Arrow"></a>Arrow</h2><p>Apache Arrow 将系统分为了好几层（ <a href="https://arrow.apache.org/docs/cpp/overview.html">https://arrow.apache.org/docs/cpp/overview.html</a> ）：</p><h3 id="Physical-Layer"><a href="#Physical-Layer" class="headerlink" title="Physical Layer"></a>Physical Layer</h3><p>Memory Management 物理的内存管理，涉及 <code>MemoryPool</code> , <code>Buffer</code> 系统</p><ol><li>Memory Pool 支持 JeMalloc MiMalloc 等 backend，也允许用户自己在上面包一层，比如用 <code>std::alloctor</code> 来当作系统的内存申请者，申请的内存<strong>默认 64B alignas</strong><ol><li>Jemalloc, MiMalloc 有对应的 Pool，可以直接使用 Jemalloc 等 Pool 管理</li><li>Memory Pool 接口类似 <code>std::allocator</code>，甚至有直接适配的，这两个还能互相适配，笑嘻了。反正 calloc 之类的是没有的，Free 和 <code>free</code> 也不完全对应，知道就行</li><li>默认甚至是 System Allocator，就丢给 OS 了</li></ol></li><li><code>MemoryManager</code> / <code>Device</code>:<ol><li><code>Device</code> 是对专有内存和设备的抽象，目前只支持了 CPU Memory</li><li><code>MemoryManager</code> 感觉也是在某个设备上的抽象，允许把内存 dump 到另外的 mm 中 (然而 <code>CPUMemoryManager</code> 包了一层 pool，真是惊人的大黑暗)</li><li>上述的内容在这个 patch 中被引入：<a href="https://github.com/apache/arrow/commit/9f0c70c8337b1a8c75df5cc9410b54e97351bfc0">https://github.com/apache/arrow/commit/9f0c70c8337b1a8c75df5cc9410b54e97351bfc0</a></li><li>这个 Patch 提到了一些 GPU 内存的管理 <a href="https://github.com/apache/arrow/pull/34972">https://github.com/apache/arrow/pull/34972</a></li></ol></li><li><code>Buffer</code>: Arrow 的内存系统，有着一套类型树。<ol><li><code>Buffer</code> 本身: 包含 <code>is_cpu</code> , <code>MemoryManager</code>, <code>is_mutable</code>, <code>data</code>, <code>capacity</code>, <code>parent</code>. 本身不管理内存，作为基类存在。Buffer 本身不关心 64B 对齐，但是 <code>MemoryPool</code> 造出来的可以当成是 64B 对齐的<ol><li>认为 <code>size</code> 和 <code>capacity</code> 中间的内容是 padding 部分，允许 zero padding</li><li><code>is_cpu</code> 并不完全代表这是 CPU. 是 CPU 的可以用 <code>data()</code> 拿到 <code>u8 pointer</code> ，否则只能用 <code>address</code> 拿到 <code>uintptr</code></li><li>允许有一个 <code>shared_ptr&lt;Buffer&gt;</code> 作为父级关系</li></ol></li><li><code>MutableBuffer</code>: Buffer 的子类，标注了一下 <code>is_mutable = true</code>，其他啥都没做</li><li><code>ResizableBuffer</code>: <code>MutableBuffer</code> 的子类，接口上允许 Resize</li><li>上面几个都是外部的接口，实际上「本身并不管理内存」，下面还有几个内部的实现：<ol><li><code>PoolBuffer</code>: 和 <code>MemoryPool</code> 绑定的 Buffer<ol><li>其实产生出来的，因为绑定了 <code>PoolBuffer</code>，所以事实上全是 Resizable 的</li></ol></li><li><code>StlStringBuffer</code>: 包了一层 string</li></ol></li><li>String 本身允许包一层 <code>shared_ptr</code> 然后丢给儿子，这样单层的继承关系，但是不允许多层的关系</li></ol></li></ol><h3 id="The-one-dimensional-layer"><a href="#The-one-dimensional-layer" class="headerlink" title="The one-dimensional layer"></a>The one-dimensional layer</h3><p>在我的这篇博客（ <a href="https://blog.mwish.me/2022/10/04/Parquet-Part2-arrow-Parquet-code-path/#Arrow-cheatsheet">https://blog.mwish.me/2022/10/04/Parquet-Part2-arrow-Parquet-code-path/#Arrow-cheatsheet</a> ） 贴了很多 arrow 的图，当时一直在解释这套东西，现在来看，我当时贴的图还是挺有质量的。后来 arrow 的一些进展我也可以补充到这篇博客里来。</p><p><img src="https://image.mwish.me/blog-image/D113AFDFF7CD13071A3A407B9CED5CC3.png" alt="arrowType"></p><p>除了上图，在一些新的提案中，arrow 也增加了新的类型，eg:</p><ol><li>REE: <a href="https://arrow.apache.org/docs/format/Columnar.html#run-end-encoded-layout">https://arrow.apache.org/docs/format/Columnar.html#run-end-encoded-layout</a></li><li>(提案中) ListView  <a href="https://github.com/apache/arrow/pull/35345">https://github.com/apache/arrow/pull/35345</a></li></ol><p>我们先简短介绍一下这里的类型系统和对应的限制：</p><ol><li><code>DataType</code>: 类型系统，包含嵌套等方式</li><li><code>Array</code>: 目前可以当作 POD 之类的东西的包装器，大部分是没有对象语义的</li><li>(Extension) 扩展的类型系统和 Array</li><li><strong>Chunked arrays</strong>: 物理不连续，逻辑上连续的 Array 序列。</li><li>Scalar: (Typed) 单个类型的值</li></ol><p>我们简短介绍一下这些系统：</p><p>DataType 包含 <code>DataType</code> ( 一个类型系统树 ) 和 <code>Schema</code> （具名，允许额外信息的 Schema）</p><ol><li><code>DataTypeLayout</code>: 递归的包含 Layout (定长、变长、全 NULL、Bitmap)</li><li><code>DataType</code>: 可以是树形的、带有 PhysicalType (比如 Timestamp 实际使用 Int64) 的 array，子节点是 <code>Field</code><ol><li>Arrow 的 Type 不包含 Nullable，并且 <strong>关联实际物理的 Layout</strong>，比如 <code>Dictionary</code> 甚至被抽了一个类型出来。然后可以用 Visitor 模式来访问类型树</li><li><code>FixedWidthType is DataType</code> , <code>PrimitiveCType is FixedWidthType</code>，这里有一套对应的链路，然后 FP, Integer 什么的都是它</li><li><code>NullType</code> 用来表示全 null 的</li><li><code>BaseBinaryType is DataType</code>, 其余类型继承了它。注意我们之前说的，<code>LargeBinary</code> 和 <code>Binary</code> 之类的 offset 长度不同的，属于两个类型，<code>FixedSized</code> 也有自己的类型</li><li>令人唏嘘的是，<code>DecimalType</code> 是 <code>FixedSizeBinaryType</code> 的子类…然后它还有 <code>Decimal128</code> 和 <code>Decimal256</code> 两个子类</li><li><code>ParametricType</code> 是一个奇怪的类型标记，我现在还不知道这玩意有什么用</li><li><code>NestedType</code> 是 <code>DataType</code> 和 <code>ParametricType</code> 的子类。儿子包含 <code>List</code> <code>Map</code> <code>Struct</code> 之类的</li><li><code>Union</code> 也是 <code>NestedType</code></li><li><code>DictionaryType</code> 是一种 <code>FixedWidthType</code>, 而 <code>RunEndEncodedType</code> 是一种 <code>NestedType</code></li></ol></li><li><code>Field</code>: <code>(name, type, nullable, key-value metadata)</code>. 允许带子类型和 Flatten。嵌套的 <code>DataType</code> 儿子都是 <code>Field</code>.<ol><li><code>FieldPath</code>: 一组 <code>schema-&gt;field(5)-&gt;type()-&gt;field(9)-&gt;type()-&gt;field(3)</code> 这样构成的 <code>&#123;5, 9, 3&#125;</code> 的 schema 上的路径</li><li><code>FieldRef</code>: 相对于 <code>FieldPath</code>，还多一个 <code>FieldName</code> 用名称来寻址的语义</li></ol></li><li><code>Schema</code>: 可以看作 <code>Endianness, &#123;Fields&#125;</code>, endianness 是为了读另一种 endian 的 Schema。一般结构的 Root 就是一个 Schema。<ol><li>可以通过 Schema Builder 来构建 Schema</li></ol></li></ol><p>顺带一提这个 Layout 接口真的很直观，比如下面是 Binary 的 Layout</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">DataTypeLayout <span class="title">layout</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">DataTypeLayout</span>(&#123;DataTypeLayout::<span class="built_in">Bitmap</span>(),</span><br><span class="line">                         DataTypeLayout::<span class="built_in">FixedWidth</span>(<span class="built_in">sizeof</span>(offset_type)),</span><br><span class="line">                         DataTypeLayout::<span class="built_in">VariableWidth</span>()&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Array 的系统类似 Type，不过我老实说 Array 的 Mutable 还是挺蛋疼的，思考一个问题就是，Primitive Type 可以比较简单，平坦的搞出来，但是 Binary / List 之类的其实不太好搞。</p><p>Array 本身的核心是 <code>ArrayData</code>, 它也是一个可以递归的类型，以组合的形式内嵌在 <code>Array</code> 中，Buffer 按照 Type 对应的 Layout 来排布。一般 <code>[0]</code> 是 validity bitmap，其他的随便。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">  std::shared_ptr&lt;DataType&gt; type;</span><br><span class="line">  <span class="type">int64_t</span> length = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">mutable</span> std::atomic&lt;<span class="type">int64_t</span>&gt; null_count&#123;<span class="number">0</span>&#125;;</span><br><span class="line">  <span class="comment">// The logical start point into the physical buffers (in values, not bytes).</span></span><br><span class="line">  <span class="comment">// Note that, for child data, this must be *added* to the child data&#x27;s own offset.</span></span><br><span class="line">  <span class="type">int64_t</span> offset = <span class="number">0</span>;</span><br><span class="line">  std::vector&lt;std::shared_ptr&lt;Buffer&gt;&gt; buffers;</span><br><span class="line">  std::vector&lt;std::shared_ptr&lt;ArrayData&gt;&gt; child_data;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The dictionary for this Array, if any. Only used for dictionary type</span></span><br><span class="line">  std::shared_ptr&lt;ArrayData&gt; dictionary;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>Array</code> 基类是一个 <code>ArrayData</code> 的包装器，其他类型也不外如是，只是提供了很多相关的方法。或许我们需要额外关注 Flatten 的语义，这里子级别的 Validity 需要手动处理父级别的 Validity，这逻辑还是比较复杂的。</p><p><code>Scalar</code> 和 <code>Array</code> 相反，语义上是一个单值，逻辑上差不多相当于用继承实现了一套 tagged enum，我感觉其实我不是很在意这一层的开销。</p><p><code>Datum</code> 相当于一个泛用的类型，或许没有什么能比贴几行代码说的更清楚了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \class Datum</span></span><br><span class="line"><span class="comment">/// \brief Variant type for various Arrow C++ data structures</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ARROW_EXPORT</span> Datum &#123;</span><br><span class="line">  <span class="keyword">enum</span> <span class="title class_">Kind</span> &#123; NONE, SCALAR, ARRAY, CHUNKED_ARRAY, RECORD_BATCH, TABLE &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>就这样.</p><h2 id="Velox"><a href="#Velox" class="headerlink" title="Velox"></a>Velox</h2><p>相对 Arrow 那套被很多地方用到的 Type，Velox 的 Type 一方面代码质量可能没那么读起来舒服，另一方面其实功能覆盖是广一些的。Velox 的内存管理 Hack 了一套 MemoryTracker，类型系统也更 “SQL”:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Velox type system supports a small set of SQL-compatible composeable types:</span></span><br><span class="line"><span class="comment">/// BOOLEAN, TINYINT, SMALLINT, INTEGER, BIGINT, REAL, DOUBLE, VARCHAR,</span></span><br><span class="line"><span class="comment">/// VARBINARY, TIMESTAMP, DATE, INTERVAL_DAY_TIME, ARRAY, MAP, ROW</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// This file has multiple C++ type definitions for each of these logical types.</span></span><br><span class="line"><span class="comment">/// These logical definitions each serve slightly different purposes.</span></span><br><span class="line"><span class="comment">/// These type sets are:</span></span><br><span class="line"><span class="comment">/// - TypeKind</span></span><br><span class="line"><span class="comment">/// - Type (RowType, BigIntType, ect.)</span></span><br><span class="line"><span class="comment">/// - Templated Types (Row&lt;T...&gt;, Map&lt;K, V&gt;, ...)</span></span><br><span class="line"><span class="comment">///     C++ templated classes. Never instantiated, used to pass limited type</span></span><br><span class="line"><span class="comment">///     information into template parameters.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/// Simple enum with type category.</span></span><br><span class="line"><span class="keyword">enum class</span> <span class="title class_">TypeKind</span> : <span class="type">int8_t</span> &#123;</span><br><span class="line">  BOOLEAN = <span class="number">0</span>,</span><br><span class="line">  TINYINT = <span class="number">1</span>,</span><br><span class="line">  SMALLINT = <span class="number">2</span>,</span><br><span class="line">  INTEGER = <span class="number">3</span>,</span><br><span class="line">  BIGINT = <span class="number">4</span>,</span><br><span class="line">  REAL = <span class="number">5</span>,</span><br><span class="line">  DOUBLE = <span class="number">6</span>,</span><br><span class="line">  VARCHAR = <span class="number">7</span>,</span><br><span class="line">  VARBINARY = <span class="number">8</span>,</span><br><span class="line">  TIMESTAMP = <span class="number">9</span>,</span><br><span class="line">  DATE = <span class="number">10</span>,</span><br><span class="line">  INTERVAL_DAY_TIME = <span class="number">11</span>,</span><br><span class="line">  SHORT_DECIMAL = <span class="number">12</span>,</span><br><span class="line">  LONG_DECIMAL = <span class="number">13</span>,</span><br><span class="line">  <span class="comment">// Enum values for ComplexTypes start after 30 to leave</span></span><br><span class="line">  <span class="comment">// some values space to accommodate adding new scalar/native</span></span><br><span class="line">  <span class="comment">// types above.</span></span><br><span class="line">  ARRAY = <span class="number">30</span>,</span><br><span class="line">  MAP = <span class="number">31</span>,</span><br><span class="line">  ROW = <span class="number">32</span>,</span><br><span class="line">  UNKNOWN = <span class="number">33</span>,</span><br><span class="line">  FUNCTION = <span class="number">34</span>,</span><br><span class="line">  OPAQUE = <span class="number">35</span>,</span><br><span class="line">  INVALID = <span class="number">36</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>它的 Type 系统是一棵树，分别为 ScalarType 和别的复杂的复合类型：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Abstract class hierarchy. Instances of these classes carry full</span></span><br><span class="line"><span class="comment">/// information about types, including for example field names.</span></span><br><span class="line"><span class="comment">/// Can be instantiated by factory methods, like INTEGER()</span></span><br><span class="line"><span class="comment">/// or MAP(INTEGER(), BIGINT()).</span></span><br><span class="line"><span class="comment">/// Instances of these classes form a tree, and are immutable.</span></span><br><span class="line"><span class="comment">/// For example, MAP&lt;INTEGER, ARRAY&lt;BIGINT&gt;&gt; will form a tree like:</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">///             MapType</span></span><br><span class="line"><span class="comment">///           /         \</span></span><br><span class="line"><span class="comment">///   IntegerType    ArrayType</span></span><br><span class="line"><span class="comment">///                     |</span></span><br><span class="line"><span class="comment">///                   BigintType</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Type</span> : <span class="keyword">public</span> Tree&lt;<span class="type">const</span> std::shared_ptr&lt;<span class="type">const</span> Type&gt;&gt;,</span><br><span class="line">             <span class="keyword">public</span> velox::ISerializable &#123;</span><br></pre></td></tr></table></figure><p>Velox 的 Buffer 自己做了一套侵入式的 RC，并由 MemoryTracker 记录内存，这套代码实现在 <code>velox/buffer/Buffer.h</code></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> BufferPtr = boost::intrusive_ptr&lt;Buffer&gt;;</span><br></pre></td></tr></table></figure><p>(一个有意思的 <code>intrusive_ptr</code> 使用，这里感觉上是节省了 <code>weak_ptr</code> 的内存开销)</p><ol><li>（在 <code>velox/buffer/Buffer.h</code>）Buffer: 可能由 MemoryTracker 来追溯内存的、允许 asMutable / <code>as&lt;T&gt;</code> 的 内存池，允许存放 non-pod type</li><li>（内存管理的逻辑在 <code>velox/common/memory</code> 下面）MemoryPool: 可以有父级的树形结构，MemoryPool 分为 Leaf （具体的叶子结点）和 Aggregate（汇总节点）。这里并发上 children 由 <code>folly::SharedMutex</code> 维护，<code>parent_</code> 是不会变的，内存永远按照 alignas 申请。<strong>这段逻辑最近在重构，变动比较大，我这版本理解基于 <a href="https://github.com/facebookincubator/velox/commit/c82d9f9bd335c6411fcc1f1f99c5d82796535733">https://github.com/facebookincubator/velox/commit/c82d9f9bd335c6411fcc1f1f99c5d82796535733</a></strong> <ol><li><code>MemoryPoolImpl</code> 是 <code>MemoryPool</code> 实际使用的逻辑，它的内存添加会走一把锁（还是 <code>std::mutex</code>，我日）。它自己有一组统计信息，同时绑定了一个 <code>MemoryManager</code></li><li><code>MemoryManager</code> 几乎是类似单例的全局内存分配器，它有一个单例，然后可以根据他产生 <code>MemoryPool</code> 和绑定 <code>MemoryPool</code></li><li><code>MemoryArbitrator</code> 是一个 <code>MemoryManager</code> 中的怪东西，感觉上类似一个 burst 内存处理器。当内存不够的时候，可以根据 <code>MemoryArbitrator</code> 去向别的地方租借内存</li><li><code>MemoryReclaimer</code> 是 <code>MemoryArbitrator</code> 的 RAII 包装器，负责借/还内存的管理</li></ol></li></ol><p>这里有个 Hacking 的地方是，MemoryPool 自己和父级别 allocate 一遍还要去 MemoryManager 搞一遍，感觉是因为各种地方的上限不是简单硬从父亲那里分配多少，而是每个级别有一些内存，然后允许去 steal。</p><p>和 Arrow 不一样，Velox 的 Vector 和类型和物理的 Layout 没有直接对应。</p><p>这里给 Vector 提供了不同的 Encoding 方式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Provides an enumeration of vector encoding types.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">enum class</span> <span class="title class_">Simple</span> &#123;</span><br><span class="line">  BIASED,</span><br><span class="line">  CONSTANT,</span><br><span class="line">  DICTIONARY,</span><br><span class="line">  FLAT,</span><br><span class="line">  SEQUENCE,</span><br><span class="line">  ROW,</span><br><span class="line">  MAP,</span><br><span class="line">  ARRAY,</span><br><span class="line">  LAZY,</span><br><span class="line">  FUNCTION</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>Velox 的 null 也是个 bitmap。值得一提的是，Velox 代码中 <code>BaseVector</code> 都快有 1000 行了，我们先看点简单的内容：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> TypePtr type_;</span><br><span class="line"><span class="type">const</span> TypeKind typeKind_;</span><br><span class="line"><span class="type">const</span> VectorEncoding::Simple encoding_;</span><br><span class="line">BufferPtr nulls_;</span><br><span class="line"><span class="comment">// Caches raw pointer to &#x27;nulls-&gt;as&lt;uint64_t&gt;().</span></span><br><span class="line"><span class="type">const</span> <span class="type">uint64_t</span>* rawNulls_ = <span class="literal">nullptr</span>;</span><br><span class="line">velox::memory::MemoryPool* pool_;</span><br><span class="line"><span class="type">vector_size_t</span> length_ = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Holds the number of nulls in the vector. If the number of nulls</span></span><br><span class="line"><span class="comment"> * is not available, it is set to std::nullopt. Setting the value to</span></span><br><span class="line"><span class="comment"> * zero does have implications (SIMD operations need null count to be</span></span><br><span class="line"><span class="comment"> * zero) and is not the same as std::nullopt.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">std::optional&lt;<span class="type">vector_size_t</span>&gt; nullCount_;</span><br><span class="line">std::optional&lt;<span class="type">vector_size_t</span>&gt; distinctValueCount_;</span><br><span class="line">std::optional&lt;ByteCount&gt; representedByteCount_;</span><br><span class="line">std::optional&lt;ByteCount&gt; storageByteCount_;</span><br><span class="line">ByteCount inMemoryBytes_ = <span class="number">0</span>;</span><br></pre></td></tr></table></figure><p>这些是它的成员，这里没有处理数据，但是包装了很多 <code>wrap</code> 之类的反解方法。这里上面再套了一层 <code>SimpleVector</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// This class abstracts over various Columnar Storage Formats such that Velox</span></span><br><span class="line"><span class="comment">// can select the most appropriate one on a per field / per block basis.</span></span><br><span class="line"><span class="comment">// The goal is to use the most appropriate type to optimize for:</span></span><br><span class="line"><span class="comment">//   - Lazy deserialization if desired.</span></span><br><span class="line"><span class="comment">//   - serialization / rehydration cost, ideally we use a smart view into the</span></span><br><span class="line"><span class="comment">//     data without fully rehydrating.</span></span><br><span class="line"><span class="comment">//   - serialized bytes</span></span><br><span class="line"><span class="comment">//   - cpu cost of filtering</span></span><br><span class="line"><span class="comment">//   - optimize aggregation of sequential values</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleVector</span> : <span class="keyword">public</span> BaseVector &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">SimpleVector</span>(</span><br><span class="line">      velox::memory::MemoryPool* pool,</span><br><span class="line">      TypePtr type,</span><br><span class="line">      VectorEncoding::Simple encoding,</span><br><span class="line">      BufferPtr nulls,</span><br><span class="line">      <span class="type">size_t</span> length,</span><br><span class="line">      <span class="type">const</span> SimpleVectorStats&lt;T&gt;&amp; stats,</span><br><span class="line">      std::optional&lt;<span class="type">vector_size_t</span>&gt; distinctValueCount,</span><br><span class="line">      std::optional&lt;<span class="type">vector_size_t</span>&gt; nullCount,</span><br><span class="line">      std::optional&lt;<span class="type">bool</span>&gt; isSorted,</span><br><span class="line">      std::optional&lt;ByteCount&gt; representedByteCount,</span><br><span class="line">      std::optional&lt;ByteCount&gt; storageByteCount = std::<span class="literal">nullopt</span>)</span><br><span class="line">      : <span class="built_in">BaseVector</span>(</span><br><span class="line">            pool,</span><br><span class="line">            std::<span class="built_in">move</span>(type),</span><br><span class="line">            encoding,</span><br><span class="line">            std::<span class="built_in">move</span>(nulls),</span><br><span class="line">            length,</span><br><span class="line">            distinctValueCount,</span><br><span class="line">            nullCount,</span><br><span class="line">            representedByteCount,</span><br><span class="line">            storageByteCount),</span><br><span class="line">        <span class="built_in">isSorted_</span>(isSorted),</span><br><span class="line">        <span class="built_in">elementSize_</span>(<span class="built_in">sizeof</span>(T)),</span><br><span class="line">        <span class="built_in">stats_</span>(stats) &#123;&#125;</span><br></pre></td></tr></table></figure><p>SimpleVector 有几个不同的子类，对应文档里的编码：</p><ol><li>Constant</li><li>Bias (Delta + Base)</li><li>Dictionary</li><li>Flat (啥都没有)</li><li>Sequence (RLE)</li></ol><p>复杂类型的处理逻辑和 Arrow 差别很大，见：<a href="https://facebookincubator.github.io/velox/develop/vectors.html#flat-vectors-complex-types">https://facebookincubator.github.io/velox/develop/vectors.html#flat-vectors-complex-types</a></p><p>对 Null 处理而言，区别有：</p><p>Struct</p><blockquote><p>Child vectors may include nulls buffers of their own, therefore, it is possible to have a non-null top-level struct value with some or all child fields being null. A null struct is not the same as a struct with all its fields being null. Values of child fields for rows where the top-level struct is null are undefined.</p></blockquote><p>Map:</p><blockquote><p>Null map and empty map are not the same.</p><p>Keys and values vectors may have nulls buffer independent of each other and of the nulls buffer of the map vector itself. This allows us to specify non-null maps with some or all values being null. Technically speaking a map may have a null key as well, although this may not be very useful in practice. Null map and a map with all values being null are not the same.</p><p>Map vector layout does not guarantee or require that keys of individual maps are unique. However, in practice, places which create maps, e.g. ORC and Parquet readers, <a href="https://facebookincubator.github.io/velox/functions/presto/map.html#id0"><code>map()</code></a> function, etc., ensure that map keys are unique.</p></blockquote><p>Array:</p><blockquote><p>Null array and empty array are not the same.</p><p>Elements vector may have a nulls buffer independent of the nulls buffer of the array vector itself. This allows us to specify non-null arrays with some or all null elements. Null array and array of all null elements are not the same.</p></blockquote><p>总之，这块语义本身也需要一定 checking。</p><h2 id="ClickHouse"><a href="#ClickHouse" class="headerlink" title="ClickHouse"></a>ClickHouse</h2><p>内存见  <a href="https://www.jianshu.com/p/4b15fae5d400">https://www.jianshu.com/p/4b15fae5d400</a> ，比较值得借鉴的地方是各种 Hook</p><p>相关的 Doris 也可以见 <a href="https://cwiki.apache.org/confluence/display/DORIS/DSIP-002%3A+Refactor+memory+tracker+on+BE">https://cwiki.apache.org/confluence/display/DORIS/DSIP-002%3A+Refactor+memory+tracker+on+BE</a></p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li>Arrow 的介绍：<a href="https://arrow.apache.org/docs/cpp/arrays.html">https://arrow.apache.org/docs/cpp/arrays.html</a></li><li>向量化的查询引擎里使用Bitmap还是Select Vectors表示过滤后的结果更优？ - 码上DX3906的回答 - 知乎 <a href="https://www.zhihu.com/question/546231083/answer/2601582280">https://www.zhihu.com/question/546231083/answer/2601582280</a></li><li>ClickHouse 的内存管理: <a href="https://www.jianshu.com/p/4b15fae5d400">https://www.jianshu.com/p/4b15fae5d400</a></li><li>Jemalloc: <a href="https://jemalloc.net/jemalloc.3.html">https://jemalloc.net/jemalloc.3.html</a> (<code>sallocx</code> 等)</li><li>Doris 内存管理：<a href="https://cwiki.apache.org/confluence/display/DORIS/DSIP-002%3A+Refactor+memory+tracker+on+BE">https://cwiki.apache.org/confluence/display/DORIS/DSIP-002%3A+Refactor+memory+tracker+on+BE</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>[SIGMOD&#39;18] Column Sketches: a index for OLAP workload</title>
      <link href="/2023/04/16/Column-Sketches-a-index-for-OLAP-workload/"/>
      <url>/2023/04/16/Column-Sketches-a-index-for-OLAP-workload/</url>
      
        <content type="html"><![CDATA[<ul><li><p><code>&lt;Column Sketches: A Scan Accelerator for Rapid and Robust Predicate Evaluation&gt;</code> 是 SIGMOD’18 上的一篇 Research Paper. 它描述了怎么用 Column Sketches 来构建一个合适的、以 Table 为顺序的 Sketch，来优化查询。这篇文章的 idea 比较简单，但是数学部分相对复杂一些，比较值得借鉴。不过这里也得小小注意一下，Column Sketches 和经常用的缩略词 CM Sketch (Count-Min) 是不一样的，后者经常用来做 ndv 的统计，而前者可以看作是 bitmap index 的类似物。</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a><strong>背景</strong></h2><p>抱歉我们需要在背景部分介绍比较长的时间. 本质上，AP 系统的 Index 和 tp 系统的 index 可能稍微有一些不一样：</p><ol><li>数据的规模大，可能过滤掉的数据规模大，粒度可能也比较大</li><li>（可能会）允许一些 false positive</li><li>（并不一定会）可能不太会考虑 update / insert 的情况</li></ol><p>TP 的 BTree / LSM / ART 等索引都不是很适合这个情况。在 AP 系统中，可能还会有几个 consideration（TP可能也有）：</p><ol><li>Predicate Seletivity<ol><li>其实我觉得还有一个很重要的，但是论文和 15-721 都没咋提，就是数据的分布的情况。比如 0 1 0 1 0 1 这种，你在 loading 层面如果</li></ol></li><li>Skewness<ol><li>可能会有高分布的 unique value 数据</li></ol></li><li>cluster / sorting<ol><li>数据是否预先 clustering 了</li></ol></li></ol><p>在 15-721 里面，整理了一些索引，部分也来自 Column Sketches 的举例，不知道有没有什么专论。</p><h3 id="Zone-Maps"><a href="#Zone-Maps" class="headerlink" title="Zone Maps"></a><strong>Zone Maps</strong></h3><p>Apache Iceberg, Apache Parquet, Apache ORC 之类的都有这个东西，我倒是很难想象有谁没有的。本质上是一种超级粗粒度 pruning。一般来说还是有一些各种 corner case 的，比如哪些东西应该放 min-max，一些特殊值的处理，什么时候应该退化。不过这些我理解是什么索引都有。</p><h3 id="Bitmap-Index"><a href="#Bitmap-Index" class="headerlink" title="Bitmap Index"></a><strong>Bitmap Index</strong></h3><p>StarRocks / Doris 都引入了 Bitmap Index. Bitmap Index 有一些思路发表在论文 <Bitmap Index Design and Evaluation> 中，论文本身比较简单。bitmap index 的最原始思路是「一个值一个 bitmap index」。然后 Filter 的时候扫那几个 bitmap 就行了。这个 idea 我个人认为本质上是把 domain 拆分成多组，然后 filter 的时候只扫描需要的 domain。</p><p>这种方式直观看是没有问题的，但是问题是多方面的，比如 domain 需要很小，但是又不太好过小（想象一下，如果 domain = 2，那么是不是就没有区别了…），同时还有各种问题，所以这里可能要引入一些 pattern 和压缩方式。</p><p>论文 Bitmap Index Design and Evaluation 提出了对应的比较框架，来给这个一个量化的渠道。这篇论文发表的比较早，不过其实评估还是很好的。</p><p>这篇论文拆分出了两个维度，作为评价的标准：</p><ol><li>Space-Time Tradeoff</li><li>Encoding Scheme</li></ol><p>同时做了一些 bitmap eval 相关的工作。同时定义了一些 bitmap 相关的启发式工作</p><p>这里：</p><ol><li>C = attribute cardnality</li><li>定义下列 Decomposition:</li></ol><p><img src="https://image.mwish.me/blog-image/bitmap.png" alt="bitmap"></p><p>也就是说，这里可以把值拆成 n 组 bitmap 的集合 {B0, B1, B…, B_{n-1}}，共同构成对应的数字。这里展示同一组数据的两种表示方式，可以看到 Filter 性能和占用空间上的区别：</p><p><img src="https://image.mwish.me/blog-image/bitmap-2-component.png" alt="bitmap-2-component"></p><p><img src="https://image.mwish.me/blog-image/bitmap-value-list.png" alt="bitmap-value-list"></p><p>这里还有一个 Encoding Schema 的问题，这里分为两种：</p><ol><li>Equality Encoding: 单组数据内，等于要求的mark 为 1 </li><li>Range Encoding: 单组数据内，大于等于要求的全部mark 为 1。<strong>它的宽度会少一，因为它相当于用 range 的方式缩减了需要的信息</strong>。</li></ol><p>Figure1 和 Figure3 内容均为 Equality Encoding，下面展示 Range Encoding:</p><p><img src="https://image.mwish.me/blog-image/bitmap-abc.png" alt="bitmap-abc"></p><h4 id="演算"><a href="#演算" class="headerlink" title="演算"></a>演算</h4><p><img src="https://image.mwish.me/blog-image/bitmap-eval.png" alt="bitmap-eval"></p><p>这里有两种算法：</p><ol><li>RangeEval: 对于 <code>&gt;=</code> 和 <code>&lt;=</code>，维护每个 bitmap 的 Eq, GT 或者 Eq, LT。然后推算。<ol><li>初始化的 GT, LT 为全 0 的向量，Eq 为 non-nulls</li><li>每一轮中，求解需要的 Eq, LT, GT</li></ol></li><li>RangeEval-Opt:<ol><li>把 <code>&gt;=</code> 和 <code>&lt;=</code> 推成 <code>&gt; v - 1</code> 和  <code>&lt; v + 1</code>，然后执行操作。</li></ol></li></ol><p>（我其实没完全看懂这里，可能之后得翻翻代码）</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><img src="https://image.mwish.me/blog-image/bitmap-design-space.png" alt="bitmap-design-space"></p><p>论文中提出了对应的 space-time 抽象，来评估对应的实现。</p><p>你可能会注意到右下角有个 Bit-Sliced Index，这个东西…和 Bit-Weaving 一样，算是极端特化的 bitmap index，算法大致类似之前贴出来的部分（但是可能有 SIMD），类似一套提前的裁剪</p><p><img src="https://image.mwish.me/blog-image/bit-slice.png" alt="bit-slice"></p><p>在实践中，有的数据库实现了 Bitmap Index:</p><ol><li>Oracle</li><li>Greenplum, 这套做的比较细，直接做到 Page 上头了</li><li>StarRocks/Doris, 这个做的相当于是多列无序字典</li></ol><p>(其实我认为某种程度上 bitmap 相当于一种奇怪的 encoding 了，而不是传统 Index 那种含义，我目前没找到很好的材料，所以语言上说不太清楚，懂我意思就行)</p><h3 id="Bit-Weaving"><a href="#Bit-Weaving" class="headerlink" title="Bit Weaving"></a>Bit Weaving</h3><p>Bit Weaving 有 wisc 的作者们发表于 SIGMOD’13 的论文 BitWeaving: Fast Scans for Main Memory Data Processing 上。某种程度上，Bit Weaving 有点像 Bit-Slices 这一套，它往前走了一步：对整数（尽量）压缩，对位采用特殊的模式，使其适合于 SIMD 的执行。</p><p><img src="https://image.mwish.me/blog-image/bit-weaving.png" alt="bit-weaving"></p><p><img src="https://image.mwish.me/blog-image/bit-weaving-hbp.png" alt="img"></p><p>这里给各种算子都做了基本的实现。性能评估如下：</p><p><img src="https://image.mwish.me/blog-image/bitweaving-eval.png" alt="bitweaving-eval"></p><p>这里我建议还是回到论文的标题，「一个 fast-scan」 来理解。</p><h2 id="Column-Sketches-and-Column-Inprints"><a href="#Column-Sketches-and-Column-Inprints" class="headerlink" title="Column Sketches ( and Column Inprints )"></a><strong>Column Sketches ( and Column Inprints )</strong></h2><p>（下面是 Column Inprints，思路很简单）</p><p><img src="https://image.mwish.me/blog-image/column-imprint.png" alt="column-imprint"></p><p>这部分相当于进行一系列有损压缩，来拿到一个帮助裁剪的 sketches，感觉这个方式明显合理很多。我觉得在现代 AP 系统中，属于值得一试的方案。</p><p>论文来自哈佛大学的实验室: <a href="https://stratos.seas.harvard.edu/publications/adaptive-data-skipping-main-memory-systems">https://stratos.seas.harvard.edu/publications/adaptive-data-skipping-main-memory-systems</a></p><p>LSM 著名的 Dostoyevsky 也是来自这个实验室，感觉他们是工程能力没有那么强，但是对各种 metrics</p><p>论文里面评估了 Zone Map, BitWeaving, Btr 之类的策略，下列内容评估范围是：</p><ol><li>Selectivity 3%</li><li>数据分布有 skew (可见 Figure 1 是有利于 sketch 的，因为数据分布有 skew 的场景是它的优势区，这就是论文做实验的方式，嘿嘿) </li></ol><p><img src="https://image.mwish.me/blog-image/sketches-1.png" alt="sketches-1"></p><blockquote><p>Compared to standard scans, Column Sketches provide an improvement of 3×-6× for numerical attributes and 2.7× for categorical attributes.</p></blockquote><p>下面是一个论文简单的对比（吊打）框架：</p><p><img src="https://image.mwish.me/blog-image/rap.png" alt="rap"></p><p>论文评估的范围有：</p><ul><li>B-Tree：<ul><li>对 low-selectivity 效果好，但是当 Seletivity 上去的时候，性能就会暴跌（传统 rdbms 也要考虑回表的 io/cpu 开销）</li><li>论文中提到 Btree 不适合在 append-only 系统更新、cache-locality 在 modern scan 上表现不好。我理解前者是实现问题，后者感觉确实是个小问题。但我理解某种程度上 btr 和 sketch 确实是两回事。此外还有个问题是，这里 btr 是按照 domain 切分的，切分完可能还要转化成 scan 回表（或者直接 icp）。作者实验中，在选择率大于 1% 的情况下，就不建议用 btr 了（其实我也挺好奇他实验的环境的，不过不深究了）</li></ul></li><li>Lightweight Indices (Zone Map, Column Inprints)<ul><li>用数据的 Summary 来做 Skipping</li><li>对于 data 的 clustering properties 不好的时候，效果并不好（像 Figure 1）. 这个其实可以看一篇别的论文 Adaptive Data Skipping in Main Memory System 的图，总的来说和 zone map 粒度、selectivity 和数据混乱程度都有关。当某几列数据不太 clustering 的时候效果显然是不好的</li></ul></li><li>Early Pruning Methods<ul><li>提前（细粒度的）pruning 数据，比如 bit-slicing, byte-slicing。通常策略是按 bit / byte 来切分（partition）值，然后读的时候去把用户的 Operator 也推给需要的 partition 再合并，这里下推的顺序从高到低，然后尽量 skip 已经 prune 掉的数据。</li><li>当数据或 filter 集中在低位、或者出现 skew 的时候，高位 filter 会做很多无用功，同时也不能 prune 掉什么数据。（the high order bits are biased towards zero, enabling very little pruning. As a result early pruning brings no significant advantage over a traditional scan.）</li></ul></li></ul><p>论文提出了 Column Sketches，特点是：</p><ol><li>Robust to Selectivity, data value distribution, data clustering</li><li>Lossy Compression<ol><li>可以比较粗糙又不影响正确性的摸出一个 encoder</li><li>Space efficient</li><li>更快的 ingestion speed (就是写的快,因为查表少我理解)，同时，Update 之类的不用像字典一样重写字典。</li><li>把查询拆分为：<ol><li>走 sketched data 粗过滤一遍（会有 false positive）</li><li>如果有需要，走 Base data 细过滤一遍</li></ol></li></ol></li><li>论文框架中，尽量适配 SIMD、多核优化。论文声称也可以适配 TP数据库。</li></ol><p>那么，简单来一张图表示 Column Sketches 的框架：</p><p><img src="https://image.mwish.me/blog-image/BB82ECF4-14BB-4F3A-957E-36E821C7F220.png" alt="BB82ECF4-14BB-4F3A-957E-36E821C7F220"></p><p>这部分内容在论文第二章，上图一图感觉就行了。</p><ol><li>Column Sketches 支持 Ordered 和 Unordered 两种模式。数据结构分为 Compression Map ( function S(x) ) 和 Sketched Column （固定 bits）。Build 阶段，Base Data 根据 Compression Map 的信息被映射到 Sketched Column 上；Probe 阶段</li><li>对于 Ordered 结构，Compression Map 类似一个有序的 eq-depth histogram. Figure 2 左侧写的很清楚。根据这个可以构建，然后右图中，根据 Map 可以粗筛一遍，再根据 filter 的结果细筛（这个地方有一个问题是，<strong>空间占用和 fpp</strong> 都是多少，别急，论文后面会讲）</li><li>对于 Unordered 结构，Compression Map 是一个含有 unique code 的 HashTable + HashFunction </li></ol><p>文章贴了一个算法，然后表示这个玩意最好是 byte-alignment 的，反正这种东西都是实现层面的因素：</p><blockquote><p>Byte Alignment. Column Sketches work for any code size. However, we find that on modern hardware there exists around a 30% performance penalty for using non-byte aligned codes. Thus, we give special attention to 8 bit Column Sketches and to 16 bit Column Sketches.</p></blockquote><p>S(x) 已知的情况下，构建和查询过程都很简单。显然这个结构的问题就变成了如何构建 S(x)。</p><h3 id="CONSTRUCTING-COMPRESSION-MAPS"><a href="#CONSTRUCTING-COMPRESSION-MAPS" class="headerlink" title="CONSTRUCTING COMPRESSION MAPS"></a>CONSTRUCTING COMPRESSION MAPS</h3><p>需要满足论文画的 Robust to Selectivity, data value distribution, data clustering 这几个饼，构建一个合适的 Mapping 就变得很重要了，论文先提出了一些原则，然后再具体分析：</p><ol><li>给 frequency value（超过一定比例）去分配独立的 code.<ol><li>分配独立的 code 有一个特殊的好处就是不用回表再套一层这个 Column 的 Filter。同时论文提到，在出现一个 value 对应很多 key 的（假设是 10%）这种数据分布情况下，访问 cacheline 中的任意数据，就会需要访问cacheline 全部的数据，同时也会影响这个 value 里面分布的其他数据。不好做到 robust。（论文里论证感觉不是很清楚，我理解大概是这个意思）</li></ol></li><li>给非 frequency value 分配非独立的 code 很合理，压缩空间，访问 base data 的比例也很小</li><li>允许 order preserving (废话)</li><li>如果有（sampling 中）没见到过的 value，也可以当成 non-unique code 正确处理（想象一下，作为反例的 dict encoding）</li><li>Optional: Exploit Frequently Queried Values </li></ol><p>下面有一段数学证明：</p><p><img src="https://image.mwish.me/blog-image/image.png" alt="image"></p><blockquote><p>256 那个地方我怀疑是个笔误，当成 n 处理就行。</p></blockquote><p>这里特别做了一个不难证明的上限 (2/n). 这个上线在实现上是有操作空间的。大于 2/n 的能保证分配到 unique value.</p><h3 id="有序数列的构建"><a href="#有序数列的构建" class="headerlink" title="有序数列的构建"></a>有序数列的构建</h3><p>对于有序 Map，构建方式大概是 CDF 采样，然后构建 eq-depth histogram。这里的方式是 采样 + Sort，然后构建 histogram，根据这个 histogram 来处理。论文列出了 sample 200k 个值，然后构建 256 个 bucket 和 assign unique value 的情况。</p><p>Unique value assign 在这里被做了一种很简单的抽样法：</p><ol><li>假设有 n 个数值，其中，出现数多于 1/z 的要被 assign unique value, c 是 column sketches 中准备分配的 codepoint 数量</li><li>构造方式：抽样 n/z, 2n/z… 这些轴点上的数据，然后 check 每个轴点上数据的 begin, end，是否超过了 1/z (这个构造方式还是 O(N) 的，不过可以跳过很多非 unique 的数据，采样策略也比较简单）</li><li>Assign c * midpoint / n 的 codepoint 给中间的值。论文中，令 z = c。</li><li>分配剩下的 code</li></ol><h3 id="Category-数列的构建"><a href="#Category-数列的构建" class="headerlink" title="Category 数列的构建"></a>Category 数列的构建</h3><p>有序的 S(x) 类似一个 eq-depth 直方图，无序的数列则是 Hash Function + Bucket Size + Unique Values。</p><p>这里采样就比较弱智了，给高频值做分配，然后低频值 hash</p><h3 id="Eval"><a href="#Eval" class="headerlink" title="Eval"></a>Eval</h3><p><img src="https://image.mwish.me/blog-image/sketches-eval.png" alt="sketches-eval"></p><p>Eval 分成两部分：</p><ol><li>Definite</li><li>Possible</li></ol><p>然后用来求职，相当于 unique value 比较独立的抽出来了。</p><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>对于 AP，相对于 TP 的 Domain-Based Index，AP 更倾向于用 Table-Based Index，来读取数据（类似 ICP）或者对 Table 读取的数据进行裁剪（拿到一个 mask，然后去 filter）。同时，也有一些改变 Table 数据存放模式，方便 fast filtering 的方案。这里也要考虑上空间放大之类的。</p><p>目前感觉市面上的 AP 产品都没有什么做的特别成熟的。我要发力了（误）。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a><strong>Reference</strong></h2><ul><li><strong>Bitmap Index Design and Evaluation</strong> <a href="http://www.cs.tau.ac.il/~matias/courses/sem_fall98/bitmaps/bitmapIndexes.html">http://www.cs.tau.ac.il/~matias/courses/sem_fall98/bitmaps/bitmapIndexes.html</a></li><li><a href="https://www.youtube.com/watch?v=2sRyOTZ5Kh0&amp;ab_channel=Sigmod2018">https://www.youtube.com/watch?v=2sRyOTZ5Kh0&amp;ab_channel=Sigmod2018</a></li></ul></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB Data Locking: Part 1</title>
      <link href="/2023/03/25/InnoDB-Data-Locking/"/>
      <url>/2023/03/25/InnoDB-Data-Locking/</url>
      
        <content type="html"><![CDATA[<p>每一个需要实现锁的人，都需要考虑 Data Locking，在 Btree 上如何进行数据的锁定，特别是 InnoDB / PostgreSQL。这篇文章简单介绍一下 InnoDB 是怎么锁定数据的。本身这篇文章参考的是 InnoDB 官方博客中，Kuba Łopuszański 写的几部分 InnoDB Data Locking 的文章，再加上 阿里巴巴数据库月报一些相关的详细一些的介绍。</p><p>Locking 一直是数据库里面非常难的内容，在 InnoDB 里面，难点也在于很多地方：</p><ol><li>不同层次的（database, table, row）的锁定</li><li>不同的隔离级别</li><li>读/写等不同的锁的权限<ol><li>事务冲突</li><li>需要的时候，维护 consistent read view</li></ol></li><li>锁的超时 / 饿死(priority) / 排队</li><li>死锁处理<ol><li>识别冲突</li><li>挑选 victim</li><li>高效，不影响全局</li><li>识别不同模式的，甚至是锁升级引起的冲突</li></ol></li></ol><p>本身，事务这个抽象暗示着 DB 对外层提供的是一种 total-ordering 的语义。但是为了性能，db 会做到行或者一些级别的锁定，来允许并发存在。同时，为了给性能或者使用开一些口子，DB 甚至（也不能说甚至）允许很多低级别的 Isolation Level。其实单纯从取 snapshot 或者一些小地方来看，性能甚至不一定更好（比如 RC 可能每次读要拿一个 read-view，虽然也有一些性能优化），但是降低了总体冲突的概率。</p><p>这里的问题是怎么（高效的）提供锁定和识别冲突并 abort。</p><h2 id="表和数据锁定"><a href="#表和数据锁定" class="headerlink" title="表和数据锁定"></a>表和数据锁定</h2><p>InnoDB 的数据锁定是 MySQL 面试一大坑，比如经典的 GAP_LOCK 和 next-key locking，比较乐子的是，其实数据库业务部门比大部分如今的 DB R&amp;D 更懂这块的内容，因为他们在生产中会实际和这些东西打交道。</p><p>比较常见的内容是表锁和数据锁。表锁是一个 MySQL 级别的概念，但是它可以被转化为 InnoDB 的数据锁然后飘在 InnoDB 上。举博客中的例子：</p><p>数据锁定的 sample:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="keyword">SELECT</span> </span><br><span class="line">    ENGINE_TRANSACTION_ID <span class="keyword">as</span> trx_id,</span><br><span class="line">    LOCK_DATA <span class="keyword">as</span> <span class="type">row</span>,</span><br><span class="line">    OBJECT_NAME <span class="keyword">as</span> `<span class="keyword">table</span>`,</span><br><span class="line">    LOCK_MODE,</span><br><span class="line">    LOCK_STATUS </span><br><span class="line">  <span class="keyword">FROM</span> performance_schema.data_locks <span class="keyword">WHERE</span> LOCK_TYPE<span class="operator">=</span><span class="string">&#x27;RECORD&#x27;</span>; </span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-----+--------+-----------+-------------+ </span></span><br><span class="line"><span class="operator">|</span> trx_id <span class="operator">|</span> <span class="type">row</span> <span class="operator">|</span>  <span class="keyword">table</span> <span class="operator">|</span> LOCK_MODE <span class="operator">|</span> LOCK_STATUS <span class="operator">|</span> </span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-----+--------+-----------+-------------+ </span></span><br><span class="line"><span class="operator">|</span>   <span class="number">3305</span> <span class="operator">|</span>   <span class="number">2</span> <span class="operator">|</span> report <span class="operator">|</span>         S <span class="operator">|</span>     GRANTED <span class="operator">|</span> </span><br><span class="line"><span class="operator">|</span>   <span class="number">3305</span> <span class="operator">|</span>   <span class="number">2</span> <span class="operator">|</span> report <span class="operator">|</span>         X <span class="operator">|</span>     GRANTED <span class="operator">|</span> </span><br><span class="line"><span class="operator">|</span>   <span class="number">3306</span> <span class="operator">|</span>   <span class="number">2</span> <span class="operator">|</span> report <span class="operator">|</span>         X <span class="operator">|</span>     WAITING <span class="operator">|</span> </span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-----+--------+-----------+-------------+</span></span><br></pre></td></tr></table></figure><p>上面是很明显的数据锁定，我们还可以看到表锁：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">con2<span class="operator">&gt;</span> <span class="keyword">SELECT</span> LOCK_TYPE,LOCK_STATUS,OWNER_THREAD_ID </span><br><span class="line">      <span class="keyword">FROM</span> performance_schema.metadata_locks </span><br><span class="line">      <span class="keyword">WHERE</span> OBJECT_NAME<span class="operator">=</span><span class="string">&#x27;t&#x27;</span> <span class="keyword">AND</span> OBJECT_TYPE<span class="operator">=</span>&quot;TABLE&quot;;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------------+-------------+-----------------+</span></span><br><span class="line"><span class="operator">|</span> LOCK_TYPE        <span class="operator">|</span> LOCK_STATUS <span class="operator">|</span> OWNER_THREAD_ID <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------+-------------+-----------------+</span></span><br><span class="line"><span class="operator">|</span> SHARED_READ_ONLY <span class="operator">|</span> GRANTED     <span class="operator">|</span>              <span class="number">53</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SHARED_WRITE     <span class="operator">|</span> PENDING     <span class="operator">|</span>              <span class="number">54</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------+-------------+-----------------+</span></span><br></pre></td></tr></table></figure><p>这里可以看到，<code>performance_schema.metadata_locks</code> 有 <code>SHARED_READ_ONLY</code> 锁的表，这里锁有下面的几种形式：<a href="https://dev.mysql.com/doc/refman/5.7/en/performance-schema-metadata-locks-table.html">https://dev.mysql.com/doc/refman/5.7/en/performance-schema-metadata-locks-table.html</a></p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOCK_TYPE</span><br></pre></td></tr></table></figure><ul><li>The lock type from the metadata lock subsystem. The value is one of <code>INTENTION_EXCLUSIVE</code>, <code>SHARED</code>, <code>SHARED_HIGH_PRIO</code>, <code>SHARED_READ</code>, <code>SHARED_WRITE</code>, <code>SHARED_UPGRADABLE</code>, <code>SHARED_NO_WRITE</code>, <code>SHARED_NO_READ_WRITE</code>, or <code>EXCLUSIVE</code>.</li></ul></blockquote><p>这里想必在 MDL 阶段也会上 X 锁。</p><p>表锁在 InnoDB 中，可能会以意向锁的形式存在（IX IS），其实反过来说，InnoDB 的意向锁也只会在上面表锁的情况下开。我们继续举官方博客中的例子：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SET</span> autocommit <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"> </span><br><span class="line">mysql<span class="operator">&gt;</span> LOCK <span class="keyword">TABLE</span> t READ, t1 WRITE;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.04</span> sec)</span><br><span class="line"> </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> OBJECT_NAME,LOCK_TYPE,LOCK_STATUS,OWNER_THREAD_ID </span><br><span class="line">       <span class="keyword">FROM</span> performance_schema.metadata_locks </span><br><span class="line">       <span class="keyword">WHERE</span> OBJECT_SCHEMA<span class="operator">=</span><span class="string">&#x27;test&#x27;</span> <span class="keyword">AND</span> OBJECT_TYPE<span class="operator">=</span>&quot;TABLE&quot;;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+----------------------+-------------+-----------------+</span></span><br><span class="line"><span class="operator">|</span> OBJECT_NAME <span class="operator">|</span> LOCK_TYPE            <span class="operator">|</span> LOCK_STATUS <span class="operator">|</span> OWNER_THREAD_ID <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+----------------------+-------------+-----------------+</span></span><br><span class="line"><span class="operator">|</span> t           <span class="operator">|</span> SHARED_READ_ONLY     <span class="operator">|</span> GRANTED     <span class="operator">|</span>              <span class="number">49</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> t1          <span class="operator">|</span> SHARED_NO_READ_WRITE <span class="operator">|</span> GRANTED     <span class="operator">|</span>              <span class="number">49</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+----------------------+-------------+-----------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"> </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> thread_id,processlist_id </span><br><span class="line">       <span class="keyword">FROM</span> performance_schema.threads </span><br><span class="line">       <span class="keyword">WHERE</span> thread_id<span class="operator">=</span><span class="number">49</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+----------------+</span></span><br><span class="line"><span class="operator">|</span> thread_id <span class="operator">|</span> processlist_id <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+----------------+</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">49</span> <span class="operator">|</span>              <span class="number">8</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+----------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"> </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> trx_id <span class="keyword">FROM</span> information_schema.innodb_trx </span><br><span class="line">       <span class="keyword">WHERE</span> trx_mysql_thread_id<span class="operator">=</span><span class="number">8</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------+</span></span><br><span class="line"><span class="operator">|</span> trx_id <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+</span></span><br><span class="line"><span class="operator">|</span>   <span class="number">3851</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+</span></span><br><span class="line"> </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> </span><br><span class="line">         ENGINE_TRANSACTION_ID <span class="keyword">as</span> trx_id,</span><br><span class="line">         OBJECT_NAME <span class="keyword">as</span> `<span class="keyword">table</span>`,</span><br><span class="line">         INDEX_NAME,</span><br><span class="line">         LOCK_DATA,</span><br><span class="line">         LOCK_MODE,</span><br><span class="line">         LOCK_STATUS </span><br><span class="line">       <span class="keyword">FROM</span> performance_schema.data_locks;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-------+------------+-----------+-----------+-------------+</span></span><br><span class="line"><span class="operator">|</span> trx_id <span class="operator">|</span> <span class="keyword">table</span> <span class="operator">|</span> INDEX_NAME <span class="operator">|</span> LOCK_DATA <span class="operator">|</span> LOCK_MODE <span class="operator">|</span> LOCK_STATUS <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-------+------------+-----------+-----------+-------------+</span></span><br><span class="line"><span class="operator">|</span>   <span class="number">3851</span> <span class="operator">|</span> t     <span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> S         <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   <span class="number">3851</span> <span class="operator">|</span> t1    <span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> X         <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-------+------------+-----------+-----------+-------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>这里观察到了 <code>metadata_lock</code> 的锁和 <code>data_locks</code> 的映射关系。</p><p>回忆一下在数据库中 Intention Lock 都是为了满足不同层次的锁定。可以想象，写事务会拿到 <code>IX</code> 锁，然后写；读事务会拿到 IS 锁，然后读。这个时候如果有全局的表锁，会走 InnoDB Lock 的流程，等待拿到锁然后进行操作。（不知道有没有什么特定的优化，应该有吧）</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"> </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT</span> <span class="keyword">INTO</span> t <span class="keyword">VALUES</span> (<span class="number">200</span>);</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> </span><br><span class="line">         ENGINE_TRANSACTION_ID <span class="keyword">as</span> trx_id,</span><br><span class="line">         OBJECT_NAME <span class="keyword">as</span> `<span class="keyword">table</span>`,</span><br><span class="line">         INDEX_NAME,</span><br><span class="line">         LOCK_DATA,</span><br><span class="line">         LOCK_MODE,</span><br><span class="line">         LOCK_STATUS </span><br><span class="line">       <span class="keyword">FROM</span> performance_schema.data_locks;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-------+------------+-----------+-----------+-------------+</span></span><br><span class="line"><span class="operator">|</span> trx_id <span class="operator">|</span> <span class="keyword">table</span> <span class="operator">|</span> INDEX_NAME <span class="operator">|</span> LOCK_DATA <span class="operator">|</span> LOCK_MODE <span class="operator">|</span> LOCK_STATUS <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-------+------------+-----------+-----------+-------------+</span></span><br><span class="line"><span class="operator">|</span>   <span class="number">3852</span> <span class="operator">|</span> t     <span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> IX        <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-------+------------+-----------+-----------+-------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t1 <span class="keyword">FOR</span> SHARE;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----+</span></span><br><span class="line"><span class="operator">|</span> id  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">123</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"> </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> </span><br><span class="line">         ENGINE_TRANSACTION_ID <span class="keyword">as</span> trx_id,</span><br><span class="line">         OBJECT_NAME <span class="keyword">as</span> `<span class="keyword">table</span>`,</span><br><span class="line">         INDEX_NAME,</span><br><span class="line">         LOCK_DATA,</span><br><span class="line">         LOCK_MODE,</span><br><span class="line">         LOCK_STATUS </span><br><span class="line">       <span class="keyword">FROM</span> performance_schema.data_locks <span class="keyword">AND</span> LOCK_TYPE<span class="operator">=</span>&quot;TABLE&quot;;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-------+------------+------------------------+-----------+-------------+</span></span><br><span class="line"><span class="operator">|</span> trx_id <span class="operator">|</span> <span class="keyword">table</span> <span class="operator">|</span> INDEX_NAME <span class="operator">|</span> LOCK_DATA              <span class="operator">|</span> LOCK_MODE <span class="operator">|</span> LOCK_STATUS <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-------+------------+------------------------+-----------+-------------+</span></span><br><span class="line"><span class="operator">|</span>   <span class="number">3852</span> <span class="operator">|</span> t     <span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">NULL</span>                   <span class="operator">|</span> IX        <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   <span class="number">3852</span> <span class="operator">|</span> t1    <span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">NULL</span>                   <span class="operator">|</span> <span class="keyword">IS</span>        <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-------+------------+------------------------+-----------+-------------+</span></span><br><span class="line"><span class="number">4</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>关于锁定，这里希望下表没有超过你的常识（误）：</p><p><img src="https://image.mwish.me/blog-image/innodb-lock-01.png" alt="innodb-lock-01"></p><p>（AUTO_INC 也是一种表锁，两个 AUTO_INC 之间的访问是互斥的）</p><h3 id="Record-Lock-amp-Gap"><a href="#Record-Lock-amp-Gap" class="headerlink" title="Record Lock &amp; Gap"></a>Record Lock &amp; Gap</h3><p>这个部分应该是非常恶心的一部分了，因为 InnoDB 切的非常细，直接导致这块细节处理非常恶心而且 bug-prune。</p><p>官方博客举了个非常好的例子，再次允许我原封不动的贴上来：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT * FROM t;</span><br><span class="line">+----+</span><br><span class="line">| id |</span><br><span class="line">+----+</span><br><span class="line">|  <span class="number">5</span> |</span><br><span class="line">| <span class="number">10</span> |</span><br><span class="line">| <span class="number">42</span> |</span><br><span class="line">+----+</span><br><span class="line"><span class="number">3</span> rows in set (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line"># Could be conceptualized as<span class="punctuation">:</span></span><br><span class="line">--(<span class="number">5</span>)---(<span class="number">10</span>)-----(<span class="number">42</span>)---&gt; id</span><br><span class="line"></span><br><span class="line"># Our mental image should consist of points and gaps between them<span class="punctuation">:</span></span><br><span class="line"></span><br><span class="line">--(                        the gap before the row #<span class="number">5</span></span><br><span class="line"> </span><br><span class="line">   <span class="number">5</span>                       the row #<span class="number">5</span> itself</span><br><span class="line"> </span><br><span class="line">    )---(                  the gap before the row #<span class="number">10</span></span><br><span class="line"> </span><br><span class="line">         <span class="number">10</span>                the row #<span class="number">10</span> itself</span><br><span class="line"> </span><br><span class="line">           )-----(         the gap before the row #<span class="number">42</span></span><br><span class="line"> </span><br><span class="line">                  <span class="number">42</span>       the row #<span class="number">42</span> itself</span><br><span class="line"> </span><br><span class="line">                    )---&gt;  the gap before infinity</span><br></pre></td></tr></table></figure><p>GAP_LOCK，据伟大的 Graefe Goetz 所说，是一种把 Predicate Lock 转化为记录锁的好方案，InnoDB 的锁有如下类型：</p><blockquote><ul><li><strong>S,REC_NOT_GAP</strong> → shared access to the record itself</li><li><strong>X,REC_NOT_GAP</strong> → exclusive access to the record itself</li><li><strong>S,GAP</strong> → right to prevent anyone from inserting anything into the gap before the row</li><li><strong>X,GAP</strong> → same as above. Yes, “S” and “X” are short for “shared” and “exclusive”, but given that the semantic of this access right is to “prevent insert from happening” several threads can all agree to prevent the same thing without any conflict, thus currently InnoDB treats <strong>S,GAP</strong> and <strong>X,GAP</strong> (or <strong>*,GAP</strong> locks, for short) the same way: as conflicting just with <strong>*,INSERT_INTENTION</strong></li><li><strong>S</strong> → is like a combination of <strong>S,REC_NOT_GAP</strong> and <strong>S,GAP</strong> at the same time. So it is a shared access right to the row, and prevents insert before it.</li><li><strong>X</strong> → is like a combination of <strong>X,REC_NOT_GAP</strong> and <strong>X,GAP</strong> at the same time. So it is an exclusive access right to the row, and prevents insert before it.</li><li><strong>X,GAP,INSERT_INTENTION</strong> → right to insert a new row into the gap before this row. Despite “X” in its name it is actually compatible with others threads trying to insert at the same time.</li><li><strong>X,INSERT_INTENTION</strong> → conceptually same as above, but only happens for the “supremum pseudo-record” which is imaginary record “larger than any other record on the page” so that the gap “before” “it” is actually “gap after the last record”.</li></ul></blockquote><p><code>INSERT_INTENTION</code> 是个很坑爹的东西，我们先理解 GAP:</p><ol><li>锁的类型是个 flag，S 和 REC_NOT_GAP 直接按位 <code>|</code> 就行</li><li>InnoDB 的锁和叶子结构是（半）绑定的，之后我们看 Lock 分裂/继承的时候也会看到。在 InnoDB 的 Page 上，会有 Infimum record（下确界）/ supremum record（上确界）</li><li>GAP 锁定的是记录之前的 GAP</li><li>InnoDB 的实现中，资源只有一个点（物理的 record），但是有不同种类的权限，<code>GAP</code>, <code>REC_NOT_GAP</code>, 和都有</li></ol><p>这里的互斥关系如下图：</p><p><img src="https://image.mwish.me/blog-image/innodb-02.png" alt="innodb-02"></p><p>INTENTION_LOCK 是一个很恶心的事情，考虑一个事实，在 InnoDB 申请锁可能会在 Page 相关的结构上做一些标记，然后物理上插入这行记录。在插入的时候，实际上的流程如下：</p><ol><li>Latching the page</li><li>找到数据对应的位置（innodb page 对应的稀疏链表）</li><li>检查锁（但不上锁）：then latching the Lock System queue for the point to the right of insertion point and checking if there is any <strong>*,GAP</strong>, <strong>S</strong> or <strong>X</strong> lock.<ol><li>如果没有冲突的锁，直接插入这条记录，然后不上锁。依靠记录的 txn 标记来识别</li><li>有冲突的锁，就发起一条 <code>INSERT_INTENTION</code> 提交到锁队列中</li></ol></li><li>如果是有锁的情况（包括自己的锁）这里会需要做一些锁继承相关的操作。具体的继承细节在后面讲，这里简单说就是比如原先是自己的 S 锁，然后插入之后，区间从一个 gap 被拆成新的一条记录 + 一个新的 gap。这个地方要注意锁保留权限</li></ol><p>举官方博客的例子：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"> </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> t <span class="keyword">FOR</span> SHARE;</span><br><span class="line"><span class="operator">+</span><span class="comment">----+</span></span><br><span class="line"><span class="operator">|</span> id <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+</span></span><br><span class="line"><span class="operator">|</span>  <span class="number">5</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">42</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"> </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">DELETE</span> <span class="keyword">FROM</span> t <span class="keyword">WHERE</span> id<span class="operator">=</span><span class="number">10</span>;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"> </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">INSERT</span> <span class="keyword">INTO</span> t <span class="keyword">VALUES</span> (<span class="number">4</span>);</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"> </span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SELECT</span> INDEX_NAME,LOCK_TYPE,LOCK_DATA,LOCK_MODE</span><br><span class="line">       <span class="keyword">FROM</span> performance_schema.data_locks <span class="keyword">WHERE</span> OBJECT_NAME<span class="operator">=</span><span class="string">&#x27;t&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-----------+------------------------+---------------+</span></span><br><span class="line"><span class="operator">|</span> INDEX_NAME <span class="operator">|</span> LOCK_TYPE <span class="operator">|</span> LOCK_DATA              <span class="operator">|</span> LOCK_MODE     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-----------+------------------------+---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">TABLE</span>     <span class="operator">|</span> <span class="keyword">NULL</span>                   <span class="operator">|</span> <span class="keyword">IS</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">PRIMARY</span>    <span class="operator">|</span> RECORD    <span class="operator">|</span> supremum pseudo<span class="operator">-</span>record <span class="operator">|</span> S             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">PRIMARY</span>    <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">5</span>                      <span class="operator">|</span> S             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">PRIMARY</span>    <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">10</span>                     <span class="operator">|</span> S             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">PRIMARY</span>    <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">42</span>                     <span class="operator">|</span> S             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">TABLE</span>     <span class="operator">|</span> <span class="keyword">NULL</span>                   <span class="operator">|</span> IX            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">PRIMARY</span>    <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">10</span>                     <span class="operator">|</span> X,REC_NOT_GAP <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">PRIMARY</span>    <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">4</span>                      <span class="operator">|</span> S,GAP         <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-----------+------------------------+---------------+</span></span><br><span class="line"><span class="number">8</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><ol><li>SELECT 的时候，全部带上 S 锁. 这个地方注意 supremum 的锁。这里也申请了一个 IS 的表锁</li><li>DELETE 的时候，生成一条 X 的删除锁</li><li>INSERT 的时候，没有生成锁，因为没有冲突</li></ol><h3 id="Lock-Compression"><a href="#Lock-Compression" class="headerlink" title="Lock Compression"></a>Lock Compression</h3><p><code>performance_schema.data_locks</code> 并不是一张具体的表，而是从 <code>&lt;space id, page no, heap no&gt;</code> 恢复出来的。锁只是一个内存结构。</p><p>InnoDB 在内存中会有一个压缩位图，Hedengcheng Slide 有一张很好的图：</p><p><img src="https://image.mwish.me/blog-image/1cfad4ec-a6fa-47e8-aab8-f5e8581f8ad3.png" alt="1cfad4ec-a6fa-47e8-aab8-f5e8581f8ad3"></p><p>这里我们注意到几个事实：</p><ol><li>依赖 <code>heap_no</code> 来维护 bitmap 的大小和对应的顺序</li><li>可能第一次上锁的时候会申请一个比较大的 bitmap，后面上锁开开销就会减小。</li></ol><h3 id="Implicit-Lock"><a href="#Implicit-Lock" class="headerlink" title="Implicit Lock"></a>Implicit Lock</h3><p>这坨东西和 implicit lock 有什么关系呢？有，implicit lock 就是在这种王八蛋时间突然冒出来的。还记得我们的插入的时候，其实一开始没有 INSERT_INTENTION 锁吗，我举个让这个锁飘出来的例子：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(client1) mysql<span class="operator">&gt;</span> <span class="keyword">INSERT</span> <span class="keyword">INTO</span> t <span class="keyword">VALUES</span> (<span class="number">4</span>);</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">(client2) mysql<span class="operator">&gt;</span> <span class="keyword">INSERT</span> <span class="keyword">INTO</span> t <span class="keyword">VALUES</span> (<span class="number">4</span>);</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>这个地方可能本来的优化中， client1 插入后是没有一把锁，在 Delete 之后锁就出现了. 这种<strong>因为优化导致暂时不出现，但是你发现问题的时候要查它找冲突的锁</strong>叫做 implicit lock。后面在 Secondary Index 一节，会有比较多内容介绍这个。</p><h3 id="Lock-Spliting"><a href="#Lock-Spliting" class="headerlink" title="Lock Spliting"></a>Lock Spliting</h3><p>在申请锁的时候，我们常见的有锁的升级（Upgrade），同时，在 InnoDB 的结构下，也会有从 A 类型的锁切到 B 类型锁的 Pattern。</p><p>考虑到几种 Pattern:</p><ol><li>读锁升级到写锁</li><li>从 S|REC_NOT_GAP 升级到 S</li></ol><p>对于 (2) InnoDB 在申请资源的时候，会按照集合做减法，尝试只 acquire <code>S - S|REC_NOT_GAP = S|GAP</code> 的锁</p><h3 id="Btree-分裂和锁继承"><a href="#Btree-分裂和锁继承" class="headerlink" title="Btree 分裂和锁继承"></a>Btree 分裂和锁继承</h3><p>这部分知识在这篇文章中很详细：<a href="http://mysql.taobao.org/monthly/2016/06/01/">http://mysql.taobao.org/monthly/2016/06/01/</a></p><p>为什么合并不需要呢？答案是 next-key locking 是真的会找到下一个 key, 但是这个 Page 内部也需要表示 「Page 内最大已经被锁定」。</p><p>这里在 Page 分裂的时候，也要处理对应的 GAP 和 Locking。</p><h3 id="Secondary-Index-amp-Implicit-Lock"><a href="#Secondary-Index-amp-Implicit-Lock" class="headerlink" title="Secondary Index &amp; Implicit Lock"></a>Secondary Index &amp; Implicit Lock</h3><p>Secondary Index 和 Lock 结合起来…非常复杂。首先要知道：</p><ol><li>Secondary Index Page 上也是有锁定的</li><li>MVCC 中，Secondary Index 会保有最新的数据，这里可能会影响 ICP</li></ol><p>这里官方博客举了个非常好的例子：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> point2D(</span><br><span class="line">  x <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">PRIMARY</span> KEY,</span><br><span class="line">  y <span class="type">INT</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span> <span class="keyword">UNIQUE</span> </span><br><span class="line">);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> point2D (x,y) <span class="keyword">VALUES</span></span><br><span class="line">  (<span class="number">0</span>,<span class="number">3</span>),      </span><br><span class="line">        (<span class="number">1</span>,<span class="number">2</span>), </span><br><span class="line">                    (<span class="number">3</span>,<span class="number">1</span>),</span><br><span class="line">             (<span class="number">2</span>,<span class="number">0</span>);</span><br></pre></td></tr></table></figure><p>然后查询：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">con1<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">con1<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> point2D <span class="keyword">WHERE</span> y<span class="operator">=</span><span class="number">2</span> <span class="keyword">FOR</span> SHARE;</span><br><span class="line">con1<span class="operator">&gt;</span> <span class="keyword">SELECT</span> INDEX_NAME,LOCK_TYPE,LOCK_DATA,LOCK_MODE </span><br><span class="line">      <span class="keyword">FROM</span> performance_schema.data_locks <span class="keyword">WHERE</span> OBJECT_NAME<span class="operator">=</span><span class="string">&#x27;point2D&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-----------+-----------+---------------+</span></span><br><span class="line"><span class="operator">|</span> INDEX_NAME <span class="operator">|</span> LOCK_TYPE <span class="operator">|</span> LOCK_DATA <span class="operator">|</span> LOCK_MODE     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-----------+-----------+---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">TABLE</span>     <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="keyword">IS</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> y          <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">2</span>, <span class="number">1</span>      <span class="operator">|</span> S,REC_NOT_GAP <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-----------+-----------+---------------+</span></span><br></pre></td></tr></table></figure><p>这个锁 <strong>非常符合预期。</strong>回滚这个事务，删除 x :</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">con1<span class="operator">&gt;</span> <span class="keyword">COMMIT</span>;</span><br><span class="line">con1<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">con1<span class="operator">&gt;</span> <span class="keyword">DELETE</span> <span class="keyword">FROM</span> point2D <span class="keyword">WHERE</span> x<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line">con1<span class="operator">&gt;</span> <span class="keyword">SELECT</span> INDEX_NAME,LOCK_TYPE,LOCK_DATA,LOCK_MODE <span class="keyword">FROM</span> performance_schema.data_locks <span class="keyword">WHERE</span> OBJECT_NAME<span class="operator">=</span><span class="string">&#x27;point2D&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-----------+-----------+---------------+</span></span><br><span class="line"><span class="operator">|</span> INDEX_NAME <span class="operator">|</span> LOCK_TYPE <span class="operator">|</span> LOCK_DATA <span class="operator">|</span> LOCK_MODE     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-----------+-----------+---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">TABLE</span>     <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> IX            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">PRIMARY</span>    <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">1</span>         <span class="operator">|</span> X,REC_NOT_GAP <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-----------+-----------+---------------+</span></span><br></pre></td></tr></table></figure><p>这个地方表面上也符合预期，但是回顾一下，对应的 x/y 呢？</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">con2<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">con2<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> point2D <span class="keyword">WHERE</span> y<span class="operator">=</span><span class="number">2</span> <span class="keyword">FOR</span> SHARE;</span><br></pre></td></tr></table></figure><p>这里 con2 就 hang 住了，再去 con1:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">con1<span class="operator">&gt;</span> <span class="keyword">SELECT</span> ENGINE_TRANSACTION_ID trx_id,INDEX_NAME,LOCK_TYPE,LOCK_DATA,LOCK_MODE,LOCK_STATUS </span><br><span class="line">      <span class="keyword">FROM</span> performance_schema.data_locks <span class="keyword">WHERE</span> OBJECT_NAME<span class="operator">=</span><span class="string">&#x27;point2D&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+------------+-----------+-----------+---------------+-------------+</span></span><br><span class="line"><span class="operator">|</span>          trx_id <span class="operator">|</span> INDEX_NAME <span class="operator">|</span> LOCK_TYPE <span class="operator">|</span> LOCK_DATA <span class="operator">|</span> LOCK_MODE     <span class="operator">|</span> LOCK_STATUS <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+------------+-----------+-----------+---------------+-------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">283410363307272</span> <span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">TABLE</span>     <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="keyword">IS</span>            <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">283410363307272</span> <span class="operator">|</span> y          <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">2</span>, <span class="number">1</span>      <span class="operator">|</span> S             <span class="operator">|</span> WAITING     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="number">1560</span> <span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">TABLE</span>     <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> IX            <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="number">1560</span> <span class="operator">|</span> <span class="keyword">PRIMARY</span>    <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">1</span>         <span class="operator">|</span> X,REC_NOT_GAP <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="number">1560</span> <span class="operator">|</span> y          <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">2</span>, <span class="number">1</span>      <span class="operator">|</span> X,REC_NOT_GAP <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+------------+-----------+-----------+---------------+-------------+</span></span><br></pre></td></tr></table></figure><p>多出来了 implicit lock，邪恶吧！这里逻辑流程如下：</p><ol><li>InnoDB 删除会推高 Page 的最大 trx id</li><li>Secondary Index 查找的时候有一个 read_view，发现 Page 上修改的 trx 大（ <code>page_get_max_trx_id(page)</code>），就要走逻辑去查这个 trx 是不是还持有锁：<a href="https://github.com/mysql/mysql-server/blob/a2f0879/storage/innobase/row/row0vers.cc#L536">row_vers_impl_x_locked</a></li><li>查看是否冲突，上 implicit lock</li></ol><p>这段逻辑是很清晰的，现在让我们调个个，看看如果 先读 Secondary Index，再删：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">con2<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">con2<span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">FROM</span> point2D <span class="keyword">WHERE</span> y<span class="operator">=</span><span class="number">2</span> <span class="keyword">FOR</span> SHARE;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------+</span></span><br><span class="line"><span class="operator">|</span> <span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+</span></span><br><span class="line"><span class="operator">|</span>        <span class="number">1</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+</span></span><br><span class="line"></span><br><span class="line">con1<span class="operator">&gt;</span> <span class="keyword">BEGIN</span>;</span><br><span class="line">con1<span class="operator">&gt;</span> <span class="keyword">DELETE</span> <span class="keyword">FROM</span> point2D <span class="keyword">WHERE</span> x<span class="operator">=</span><span class="number">1</span>;</span><br><span class="line">⌛</span><br></pre></td></tr></table></figure><p>con1 hang 死了，这个时候 con2 查锁：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&gt;</span> <span class="keyword">SELECT</span> ENGINE_TRANSACTION_ID trx_id,INDEX_NAME,LOCK_TYPE,LOCK_DATA,LOCK_MODE,LOCK_STATUS </span><br><span class="line">  <span class="keyword">FROM</span> performance_schema.data_locks <span class="keyword">WHERE</span> OBJECT_NAME<span class="operator">=</span><span class="string">&#x27;point2D&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+------------+-----------+-----------+---------------+-------------+</span></span><br><span class="line"><span class="operator">|</span> trx_id          <span class="operator">|</span> INDEX_NAME <span class="operator">|</span> LOCK_TYPE <span class="operator">|</span> LOCK_DATA <span class="operator">|</span> LOCK_MODE     <span class="operator">|</span> LOCK_STATUS <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+------------+-----------+-----------+---------------+-------------+</span></span><br><span class="line"><span class="operator">|</span>            <span class="number">2077</span> <span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">TABLE</span>     <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> IX            <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="number">2077</span> <span class="operator">|</span> <span class="keyword">PRIMARY</span>    <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">1</span>         <span class="operator">|</span> X,REC_NOT_GAP <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="number">2077</span> <span class="operator">|</span> y          <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">2</span>, <span class="number">1</span>      <span class="operator">|</span> X,REC_NOT_GAP <span class="operator">|</span> WAITING     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">283410363307272</span> <span class="operator">|</span> <span class="keyword">NULL</span>       <span class="operator">|</span> <span class="keyword">TABLE</span>     <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="keyword">IS</span>            <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">283410363307272</span> <span class="operator">|</span> y          <span class="operator">|</span> RECORD    <span class="operator">|</span> <span class="number">2</span>, <span class="number">1</span>      <span class="operator">|</span> S,REC_NOT_GAP <span class="operator">|</span> GRANTED     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+------------+-----------+-----------+---------------+-------------+</span></span><br></pre></td></tr></table></figure><p>这个地方，我们之前 Delete x 没有在 y 加锁，怎么会是呢？答案是这里会尝试在 y 上加锁，没有的话就 implicit lock 那种模式了 （ <code>lock_sec_rec_modify_check_and_lock</code> ）</p><h3 id="关于-MVCC-read-view-和锁"><a href="#关于-MVCC-read-view-和锁" class="headerlink" title="关于 MVCC, read_view 和锁"></a>关于 MVCC, read_view 和锁</h3><p>实际上，之前演示的部分都上锁了。read_view 读取其实看隔离级别不一定会一直持有锁。</p><p>比如 InnoDB 的 semi-consistent read （ <a href="http://mysql.taobao.org/monthly/2018/11/04/">http://mysql.taobao.org/monthly/2018/11/04/</a> ) 。会尝试第一次不上锁，直接读 Undo Chain。</p><h3 id="插入和已经存在的记录"><a href="#插入和已经存在的记录" class="headerlink" title="插入和已经存在的记录"></a>插入和已经存在的记录</h3><p>如果发现已经存在的记录：</p><blockquote><p>通常INSERT操作是不加锁的，但如果在插入或更新记录时，检查到 duplicate key（或者有一个被标记删除的duplicate key），对于普通的INSERT/UPDATE，会加LOCK_S锁，而对于类似REPLACE INTO或者INSERT … ON DUPLICATE这样的SQL加的是X锁。而针对不同的索引类型也有所不同：</p><ul><li>对于聚集索引（参阅函数<code>row_ins_duplicate_error_in_clust</code>），隔离级别小于等于RC时，加的是<code>LOCK_REC_NOT_GAP</code>类似的S或者X记录锁。否则加<code>LOCK_ORDINARY</code>类型的记录锁（NEXT-KEY LOCK）；</li><li>对于二级唯一索引，若检查到重复键，当前版本总是加 LOCK_ORDINARY 类型的记录锁(函数 <code>row_ins_scan_sec_index_for_duplicate</code>)。实际上按照RC的设计理念，不应该加GAP锁（<a href="http://bugs.mysql.com/bug.php?id=68021">bug#68021</a>），官方也事实上尝试修复过一次，即对于RC隔离级别加上<code>LOCK_REC_NOT_GAP</code>，但却引入了另外一个问题，导致二级索引的唯一约束失效(<a href="http://bugs.mysql.com/bug.php?id=73170">bug#73170</a>)，感兴趣的可以参阅我写的<a href="http://mysqllover.com/?p=1041">这篇博客</a>，由于这个严重bug，官方很快又把这个fix给revert掉了。</li></ul></blockquote><p>摘自：<a href="http://mysql.taobao.org/monthly/2016/01/01/">http://mysql.taobao.org/monthly/2016/01/01/</a> . 你或许会发现，这里上的是<strong>数据锁</strong>，而不是意向锁。这里原因代码说的比较清晰。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">lock_type = ((trx-&gt;isolation_level &lt;= TRX_ISO_READ_COMMITTED) ||</span><br><span class="line">             (cursor-&gt;index-&gt;table-&gt;<span class="built_in">skip_gap_locks</span>()))</span><br><span class="line">                ? LOCK_REC_NOT_GAP</span><br><span class="line">                : LOCK_ORDINARY;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* We set a lock on the possible duplicate: this</span></span><br><span class="line"><span class="comment">is needed in logical logging of MySQL to make</span></span><br><span class="line"><span class="comment">sure that in roll-forward we get the same duplicate</span></span><br><span class="line"><span class="comment">errors as in original execution */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (flags &amp; BTR_NO_LOCKING_FLAG) &#123;</span><br><span class="line">  <span class="comment">/* Do nothing if no-locking is set */</span></span><br><span class="line">  err = DB_SUCCESS;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (trx-&gt;duplicates) &#123;</span><br><span class="line">  <span class="comment">/* If the SQL-query will update or replace</span></span><br><span class="line"><span class="comment">  duplicate key we will take X-lock for</span></span><br><span class="line"><span class="comment">  duplicates ( REPLACE, LOAD DATAFILE REPLACE,</span></span><br><span class="line"><span class="comment">  INSERT ON DUPLICATE KEY UPDATE). */</span></span><br><span class="line"></span><br><span class="line">  err =</span><br><span class="line">      <span class="built_in">row_ins_set_exclusive_rec_lock</span>(lock_type, <span class="built_in">btr_cur_get_block</span>(cursor),</span><br><span class="line">                                     rec, cursor-&gt;index, offsets, thr);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  err = <span class="built_in">row_ins_set_shared_rec_lock</span>(lock_type, <span class="built_in">btr_cur_get_block</span>(cursor),</span><br><span class="line">                                    rec, cursor-&gt;index, offsets, thr);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>感觉和谓词锁有关，属于读写联合机制。</p><h2 id="Not-in-this-article"><a href="#Not-in-this-article" class="headerlink" title="Not in this article"></a>Not in this article</h2><p>下篇文章这里需要介绍 InnoDB 的 8.0.18 新的死锁检测算法、调度，还有 8.0.21 的并发队列和锁拆分.</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://dev.mysql.com/doc/refman/8.0/en/internal-locking.html">https://dev.mysql.com/doc/refman/8.0/en/internal-locking.html</a></li><li><a href="https://dev.mysql.com/blog-archive/innodb-data-locking-part-2-locks/">https://dev.mysql.com/blog-archive/innodb-data-locking-part-2-locks/</a> 这一系列的文章</li><li>InnoDB 事务锁源码分析 - 宋昭的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/412358771">https://zhuanlan.zhihu.com/p/412358771</a></li><li>MySQL 引擎特性-死锁检测 <a href="http://mysql.taobao.org/monthly/2021/05/02/">http://mysql.taobao.org/monthly/2021/05/02/</a></li><li>MySQL · 引擎特性 · InnoDB 事务锁系统简介 <a href="http://mysql.taobao.org/monthly/2016/01/01/">http://mysql.taobao.org/monthly/2016/01/01/</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Apache Iceberg and changes above Hive</title>
      <link href="/2023/03/19/Apache-Iceberg-and-changes-above-Hive/"/>
      <url>/2023/03/19/Apache-Iceberg-and-changes-above-Hive/</url>
      
        <content type="html"><![CDATA[<p>当我们说一个东西是屎山的时候，它最好真的不是…「大数据」这个词在很长一段时间事实标准就是 Apache Hadoop 下那堆东西，因为历史原因，很多东西实际上在 Hive / Spark 之类的东西上有一套实现和名词，这套名词本身可能比较草台班子：比如 Bucket / Partition 这些东西，在各个系统有不同的叫法，有的东西可能直接和别的系统对应…</p><p>你一定想问这些东西和 iceberg 有什么关系了，答案是息息相关。Iceberg 本身就是一帮人受不了 Hive 折磨搞出来的，在文档里三步一提 Hive，关系比亲爹还亲，然后 Iceberg 又只是一个 table format。这导致了几个后果：</p><ol><li>在介绍 Iceberg 的时候，会不断介绍 Hive 之前的设计为什么导致了 Iceberg 会这么做…这导致其实你得对 Hive 有个基本的认知。妈的，我为啥要对这种老草台系统有认知…</li><li>Iceberg 只是一个 Table format，它有的时候甚至会跑在 HMS 上。同时，Iceberg 很多时候只说明了「需要这么做」，实现行为还是要自己决定的，所以很多时候实现行为是各家一坨屎，e.g:<ol><li>Spark Partition: <a href="https://iceberg.apache.org/docs/latest/spark-writes/">https://iceberg.apache.org/docs/latest/spark-writes/</a></li><li>Hive Partition: <a href="https://iceberg.apache.org/docs/latest/hive/">https://iceberg.apache.org/docs/latest/hive/</a></li></ol></li></ol><p>我们这里会介绍一下 Hive 和 iceberg format，这个文档会持续更新，因为笔者可能认知也是会更新的。然后也会简单介绍一下 Snowflake、StarRocks 的行为是怎么兼容 iceberg 的。</p><h2 id="所谓数据湖"><a href="#所谓数据湖" class="headerlink" title="所谓数据湖"></a>所谓数据湖</h2><p>众所周知，Hive 本身的设计中，存储 Partition 以目录的形式，而存储 Bucket 以目录下文件的形式存放。这样 Partition 裁剪，Bucket Join 之类的操作本身是很正常的，但是在 Hive 查询的时候，对超大表会有一些很奇怪的问题。比如 Meta 信息拿到分区之后 List 过慢、对 Underlying NameNode 的依赖等。很自然的，这套东西还可以移动到 S3 之类的存储上，但是 S3 之类的存储也有问题。</p><p>Apache Iceberg 名义上定位其实很低，它定位为对 OSS 之类的存储比较友好的 Table Format，它表层面的 RFC 变动相当克制，带来了一些格式兼容性。继承了一些 Hive 比较好的地方，比如哪个傻大个都可以往里写，同时在 Partition / Bucket / Schema 等方向上做出了演进或者限制，带来了比较细致的演进方式。</p><p>Iceberg 经常和「数据湖」这个词一起被提起，而不是我们之前说的 Table Format。这个词更多是个宣传用词，按我之前的理解（ <a href="https://blog.mwish.me/2022/05/01/Delta-Lake-Lakehouse/">https://blog.mwish.me/2022/05/01/Delta-Lake-Lakehouse/</a> ），Data Lake 意味着：</p><ol><li>ACID 的能力，防止 Job 跑到一半挂了又没法处理</li><li>柔性的 Schema</li><li>Streaming 等接口</li><li>SQL 相关的 Pruning，Min-Max</li><li>对应的 Format Compaction / Auto-Clustering，包括 z-ordering</li></ol><p>过了一年多，回顾这个结论，确实是我当时结论问题没那么大，但是这些是核心语义吗？其实回头来想，Apache Iceberg 不是一个很 Fancy 的东西，但却是一个很可怕的东西，新的数据湖产品，像 Snowflake，StarRocks， Doris 这些产品，都开始兼容了 Apache Iceberg 协议。然后 DeltaLake 感觉在路子上是更加靠前的产品，但是在 Apache Iceberg 的「攻势」下也开始部分开源了（笑）。</p><p>所以回过头来，也结合网易那几篇文章的理解：</p><ul><li>从 Hive 这条路线的演进，看 Apache Iceberg 是一个 Table Format，它把表结构（表，Bucket，分区）抽离了物理的 Layout，从目录的部分依赖走到了自己拆分出一层逻辑的 Manifest 层。同时，也做了一些对原子 ACID 之类的支持（和部分反对者说的不完全一样，Hive 也支持 ACID，不过折腾的很别扭，而这在 Apache Iceberg 中师一等公民）</li><li>Delta 也类似，拆分出一套日志层（甚至依赖 DynamoDB）来做提交</li></ul><p>但是，从外部用户的视角来理解：</p><ul><li>引擎平权，Apache Iceberg 是一套标准，用户可以尽量不 Lock-In 在某个系统中（而引擎当然巴不得你 Lock-In），包括猫猫狗狗都可以来根据这个 Format 去读 / 写对应的结构，写入的数据也可以是具体实现无关（Parquet，Avro，…）相当于自身的结构是开放的。</li><li>写入数据和 Schema 很方便，包括很多情况下，导入数据 - 加列 之后，数据符合某种标准。同时，数据只要符合某种 Schema 即可（Apache Iceberg 允许 Avro，Parquet，Orc 等多种数据）</li><li>ACID，这里并不同于 TP 数据库的快速小事务，这里更多是要求 abortable / 隔离性 这样的需求。我在之前其实是列了 Streaming 需求的，但是其实这个就类似 AP 测向 TP 测靠拢，属于大家却是不清楚这个做了是不是真的有收益的环节了。</li><li>CDC？其实我并不知道是不是用户真的需要 CDC 之类的需求，但是某种意义上（去掉 Compaction）很多场景做 CDC 确实是非常自然的场景了。</li></ul><p>（Optimize 和 Compaction 感觉很必要，但是暂时不在列）</p><p>这个时候你就会发现，有的东西确实是 Hive 有的，但是它指向了一个更混沌开放的领域。和我之前理解不完全一样的是，这里确实要有一些 Schema 限制，但并不是整体 Enforce 某个 Schema，而是一些读时模式 + 列变换的限制。</p><p>今天就简单介绍一下 Apache Iceberg 的 Spec</p><h2 id="Hive-的缺陷"><a href="#Hive-的缺陷" class="headerlink" title="Hive 的缺陷"></a>Hive 的缺陷</h2><p>Hive 可能现在不怎么用了，但是 Hive 的表结构还是数据的事实标准。在这个世界还青春的时候，Spark 的 Core 本身作为一套计算的逻辑维护 RDD。之后感觉很多引擎推进的都是计算上的方式，而存储的方式很多还是在 Hive 上或者自己去搞 Share nothing。Hive 在很长一段时间至少在表结构上还是 de-facto 的主导者。Hive Table Format 如下：</p><p><img src="https://image.mwish.me/blog-image/iceberg-01.png" alt="iceberg-01"></p><p>然而，这里列出来一些缺点：</p><ul><li>Hive ACID 通过 fs rename 来实现。在 POSIX 上，rename 可以是原子的。然而 S3: ?</li><li>没有 WAL 之类的方式，无法原子性写多个 Partition</li><li>无法对多个写同一个 Partition 的 Txn 作出什么限制</li><li>需要依赖 <code>List</code>，可能会开销很长的时间 （分区多或者分区的文件多都会加重这个问题，而且 S3 的 List 本身就很昂贵，见 <a href="https://www.youtube.com/watch?t=138&amp;v=nWwQMlrjhy0&amp;feature=youtu.be">https://www.youtube.com/watch?t=138&amp;v=nWwQMlrjhy0&amp;feature=youtu.be</a> ）</li><li>用户需要手动写分区，因为在 Hive 中，<strong>分区列并不是表数据的一部分</strong>，要手动写对应的分区信息</li><li>Hive 的 Table Statistics 常常并不准确（显然数据库都不那么准确？）</li><li>在 OSS 中，Hive 的路径 <code>/path/to/table/partition_column=partition_value</code> 限制了物理路径的打散能力，导致可能落在几个固定的节点上，造成一定的性能问题。（本质上还是对物理路径的依赖？）</li></ul><p><img src="https://image.mwish.me/blog-image/iceberg-02.png" alt="iceberg-02"></p><h2 id="Iceberg"><a href="#Iceberg" class="headerlink" title="Iceberg"></a>Iceberg</h2><p>Netflix 搞了一套新的 Table Format: Iceberg，主导者 Ryan Blue 随后也创建了公司。</p><p>Netflix 的思路是，发现 Table format 和 fs 目录的物理结构是完全绑定的，它们的简单设计是：</p><ul><li>抽离这个<strong>物理</strong> Directory 的层次，造了一个逻辑的 Directory</li><li>Track 文件和文件的变更</li><li>用这套 Track 机制做了一套文件层面的 MVCC</li><li>把 Partition 机制融合进数据中</li></ul><p><img src="https://image.mwish.me/blog-image/iceberg-03.png" alt="iceberg-03"></p><p>Iceberg 抽象了一套多层的架构：</p><p><img src="https://image.mwish.me/blog-image/iceberg-04.png" alt="iceberg-04"></p><p>显然，中间层是 iceberg 的核心，但我们最后介绍：</p><ol><li>Data layer: 用户写 data 就写 data，没有挂在 list 上 commit，就不是表的一部分</li><li>Iceberg Catalog: iceberg 整个结构的 root 指针，它可以是 HDFS / HMS 等，需要支持原子的变更</li></ol><p>那下面比较重要的就是中间的结构了。</p><h2 id="Iceberg-Metadata-Layer"><a href="#Iceberg-Metadata-Layer" class="headerlink" title="Iceberg Metadata Layer"></a>Iceberg Metadata Layer</h2><p>首先还是需要注意，在数据库领域，我们经常提到 record, wal, page 之类的概念，而在大数据领域，某种意义上，<strong>数据的一等公民是文件</strong>。</p><h3 id="Table-Metadata-and-Snapshot"><a href="#Table-Metadata-and-Snapshot" class="headerlink" title="Table Metadata and Snapshot"></a>Table Metadata and Snapshot</h3><p>Table Metadata / Metadata File: 是一个 JSON，表达表的信息，包含表的 schema，Partition specs，格式的版本. ( The table metadata file tracks the table schema, partitioning config, custom properties, and <strong>snapshot</strong>s of the table contents. A snapshot represents the state of a table at some time and is used to access the complete set of data files in the table. )</p><ul><li>Snapshot 可以视作一次写产生的 snapshot，snapshot 被内包含在 Metadata File 中。系统一定有一个当前的 Snapshot (对于刚创建的表，这个 snapshot 里面一个文件都没有）。Snapshot 也可以包含创建者的 Summary</li></ul><p>举个博客中的例子：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="comment">// 在 iceberg 中的版本是 v1</span></span><br><span class="line">    <span class="attr">&quot;format-version&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// 对应的 table 生成的 uuid</span></span><br><span class="line">    <span class="attr">&quot;table-uuid&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;4b96b6e8-9838-48df-a111-ec1ff6422816&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// Table 的位置. 你可能要问了, 这个鬼玩意和 Hive 那样目录有啥区别,</span></span><br><span class="line">    <span class="comment">// 答案是数据不在目录下</span></span><br><span class="line">    <span class="attr">&quot;location&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;/home/hadoop/warehouse/db2/part_table2&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// table 最后更新的 unix epoch</span></span><br><span class="line">    <span class="comment">// (其实这里还应该有一个最新的 sequence-id)</span></span><br><span class="line">    <span class="attr">&quot;last-updated-ms&quot;</span> <span class="punctuation">:</span> <span class="number">1611694436618</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// 已经分配的最高的 column-id</span></span><br><span class="line">    <span class="attr">&quot;last-column-id&quot;</span> <span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// table 的 schema, 注意这里 id 的分配</span></span><br><span class="line">    <span class="comment">// 这个东西已经 deprecated 了, 新一点的是 schemas,</span></span><br><span class="line">    <span class="comment">// 就是包括历史有的 schema.</span></span><br><span class="line">    <span class="attr">&quot;schema&quot;</span> <span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;struct&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;fields&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;id&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;id&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;required&quot;</span> <span class="punctuation">:</span> <span class="keyword">true</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;int&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;id&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;ts&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;required&quot;</span> <span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;timestamptz&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;id&quot;</span> <span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;message&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;required&quot;</span> <span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;string&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span> <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// Partition 相关的信息.</span></span><br><span class="line">    <span class="comment">// 你可能注意到了 spec 和 specs</span></span><br><span class="line">    <span class="comment">// spec 也已经 deprecated 了, 令人唏嘘</span></span><br><span class="line">    <span class="attr">&quot;partition-spec&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;ts_hour&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;transform&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;hour&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;source-id&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;field-id&quot;</span> <span class="punctuation">:</span> <span class="number">1000</span></span><br><span class="line">    <span class="punctuation">&#125;</span> <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;default-spec-id&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;partition-specs&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;spec-id&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;fields&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;ts_hour&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;transform&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;hour&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;source-id&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;field-id&quot;</span> <span class="punctuation">:</span> <span class="number">1000</span></span><br><span class="line">        <span class="punctuation">&#125;</span> <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span> <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// 排序的 key</span></span><br><span class="line">    <span class="comment">// 其实 Sort 也比这个定义复杂, 还包括对应的</span></span><br><span class="line">    <span class="comment">// SortOrder, null first 之类的.</span></span><br><span class="line">    <span class="attr">&quot;default-sort-order-id&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;sort-orders&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;order-id&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;fields&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span> <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// table 的属性, 可以用来控制 table 的读写</span></span><br><span class="line">    <span class="attr">&quot;properties&quot;</span> <span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;owner&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;hadoop&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// 指向 latest 的 snapshot id.</span></span><br><span class="line">    <span class="attr">&quot;current-snapshot-id&quot;</span> <span class="punctuation">:</span> <span class="number">1257424822184505371</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;snapshots&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="comment">// snapshot</span></span><br><span class="line">        <span class="attr">&quot;snapshot-id&quot;</span> <span class="punctuation">:</span> <span class="number">8271497753230544300</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;timestamp-ms&quot;</span> <span class="punctuation">:</span> <span class="number">1611694406483</span><span class="punctuation">,</span></span><br><span class="line">        <span class="comment">// 关于写入的一些信息</span></span><br><span class="line">        <span class="attr">&quot;summary&quot;</span> <span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;operation&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;append&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;spark.app.id&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;application_1611687743277_0002&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;added-data-files&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;added-records&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;added-files-size&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;960&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;changed-partition-count&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;total-records&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;total-data-files&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;total-delete-files&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;0&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;total-position-deletes&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;0&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;total-equality-deletes&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;0&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="comment">// 一个 snapshot 会有一个对应的 manifest list</span></span><br><span class="line">        <span class="attr">&quot;manifest-list&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;/home/hadoop/warehouse/db2/part_table2/metadata/snap-8271497753230544300-1-d8a778f9-ad19-4e9c-88ff-28f49ec939fa.avro&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;snapshot-id&quot;</span> <span class="punctuation">:</span> <span class="number">1257424822184505371</span><span class="punctuation">,</span></span><br><span class="line">        <span class="comment">// 有的 snapshot 会有对应的 parent snapshot.</span></span><br><span class="line">        <span class="attr">&quot;parent-snapshot-id&quot;</span> <span class="punctuation">:</span> <span class="number">8271497753230544300</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;timestamp-ms&quot;</span> <span class="punctuation">:</span> <span class="number">1611694436618</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;summary&quot;</span> <span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;operation&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;append&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;spark.app.id&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;application_1611687743277_0002&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;added-data-files&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;added-records&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;added-files-size&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;973&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;changed-partition-count&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;total-records&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;2&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;total-data-files&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;2&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;total-delete-files&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;0&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;total-position-deletes&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;0&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;total-equality-deletes&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;0&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;manifest-list&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;/home/hadoop/warehouse/db2/part_table2/metadata/snap-1257424822184505371-1-eab8490b-8d16-4eb1-ba9e-0dede788ff08.avro&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span> <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// snapshot 时间对应上物理时间</span></span><br><span class="line">    <span class="attr">&quot;snapshot-log&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;timestamp-ms&quot;</span> <span class="punctuation">:</span> <span class="number">1611694406483</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;snapshot-id&quot;</span> <span class="punctuation">:</span> <span class="number">8271497753230544300</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;timestamp-ms&quot;</span> <span class="punctuation">:</span> <span class="number">1611694436618</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;snapshot-id&quot;</span> <span class="punctuation">:</span> <span class="number">1257424822184505371</span></span><br><span class="line">    <span class="punctuation">&#125;</span> <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// 可选的 metadata 列表</span></span><br><span class="line">    <span class="attr">&quot;metadata-log&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;timestamp-ms&quot;</span> <span class="punctuation">:</span> <span class="number">1611694097253</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;metadata-file&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;/home/hadoop/warehouse/db2/part_table2/metadata/v1.metadata.json&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;timestamp-ms&quot;</span> <span class="punctuation">:</span> <span class="number">1611694406483</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;metadata-file&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;/home/hadoop/warehouse/db2/part_table2/metadata/v2.metadata.json&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span> <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>(说是版本 1，其实版本2 包含了一些 delete 之类的信息）</p><p>(其实我很好奇这个时间，如果遇到了分布式时钟回退怎么办)</p><p>这里表级别包含了文件的 Partition，Schema，Snapshots，和 snapshot 的 History。这里还有一些物理时间变更的信息。没有写清楚的是，这里还可以存储 table statistics 和 snapshot refs。table statistics 定义见：<a href="https://iceberg.apache.org/spec/#table-statistics">https://iceberg.apache.org/spec/#table-statistics</a></p><p>这部分内容可以被存储在 Metastore 或者 HDFS 之类的东西上，靠 Atomic Swap 来解决。</p><p>这个 Summary 也比较有意思，能代表 snapshot 的来源，举个好玩的例子，Compaction 可以用 <code>replace</code> 来表示。</p><h3 id="Metadata-File-Manifest-List"><a href="#Metadata-File-Manifest-List" class="headerlink" title="Metadata File (Manifest List)"></a>Metadata File (Manifest List)</h3><p>Manifest List 对应一个 Snapshot，以一个 Avro 文件的形式存在。Snapshot 本身 inline 在了 Metadata 里面，但是 Manifest List 却被抽出来了。这种抽象也算是避免进一步膨胀。同时，Manifest List 是一个完成的 snapshot，它包含了一些 Manifest。而这些 Manifest 比较值得玩味：</p><ol><li>Manifest 本身按照 Table 或者 Partition 有一些切分，查询可以跳过一定的 Manifest</li><li>如果 Manifest 本身和 Partition 一一绑定的话，写入需要重写整个 Partition 甚至 Table 的 Manifest，但是实际上，这里 Manifest 也可以被当成 Log，快速写插入一个文件，然后加入 Manifest List，这项技术被称为 fast append</li><li>大表也可以拆分 Manifest，来某种意义上加速 Planning</li></ol><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="comment">// 需要注意的是, 在 v2 上, 这里还有个 sequence number</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">// manifest 对应的路径.</span></span><br><span class="line">    <span class="attr">&quot;manifest_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/home/hadoop/warehouse/db2/part_table2/metadata/eab8490b-8d16-4eb1-ba9e-0dede788ff08-m0.avro&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;manifest_length&quot;</span><span class="punctuation">:</span> <span class="number">4884</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;partition_spec_id&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;added_snapshot_id&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;long&quot;</span><span class="punctuation">:</span> <span class="number">1257424822184505300</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// 这些字段算是 table summaries, 表达对应的增 / 删</span></span><br><span class="line">    <span class="attr">&quot;added_data_files_count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;int&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;existing_data_files_count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;int&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;deleted_data_files_count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;int&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// 包含的 Partition 相关的信息</span></span><br><span class="line">    <span class="comment">// 这里还可以记录 Partition 相关的和 field-summary,</span></span><br><span class="line">    <span class="comment">// 做进一步的分区裁剪.</span></span><br><span class="line">    <span class="attr">&quot;partitions&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;array&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;contains_null&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;lower_bound&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;bytes&quot;</span><span class="punctuation">:</span> <span class="string">&quot;¹Ô\\u0006\\u0000&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;upper_bound&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;bytes&quot;</span><span class="punctuation">:</span> <span class="string">&quot;¹Ô\\u0006\\u0000&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span> <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;added_rows_count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;long&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;existing_rows_count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;long&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;deleted_rows_count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;long&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;manifest_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/home/hadoop/warehouse/db2/part_table2/metadata/d8a778f9-ad19-4e9c-88ff-28f49ec939fa-m0.avro&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;manifest_length&quot;</span><span class="punctuation">:</span> <span class="number">4884</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;partition_spec_id&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;added_snapshot_id&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;long&quot;</span><span class="punctuation">:</span> <span class="number">8271497753230544000</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;added_data_files_count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;int&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;existing_data_files_count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;int&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;deleted_data_files_count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;int&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;partitions&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;array&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;contains_null&quot;</span><span class="punctuation">:</span> <span class="keyword">false</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;lower_bound&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;bytes&quot;</span><span class="punctuation">:</span> <span class="string">&quot;¸Ô\\u0006\\u0000&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;upper_bound&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;bytes&quot;</span><span class="punctuation">:</span> <span class="string">&quot;¸Ô\\u0006\\u0000&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span> <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;added_rows_count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;long&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;existing_rows_count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;long&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;deleted_rows_count&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;long&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="Manifests"><a href="#Manifests" class="headerlink" title="Manifests"></a>Manifests</h3><p>在 v2 中，format 还允许标注 Manifest 为 Delete Manifest. 这个 Manifest 就是单纯一个 「文件列表」了，我们真的走了好一会儿才看到这里呢…</p><p>Manifest 本身有点像 G+ 写的那篇 when metadata is bigdata. 整个文件会被记录 Schema 和统计信息，来进行分析，我们接着看一个 v1 的文件：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="comment">// (existing / add / deleted )</span></span><br><span class="line">    <span class="attr">&quot;status&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// 插入的 snapshot id</span></span><br><span class="line">    <span class="attr">&quot;snapshot_id&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;long&quot;</span><span class="punctuation">:</span> <span class="number">1257424822184505300</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="comment">// (这里还隐含了 seq-number 和 file-seqnumber, 因为这个文件</span></span><br><span class="line">    <span class="comment">// 本身是一个 v1 文件, 所以不包含, 当读取的时候, 这里有一套继承机制)</span></span><br><span class="line">    <span class="attr">&quot;data_file&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;file_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/home/hadoop/warehouse/db2/part_table2/data/ts_hour=2021-01-26-01/00000-6-7c6cf3c0-8090-4f15-a4cc-3a3a562eed7b-00001.parquet&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;file_format&quot;</span><span class="punctuation">:</span> <span class="string">&quot;PARQUET&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;partition&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;ts_hour&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;int&quot;</span><span class="punctuation">:</span> <span class="number">447673</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;record_count&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;file_size_in_bytes&quot;</span><span class="punctuation">:</span> <span class="number">973</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;block_size_in_bytes&quot;</span><span class="punctuation">:</span> <span class="number">67108864</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;column_sizes&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;array&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="number">47</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="number">57</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="number">60</span></span><br><span class="line">            <span class="punctuation">&#125;</span> <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value_counts&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;array&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">            <span class="punctuation">&#125;</span> <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;null_value_counts&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;array&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">            <span class="punctuation">&#125;</span> <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;lower_bounds&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;array&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;\\u0002\\u0000\\u0000\\u0000&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;\\u0000„ ,Ã¹\\u0005\\u0000&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;test message 2&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span> <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;upper_bounds&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;array&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;\\u0002\\u0000\\u0000\\u0000&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;\\u0000„ ,Ã¹\\u0005\\u0000&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;key&quot;</span><span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;test message 2&quot;</span></span><br><span class="line">            <span class="punctuation">&#125;</span> <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;key_metadata&quot;</span><span class="punctuation">:</span> <span class="keyword">null</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;split_offsets&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;array&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="number">4</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>这里就可以咔咔杀文件了. 回顾一下，这里每一个层次都有统计，Manifest <del>即是神又是魔（这是我中二犯了）</del> 既能删除又能添加，同时提供了 Prune 文件的能力。</p><h3 id="File-Format"><a href="#File-Format" class="headerlink" title="File Format"></a>File Format</h3><p>其实 File Format 层面，Iceberg 类似 Arrow Parquet 那套。什么意思呢？它不能适应任何格式，但是会需要你这个格式预留一些符合它 spec 的东西，比如：</p><ol><li>FieldId：<a href="https://github.com/apache/iceberg/blob/master/format/spec.md#column-projection">https://github.com/apache/iceberg/blob/master/format/spec.md#column-projection</a></li><li>Default Value (and spec)：<a href="https://github.com/apache/iceberg/blob/master/format/spec.md#default-values">iceberg/spec.md at master · apache/iceberg</a><ol><li>这里提供了 <code>initial-default</code>（添加字段的时候的默认值）和 <code>write-default</code>（写入的默认值）</li></ol></li><li>类型：<a href="https://github.com/apache/iceberg/blob/master/format/spec.md#schemas-and-data-types">https://github.com/apache/iceberg/blob/master/format/spec.md#schemas-and-data-types</a> 这里限制的还是相对比较死的</li></ol><h3 id="Row-Level-Delete-Formats"><a href="#Row-Level-Delete-Formats" class="headerlink" title="Row-Level Delete Formats"></a>Row-Level Delete Formats</h3><p>Iceberg format v2.0 提供了 Delete format. 这里有 Positional-Delete File 和 Equality Delete-File</p><ol><li>Positional Delete File: 对文件提供删除，以行的形式标记删除</li><li>Equality Delete-File: 对文件提供删除，以某个 Column 的 Value 形式<strong>全部</strong>删除</li></ol><p>这里文件也要提供对应的 Stats，比如删除文件也要提供自己删除的 Stats。</p><p>Iceberg 的 Stats 比较有意思，语义是：「<strong>你可以不提供，但是只要你提供了，就必须是全都准确的</strong>」。</p><p>这里还要注意，一个 Delete File 可以对应多个 Base 文件，Equality Delete-File 甚至可以对应多个分区。</p><h3 id="Concurrency-Control-and-Sequence-Number"><a href="#Concurrency-Control-and-Sequence-Number" class="headerlink" title="Concurrency Control and Sequence Number"></a>Concurrency Control and Sequence Number</h3><p>Apache Iceberg 没有 row-level transaction 和 row-level mvcc，取而代之，它模型关键是 Snapshot / 文件级别的 MVCC：</p><ol><li>每个 snapshot 有一个 sequence number</li><li>尝试提交的时候，Apache Iceberg 以 OCC 的协议提交，在前面申请一个 Sequence number，然后在 validation 阶段做 checking</li><li>创建的新 Delete / Insert 继承新的 Snapshot 的 Sequence Number，而之前创建的（Existing）享有之前的 Sequence number<ol><li>因为这套机制，Compaction 前后文件其实是不太一致的，令人唏嘘。</li></ol></li></ol><h2 id="Partition-Bucket-Sorting"><a href="#Partition-Bucket-Sorting" class="headerlink" title="Partition / Bucket / Sorting"></a>Partition / Bucket / Sorting</h2><h3 id="Partition-Evolution-amp-Sort-Order-Evolution"><a href="#Partition-Evolution-amp-Sort-Order-Evolution" class="headerlink" title="Partition Evolution &amp; Sort Order Evolution"></a>Partition Evolution &amp; Sort Order Evolution</h3><p>Iceberg 通过 PartitionSpecs 和 Sort Order 的 Specs 的方式来提供相关的内容。Hive Partition 不是数据表的一列，但是 Iceberg Partition 可以选择 <code>expr-transform(表的一列)</code>，比如它 spec 要求是</p><blockquote><ul><li>A source column id from the table’s schema</li><li>A partition field id that is used to identify a partition field and is unique within a partition spec. In v2 table metadata, it is unique across all partition specs.</li><li>A transform that is applied to the source column to produce a partition value</li><li>A partition name</li></ul></blockquote><p>这里举个之前的例子：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;default-spec-id&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;partition-specs&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;spec-id&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;fields&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;name&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;ts_hour&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;transform&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;hour&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;source-id&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;field-id&quot;</span> <span class="punctuation">:</span> <span class="number">1000</span></span><br><span class="line">    <span class="punctuation">&#125;</span> <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span> <span class="punctuation">]</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure><p>这个地方就很直观介绍了 Partition 的模样。在 Manifest 上也有 partition-spec:</p><p><img src="https://image.mwish.me/blog-image/iceberg-05.png" alt="iceberg-05"></p><p>类似 Partition，Bucket 也做成 Partition 的内容，可以套: </p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;source-id&quot;</span><span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;field-id&quot;</span><span class="punctuation">:</span> <span class="number">1000</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ts_day&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span> <span class="string">&quot;day&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;source-id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;field-id&quot;</span><span class="punctuation">:</span> <span class="number">1001</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;id_bucket&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;transform&quot;</span><span class="punctuation">:</span> <span class="string">&quot;bucket[16]&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span> <span class="punctuation">]</span></span><br></pre></td></tr></table></figure><p>其实 Sort Order 也差不多就是这套 Rule，下面来介绍</p><p><img src="https://image.mwish.me/blog-image/iceberg-06.png" alt="iceberg-06"></p><h2 id="Wrapup-How-does-Iceberg-run-query"><a href="#Wrapup-How-does-Iceberg-run-query" class="headerlink" title="Wrapup: How does Iceberg run query"></a>Wrapup: How does Iceberg run query</h2><p>比较细节的部分在 Spec 的 Scan Planning 部分：<a href="https://iceberg.apache.org/spec/#scan-planning">https://iceberg.apache.org/spec/#scan-planning</a></p><ol><li>找到 Iceberg Catalog，拿到 Metadata file</li><li>DELETED 的文件不会参与 Planning，专注处理 EXISTING  和 ADDED</li><li>裁剪分区</li></ol><p>下面有一些 DELETED File Apply 的规则：</p><ol><li>对于 Position，这里会根据 ts-rule 来 apply，<strong>如果是分区表，必须在同一个分区做删除</strong></li><li>对于 Equality，这里会根据 ts-rule 来删除，<strong>它可以是 unpartition 的，作用于全局</strong></li></ol><p><img src="https://image.mwish.me/blog-image/iceberg-07.png" alt="iceberg-07"></p><p>这样就可以 Plan 出对应的表，然后进行查询了。</p><h2 id="Iceberg-兼容"><a href="#Iceberg-兼容" class="headerlink" title="Iceberg 兼容"></a>Iceberg 兼容</h2><p>Snowflake, StarRocks 这些系统都兼容了 Iceberg，我们以 Snowflake 为例，讲讲这块是怎么兼容的：</p><p><a href="https://www.snowflake.com/blog/expanding-the-data-cloud-with-apache-iceberg/">https://www.snowflake.com/blog/expanding-the-data-cloud-with-apache-iceberg/</a></p><ol><li>从内部格式为生成 Parquet，可能会双写</li><li>Manifest 层面去双写</li></ol><p><img src="https://image.mwish.me/blog-image/iceberg-08.png" alt="iceberg-08"></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>[强烈推荐] <a href="https://www.dremio.com/resources/guide/apache-iceberg-an-architectural-look-under-the-covers/">https://www.dremio.com/resources/guide/apache-iceberg-an-architectural-look-under-the-covers/</a></li><li><a href="https://tabular.io/blog/iceberg-fileio/">https://tabular.io/blog/iceberg-fileio/</a></li><li>Iceberg V2 Spec: <a href="https://docs.google.com/document/d/1ZqVaSI_vBXekqXxNEg8NYvuiKgV2fKpMARhU54FhQaM/edit#">https://docs.google.com/document/d/1ZqVaSI_vBXekqXxNEg8NYvuiKgV2fKpMARhU54FhQaM/edit#</a></li><li>Snowflake and iceberg</li><li>Apache Iceberg 的设计哲学 - lfyzjck的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/601654830">https://zhuanlan.zhihu.com/p/601654830</a></li><li>从 Delta 2.0 开始聊聊我们需要怎样的数据湖 - 网易数帆的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/552390193">https://zhuanlan.zhihu.com/p/552390193</a></li><li>深度对比delta、iceberg和hudi三大开源数据湖方案 - openinx的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/110748218">https://zhuanlan.zhihu.com/p/110748218</a></li><li>数据湖（Data Lake） 总结 - 我吃印度飞饼的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/91165577">https://zhuanlan.zhihu.com/p/91165577</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Apache Hive: A History on Hadoop</title>
      <link href="/2023/03/17/Apache-Hive-A-History-on-Hadoop/"/>
      <url>/2023/03/17/Apache-Hive-A-History-on-Hadoop/</url>
      
        <content type="html"><![CDATA[<p>（这是最近写的最烂的一篇文章了）</p><p>对于 OTAP 和传统的数据库来说，执行引擎 / 前台 / 存储即使有一些拆分，总体上还是单个程序执行。在前台由 SQL 解析，然后 Planner 下发到执行层，执行层可能会带一个 Context 来部分限制资源的执行。然后 Queuing 的话，有一些全链路的 Queue，然后在 overquota 或者内存过大的时候，触发一些内存上的限制。</p><p>Hive 由 Facebook 开发，发表于 ICDE’10，后来 Cloudera 也进行了不少开发，感觉基本上是他们在管，Hive 经历了 0.x、1.0、2.0、3.0 版本，在过去 SQL on BigData 不甚完善的时代，是大数据的事实标准。即使现在新技术一代代出现，他们也要兼容一些 Hive 相关的语义，同时，即使 Hive 哪天真的死了，它在 HDFS / S3 的表结构相关的信息也会存活。大体来说，Hive 是一个数据仓库，你可以说「Hive 流程大致和它们差不多」，但具体还是有蛮多设计上的比较大的区别的，我们可以简单从一张架构图来延展：</p><p><img src="https://image.mwish.me/blog-image/arch-hive.png" alt="arch-hive"></p><ol><li>MetaData 存储在单独的服务（MetaStore）上</li><li>Hive 自己不完全负责查询的执行，而是下发给 MapReduce/Tez 之类的 Runtime</li><li>Hive 自己不完全负责任务的调度，而是下发给 Yarn 之类的，在 Yarn 的框架下进行调度</li><li>数据存放在 HDFS 上。对外部数据源的尊重，不分情况支持对托管表的处理</li><li>Planner 并不是那么「物理」的 SQL Operator，很大程度上是下推给执行引擎的 Plan</li></ol><p>在 Hive 中，任务调度如上图所示。</p><p>同时，Hive SQL 和 OLTP 的 SQL 使用区别还是比较大的，它提供了 Partition / Bucket 的概念，在操作的时候，经常对 Partition 和 Bucket 做 Insert Overwrite 等相对比较重的处理操作. 这里可能可以让它的 SQL 被弄进 SQL 标准，但总的来说，这个和 TP 系常用的那些 SQL 差别还是不小的。此外，对于 Hive 而言，有一点比较乐子的地方是，它虽然能做一些优化，但是你可能是用 Calcite 来优化，最后跑在一个 MapReduce 上，多少有点隔靴子挠痒，然后 Plan 也是对应 Stage 的 Plan，因此 Hive SQL 也得专门抽时间学习才能写好，而不如 DB 那样 EXPLAIN / PROFILE 那样直观。（还有一些比较好玩的 case 是，因为 MR 几乎总是 Shuffle，所以我们某种程度上可以发现，一些公司 Data Stack 会在查询引擎逐步降级，从 Presto -&gt; Spark -&gt; Hive 这样逐步的降级，直到跑出任务）。</p><p>Hive 在历史上也进行过不少优化，包括从 MapReduce 换 Tez 等模式、向量化、LLAP。很多用户的观念还停留在 0.14 之类的版本。</p><h2 id="Hive-一些常用的-SQL"><a href="#Hive-一些常用的-SQL" class="headerlink" title="Hive 一些常用的 SQL"></a>Hive 一些常用的 SQL</h2><h3 id="表的创建和加载"><a href="#表的创建和加载" class="headerlink" title="表的创建和加载"></a>表的创建和加载</h3><p>Hive 的 config 用 set 之类的定义，数据源也可以定义 Serde 之类的 config:</p><p>在创建表的时候，内容如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> pageviews (userid <span class="type">VARCHAR</span>(<span class="number">64</span>), link STRING, came_from STRING)</span><br><span class="line">  PARTITIONED <span class="keyword">BY</span> (datestamp STRING) CLUSTERED <span class="keyword">BY</span> (userid) <span class="keyword">INTO</span> <span class="number">256</span> BUCKETS STORED <span class="keyword">AS</span> ORC;</span><br></pre></td></tr></table></figure><p>这里:</p><ol><li>注意 Partition BY 的内容不完全出现在表 Schema 中</li><li>CLUSTER BY 指定分 bucket 之类的信息</li><li>还可以指定表的一些 Schema</li></ol><p>然后用户可以通过 load 等方式来加载数据，这里加载甚至可以选择 OVERWRITE 某个 Partition 的方式进行</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)]</span><br><span class="line"> </span><br><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)] [INPUTFORMAT <span class="string">&#x27;inputformat&#x27;</span> SERDE <span class="string">&#x27;serde&#x27;</span>] (<span class="number">3.0</span> <span class="keyword">or</span> later)</span><br></pre></td></tr></table></figure><p>然后，INSERT 可以选中数据，分别有 INSERT INTO 和 INSERT OVERWRITE. 大致上，INTO 是插入的时候直接插入，OVERWRITE 是覆写，插入的对象是 Table 或者 Partition。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)]</span><br><span class="line"> </span><br><span class="line">LOAD DATA [<span class="keyword">LOCAL</span>] INPATH <span class="string">&#x27;filepath&#x27;</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1<span class="operator">=</span>val1, partcol2<span class="operator">=</span>val2 ...)] [INPUTFORMAT <span class="string">&#x27;inputformat&#x27;</span> SERDE <span class="string">&#x27;serde&#x27;</span>] (<span class="number">3.0</span> <span class="keyword">or</span> later)</span><br></pre></td></tr></table></figure><p>Hive 的 Insert 还支持 Multi-Table-Insert，这是什么玩意呢？答案是它希望只读一遍数据然后插入多个 Partition / 表，借用一个 SQL：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> my_table</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> temp_table_20201115 <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">WHERE</span> dt <span class="operator">=</span><span class="string">&#x27;2020-11-15&#x27;</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> temp_table_20201116 <span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">WHERE</span> dt <span class="operator">=</span><span class="string">&#x27;2020-11-16&#x27;</span></span><br></pre></td></tr></table></figure><p>恶心吧！</p><p>哦对了，虽然不是很想在这个阶段介绍 Partition，但是 INSERT 的时候，如果打开了动态分区，Hive 会根据最后几列的内容，创建新的分区，具体见：<a href="https://cwiki.apache.org/confluence/display/Hive/Tutorial#Tutorial-Dynamic-PartitionInsert">https://cwiki.apache.org/confluence/display/Hive/Tutorial#Tutorial-Dynamic-PartitionInsert</a></p><p>CRUD 就不介绍了，另一些有意思的包括 MERGE INTO, Merge 在 Hive 2.2 支持:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Standard Syntax:</span><br><span class="line"><span class="keyword">MERGE</span> <span class="keyword">INTO</span> <span class="operator">&lt;</span>target <span class="keyword">table</span><span class="operator">&gt;</span> <span class="keyword">AS</span> T <span class="keyword">USING</span> <span class="operator">&lt;</span>source expression<span class="operator">/</span><span class="keyword">table</span><span class="operator">&gt;</span> <span class="keyword">AS</span> S</span><br><span class="line"><span class="keyword">ON</span> <span class="operator">&lt;</span><span class="type">boolean</span> expression1<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">WHEN</span> MATCHED [<span class="keyword">AND</span> <span class="operator">&lt;</span><span class="type">boolean</span> expression2<span class="operator">&gt;</span>] <span class="keyword">THEN</span> <span class="keyword">UPDATE</span> <span class="keyword">SET</span> <span class="operator">&lt;</span><span class="keyword">set</span> clause list<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">WHEN</span> MATCHED [<span class="keyword">AND</span> <span class="operator">&lt;</span><span class="type">boolean</span> expression3<span class="operator">&gt;</span>] <span class="keyword">THEN</span> <span class="keyword">DELETE</span></span><br><span class="line"><span class="keyword">WHEN</span> <span class="keyword">NOT</span> MATCHED [<span class="keyword">AND</span> <span class="operator">&lt;</span><span class="type">boolean</span> expression4<span class="operator">&gt;</span>] <span class="keyword">THEN</span> <span class="keyword">INSERT</span> <span class="keyword">VALUES</span><span class="operator">&lt;</span><span class="keyword">value</span> list<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure><p>Merge 是一套相对恶心的东西…就是对匹配到的数据进行操作，举个例子：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">MERGE</span> <span class="keyword">INTO</span> customer <span class="keyword">USING</span> (<span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> new_customer_stage) sub <span class="keyword">ON</span> sub.id <span class="operator">=</span> customer.id </span><br><span class="line"><span class="keyword">WHEN</span> MATCHED <span class="keyword">THEN</span> <span class="keyword">UPDATE</span> <span class="keyword">SET</span> name <span class="operator">=</span> sub.name, state <span class="operator">=</span> sub.new_state </span><br><span class="line"><span class="keyword">WHEN</span> <span class="keyword">NOT</span> MATCHED <span class="keyword">THEN</span> <span class="keyword">INSERT</span> <span class="keyword">VALUES</span> (sub.id, sub.name, sub.state);</span><br></pre></td></tr></table></figure><p>好用是蛮好用的，就是 SCOPE 太大了点，有点震撼，相当于做出一定的筛选，再对筛选出来的数据处理。好像 Oracle 也支持这样的语法。</p><h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><p>INSERT OVERWRITE 从一张表插入另外一张表这种 SQL 我就不说了，这里着重贴一下分区相关的 SQL 和 JOIN</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> xyz_com_page_views</span><br><span class="line"><span class="keyword">SELECT</span> page_views.<span class="operator">*</span></span><br><span class="line"><span class="keyword">FROM</span> page_views</span><br><span class="line"><span class="keyword">WHERE</span> page_views.date <span class="operator">&gt;=</span> <span class="string">&#x27;2008-03-01&#x27;</span> <span class="keyword">AND</span> page_views.date <span class="operator">&lt;=</span> <span class="string">&#x27;2008-03-31&#x27;</span> <span class="keyword">AND</span></span><br><span class="line">      page_views.referrer_url <span class="keyword">like</span> <span class="string">&#x27;%xyz.com&#x27;</span>;</span><br></pre></td></tr></table></figure><p>注意到 date 不一定是 table 中的字段，这里可能作为对应的分区字段。</p><p>这里还支持了 SAMPLING，Array/Map/Struct 类型，Schema Evolution 等：<a href="https://cwiki.apache.org/confluence/display/Hive/Tutorial#Tutorial-QueryingandInsertingData">Tutorial - Apache Hive - Apache Software Foundation</a></p><p>总之，Hive 提供的这套语义在大数据场景下，还是有用武之地的。这里专门提一下 Co-Groups:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">     <span class="keyword">FROM</span> (</span><br><span class="line">             <span class="keyword">FROM</span> action_video av</span><br><span class="line">             <span class="keyword">SELECT</span> av.uid <span class="keyword">AS</span> uid, av.id <span class="keyword">AS</span> id, av.date <span class="keyword">AS</span> <span class="type">date</span></span><br><span class="line"> </span><br><span class="line">            <span class="keyword">UNION</span> <span class="keyword">ALL</span></span><br><span class="line"> </span><br><span class="line">             <span class="keyword">FROM</span> action_comment ac</span><br><span class="line">             <span class="keyword">SELECT</span> ac.uid <span class="keyword">AS</span> uid, ac.id <span class="keyword">AS</span> id, ac.date <span class="keyword">AS</span> <span class="type">date</span></span><br><span class="line">     ) union_actions</span><br><span class="line">     <span class="keyword">SELECT</span> union_actions.uid, union_actions.id, union_actions.date</span><br><span class="line">     CLUSTER <span class="keyword">BY</span> union_actions.uid) map</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> actions_reduced</span><br><span class="line">     <span class="keyword">SELECT</span> TRANSFORM(map.uid, map.id, map.date) <span class="keyword">USING</span> <span class="string">&#x27;reduce_script&#x27;</span> <span class="keyword">AS</span> (uid, id, reduced_val);</span><br></pre></td></tr></table></figure><p>这里后台需要是一个 MapReduce 程序，然后定义 reduce_script。这套东西就能泡在它上面了。</p><p>此外，大数据还需要一些作为 CUBE，ROLLUP 之类的语义，比如：</p><ul><li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+GroupBy">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+GroupBy</a> （GROUP BY，GROUPINGSETS，ROLLUP，CUBE）</li><li>使用窗口函数来获得一定的 WINDOW 信息（TODO(mwish): 丰富这里）</li><li>Coalesce, CASE WHEN 之类的，处理类似 if 的语义</li></ul><p>在 JOIN 的时候，Hive SQL 还支持类似 HINT 的语法（我看了下，Spark 也支持），来手动干预 JOIN 的 Plan: <a href="https://cwiki.apache.org/confluence/display/hive/languagemanual+joinoptimization">https://cwiki.apache.org/confluence/display/hive/languagemanual+joinoptimization</a></p><h4 id="恶补一些查询的时候需要的-SQL"><a href="#恶补一些查询的时候需要的-SQL" class="headerlink" title="恶补一些查询的时候需要的 SQL"></a>恶补一些查询的时候需要的 SQL</h4><p>本来 Hive 和 SQL 标准应该尽量分开讲的，除非一些标准的 SQL，不应该在文章正文部分介绍，但是我又不想专门花一篇内容介绍高级 SQL, 所以干脆在这里说了</p><p>RANK 之类的，可以在序列中，额外提供一个 RANK 的数字，相当于在 SQL 中提供了一个 idx 的抽象：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ID, <span class="built_in">rank</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> (GPA) <span class="keyword">desc</span>) <span class="keyword">as</span> s_rank</span><br><span class="line"><span class="keyword">from</span> student_grades;</span><br></pre></td></tr></table></figure><p>这里没有指定输出排序顺序。还有一些能替代 <code>rank</code> 的函数，比如：</p><ul><li><code>percent_rank</code>: 排序中的比例</li><li><code>cume_dist</code>:累积分布</li><li><code>row_number</code>: 类似 rank, 作为排序的时候唯一的行号。</li><li><code>ntile</code> 把结果分成对应的桶，来处理相关的逻辑</li></ul><p>SQL 还提供了窗口函数和对应的功能。这个是可以向前滑动的，就是一个row可能被算进多个窗口：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">year</span>, <span class="built_in">avg</span>(num_credits) <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">year</span> <span class="keyword">rows</span> <span class="number">3</span> preceding) <span class="keyword">as</span> avg_total_credits</span><br><span class="line"><span class="keyword">from</span> tot_credits;</span><br></pre></td></tr></table></figure><p><code>range</code> <code>over</code> 可以提供窗口有关的靠谱功能</p><p><code>pivot</code>做的时期相当于把SQL中的 enum 展开，从 <code>table(a, b, c)</code> 展开成 <code>table(a, b, c_value1, c_value2 ...)</code>:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> <span class="keyword">table</span></span><br><span class="line">pivot (</span><br><span class="line">  <span class="built_in">sum</span>(d)</span><br><span class="line">  <span class="keyword">for</span> c <span class="keyword">in</span> (c_value1, c_value2, ...)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>这里还有一些 rollup, cube 和 grouping sets 来表达一些混杂的 GROUP BY. 简单来说，这些不同于多列 GROUP BY (<code>GROUP BY c1, c2</code>), 他们相当于多列 GROUP BY 的 UNION。</p><ol><li><code>rollup</code> 相当于<strong>前缀</strong>的 group by 和，<code>rollup(a, b, c...)</code> 相当于 <code>UNION&#123;(a, b, c..), ... (a, b), (a), ()&#125;</code></li><li><code>cube</code> 相当于所有按照顺序排列的子集 (<code>CUBE(a,b,c) == GROUPING SETS((a,b,c), (a,b),(a,c),(b,c),(a),...())</code> )</li><li><code>grouping sets</code> 相当于手动列出这些集合 </li></ol><p>这些还可以和 <code>COALESCE</code> 连用</p><h2 id="Hive-简单使用"><a href="#Hive-简单使用" class="headerlink" title="Hive 简单使用"></a>Hive 简单使用</h2><p>知道了上面的内容之后，就可以写基本的 Hive SQL 了，Hive 的 EXPLAIN 有点难懂，会输出一大堆和 Stage 有关的东西：</p><ul><li><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Explain">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Explain</a></li><li><a href="https://cwiki.apache.org/confluence/display/Hive/Cost-based+optimization+in+Hive">https://cwiki.apache.org/confluence/display/Hive/Cost-based+optimization+in+Hive</a></li><li><a href="https://zhuanlan.zhihu.com/p/352076174">https://zhuanlan.zhihu.com/p/352076174</a></li></ul><p>EXPLAIN 这里可能输出对应的 Stage，Hive 高版本还引入了 CBO。</p><p><img src="https://image.mwish.me/blog-image/arch-hive-1-x.png" alt="arch-hive-1-x"></p><p>Hive 在执行的时候，在进行数据处理时先将计算发往数据所在的节点，将数据以键-值对作为输入，在本地处理后再以键-值对的形式发往远端的节点，这个过程通用叫法为Shuffle，远端的节点将接收的数据组织成键-值对的形式作为输入，处理后的数据，最终也以键-值对的形式输出。</p><p>这里非 LLAP 的模式可能还要通过 Yarn 拉起一个进程，然后选出一个管理器，来协调任务的执行</p><p><img src="https://image.mwish.me/blog-image/hive-on-yarn.png" alt="hive-on-yarn"></p><p><img src="https://image.mwish.me/blog-image/yarn-internal.png" alt="yarn-internal"></p><p>这里要关注一个问题，就是，在 Hive 1.x 执行问题按我们最早贴的那张图所述，这里 YARN 会有调度器和队列，然后进程都是拉起一大堆的，整个流程相对于 OLTP Database 都很重量级。YARN 按照 DRF 之类的方式进行调度。</p><p>数据在这里存储在 HDFS 上。</p><p>这里计算引擎还有对应的：</p><ul><li>MapReduce</li><li>Tez</li></ul><p>MapReduce 如下图所示</p><p><img src="https://image.mwish.me/blog-image/hive-and-mr.png" alt="hive-and-mr"></p><p><img src="https://image.mwish.me/blog-image/tez-and-hive.png" alt="tez-and-hive"></p><p>Hive 还有 LLAP 模式，这里相当于持久驻留进程，有点类似现代人心目中的 database (但话又说回来，某种意义上，非 LLAP 那套还挺<strong>云</strong>）</p><p><img src="https://image.mwish.me/blog-image/tez-llap.png" alt="tez-llap"></p><p>LLAP 模式中，可以：</p><ol><li>push 对应的数据，而不用必须 shuffle 到 HDFS 上</li><li>缓存数据</li><li>…</li></ol><p>此外，这里还支持计算调度到 Hive 上.</p><h2 id="Partition-amp-Bucket"><a href="#Partition-amp-Bucket" class="headerlink" title="Partition &amp; Bucket"></a>Partition &amp; Bucket</h2><p><a href="https://cwiki.apache.org/confluence/display/Hive/Design">Design - Apache Hive - Apache Software Foundation</a></p><ul><li>Table 是 HDFS 上的一个目录</li><li>Partition 被设置成 HDFS 上的一个目录</li><li>Bucket 作为一个文件来被存储</li></ul><p>这就是 Hive 的表结构，Iceberg 优化了这个表结构。</p><p><img src="https://image.mwish.me/blog-image/hive-partition-and-buckets.png" alt="hive-partition-and-buckets"></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>面试|不可不知的十大Hive调优技巧最佳实践 - 大数据技术与数仓的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/296254978">https://zhuanlan.zhihu.com/p/296254978</a></li><li>SQL to Hive CheatSheet: <a href="https://hortonworks.com/wp-content/uploads/2016/05/Hortonworks.CheatSheet.SQLtoHive.pdf">https://hortonworks.com/wp-content/uploads/2016/05/Hortonworks.CheatSheet.SQLtoHive.pdf</a></li><li><strong>Hive性能调优实战</strong> </li><li>Hive Wiki: <a href="https://cwiki.apache.org/confluence/display/Hive/">https://cwiki.apache.org/confluence/display/Hive/</a></li><li>HCatalog Wiki: <a href="https://cwiki.apache.org/confluence/display/Hive/HCatalog">https://cwiki.apache.org/confluence/display/Hive/HCatalog</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Beyond Parquet: ORC and new file format</title>
      <link href="/2023/03/11/Beyond-Parquet-ORC-and-new-file-format/"/>
      <url>/2023/03/11/Beyond-Parquet-ORC-and-new-file-format/</url>
      
        <content type="html"><![CDATA[<p>Apache Parquet 是一个功能强大的列存系统，不过也有一些同类的顶级项目，比如 Apache ORC。Google 自己发过一些 Capacitor 格式，作为 Dremel (BigQuery) 的文件格式。此外，Biswapesh Chattopadhyay 在一些新的论文中谈过 Youtube (2019) 和 Shared Foundations (CIDR’23) 一些设计的新的格式。</p><p>此外，还有人为 AI workload 做了一些特殊的格式，比如 IndexR. 包括还有历史悠久的 HDF5 和新鲜的 lance。</p><p>这些格式的需求各有不同，和我熟悉的 Parquet 相比有同有异。下面可以开始简单介绍</p><h2 id="Apache-ORC"><a href="#Apache-ORC" class="headerlink" title="Apache ORC"></a>Apache ORC</h2><p>Apache ORC 由 Hive 社区开发，如果你听过 RC 或者 RCFile 的话，会发现 ORC 这个名字有点熟悉，其实 ORC 前面那个 O 是 Optimized 的概念。Apache ORC 自认为可以：</p><ul><li>typed, self-describe</li><li>挑选合适的 encoding 方式</li><li>提供 Index</li><li>切分 10000 rows，然后 Predicate Pushdown</li><li>支持 ComplexType: Map, Union, Struct, List</li></ul><p>Apache ORC 有三个版本：</p><ol><li>v0: Hive 旧版本使用</li><li>V1: Hive1.0 和 0.12 之后使用</li><li>V2: 不知道啥状态，好像每次看都是 TODO，虽然内容挺多的</li></ol><p>Apache ORC 格式如下图，有一些相似的概念：</p><ul><li>File Tail: 类似 Parquet 的 Footer 和 FileMetaData，在文件的尾部<ul><li>File Tail 包含 encrypted statistics, stripe metadata, Footer , file footer, postscript</li><li>PostScript: 文件本身元信息，包括版本，Footer 长度，写者（很奇怪的是竟然有文件压缩方式）</li><li>File Footer 类似 Parquet Footer，是一个 protobuf，内容如下：<a href="https://github.com/apache/orc/blob/main/proto/orc_proto.proto#L354">https://github.com/apache/orc/blob/main/proto/orc_proto.proto#L354</a><ul><li>包含文件类型，整个文件的 statistics，文件 header，所有 Stripe 的信息</li><li>Stripe 信息包含 Stripe 的起始地，index 长度，Row Data 长度，Stripe Footer 长度，行数</li><li>Type 包含文件类型，整个文件有相同的类型。</li><li>ColumnStatistics 包含各列的 min/max/hasNull</li><li>user metadata: 塞入 key-value</li><li>Encryption 相关的信息，不太懂加密，不写了</li></ul></li></ul></li><li>Index: Parquet 有 BloomFilter 和没有实现任何 Index 的 Index Page (笑)，ORC 有 Index Data</li><li>Stripe: 对应 Parquet 的 RowGroup，由 Index Data + Row Data + Stripe Footer 构成。Row 不会跨 Stripe。<ul><li>Stripe 通常比较大 (~200MB)，可以当作并发的单位</li><li>Stripe 数据被存储在相邻的多个 Stream 中。列的数据氛围 Present Stream 和 Data Stream，Present 存放类似 null 的信息，Stream 有自己的 Kind, length。我们之后再来介绍它是如何表示 Complex Type 的。Present Stream 是靠压缩和 Encoding 来减少空间开销的</li><li>此外，索引、Stats之类的内容也被统一到了 Stream 中，由 Stream 表示</li></ul></li></ul><p><img src="https://image.mwish.me/blog-image/gpdhpp5sx7.jpeg" alt="gpdhpp5sx7"></p><p>Orc 的 Compression 到处都是，它除了 Postscript，各段都会用 Postscript 指定的 compression 来编码，此外，这里会有一些 <code>is_compression</code> flag， Parquet 的 Page V1 是没有这个东西的，Page V2 才有。压缩效果不好的时候，可以通过这个 flag 来取消压缩。</p><p>在数据层，Orc 针对不同的类型支持了不同的 Encoding 方式，其实我感觉类似 Parquet 了。Present 强调用 Boolean RLE 编码。ORC 支持了：</p><ol><li>RLE</li><li>Dictionary</li></ol><p>这样的编码方式，具体而言，RLE 类似 Parquet 的 RLE，可能也会有 delta 之类的逻辑。Dict 编码会分成多条 Stream 来写。此外，ORC 还有 SECONDARY Stream，用来表示一些异构的值。简单来说：</p><ul><li>Orc 把列拆成了多条 Stream</li><li>优化好了 Stream 的对各种类型的简单编码方式</li><li>用这种简单编码 + 多条流表示类型</li></ul><p>编码方式我就不介绍了，之后专门开个专题啃算了，感觉放这不太好。</p><p>对于 Complex 类型的表示，简单来说如下：</p><ol><li>Struct 只记录 Struct 本身的 PRESENT</li><li>List = Present Stream + Length Stream</li><li>Map = Map 等价于一种很奇怪的 List 和 List 表现一样，但后面有一组 Key 一组 Value</li><li>Union 分成 PRESENT + Tag，后面接不同种类的 Stream</li></ol><h3 id="Statistics-amp-Index"><a href="#Statistics-amp-Index" class="headerlink" title="Statistics &amp; Index"></a>Statistics &amp; Index</h3><p>书接上回，Orc 的 format 支持了一大把不同的 Statistics. Parquet 的 Statistics 靠 bytes 来怼通用性，Orc 则是定义了一堆 adhoc 的东西，但是这并不要紧…</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">message </span><span class="title class_">ColumnStatistics</span> &#123;</span><br><span class="line">  <span class="keyword">optional</span> <span class="type">uint64</span> numberOfValues = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">optional</span> IntegerStatistics intStatistics = <span class="number">2</span>;</span><br><span class="line">  <span class="keyword">optional</span> DoubleStatistics doubleStatistics = <span class="number">3</span>;</span><br><span class="line">  <span class="keyword">optional</span> StringStatistics stringStatistics = <span class="number">4</span>;</span><br><span class="line">  <span class="keyword">optional</span> BucketStatistics bucketStatistics = <span class="number">5</span>;</span><br><span class="line">  <span class="keyword">optional</span> DecimalStatistics decimalStatistics = <span class="number">6</span>;</span><br><span class="line">  <span class="keyword">optional</span> DateStatistics dateStatistics = <span class="number">7</span>;</span><br><span class="line">  <span class="keyword">optional</span> BinaryStatistics binaryStatistics = <span class="number">8</span>;</span><br><span class="line">  <span class="keyword">optional</span> TimestampStatistics timestampStatistics = <span class="number">9</span>;</span><br><span class="line">  <span class="keyword">optional</span> <span class="type">bool</span> hasNull = <span class="number">10</span>;</span><br><span class="line">  <span class="keyword">optional</span> <span class="type">uint64</span> bytesOnDisk = <span class="number">11</span>;</span><br><span class="line">  <span class="keyword">optional</span> CollectionStatistics collectionStatistics = <span class="number">12</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们的关键是，Statistics 可能出现在什么地方？</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// StripeStatistics (1 per a stripe), which each contain the</span></span><br><span class="line"><span class="comment">// ColumnStatistics for each column.</span></span><br><span class="line"><span class="comment">// This message type is only used in ORC v0 and v1.</span></span><br><span class="line"><span class="keyword">message </span><span class="title class_">StripeStatistics</span> &#123;</span><br><span class="line">  <span class="keyword">repeated</span> ColumnStatistics colStats = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// This message type is only used in ORC v0 and v1.</span></span><br><span class="line"><span class="keyword">message </span><span class="title class_">Metadata</span> &#123;</span><br><span class="line">  <span class="keyword">repeated</span> StripeStatistics stripeStats = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你会发现，这里 Statistics 都是 Stripe 级别的。那么有没有更细粒度的 Statistics 呢？有，Row Group Index。</p><p>这里的 RowGroup 和 Parquet 的 Row Group 是不同的概念，类似 Parquet 中的 Page Statistics，不过有一些 trickey 的 RLE 细节：</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">message </span><span class="title class_">RowIndexEntry</span> &#123;</span><br><span class="line"> <span class="keyword">repeated</span> <span class="type">uint64</span> positions = <span class="number">1</span> [packed=<span class="literal">true</span>];</span><br><span class="line"> <span class="keyword">optional</span> ColumnStatistics statistics = <span class="number">2</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>To record positions, each stream needs a sequence of numbers. For uncompressed streams, the position is the byte offset of the RLE run’s start location followed by the number of values that need to be consumed from the run. In compressed streams, the first number is the start of the compression chunk in the stream, followed by the number of decompressed bytes that need to be consumed, and finally the number of values consumed in the RLE.</p></blockquote><p>这个地方就是 hack 到 RLE format 内部了。</p><h3 id="ACID"><a href="#ACID" class="headerlink" title="ACID?"></a>ACID?</h3><p>ORC 是 Hive 的亲儿子，在 format 标注上，它写了一些 Delta。这个感觉翻翻 iceberg 就行了.</p><h2 id="Capacitor-in-Dremel"><a href="#Capacitor-in-Dremel" class="headerlink" title="Capacitor in Dremel"></a>Capacitor in Dremel</h2><p>Capacitor 是 Parquet 的野爹，之所以说不是亲爹…Google 啥时候成过亲爹？Parquet 是 Twitter 和 LinkedIn 一起实际开发的，然后 15 年成了顶级项目，G+ 就喜欢憋大招的。</p><p>Google 这家伙贼喜欢藏大招，但是这里透露的材料还是不错的：</p><ul><li>参考 Storing and Querying Tree-Structured Records in Dremel: <a href="https://research.google/pubs/pub43119/">https://research.google/pubs/pub43119/</a> 做谓词下推和 encoding + query exec。</li><li>采样数据，存储到 Meta 中，帮助提供了一套 Reordering Record 的方式。这里可以参见 Arxiv: <a href="https://arxiv.org/abs/1207.2189">https://arxiv.org/abs/1207.2189</a></li></ul><p>在这里，我感觉这里不是单纯的格式了，而是一套自上而下的 Stats/Reorder + Format + Query Exec 融合的系统了。Query Exec 的地方我感觉我可以借鉴一下，但是 Stats + Reorder 我感觉我就不会搞了 Orz。</p><h2 id="HTAP-HSAP-Design"><a href="#HTAP-HSAP-Design" class="headerlink" title="HTAP/HSAP Design"></a>HTAP/HSAP Design</h2><p>在 AP 中，数据经常是下推 Filter，然后扫大量数据。HTAP / HSAP 这种场景，会混杂 Point Lookup 和 Range Filter。对于 Point Lookup 来说，在压缩的 Group 中感觉效果是不太好的，因为这里有个问题是，可能需要走一遍 解压 + Decoding。</p><p>HTAP / HSAP 的场景，在这方面能够选出比较好的格式，需要有 Skipable 的 format，快速找到对应的列。</p><p>SingleStore 的做法在博客中有提到：<a href="https://www.singlestore.com/blog/winter-2022-universal-storage-part-5/">https://www.singlestore.com/blog/winter-2022-universal-storage-part-5/</a> . 简单说是靠索引 + Encoding Skip 来实现，RLE / LZ4 都是有类似 RLE 的性质的，因为有 RLE 的性质，所以可以在有 Secondary Index to RowId 的情况下，做一些快速的 Skipping。</p><p>在 Procella: Unifying serving and analytical data at YouTube 这篇论文中，作者描述了 HSAP 中的格式 Artus，系统用这个格式来代替 Capacitor。这个格式也是给相似的逻辑设定的，但是相对于 S2DB 这种靠 Secondary Index 的，它这里还是会做一些（主动的）搜索的：</p><ol><li>（类似 S2DB），避免用通用的 compression，倾向于 Seekable format</li><li>Multi-pass adaptive encoding: 先采集 ndv/min-max/sorting 之类的信息，再 adaptive 选择编码方式。Artus 提供了一套 encoding data 的 evaluation: Dict, Index, RLE, Delta 这些方式，同时，格式提供了一个 Score，能根据 (size, speed) 比较好评估这些格式的代价，来做 eval</li><li>采用 Binary Search able 的编码方式，允许用户以 $O(logN)$ 的 Complexity 去搜索<ol><li>$O(1)$ 的 Seek to RowId。这个在等宽 bitpacking 上没啥问题，但是别的 RLE 之类的，需要准备一些稀疏索引（Skip Block），这里 Block Size 通常是 32/128，来保证这个很小（Parquet C++ 现在 是很傻逼的 32 * 4）</li><li>$O(logN + K)$ 的 Primary Key Searching</li></ol></li><li>用 ORC 那种方式来存。我感觉这种格式在 HTAP Nested Search 上有一些优势？毕竟 Parquet 那种 format row-id 对一些东西其实还是要反解 rep/def 的。</li><li>暴露 Dictionary Index 和 RLE 给引擎，方便 Pushdown</li><li>尝试暴露很多元信息，然后按照 pk 切分文件，保证（粗粒度的）过滤性</li><li>支持 inverted index (S2DB 也走了这条路)</li></ol><p>感觉 HTAP 的场景上述还是要支持的。</p><h2 id="AI-The-Old-one-and-The-new-one"><a href="#AI-The-Old-one-and-The-new-one" class="headerlink" title="AI, The Old one and The new one"></a>AI, The Old one and The new one</h2><p>在 AI 领域，有 HDF5 格式之类的老东西，还有新的很多存储系统类似 Feature Store，会存一些稀疏的大宽表，比如下面论文的描述：</p><blockquote><p>For example, it is increasingly common for ML tables to outgrow analytical tables by up to an order of magnitude. ML tables are also typically much wider, and tend to have tens of thousands of features usually stored as large maps.</p></blockquote><p>这个领域可以简单当成可能有稀疏的大宽表，有一些随机访问，但是又是列存？在 这里：</p><ol><li>Shared Foundations 提出了一些元数据优化，因为 Orc / Parquet 列元数据都很大了，但是没提自己是怎么做的</li><li>HDF5 简单的将数据集打包</li><li>lance 是一个新的格式，类似 ORC，坦白的说，它在 PPT 里面写的东西都是垃圾，但是看到它支持了一些 ad-hoc 的 kmeans 之类的东西，还是挺有意思的。</li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><p>Parquet / Capacitor</p><ul><li>InfluxDB-IOx 的 Parquet 使用 <a href="https://www.influxdata.com/blog/querying-parquet-millisecond-latency/">https://www.influxdata.com/blog/querying-parquet-millisecond-latency/</a></li><li>Dremel: Interactive Analysis of Web-Scale Datasets: <a href="https://research.google/pubs/pub36632/">https://research.google/pubs/pub36632/</a></li><li>Storing and Querying Tree-Structured Records in Dremel: <a href="https://research.google/pubs/pub43119/">https://research.google/pubs/pub43119/</a></li><li><a href="https://cloud.google.com/blog/products/bigquery/inside-capacitor-bigquerys-next-generation-columnar-storage-format">https://cloud.google.com/blog/products/bigquery/inside-capacitor-bigquerys-next-generation-columnar-storage-format</a><ul><li>值得一提的是，这个文章的老板已经去 firebolt 当老板了</li></ul></li></ul></li><li><p>lance: <a href="https://github.com/eto-ai/lance">https://github.com/eto-ai/lance</a></p></li><li><p>特征平台（Feature Store）：序论 - 曾中铭的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/406897374">https://zhuanlan.zhihu.com/p/406897374</a></p></li><li><p>Guide to File Formats for Machine Learning: Columnar, Training, Inferencing, and the Feature Store <a href="https://towardsdatascience.com/guide-to-file-formats-for-machine-learning-columnar-training-inferencing-and-the-feature-store-2e0c3d18d4f9">https://towardsdatascience.com/guide-to-file-formats-for-machine-learning-columnar-training-inferencing-and-the-feature-store-2e0c3d18d4f9</a></p></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>[WIP] Storage in AP Systems</title>
      <link href="/2023/03/05/Storage-in-AP-Systems/"/>
      <url>/2023/03/05/Storage-in-AP-Systems/</url>
      
        <content type="html"><![CDATA[<h2 id="上层架构-对存储的需求"><a href="#上层架构-对存储的需求" class="headerlink" title="上层架构 / 对存储的需求"></a>上层架构 / 对存储的需求</h2><p>相关的论文：</p><ol><li>SIGMOD‘16，知名的： <a href="https://www.snowflake.com/resource/sigmod-2016-paper-snowflake-elastic-data-warehouse/">The Snowflake Elastic Data Warehouse</a></li><li>SIGMOD’22: Amazon Redshift Reinvent</li><li>NSDI’20: snowflake 的弹性存储：Building An Elastic Query Engine on Disaggregated Storage</li><li>(BigQuery) Dremel: A Decade of Interactive SQL Analysis at Web Scale</li><li>PushdownDB / FlexPushdownDB</li></ol><p>我们分成几个子话题</p><p>数据分布：</p><ol><li>[PVLDB’20] Fast and effective distribution-key recommendation for amazon redshift / [SIGMOD’20] Learning a partitioning advisor for cloud databases.</li><li><a href="https://cloud.google.com/blog/topics/developers-practitioners/bigquery-admin-reference-guide-storage">https://cloud.google.com/blog/topics/developers-practitioners/bigquery-admin-reference-guide-storage</a> / snowflake paper</li></ol><h3 id="调度-弹性"><a href="#调度-弹性" class="headerlink" title="调度 / 弹性"></a>调度 / 弹性</h3><p>这块其实不太完全是 AP 系统的知识</p><ul><li>Yarn / Mesos (机制)</li><li>DRF (策略)</li></ul><h3 id="计算-colocate"><a href="#计算-colocate" class="headerlink" title="计算 ( colocate )"></a>计算 ( colocate )</h3><h3 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h3><p>相关文章：</p><ol><li><p>facebook 关于 CacheLib 的两篇论文</p></li><li><p>snowflake 弹性存储</p></li><li><p>Crystal: A Unified Cache Storage System for Analytical Databases</p></li><li><p>Alluxio</p></li></ol><h3 id="shuffle-service"><a href="#shuffle-service" class="headerlink" title="shuffle service"></a>shuffle service</h3><ul><li>Cosco: An Efficient Facebook-Scale Shuffle Service</li><li>Dremel: A Decade of Interactive SQL Analysis at Web Scale</li></ul><h3 id="Multi-tanent"><a href="#Multi-tanent" class="headerlink" title="Multi-tanent"></a>Multi-tanent</h3><p>这里感觉得分开来讨论， Dynamo 这些用的都是 quota 之类的，Yarn 之类的是上层调度，我不确定这里合不合适</p><ul><li>StarRocks技术内幕 | 资源隔离原理解析 - <em>StarRocks</em>的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/605900476">https://zhuanlan.zhihu.com/p/605900476</a></li></ul><h3 id="计算下推"><a href="#计算下推" class="headerlink" title="计算下推"></a>计算下推</h3><ul><li>PushdownDB: Accelerating a DBMS using S3 Computation (Presto 用了这套逻辑)</li></ul><h3 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h3><ul><li>Big Metadata: When Metadata is Big Data</li><li>Delta-Lake</li></ul><h2 id="存储格式"><a href="#存储格式" class="headerlink" title="存储格式"></a>存储格式</h2><p>Parquet: <a href="https://github.com/apache/parquet-format/blob/master/Encodings.md">https://github.com/apache/parquet-format/blob/master/Encodings.md</a></p><p>ORC: <a href="https://orc.apache.org/specification/ORCv2/">https://orc.apache.org/specification/ORCv2/</a></p><p>Doris: <a href="https://xie.infoq.cn/article/4f7d09d6185fb3055d4e7e51c">https://xie.infoq.cn/article/4f7d09d6185fb3055d4e7e51c</a></p><p>ClickHouse MergeTree</p><p>HyPer</p><p>Umbra: 内存数据库的特殊优化</p><p>Kudu: CFile，本质上和 Doris 那些 Unique 是同一套</p><h3 id="Encoding"><a href="#Encoding" class="headerlink" title="Encoding"></a>Encoding</h3><p><a href="https://github.com/apache/parquet-format/blob/master/Encodings.md">https://github.com/apache/parquet-format/blob/master/Encodings.md</a></p><p>要点：压缩率 / 性能对比，能否 SIMD，针对 pattern 做特定的优化（子问题：如何识别 pattern）</p><p>还有一些 HTAP 的编码方式。</p><p>此外，关注 SIGMOD’21 CodecDB</p><h4 id="Query-on-Encoded-Data"><a href="#Query-on-Encoded-Data" class="headerlink" title="Query on Encoded Data"></a>Query on Encoded Data</h4><p>要点：<a href="https://blog.mwish.me/2022/01/15/format-thinking-2/#DB-%E7%9B%B4%E6%8E%A5%E5%9C%A8%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97">https://blog.mwish.me/2022/01/15/format-thinking-2/#DB-%E7%9B%B4%E6%8E%A5%E5%9C%A8%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97</a></p><p>DB 可以直接在压缩的数据上跑一些简单的计算，但是这个需要让存储知道具体走了什么样的算子</p><h4 id="Lazy-Evaluation"><a href="#Lazy-Evaluation" class="headerlink" title="Lazy Evaluation"></a>Lazy Evaluation</h4><p>要点：行中的列可以需要的时候再 load，不访问可以不加载，加载出来的结构也可以标识自己是 RLE 还是什么样的，来避免：</p><ol><li>访问 Page 的开销</li><li>加载不需要的列的开销</li></ol><p>这部分其实和实现绑定的特别死，主要是 runtime 的实现，甚至有一些是 Query Optimizer 有关的部分</p><h4 id="字典和全局字典"><a href="#字典和全局字典" class="headerlink" title="字典和全局字典"></a>字典和全局字典</h4><p>要点：字典和字符串有序性</p><p>例如：<a href="https://forum.starrocks.com/t/topic/1469">StarRocks2.0.1低基数全局字典优化测试</a> 和 <a href="http://mysql.taobao.org/monthly/2022/08/01/">PolarDB MySQL·HTAP·浅析IMCI的列存数据压缩</a> . 这里关心：</p><ol><li>是否走到字典上（有的地方字符串类型之外的类型不会走到字典上）</li><li>字典的顺序是否和原始顺序一样</li><li>是否物化（字典可能不那么急着物化，上层可以根据字典来做 JOIN、DISTINCT 之类的优化）。</li></ol><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><p>这里说索引这个词有歧义，TP 方面一般这里指全局的 1:1 的索引，而 AP 这里既有 1:1 的索引，更多还是稀疏索引、Page 上、RowGroup 上的信息统计。因为做 skipping 要考虑这些信息，所以我们汇总到索引这里。</p><p>这里有：</p><ol><li>Page 上的统计信息，例如 Page Index / Zone Map</li><li>Z-ordering，可以当成是拍平的 zone-map</li></ol><p>可参考的：</p><ol><li>pinot: <a href="https://docs.pinot.apache.org/basics/indexing">https://docs.pinot.apache.org/basics/indexing</a></li></ol><p>有很多统计信息相关的，见：<a href="http://dimacs.rutgers.edu/~graham/ssbd.html">http://dimacs.rutgers.edu/~graham/ssbd.html</a> 。论文有</p><ul><li><a href="https://15721.courses.cs.cmu.edu/spring2023/papers/04-olapindexes/hentschel-sigmod18.pdf">Column Sketches: A Scan Accelerator for Rapid and Robust Predicate Evaluation</a> </li></ul><p>此外，还有一些 SuRF 之类的 Succinct 类型: <a href="https://6.5210.csail.mit.edu/">https://6.5210.csail.mit.edu/</a></p><p>还需要关注 Inverted Index，见 Lucene。</p><h4 id="特殊的索引"><a href="#特殊的索引" class="headerlink" title="特殊的索引"></a>特殊的索引</h4><p>本来 z-ordering 应该放这里的，但是由于其重要性，我们放到了上面？</p><ol><li>空间索引。</li><li>相似度索引：<a href="https://github.com/ClickHouse/ClickHouse/blob/master/docs/en/engines/table-engines/mergetree-family/annindexes.md">https://github.com/ClickHouse/ClickHouse/blob/master/docs/en/engines/table-engines/mergetree-family/annindexes.md</a></li></ol><h3 id="IO-Pattern"><a href="#IO-Pattern" class="headerlink" title="IO Pattern"></a>IO Pattern</h3><h4 id="Share-nothing"><a href="#Share-nothing" class="headerlink" title="Share-nothing"></a>Share-nothing</h4><p>ClickHouse</p><p>Doris</p><h4 id="Shared-storage"><a href="#Shared-storage" class="headerlink" title="Shared-storage"></a>Shared-storage</h4><p>Apache-Arrow</p><p>Velox</p><h3 id="变更-Insert-Update-Delete"><a href="#变更-Insert-Update-Delete" class="headerlink" title="变更 (Insert / Update / Delete)"></a>变更 (Insert / Update / Delete)</h3><ul><li><a href="https://ir.cwi.nl/pub/16172/16172D.pdf">Positional Update Handling in Column Stores</a>：最早用 Positional Delta 描述删除的论文之一</li><li>SQL Server (Delete + Insert 的代表，论文很多地方描述非常详细，包括 Positional Delete 和 Conditional Delete)</li><li>Kudu （Delta File 的代表，机制和 MVCC 是整合的，Update 支持很高效，但是对 Scan / Pruning 不是很友好）</li><li>ClickHouse MergeTree （Merge-on-Read 的代表，暴力实现）</li><li>TiFlash (复杂的树结构)</li><li>S2DB SingleStore</li></ul><h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h3><h3 id="特殊类型-struct-array-map-json"><a href="#特殊类型-struct-array-map-json" class="headerlink" title="特殊类型: struct / array / map / json"></a>特殊类型: struct / array / map / json</h3><p>dremel and parquet</p><h3 id="Schema-Evolution"><a href="#Schema-Evolution" class="headerlink" title="Schema Evolution"></a>Schema Evolution</h3><p>Iceberg schema evolution</p><h3 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h3><p>kudu compaction</p><h4 id="Auto-Clustering"><a href="#Auto-Clustering" class="headerlink" title="Auto Clustering"></a>Auto Clustering</h4><p>snowflake auto clustering</p><h2 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h2><p>CDC: databus</p><p>Flink</p><p>Kafka</p><p>Husky</p><p>BigQuery Streaming / Snowflake Unistore</p><h2 id="Data-Lake"><a href="#Data-Lake" class="headerlink" title="Data Lake"></a>Data Lake</h2><ol><li>Iceberg</li><li>Hudi</li><li>DeltaLake</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Parquet C++: Statistics</title>
      <link href="/2023/02/26/Parquet-C-Statistics/"/>
      <url>/2023/02/26/Parquet-C-Statistics/</url>
      
        <content type="html"><![CDATA[<p>上面一节我们讨论了 arrow 类型到 Parquet 类型的外层类型映射，我们学到的技巧是，用 arrow 的 Schema 转换成 Parquet 的 Schema，做类型映射，然后冗余一份 Parquet 的 Schema。这一节介绍的是 Types and Statistics In Parquet。这节的内容也比较 Dirty，但是还是必要的。此外，这节会涉及一些 Parquet MR 的代码，因为它的代码是「好 / 对」的。arrow Schema 会有很多问题，我也会尝试修复这些问题。</p><p>此外，这节只涉及标准的、协议上的 Statistics，如果用户想打洞，这篇文章也可以提供一些 arrow 的外挂。</p><h2 id="Parquet-Standard"><a href="#Parquet-Standard" class="headerlink" title="Parquet Standard"></a>Parquet Standard</h2><h3 id="Statistics"><a href="#Statistics" class="headerlink" title="Statistics"></a>Statistics</h3><p>Parquet 协议上本身会带有一些 Statistics，分成多部分：</p><p><code>Statistics</code> 结构(我在下面删掉了兼容性对应的部分，但是实际代码是要处理的)</p><ol><li>这个地方的 <code>max_value</code> 和 <code>min_value</code> 都是 Parquet 内部的编码。根据 <code>ColumnOrder</code> 决定，什么是 ColumnOrder 呢？之后介绍</li><li><code>null_count</code> 是个非常奇怪的东西，需要注意的是 <strong>这个地方是 Parquet 内部，而不是用户层面的语义</strong>。意思就是，在 max-rep-level &gt; 1 的场景下，你用 max-rep-level 就会有奇怪的问题了</li><li><code>distinct_count</code> 稍微好理解一点，但需要注意这个对 null 的包含的情况</li><li>这里所有字段都是 optional 的，Statistics 本身也是 Optional 的</li></ol><p>请看：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Statistics per row group and per page</span></span><br><span class="line"><span class="comment"> * All fields are optional.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Statistics</span> &#123;</span><br><span class="line">   <span class="comment">/** count of null value in the column */</span></span><br><span class="line">   <span class="number">3</span>: optional i64 null_count;</span><br><span class="line">   <span class="comment">/** count of distinct values occurring */</span></span><br><span class="line">   <span class="number">4</span>: optional i64 distinct_count;</span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Min and max values for the column, determined by its ColumnOrder.</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * Values are encoded using PLAIN encoding, except that variable-length byte</span></span><br><span class="line"><span class="comment">    * arrays do not include a length prefix.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="number">5</span>: optional binary max_value;</span><br><span class="line">   <span class="number">6</span>: optional binary min_value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么，这里会有两个地方持有 Statistics: Page Header 和 ColumnChunkMetadata:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Data page header (这里是 data page v1 的 header, v2 也有, 懒得贴了, 不过 dict 没有, 只有 num_values) */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">DataPageHeader</span> &#123;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Optional statistics for the data in this page**/</span></span><br><span class="line">  <span class="number">5</span>: optional Statistics statistics;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>和：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Description for column metadata</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ColumnMetaData</span> &#123;</span></span><br><span class="line">  <span class="comment">/** Type of this column **/</span></span><br><span class="line">  <span class="number">1</span>: required Type type</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Set of all encodings used for this column. The purpose is to validate</span></span><br><span class="line"><span class="comment">   * whether we can decode those pages. **/</span></span><br><span class="line">  <span class="number">2</span>: required <span class="built_in">list</span>&lt;Encoding&gt; encodings</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Path in schema **/</span></span><br><span class="line">  <span class="number">3</span>: required <span class="built_in">list</span>&lt;<span class="built_in">string</span>&gt; path_in_schema</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** optional statistics for this column chunk */</span></span><br><span class="line">  <span class="number">12</span>: optional Statistics statistics;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Set of all encodings used for pages in this column chunk.</span></span><br><span class="line"><span class="comment">   * This information can be used to determine if all data pages are</span></span><br><span class="line"><span class="comment">   * dictionary encoded for example **/</span></span><br><span class="line">  <span class="number">13</span>: optional <span class="built_in">list</span>&lt;PageEncodingStats&gt; encoding_stats;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你可能会发现，我多留了个 <code>encoding_stats</code>，这是什么呢？别急后面会讲。还记得之前说的吗？这些 Statistics 本身会受 Schema 控制，这个</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Description for file metadata</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">FileMetaData</span> &#123;</span></span><br><span class="line">  <span class="comment">/** Parquet schema for this file.  This schema contains metadata for all the columns.</span></span><br><span class="line"><span class="comment">   * The schema is represented as a tree with a single root.  The nodes of the tree</span></span><br><span class="line"><span class="comment">   * are flattened to a list by doing a depth-first traversal.</span></span><br><span class="line"><span class="comment">   * The column metadata contains the path in the schema for that column which can be</span></span><br><span class="line"><span class="comment">   * used to map columns to nodes in the schema.</span></span><br><span class="line"><span class="comment">   * The first element is the root **/</span></span><br><span class="line">  <span class="number">2</span>: required <span class="built_in">list</span>&lt;SchemaElement&gt; schema;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Optional key/value metadata **/</span></span><br><span class="line">  <span class="number">5</span>: optional <span class="built_in">list</span>&lt;KeyValue&gt; key_value_metadata</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** String for application that wrote this file.  This should be in the format</span></span><br><span class="line"><span class="comment">   * &lt;Application&gt; version &lt;App Version&gt; (build &lt;App Build Hash&gt;).</span></span><br><span class="line"><span class="comment">   * e.g. impala version 1.0 (build 6cf94d29b2b7115df4de2c06e2ab4326d721eb55)</span></span><br><span class="line"><span class="comment">   **/</span></span><br><span class="line">  <span class="number">6</span>: optional <span class="built_in">string</span> created_by</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Sort order used for the min_value and max_value fields in the Statistics</span></span><br><span class="line"><span class="comment">   * objects and the min_values and max_values fields in the ColumnIndex</span></span><br><span class="line"><span class="comment">   * objects of each column in this file. Sort orders are listed in the order</span></span><br><span class="line"><span class="comment">   * matching the columns in the schema. The indexes are not necessary the same</span></span><br><span class="line"><span class="comment">   * though, because only leaf nodes of the schema are represented in the list</span></span><br><span class="line"><span class="comment">   * of sort orders.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Without column_orders, the meaning of the min_value and max_value fields</span></span><br><span class="line"><span class="comment">   * in the Statistics object and the ColumnIndex object is undefined. To ensure</span></span><br><span class="line"><span class="comment">   * well-defined behaviour, if these fields are written to a Parquet file,</span></span><br><span class="line"><span class="comment">   * column_orders must be written as well.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * The obsolete min and max fields in the Statistics object are always sorted</span></span><br><span class="line"><span class="comment">   * by signed comparison regardless of column_orders.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">7</span>: optional <span class="built_in">list</span>&lt;ColumnOrder&gt; column_orders;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里有个 <code>ColumnOrder</code>，正是对 Statistics 对应所有逻辑列的统计的总描述:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Empty struct to signal the order defined by the physical or logical type */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">TypeDefinedOrder</span> &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Union to specify the order used for the min_value and max_value fields for a</span></span><br><span class="line"><span class="comment"> * column. This union takes the role of an enhanced enum that allows rich</span></span><br><span class="line"><span class="comment"> * elements (which will be needed for a collation-based ordering in the future).</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Possible values are:</span></span><br><span class="line"><span class="comment"> * * TypeDefinedOrder - the column uses the order defined by its logical or</span></span><br><span class="line"><span class="comment"> *                      physical type (if there is no logical type).</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * If the reader does not support the value of this union, min and max stats</span></span><br><span class="line"><span class="comment"> * for this column should be ignored.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">union</span> <span class="title">ColumnOrder</span> &#123;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * The sort orders for logical types are:</span></span><br><span class="line"><span class="comment">   *   UTF8 - unsigned byte-wise comparison</span></span><br><span class="line"><span class="comment">   *   INT8 - signed comparison</span></span><br><span class="line"><span class="comment">   *   INT16 - signed comparison</span></span><br><span class="line"><span class="comment">   *   INT32 - signed comparison</span></span><br><span class="line"><span class="comment">   *   INT64 - signed comparison</span></span><br><span class="line"><span class="comment">   *   UINT8 - unsigned comparison</span></span><br><span class="line"><span class="comment">   *   UINT16 - unsigned comparison</span></span><br><span class="line"><span class="comment">   *   UINT32 - unsigned comparison</span></span><br><span class="line"><span class="comment">   *   UINT64 - unsigned comparison</span></span><br><span class="line"><span class="comment">   *   DECIMAL - signed comparison of the represented value</span></span><br><span class="line"><span class="comment">   *   DATE - signed comparison</span></span><br><span class="line"><span class="comment">   *   TIME_MILLIS - signed comparison</span></span><br><span class="line"><span class="comment">   *   TIME_MICROS - signed comparison</span></span><br><span class="line"><span class="comment">   *   TIMESTAMP_MILLIS - signed comparison</span></span><br><span class="line"><span class="comment">   *   TIMESTAMP_MICROS - signed comparison</span></span><br><span class="line"><span class="comment">   *   INTERVAL - unsigned comparison</span></span><br><span class="line"><span class="comment">   *   JSON - unsigned byte-wise comparison</span></span><br><span class="line"><span class="comment">   *   BSON - unsigned byte-wise comparison</span></span><br><span class="line"><span class="comment">   *   ENUM - unsigned byte-wise comparison</span></span><br><span class="line"><span class="comment">   *   LIST - undefined</span></span><br><span class="line"><span class="comment">   *   MAP - undefined</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * In the absence of logical types, the sort order is determined by the physical type:</span></span><br><span class="line"><span class="comment">   *   BOOLEAN - false, true</span></span><br><span class="line"><span class="comment">   *   INT32 - signed comparison</span></span><br><span class="line"><span class="comment">   *   INT64 - signed comparison</span></span><br><span class="line"><span class="comment">   *   INT96 (only used for legacy timestamps) - undefined</span></span><br><span class="line"><span class="comment">   *   FLOAT - signed comparison of the represented value (*)</span></span><br><span class="line"><span class="comment">   *   DOUBLE - signed comparison of the represented value (*)</span></span><br><span class="line"><span class="comment">   *   BYTE_ARRAY - unsigned byte-wise comparison</span></span><br><span class="line"><span class="comment">   *   FIXED_LEN_BYTE_ARRAY - unsigned byte-wise comparison</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * (*) Because the sorting order is not specified properly for floating</span></span><br><span class="line"><span class="comment">   *     point values (relations vs. total ordering) the following</span></span><br><span class="line"><span class="comment">   *     compatibility rules should be applied when reading statistics:</span></span><br><span class="line"><span class="comment">   *     - If the min is a NaN, it should be ignored.</span></span><br><span class="line"><span class="comment">   *     - If the max is a NaN, it should be ignored.</span></span><br><span class="line"><span class="comment">   *     - If the min is +0, the row group may contain -0 values as well.</span></span><br><span class="line"><span class="comment">   *     - If the max is -0, the row group may contain +0 values as well.</span></span><br><span class="line"><span class="comment">   *     - When looking for NaN values, min and max should be ignored.</span></span><br><span class="line"><span class="comment">   * </span></span><br><span class="line"><span class="comment">   *     When writing statistics the following rules should be followed:</span></span><br><span class="line"><span class="comment">   *     - NaNs should not be written to min or max statistics fields.</span></span><br><span class="line"><span class="comment">   *     - If the computed max value is zero (whether negative or positive),</span></span><br><span class="line"><span class="comment">   *       `+0.0` should be written into the max statistics field.</span></span><br><span class="line"><span class="comment">   *     - If the computed min value is zero (whether negative or positive),</span></span><br><span class="line"><span class="comment">   *       `-0.0` should be written into the min statistics field.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">1</span>: TypeDefinedOrder TYPE_ORDER;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这块内容比较大，我们可以看作 <strong>标准目前只实现了 TypeDefinedOrder</strong>，可以理解成，会以下面的 def 来挑选 order:</p><ul><li>LogicalType (或者 ConvertedType) 的 Order</li><li>Physical 的 Order (In the absence of logical types, the sort order is determined by the physical type)</li><li>对于 float，这里特殊处理了 NaN 的 Order，这里我这几天正好碰到一个类似的 issue:<ul><li><a href="https://issues.apache.org/jira/browse/PARQUET-2249">https://issues.apache.org/jira/browse/PARQUET-2249</a></li></ul></li></ul><p>我们可以做出如下<strong>总结</strong>：</p><ol><li><code>FileMetadata</code> 上有 Schema，同时也有 <code>column_orders</code><ol><li>Order 按照 LogicalType, Type 来定义</li></ol></li><li><code>ColumnChunkMetadata</code> 和 <code>Page</code> 上都有对应的 Statistics，Statistics 本身的 Order 遵循 <code>FileMetadata</code>. Statistics 本身和上面的内容都是 optional 的</li></ol><h3 id="Statistic-Dictionary-amp-Corner-Cases"><a href="#Statistic-Dictionary-amp-Corner-Cases" class="headerlink" title="Statistic: Dictionary &amp; Corner Cases"></a>Statistic: Dictionary &amp; Corner Cases</h3><p>你肯定觉得之前已经讲过 Statistics 了，但是之前其实还确实了一部分。我们知道 Page 有 min-max，那么：</p><ol><li>字典页面的 Min-Max 是怎么处理的呢？</li><li>字典页面的 Layout 是什么样子的呢？</li><li>Null 之类的，会不会进 ndv 呢？</li></ol><p>我们可以介绍一些 Parquet 字典格式的黑暗部分了。这里可以先简单翻阅一下 Parquet 的 Encoding 部分：<a href="https://github.com/apache/parquet-format/blob/master/Encodings.md#dictionary-encoding-plain_dictionary--2-and-rle_dictionary--8">https://github.com/apache/parquet-format/blob/master/Encodings.md#dictionary-encoding-plain_dictionary--2-and-rle_dictionary--8</a></p><p>这里会发现，字典有编码 <code>PLAIN_DICTIONARY</code> 和 <code>RLE_DICTIONARY</code>.</p><ul><li>PLAIN_DICTIONARY: 所有页面都是 <code>PLAIN_DICTIONARY</code> 标头，在 format-1.0 中使用</li><li>RLE_DICTIONARY: 字典(index)页是 <code>PLAIN</code>, Data 页面是 <code>RLE_DICTIONARY</code></li></ul><p>实际上，我们可以看下 Parquet 的 Properties:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> ParquetVersion::type <span class="title">version</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> parquet_version_; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> std::string <span class="title">created_by</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> parquet_created_by_; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">bool</span> <span class="title">page_checksum_enabled</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> page_checksum_enabled_; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> Encoding::type <span class="title">dictionary_index_encoding</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (parquet_version_ == ParquetVersion::PARQUET_1_0) &#123;</span><br><span class="line">    <span class="keyword">return</span> Encoding::PLAIN_DICTIONARY;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> Encoding::RLE_DICTIONARY;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> Encoding::type <span class="title">dictionary_page_encoding</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (parquet_version_ == ParquetVersion::PARQUET_1_0) &#123;</span><br><span class="line">    <span class="keyword">return</span> Encoding::PLAIN_DICTIONARY;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> Encoding::PLAIN;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么字典的 Statistics 是什么样子的呢？这部分我们可以在实现里学习，不过，在标准中，我们可以直接论断：</p><ul><li>字典数据页的 Statistics 和非字典数据页的 Statistics 逻辑上是一样的，此外，因为借用了字典，它能更好的去收集 ndv</li><li>字典索引页根本没有 Statistics</li></ul><p>那么 NaN 呢？实际上 NaN 并非 null，也是一种（根据 IEEE 754，可能是两种）values。</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>我们之前提到了，Parquet Spec 有 Physical 的 type (<code>Type</code>) 和 LogicalType (<code>LogicalType</code> 和兼容 parquet-format-v1 的 <code>ConvertedType</code>)。这个 Type 会有对应的 <code>ColumnOrder</code>。接下来我们要把这坨代码映射到 C++ 上。这部分在 Parquet C++ 实现上还是比较残缺的，我们也会尽量比对 Java 版本的实现。</p><p>实现分为两个部分: 读，写</p><h4 id="C-实现-写"><a href="#C-实现-写" class="headerlink" title="C++ 实现: 写"></a>C++ 实现: 写</h4><p>这里分为好几层：</p><ol><li>Encoding 层之上：怎么支持 Statistics</li><li>Page 的 Statistics</li><li>ColumnChunk 层的 Statistics</li><li>元信息收集</li></ol><p>首先，我们从 Comparator 类型讲起，讲讲他为啥好 / 不好.</p><p>Comparator 类型的构成:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Comparator (创建的工厂)</span><br><span class="line">- TypedComparator (Compare, GetMinMax, GetMinMaxSpaced)</span><br><span class="line">  - TypedComparatorImpl</span><br><span class="line">    + ComparatorHelper&lt;Type, bool is_signed&gt;</span><br></pre></td></tr></table></figure><p>这块东西相对比较简单，我们可以关注一下 signed 和 unsigned 的实现。他们由 <code>SortOrder</code> 指定。<code>SortOrder</code> 是上层的概念，我们之后会介绍。我们先介绍整数比较：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DType&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">UnsignedCompareHelperBase</span> &#123;</span><br><span class="line">  <span class="keyword">using</span> T = <span class="keyword">typename</span> DType::c_type;</span><br><span class="line">  <span class="keyword">using</span> UCType = <span class="keyword">typename</span> std::make_unsigned&lt;T&gt;::type;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">static_assert</span>(!std::is_same&lt;T, UCType&gt;::value, <span class="string">&quot;T is unsigned&quot;</span>);</span><br><span class="line">  <span class="built_in">static_assert</span>(<span class="built_in">sizeof</span>(T) == <span class="built_in">sizeof</span>(UCType), <span class="string">&quot;T and UCType not the same size&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// <span class="doctag">NOTE:</span> according to the C++ spec, unsigned-to-signed conversion is</span></span><br><span class="line">  <span class="comment">// implementation-defined if the original value does not fit in the signed type</span></span><br><span class="line">  <span class="comment">// (i.e., two&#x27;s complement cannot be assumed even on mainstream machines,</span></span><br><span class="line">  <span class="comment">// because the compiler may decide otherwise).  Hence the use of `SafeCopy`</span></span><br><span class="line">  <span class="comment">// below for deterministic bit-casting.</span></span><br><span class="line">  <span class="comment">// (see &quot;Integer conversions&quot; in</span></span><br><span class="line">  <span class="comment">//  https://en.cppreference.com/w/cpp/language/implicit_conversion)</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="type">const</span> T <span class="title">DefaultMin</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">SafeCopy</span>&lt;T&gt;(std::numeric_limits&lt;UCType&gt;::<span class="built_in">max</span>()); &#125;</span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="type">const</span> T <span class="title">DefaultMax</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="number">0</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="type">bool</span> <span class="title">Compare</span><span class="params">(<span class="type">int</span> type_length, T a, T b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">SafeCopy</span>&lt;UCType&gt;(a) &lt; <span class="built_in">SafeCopy</span>&lt;UCType&gt;(b);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> T <span class="title">Min</span><span class="params">(<span class="type">int</span> type_length, T a, T b)</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">Compare</span>(type_length, a, b) ? a : b; &#125;</span><br><span class="line">  <span class="function"><span class="type">static</span> T <span class="title">Max</span><span class="params">(<span class="type">int</span> type_length, T a, T b)</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">Compare</span>(type_length, a, b) ? b : a; &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>因为 <code>DType::c_type</code> 对应是 signed, 所以这里操作了一套 unsigned 来处理。</p><p>那么，还有个比较 trickey 的地方是 INT96 的比较，不过 INT96 已经 deprecated 了，我就偷懒了。重点介绍一下浮点数:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DType, <span class="type">bool</span> is_signed&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">CompareHelper</span> &#123;</span><br><span class="line">  <span class="keyword">using</span> T = <span class="keyword">typename</span> DType::c_type;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">static_assert</span>(!std::is_unsigned&lt;T&gt;::value || std::is_same&lt;T, <span class="type">bool</span>&gt;::value,</span><br><span class="line">                <span class="string">&quot;T is an unsigned numeric&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">constexpr</span> <span class="type">static</span> T <span class="title">DefaultMin</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> std::numeric_limits&lt;T&gt;::<span class="built_in">max</span>(); &#125;</span><br><span class="line">  <span class="function"><span class="keyword">constexpr</span> <span class="type">static</span> T <span class="title">DefaultMax</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> std::numeric_limits&lt;T&gt;::<span class="built_in">lowest</span>(); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// MSVC17 fix, isnan is not overloaded for IntegralType as per C++11</span></span><br><span class="line">  <span class="comment">// standard requirements.</span></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T1 = T&gt;</span><br><span class="line">  <span class="type">static</span> ::arrow::<span class="type">enable_if_t</span>&lt;std::is_floating_point&lt;T1&gt;::value, T&gt; <span class="built_in">Coalesce</span>(T val,</span><br><span class="line">                                                                             T fallback) &#123;</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">isnan</span>(val) ? fallback : val;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T1 = T&gt;</span><br><span class="line">  <span class="type">static</span> ::arrow::<span class="type">enable_if_t</span>&lt;!std::is_floating_point&lt;T1&gt;::value, T&gt; <span class="built_in">Coalesce</span>(</span><br><span class="line">      T val, T fallback) &#123;</span><br><span class="line">    <span class="keyword">return</span> val;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">bool</span> <span class="title">Compare</span><span class="params">(<span class="type">int</span> type_length, <span class="type">const</span> T&amp; a, <span class="type">const</span> T&amp; b)</span> </span>&#123; <span class="keyword">return</span> a &lt; b; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> T <span class="title">Min</span><span class="params">(<span class="type">int</span> type_length, T a, T b)</span> </span>&#123; <span class="keyword">return</span> a &lt; b ? a : b; &#125;</span><br><span class="line">  <span class="function"><span class="type">static</span> T <span class="title">Max</span><span class="params">(<span class="type">int</span> type_length, T a, T b)</span> </span>&#123; <span class="keyword">return</span> a &lt; b ? b : a; &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个地方用一个 Coalesce 来强制干掉 NaN. 关于浮点数操作，可以看 Spec：</p><ul><li>IEEE 754 - 2019 浮点算数标准 - nicholaswilde的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/480834719">https://zhuanlan.zhihu.com/p/480834719</a></li><li><a href="https://stackoverflow.com/questions/38798791/nan-comparison-rule-in-c-c">https://stackoverflow.com/questions/38798791/nan-comparison-rule-in-c-c</a></li><li>注意一下标准库提供的几个抽象，下列可以简单说一下<ul><li><code>max</code>: 最大值</li><li><code>min</code>: 对浮点数来说是最小的正数</li><li><code>lowest</code> 最小（非 NaN）值</li><li><code>denorm_min</code> ，可以表示最靠近 0 的数</li></ul></li></ul><p>这个地方封装了一层后，最后我们回到上层的 <code>Make</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::shared_ptr&lt;Comparator&gt; <span class="title">Comparator::Make</span><span class="params">(Type::type physical_type,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             SortOrder::type sort_order,</span></span></span><br><span class="line"><span class="params"><span class="function">                                             <span class="type">int</span> type_length)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (SortOrder::SIGNED == sort_order) &#123;</span><br><span class="line">    <span class="keyword">switch</span> (physical_type) &#123;</span><br><span class="line">      <span class="keyword">case</span> Type::BOOLEAN:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">true</span>, BooleanType&gt;&gt;();</span><br><span class="line">      <span class="keyword">case</span> Type::INT32:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">true</span>, Int32Type&gt;&gt;();</span><br><span class="line">      <span class="keyword">case</span> Type::INT64:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">true</span>, Int64Type&gt;&gt;();</span><br><span class="line">      <span class="keyword">case</span> Type::INT96:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">true</span>, Int96Type&gt;&gt;();</span><br><span class="line">      <span class="keyword">case</span> Type::FLOAT:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">true</span>, FloatType&gt;&gt;();</span><br><span class="line">      <span class="keyword">case</span> Type::DOUBLE:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">true</span>, DoubleType&gt;&gt;();</span><br><span class="line">      <span class="keyword">case</span> Type::BYTE_ARRAY:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">true</span>, ByteArrayType&gt;&gt;();</span><br><span class="line">      <span class="keyword">case</span> Type::FIXED_LEN_BYTE_ARRAY:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">true</span>, FLBAType&gt;&gt;(type_length);</span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">        ParquetException::<span class="built_in">NYI</span>(<span class="string">&quot;Signed Compare not implemented&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (SortOrder::UNSIGNED == sort_order) &#123;</span><br><span class="line">    <span class="keyword">switch</span> (physical_type) &#123;</span><br><span class="line">      <span class="keyword">case</span> Type::INT32:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">false</span>, Int32Type&gt;&gt;();</span><br><span class="line">      <span class="keyword">case</span> Type::INT64:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">false</span>, Int64Type&gt;&gt;();</span><br><span class="line">      <span class="keyword">case</span> Type::INT96:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">false</span>, Int96Type&gt;&gt;();</span><br><span class="line">      <span class="keyword">case</span> Type::BYTE_ARRAY:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">false</span>, ByteArrayType&gt;&gt;();</span><br><span class="line">      <span class="keyword">case</span> Type::FIXED_LEN_BYTE_ARRAY:</span><br><span class="line">        <span class="keyword">return</span> std::make_shared&lt;TypedComparatorImpl&lt;<span class="literal">false</span>, FLBAType&gt;&gt;(type_length);</span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">        ParquetException::<span class="built_in">NYI</span>(<span class="string">&quot;Unsigned Compare not implemented&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="built_in">ParquetException</span>(<span class="string">&quot;UNKNOWN Sort Order&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>没有 <code>SortOrder</code> 的东西，是创建不出 Comparator 的，这个地方可以留意一下。我们回到 Statistics，它的多层级类似 Comparator。它对外会走一个叫做 <code>EncodedStatistics</code> 的东西，它算是 thrift <code>Statistics</code> 的一个包装，用户不需要直接和 <code>Statistics</code> 打交道。（这玩意不包括 num_values…但是 num_values 需要靠 Statistics 收集）。</p><p>它的内部结构如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Statistics (nullCount, minmax, Encode)</span><br><span class="line">- TypedStatistics</span><br><span class="line">  - TypedStatisticsImpl</span><br><span class="line">    + TypedComparator</span><br></pre></td></tr></table></figure><p>如果创建失败，比如 ColumnDescriptor 没有 SortOrder, 这玩意根本创建不出来。它可以根据 arrow 写入来更新内部的状态。</p><p>关于更新状态，这里也可以看作是一个联动的状态：</p><p>更新的时候：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::pair&lt;T, T&gt; <span class="title">GetMinMax</span><span class="params">(<span class="type">const</span> T* values, <span class="type">int64_t</span> length)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">  <span class="built_in">DCHECK_GT</span>(length, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  T min = Helper::<span class="built_in">DefaultMin</span>();</span><br><span class="line">  T max = Helper::<span class="built_in">DefaultMax</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int64_t</span> i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> val = <span class="built_in">SafeLoad</span>(values + i);</span><br><span class="line">    min = Helper::<span class="built_in">Min</span>(type_length_, min, Helper::<span class="built_in">Coalesce</span>(val, Helper::<span class="built_in">DefaultMin</span>()));</span><br><span class="line">    max = Helper::<span class="built_in">Max</span>(type_length_, max, Helper::<span class="built_in">Coalesce</span>(val, Helper::<span class="built_in">DefaultMax</span>()));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> &#123;min, max&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>设置的时候：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// In case of floating point types, the following rules are applied (as per</span></span><br><span class="line"><span class="comment">// upstream parquet-mr):</span></span><br><span class="line"><span class="comment">// - If any of min/max is NaN, return nothing.</span></span><br><span class="line"><span class="comment">// - If min is 0.0f, replace with -0.0f</span></span><br><span class="line"><span class="comment">// - If max is -0.0f, replace with 0.0f</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">::arrow::<span class="type">enable_if_t</span>&lt;std::is_floating_point&lt;T&gt;::value, optional&lt;std::pair&lt;T, T&gt;&gt;&gt;</span><br><span class="line"><span class="built_in">CleanStatistic</span>(std::pair&lt;T, T&gt; min_max) &#123;</span><br><span class="line">  T min = min_max.first;</span><br><span class="line">  T max = min_max.second;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Ignore if one of the value is nan.</span></span><br><span class="line">  <span class="keyword">if</span> (std::<span class="built_in">isnan</span>(min) || std::<span class="built_in">isnan</span>(max)) &#123;</span><br><span class="line">    <span class="keyword">return</span> ::std::<span class="literal">nullopt</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (min == std::numeric_limits&lt;T&gt;::<span class="built_in">max</span>() &amp;&amp; max == std::numeric_limits&lt;T&gt;::<span class="built_in">lowest</span>()) &#123;</span><br><span class="line">    <span class="keyword">return</span> ::std::<span class="literal">nullopt</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  T zero&#123;&#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (min == zero &amp;&amp; !std::<span class="built_in">signbit</span>(min)) &#123;</span><br><span class="line">    min = -min;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (max == zero &amp;&amp; std::<span class="built_in">signbit</span>(max)) &#123;</span><br><span class="line">    max = -max;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> &#123;&#123;min, max&#125;&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">SetMinMaxPair</span><span class="params">(std::pair&lt;T, T&gt; min_max)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// CleanStatistic can return a nullopt in case of erroneous values, e.g. NaN</span></span><br><span class="line">    <span class="keyword">auto</span> maybe_min_max = <span class="built_in">CleanStatistic</span>(min_max);</span><br><span class="line">    <span class="keyword">if</span> (!maybe_min_max) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> min = maybe_min_max.<span class="built_in">value</span>().first;</span><br><span class="line">    <span class="keyword">auto</span> max = maybe_min_max.<span class="built_in">value</span>().second;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!has_min_max_) &#123;</span><br><span class="line">      has_min_max_ = <span class="literal">true</span>;</span><br><span class="line">      <span class="built_in">Copy</span>(min, &amp;min_, min_buffer_.<span class="built_in">get</span>());</span><br><span class="line">      <span class="built_in">Copy</span>(max, &amp;max_, max_buffer_.<span class="built_in">get</span>());</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="built_in">Copy</span>(comparator_-&gt;<span class="built_in">Compare</span>(min_, min) ? min_ : min, &amp;min_, min_buffer_.<span class="built_in">get</span>());</span><br><span class="line">      <span class="built_in">Copy</span>(comparator_-&gt;<span class="built_in">Compare</span>(max_, max) ? max : max_, &amp;max_, max_buffer_.<span class="built_in">get</span>());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>在这个层面上，我们就能很好理解 min-max 了。</p><h5 id="SortOrder"><a href="#SortOrder" class="headerlink" title="SortOrder"></a>SortOrder</h5><p>我们上节介绍 Schema 的时候没介绍 SortOrder，因为 Parquet Standard 里面没有这个东西（有叫 sort_order 的别的东西）。这个是 C++ Parquet 内部实现 order 用的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">SortOrder::type <span class="title">sort_order</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> la = <span class="built_in">logical_type</span>();</span><br><span class="line">  <span class="keyword">auto</span> pt = <span class="built_in">physical_type</span>();</span><br><span class="line">  <span class="keyword">return</span> la ? <span class="built_in">GetSortOrder</span>(la, pt) : <span class="built_in">GetSortOrder</span>(<span class="built_in">converted_type</span>(), pt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里相当于 spec 里面的 <code>TypeDefinedOrder</code>，实现上当成了多份 SIGNED, UNSIGNED, UNKNOWN. <code>LogicalType</code> 都会定义自己的 SortOrder，比如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LogicalType</span>::Impl::Int <span class="keyword">final</span> : <span class="keyword">public</span> LogicalType::Impl::Compatible,</span><br><span class="line">                                     <span class="keyword">public</span> LogicalType::Impl::Applicable &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">IntLogicalType</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">is_applicable</span><span class="params">(parquet::Type::type primitive_type,</span></span></span><br><span class="line"><span class="params"><span class="function">                     <span class="type">int32_t</span> primitive_length = <span class="number">-1</span>)</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">is_compatible</span><span class="params">(ConvertedType::type converted_type,</span></span></span><br><span class="line"><span class="params"><span class="function">                     schema::DecimalMetadata converted_decimal_metadata)</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function">ConvertedType::type <span class="title">ToConvertedType</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      schema::DecimalMetadata* out_decimal_metadata)</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function">std::string <span class="title">ToString</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function">std::string <span class="title">ToJSON</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function">format::LogicalType <span class="title">ToThrift</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">Equals</span><span class="params">(<span class="type">const</span> LogicalType&amp; other)</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">bit_width</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> width_; &#125;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">is_signed</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> signed_; &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="built_in">Int</span>(<span class="type">int</span> w, <span class="type">bool</span> s)</span><br><span class="line">      : LogicalType::<span class="built_in">Impl</span>(LogicalType::Type::INT,</span><br><span class="line">                          (s ? SortOrder::SIGNED : SortOrder::UNSIGNED)),</span><br><span class="line">        <span class="built_in">width_</span>(w),</span><br><span class="line">        <span class="built_in">signed_</span>(s) &#123;&#125;</span><br><span class="line">  <span class="type">int</span> width_ = <span class="number">0</span>;</span><br><span class="line">  <span class="type">bool</span> signed_ = <span class="literal">false</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>也有一些类型，比如 VOID，对应的 Statistics 是 undefined.</p><p>目前的实现有个问题，如果是 undefined (甚至是类型标志奇怪了一些)，就会产生 comparator 生成的异常，然后无法产生 statistics。这些会影响 interval 相关的类型。</p><p>在最终写入的时候，会有两种 statistics:</p><ol><li><code>page_statistics</code>: 每个页面上的</li><li><code>column_statistics</code>: 汇总的 statistics.</li></ol><p>在创建的时候，内容如下:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">TypedColumnWriterImpl</span>(ColumnChunkMetaDataBuilder* metadata,</span><br><span class="line">                      std::unique_ptr&lt;PageWriter&gt; pager, <span class="type">const</span> <span class="type">bool</span> use_dictionary,</span><br><span class="line">                      Encoding::type encoding, <span class="type">const</span> WriterProperties* properties) &#123;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">  <span class="keyword">if</span> (properties-&gt;<span class="built_in">statistics_enabled</span>(descr_-&gt;<span class="built_in">path</span>()) &amp;&amp;</span><br><span class="line">      (SortOrder::UNKNOWN != descr_-&gt;<span class="built_in">sort_order</span>())) &#123;</span><br><span class="line">    page_statistics_ = <span class="built_in">MakeStatistics</span>&lt;DType&gt;(descr_, allocator_);</span><br><span class="line">    chunk_statistics_ = <span class="built_in">MakeStatistics</span>&lt;DType&gt;(descr_, allocator_);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>每个页面会收集 page statistics，然后写入：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">EncodedStatistics <span class="title">Encode</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">  EncodedStatistics s;</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">HasMinMax</span>()) &#123;</span><br><span class="line">    s.<span class="built_in">set_min</span>(<span class="keyword">this</span>-&gt;<span class="built_in">EncodeMin</span>());</span><br><span class="line">    s.<span class="built_in">set_max</span>(<span class="keyword">this</span>-&gt;<span class="built_in">EncodeMax</span>());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">HasNullCount</span>()) &#123;</span><br><span class="line">    s.<span class="built_in">set_null_count</span>(<span class="keyword">this</span>-&gt;<span class="built_in">null_count</span>());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>和：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function">EncodedStatistics <span class="title">GetPageStatistics</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">   EncodedStatistics result;</span><br><span class="line">   <span class="keyword">if</span> (page_statistics_) result = page_statistics_-&gt;<span class="built_in">Encode</span>();</span><br><span class="line">   <span class="keyword">return</span> result;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// 具体写入</span></span><br><span class="line"> EncodedStatistics page_stats = <span class="built_in">GetPageStatistics</span>();</span><br><span class="line"> page_stats.<span class="built_in">ApplyStatSizeLimits</span>(properties_-&gt;<span class="built_in">max_statistics_size</span>(descr_-&gt;<span class="built_in">path</span>()));</span><br><span class="line"> page_stats.<span class="built_in">set_is_signed</span>(SortOrder::SIGNED == descr_-&gt;<span class="built_in">sort_order</span>());</span><br><span class="line"> <span class="built_in">ResetPageStatistics</span>();</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">std::unique_ptr&lt;DataPage&gt; page_ptr = std::<span class="built_in">make_unique</span>&lt;DataPageV1&gt;(</span><br><span class="line"> compressed_data_copy, num_values, encoding_, Encoding::RLE, Encoding::RLE,</span><br><span class="line"> uncompressed_size, page_stats);</span><br></pre></td></tr></table></figure><p>最后，借助 <code>ToThrift</code> 转化：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="keyword">inline</span> format::Statistics <span class="title">ToThrift</span><span class="params">(<span class="type">const</span> EncodedStatistics&amp; stats)</span> </span>&#123;</span><br><span class="line">  format::Statistics statistics;</span><br><span class="line">  <span class="keyword">if</span> (stats.has_min) &#123;</span><br><span class="line">    statistics.__set_min_value(stats.<span class="built_in">min</span>());</span><br><span class="line">    <span class="comment">// If the order is SIGNED, then the old min value must be set too.</span></span><br><span class="line">    <span class="comment">// This for backward compatibility</span></span><br><span class="line">    <span class="keyword">if</span> (stats.<span class="built_in">is_signed</span>()) &#123;</span><br><span class="line">      statistics.__set_min(stats.<span class="built_in">min</span>());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (stats.has_max) &#123;</span><br><span class="line">    statistics.__set_max_value(stats.<span class="built_in">max</span>());</span><br><span class="line">    <span class="comment">// If the order is SIGNED, then the old max value must be set too.</span></span><br><span class="line">    <span class="comment">// This for backward compatibility</span></span><br><span class="line">    <span class="keyword">if</span> (stats.<span class="built_in">is_signed</span>()) &#123;</span><br><span class="line">      statistics.__set_max(stats.<span class="built_in">max</span>());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (stats.has_null_count) &#123;</span><br><span class="line">    statistics.__set_null_count(stats.null_count);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (stats.has_distinct_count) &#123;</span><br><span class="line">    statistics.__set_distinct_count(stats.distinct_count);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> statistics;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面是 Page 层，ColumnChunk 层会 Merge Page 层的，直到完成：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">ResetPageStatistics</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (chunk_statistics_ != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    chunk_statistics_-&gt;<span class="built_in">Merge</span>(*page_statistics_);</span><br><span class="line">    page_statistics_-&gt;<span class="built_in">Reset</span>();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="C-实现-读"><a href="#C-实现-读" class="headerlink" title="C++ 实现: 读"></a>C++ 实现: 读</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Extracts encoded statistics from V1 and V2 data page headers</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> H&gt;</span><br><span class="line"><span class="function">EncodedStatistics <span class="title">ExtractStatsFromHeader</span><span class="params">(<span class="type">const</span> H&amp; header)</span> </span>&#123;</span><br><span class="line">  EncodedStatistics page_statistics;</span><br><span class="line">  <span class="keyword">if</span> (!header.__isset.statistics) &#123;</span><br><span class="line">    <span class="keyword">return</span> page_statistics;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">const</span> format::Statistics&amp; stats = header.statistics;</span><br><span class="line">  <span class="comment">// Use the new V2 min-max statistics over the former one if it is filled</span></span><br><span class="line">  <span class="keyword">if</span> (stats.__isset.max_value || stats.__isset.min_value) &#123;</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> check if the column_order is TYPE_DEFINED_ORDER.</span></span><br><span class="line">    <span class="keyword">if</span> (stats.__isset.max_value) &#123;</span><br><span class="line">      page_statistics.<span class="built_in">set_max</span>(stats.max_value);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (stats.__isset.min_value) &#123;</span><br><span class="line">      page_statistics.<span class="built_in">set_min</span>(stats.min_value);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (stats.__isset.max || stats.__isset.min) &#123;</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> check created_by to see if it is corrupted for some types.</span></span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> check if the sort_order is SIGNED.</span></span><br><span class="line">    <span class="keyword">if</span> (stats.__isset.max) &#123;</span><br><span class="line">      page_statistics.<span class="built_in">set_max</span>(stats.max);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (stats.__isset.min) &#123;</span><br><span class="line">      page_statistics.<span class="built_in">set_min</span>(stats.min);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (stats.__isset.null_count) &#123;</span><br><span class="line">    page_statistics.<span class="built_in">set_null_count</span>(stats.null_count);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (stats.__isset.distinct_count) &#123;</span><br><span class="line">    page_statistics.<span class="built_in">set_distinct_count</span>(stats.distinct_count);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> page_statistics;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后 C++ 新版本中，有个 <code>DataPageStats</code> 用到了这个玩意。</p><p>实现的缺点</p><ul><li>字典页面没有收集 ndv</li><li>需要 comparator。LogicalType Comparator 缺失的话，会完全没有 Statistics，对 Interval 之类的类型很不友好</li><li>有几部分的实现感觉对读出来处理不太友好，比如 null_count / ndv</li></ul><h2 id="PageStats-amp-ColumnIndex"><a href="#PageStats-amp-ColumnIndex" class="headerlink" title="PageStats &amp; ColumnIndex"></a>PageStats &amp; ColumnIndex</h2><p>ColumnChunk 上还会有 PageStatistics:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/** Set of all encodings used for pages in this column chunk.</span><br><span class="line"> * This information can be used to determine if all data pages are</span><br><span class="line"> * dictionary encoded for example **/</span><br><span class="line">13: optional list&lt;PageEncodingStats&gt; encoding_stats;</span><br></pre></td></tr></table></figure><p>这个是决定内部页面的 encoding 的，可以做 Dict encoding 检测。</p><p>ColumnIndex 上会有一些东西，你看看就懂了：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Description for ColumnIndex.</span></span><br><span class="line"><span class="comment"> * Each &lt;array-field&gt;[i] refers to the page at OffsetIndex.page_locations[i]</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ColumnIndex</span> &#123;</span></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A list of Boolean values to determine the validity of the corresponding</span></span><br><span class="line"><span class="comment">   * min and max values. If true, a page contains only null values, and writers</span></span><br><span class="line"><span class="comment">   * have to set the corresponding entries in min_values and max_values to</span></span><br><span class="line"><span class="comment">   * byte[0], so that all lists have the same length. If false, the</span></span><br><span class="line"><span class="comment">   * corresponding entries in min_values and max_values must be valid.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">1</span>: required <span class="built_in">list</span>&lt;<span class="type">bool</span>&gt; null_pages</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Two lists containing lower and upper bounds for the values of each page</span></span><br><span class="line"><span class="comment">   * determined by the ColumnOrder of the column. These may be the actual</span></span><br><span class="line"><span class="comment">   * minimum and maximum values found on a page, but can also be (more compact)</span></span><br><span class="line"><span class="comment">   * values that do not exist on a page. For example, instead of storing &quot;&quot;Blart</span></span><br><span class="line"><span class="comment">   * Versenwald III&quot;, a writer may set min_values[i]=&quot;B&quot;, max_values[i]=&quot;C&quot;.</span></span><br><span class="line"><span class="comment">   * Such more compact values must still be valid values within the column&#x27;s</span></span><br><span class="line"><span class="comment">   * logical type. Readers must make sure that list entries are populated before</span></span><br><span class="line"><span class="comment">   * using them by inspecting null_pages.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">2</span>: required <span class="built_in">list</span>&lt;binary&gt; min_values</span><br><span class="line">  <span class="number">3</span>: required <span class="built_in">list</span>&lt;binary&gt; max_values</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Stores whether both min_values and max_values are ordered and if so, in</span></span><br><span class="line"><span class="comment">   * which direction. This allows readers to perform binary searches in both</span></span><br><span class="line"><span class="comment">   * lists. Readers cannot assume that max_values[i] &lt;= min_values[i+1], even</span></span><br><span class="line"><span class="comment">   * if the lists are ordered.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">4</span>: required BoundaryOrder boundary_order</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** A list containing the number of null values for each page **/</span></span><br><span class="line">  <span class="number">5</span>: optional <span class="built_in">list</span>&lt;i64&gt; null_counts</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里有个问题，就是对 NaN 的处理，这块正在 RFC 处理中：<a href="https://issues.apache.org/jira/browse/PARQUET-2249">https://issues.apache.org/jira/browse/PARQUET-2249</a> .</p><p>其他很多部分其实也依赖 PageStatistics 的收集和隐含的 SortOrder。哎，这下令人唏嘘了</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Parquet C++: from schema to schema</title>
      <link href="/2023/02/18/Parquet-C-from-schema-to-schema/"/>
      <url>/2023/02/18/Parquet-C-from-schema-to-schema/</url>
      
        <content type="html"><![CDATA[<p>这节我们讨论一个重要但是 trivial 的话题，Schema。这个话题在处理类型的时候额外重要，用户需要选择类型，来构建合理的抽象，而这里有几个问题：</p><ul><li>（这里我们讨论 Primitive Types） <a href="https://github.com/apache/parquet-format/blob/master/LogicalTypes.md">https://github.com/apache/parquet-format/blob/master/LogicalTypes.md</a> Parquet 物理类型给的并不多，而 LogicalType 支持不是完全的支持。这里面临一个类型映射的关系</li><li>每个类型的 Order 之类的都是不一样的，Order 会影响对应 Statistics 的生成</li><li>用户的类型、Statistics <strong>不一定等于</strong> Parquet 内部的 Statistics，这个有点反直觉，最典型的场景是 count 和 null。此外还要考虑很多 Sort Order 的东西</li><li>外头的数据写进 Parquet 也需要有一个合理的 Order Mapping 和对应的 Mapping，来完成高效的写</li></ul><p>这整个链路并不复杂，但是很繁琐。但是如果不理解这一块，必然会碰到问题。</p><h2 id="Arrow-Schema"><a href="#Arrow-Schema" class="headerlink" title="Arrow Schema"></a>Arrow Schema</h2><p>arrow schema 路径在 <code>src/arrow/type.h</code>。它是一个很干净的 arrow schema. 在内存中是一个树形结构</p><p>关于 fieldId, 这个需要用户手动进行编码：</p><blockquote><p>The parquet format supports an optional integer field_id which can be assigned to a field. Arrow will convert these field IDs to a metadata key named PARQUET:field_id on the appropriate field.</p></blockquote><h2 id="Parquet-Schema"><a href="#Parquet-Schema" class="headerlink" title="Parquet Schema"></a>Parquet Schema</h2><p>parquet schema 在内存中是一个树形的层级关系，写到磁盘上会以 dfs 的形式 flatten. 在标准中（见系列 1）有比较详细的描述。这里简单回顾一下存储中的 schema: <a href="https://blog.mwish.me/2022/09/18/Parquet-Part1-Basic/#%E7%B1%BB%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%92%8C%E9%80%BB%E8%BE%91%E7%B1%BB%E5%9E%8B">https://blog.mwish.me/2022/09/18/Parquet-Part1-Basic/#%E7%B1%BB%E5%9E%8B%E7%B3%BB%E7%BB%9F%E5%92%8C%E9%80%BB%E8%BE%91%E7%B1%BB%E5%9E%8B</a></p><ol><li><code>SchemaElement</code> 树的叶子结点，包括对应的类型（Logical, Physical）和一些奇怪的字段（FLBA 长度、浮点数精度）</li><li><code>FileMetaData</code> 中包含 <code>list&lt;SchemaElement&gt; schema</code> </li></ol><p>上面是存储的。内存结构对应路径在 <code>src/parquet/schema.h</code>. 简单介绍一下，这块逻辑如下：</p><ul><li><code>ColumnPath</code>: Schema 中某个路径。实现上是一个 <code>vector&lt;string&gt;</code>, 可以以 dot-path 的形式取路径 (<code>root.struct.field</code>)</li><li><code>Node</code>: 单个节点的 base-class，需要注意的是，这个 Node <strong>是 Parquet 中的 Node</strong>，而不完全等于用户的 schema<ul><li>Node 有 Primitive 和 Group 两种类型，可以理解 Group 是带崽的</li><li>包含 RepititionType、<code>field_id</code>，（可能存在的）父亲节点，本节点的 name、LogicalType (这里还实现了 ConvertType，恶心啊)</li></ul></li><li><code>PrimitiveNode</code>: 包含 PhysicalType，自然也就包含 SchemaElement 中 <em>那些奇怪的字段</em> 和 ColumnOrder</li><li><code>GroupNode</code>: 在 Parquet 内部的 map，相当于只有 LogicalType (只有 <code>PrimitiveNode</code> 有 Physical Type)，这层没有 fieldId 的概念</li></ul><p>上面是 Node 级别，下面是 Column (<strong>Physical</strong>) 级别的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// The ColumnDescriptor encapsulates information necessary to interpret</span></span><br><span class="line"><span class="comment">// primitive column data in the context of a particular schema. We have to</span></span><br><span class="line"><span class="comment">// examine the node structure of a column&#x27;s path to the root in the schema tree</span></span><br><span class="line"><span class="comment">// to be able to reassemble the nested structure from the repetition and</span></span><br><span class="line"><span class="comment">// definition levels.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PARQUET_EXPORT</span> ColumnDescriptor &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">ColumnDescriptor</span>(schema::NodePtr node, <span class="type">int16_t</span> max_definition_level,</span><br><span class="line">                   <span class="type">int16_t</span> max_repetition_level,</span><br><span class="line">                   <span class="type">const</span> SchemaDescriptor* schema_descr = NULLPTR);</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  schema::NodePtr node_;</span><br><span class="line">  <span class="type">const</span> schema::PrimitiveNode* primitive_node_;</span><br><span class="line"></span><br><span class="line">  <span class="type">int16_t</span> max_definition_level_;</span><br><span class="line">  <span class="type">int16_t</span> max_repetition_level_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>和对应的 <code>SchemaDescriptor</code>，这里是 Parquet Schema 总的 Container，也就是 Parquet 内部 Schema 的核心了。我们需要知道：</p><ol><li>RootNode 一定是个 <code>struct</code>，但某种意义上，它的 field-id 其实无所谓</li><li>RootNode 的第几个字段标志这个 Schema 长什么鬼样</li><li>可以通过 <code>Column(idx)</code> 取到 <strong>物理上的 Column</strong></li></ol><p>好了，这样你就可以从 <code>SchemaDescriptor</code> 拿到对应的东西了，顺带说一句，SchemaDescriptor 结构很简单好玩，我一定得贴出来看看：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">ColumnDescriptor</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Root Node</span></span><br><span class="line">  schema::NodePtr schema_;</span><br><span class="line">  <span class="comment">// Root Node</span></span><br><span class="line">  <span class="type">const</span> schema::GroupNode* group_node_;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">BuildTree</span><span class="params">(<span class="type">const</span> schema::NodePtr&amp; node, <span class="type">int16_t</span> max_def_level,</span></span></span><br><span class="line"><span class="params"><span class="function">                 <span class="type">int16_t</span> max_rep_level, <span class="type">const</span> schema::NodePtr&amp; base)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Result of leaf node / tree analysis</span></span><br><span class="line">  std::vector&lt;ColumnDescriptor&gt; leaves_;</span><br><span class="line"></span><br><span class="line">  std::unordered_map&lt;<span class="type">const</span> schema::PrimitiveNode*, <span class="type">int</span>&gt; node_to_leaf_index_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Mapping between leaf nodes and root group of leaf (first node</span></span><br><span class="line">  <span class="comment">// below the schema&#x27;s root group)</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// For example, the leaf `a.b.c.d` would have a link back to `a`</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// -- a  &lt;------</span></span><br><span class="line">  <span class="comment">// -- -- b     |</span></span><br><span class="line">  <span class="comment">// -- -- -- c  |</span></span><br><span class="line">  <span class="comment">// -- -- -- -- d</span></span><br><span class="line">  std::unordered_map&lt;<span class="type">int</span>, schema::NodePtr&gt; leaf_to_base_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Mapping between ColumnPath DotString to the leaf index</span></span><br><span class="line">  std::unordered_multimap&lt;std::string, <span class="type">int</span>&gt; leaf_to_idx_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="Serialize-转化为-Thrift"><a href="#Serialize-转化为-Thrift" class="headerlink" title="Serialize: 转化为 Thrift"></a>Serialize: 转化为 Thrift</h3><p>上面说的内存结构和存储结构肯定是能够互相转换的，见：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">ToParquet</span><span class="params">(<span class="type">const</span> GroupNode* schema, std::vector&lt;format::SchemaElement&gt;* out)</span> </span>&#123;</span><br><span class="line">  <span class="function">SchemaVisitor <span class="title">visitor</span><span class="params">(out)</span></span>;</span><br><span class="line">  schema-&gt;<span class="built_in">VisitConst</span>(&amp;visitor);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里会强制使用 DFS 顺序递归的去 Visit，每次 <code>push_back</code> 一个 Schema，正好和 <code>FileMetaData</code> 上 <code>list</code> 的顺序吻合</p><h3 id="Arrow-Parquet-Bridge"><a href="#Arrow-Parquet-Bridge" class="headerlink" title="Arrow-Parquet Bridge"></a>Arrow-Parquet Bridge</h3><p>你或许会觉得，讲完了 Parquet 和 Arrow schema 就完结了。但并没有。<strong>Parquet Schema 格式是一个树形的格式，而且可能不等价于 Arrow 的格式</strong>。这句话说的有点难理解，我们直接看例子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// List encodings: using the terminology from Impala to define different styles</span></span><br><span class="line"><span class="comment">// of representing logical lists (a.k.a. ARRAY types) in Parquet schemas. Since</span></span><br><span class="line"><span class="comment">// the converted type named in the Parquet metadata is ConvertedType::LIST we</span></span><br><span class="line"><span class="comment">// use that terminology here. It also helps distinguish from the *_ARRAY</span></span><br><span class="line"><span class="comment">// primitive types.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// One-level encoding: Only allows required lists with required cells</span></span><br><span class="line"><span class="comment">//   repeated value_type name</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Two-level encoding: Enables optional lists with only required cells</span></span><br><span class="line"><span class="comment">//   &lt;required/optional&gt; group list</span></span><br><span class="line"><span class="comment">//     repeated value_type item</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Three-level encoding: Enables optional lists with optional cells</span></span><br><span class="line"><span class="comment">//   &lt;required/optional&gt; group bag</span></span><br><span class="line"><span class="comment">//     repeated group list</span></span><br><span class="line"><span class="comment">//       &lt;required/optional&gt; value_type item</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 2- and 1-level encoding are respectively equivalent to 3-level encoding with</span></span><br><span class="line"><span class="comment">// the non-repeated nodes set to required.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The &quot;official&quot; encoding recommended in the Parquet spec is the 3-level, and</span></span><br><span class="line"><span class="comment">// we use that as the default when creating list types. For semantic completeness</span></span><br><span class="line"><span class="comment">// we allow the other two. Since all types of encodings will occur &quot;in the</span></span><br><span class="line"><span class="comment">// wild&quot; we need to be able to interpret the associated definition levels in</span></span><br><span class="line"><span class="comment">// the context of the actual encoding used in the file.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// NB: Some Parquet writers may not set ConvertedType::LIST on the repeated</span></span><br><span class="line"><span class="comment">// SchemaElement, which could make things challenging if we are trying to infer</span></span><br><span class="line"><span class="comment">// that a sequence of nodes semantically represents an array according to one</span></span><br><span class="line"><span class="comment">// of these encodings (versus a struct containing an array). We should refuse</span></span><br><span class="line"><span class="comment">// the temptation to guess, as they say.</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ListEncoding</span> &#123;</span><br><span class="line">  <span class="keyword">enum</span> <span class="title class_">type</span> &#123; ONE_LEVEL, TWO_LEVEL, THREE_LEVEL &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>上面这个例子并不复杂（只要你不改这块的代码，就很好理解）。但它揭示了一个事实：</p><ol><li>外部的 Schema 和 Parquet Schema 映射关系不一定一样</li><li>一个字段需要分配的 fieldId 可能没那么简单处理</li></ol><p><code>src/parquet/arrow/schema.h</code> 做的就是 arrow-parquet 格式间的 Bridge。它「符合 Parquet 标准，但不是 Parquet 标准的一部分」，但「必须要这个桥梁，才能构建 Parquet」。</p><p>我们可以在 testing 找到一个很好的 sample 代码，在我们跳进细节之前，可以简单看看这块的代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">::<span class="function">arrow::Status <span class="title">RoundTripSchema</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::vector&lt;std::shared_ptr&lt;Field&gt;&gt;&amp; fields,</span></span></span><br><span class="line"><span class="params"><span class="function">    std::shared_ptr&lt;::parquet::ArrowWriterProperties&gt; arrow_properties =</span></span></span><br><span class="line"><span class="params"><span class="function">        ::parquet::default_arrow_writer_properties())</span> </span>&#123;</span><br><span class="line">  arrow_schema_ = ::arrow::<span class="built_in">schema</span>(fields);</span><br><span class="line">  std::shared_ptr&lt;::parquet::WriterProperties&gt; properties =</span><br><span class="line">      ::parquet::<span class="built_in">default_writer_properties</span>();</span><br><span class="line">  <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">ToParquetSchema</span>(arrow_schema_.<span class="built_in">get</span>(), *properties.<span class="built_in">get</span>(),</span><br><span class="line">                                *arrow_properties, &amp;parquet_schema_));</span><br><span class="line">  ::parquet::schema::<span class="built_in">ToParquet</span>(parquet_schema_-&gt;<span class="built_in">group_node</span>(), &amp;parquet_format_schema_);</span><br><span class="line">  <span class="keyword">auto</span> parquet_schema = ::parquet::schema::<span class="built_in">FromParquet</span>(parquet_format_schema_);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">FromParquetSchema</span>(parquet_schema.<span class="built_in">get</span>(), &amp;result_schema_);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="字段级别-SchemaField"><a href="#字段级别-SchemaField" class="headerlink" title="字段级别: SchemaField"></a>字段级别: SchemaField</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \brief Bridge between an arrow::Field and parquet column indices.</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">PARQUET_EXPORT</span> SchemaField &#123;</span><br><span class="line">  std::shared_ptr&lt;::arrow::Field&gt; field;</span><br><span class="line">  std::vector&lt;SchemaField&gt; children;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Only set for leaf nodes</span></span><br><span class="line">  <span class="type">int</span> column_index = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">  parquet::internal::LevelInfo level_info;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">is_leaf</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> column_index != <span class="number">-1</span>; &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>很好懂，这里注意：</p><ol><li><code>column_index</code> 标注 leaf 的实际 column</li><li><code>level_info</code> 标注 parquet 对应的 Level</li></ol><p>在叶子上会有找到 parquet 的 column_index. 需要注意的是，这个和 arrow 的 Schema 是对应的，但是和 Parquet 的 Schema 不是一一对应的！</p><p>这个怎么理解呢，我们先留个关子，可以先理解成这里表示的是「 Parquet 中存在，arrow 中也存在的 Schema」。</p><h3 id="SchemaManifest"><a href="#SchemaManifest" class="headerlink" title="SchemaManifest"></a>SchemaManifest</h3><p><code>SchemaManifest</code> 是写入的时候，Parquet 转 arrow 的工具，同时也是读取的时候，arrow 转 Parquet 的工具，但老实说，这个工具并不怎么「显而易见」。使用方法要看代码才能知道是在做什么。这块代码主要在：<code>ArrowColumnWriterV2::Make</code> 这套代码里面。之前我们在这篇博客 Part-2 其实介绍到了这块的流程，但是更关注于内部的 writer 是怎么写入 def-level 和 rep-level 的，今天介绍的内容简单一些，单纯讲几个 Array 到 Parquet Array 的映射关系。</p><p>本来我们应该如同前面一样，介绍 <code>SchemaManifest</code> 这个类型，但我们还是先从 User 层面来介绍一些，首先，我们看看一个奇妙的递归 cacl. 这个是根据 Arrow 的类型来做 Calc。我想任何一个大一学生都能写出来…</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">CalculateLeafCount</span><span class="params">(<span class="type">const</span> DataType* type)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (type-&gt;<span class="built_in">id</span>() == ::arrow::Type::EXTENSION) &#123;</span><br><span class="line">    type = <span class="built_in">checked_cast</span>&lt;<span class="type">const</span> ExtensionType&amp;&gt;(*type).<span class="built_in">storage_type</span>().<span class="built_in">get</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Note num_fields() can be 0 for an empty struct type</span></span><br><span class="line">  <span class="keyword">if</span> (!::arrow::<span class="built_in">is_nested</span>(type-&gt;<span class="built_in">id</span>())) &#123;</span><br><span class="line">    <span class="comment">// Primitive type.</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> num_leaves = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; field : type-&gt;<span class="built_in">fields</span>()) &#123;</span><br><span class="line">    num_leaves += <span class="built_in">CalculateLeafCount</span>(field-&gt;<span class="built_in">type</span>().<span class="built_in">get</span>());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> num_leaves;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个地方，创建 SchemaManifest 的时候，会在下列构建 physical-column-to-index 和 node-to-parent 的 mapping。然后 Writer 借助这些映射来找到所有的 Leaf，完成对应的写。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">SchemaTreeContext</span> &#123;</span><br><span class="line">  SchemaManifest* manifest;</span><br><span class="line">  ArrowReaderProperties properties;</span><br><span class="line">  <span class="type">const</span> SchemaDescriptor* schema;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">LinkParent</span><span class="params">(<span class="type">const</span> SchemaField* child, <span class="type">const</span> SchemaField* parent)</span> </span>&#123;</span><br><span class="line">    manifest-&gt;child_to_parent[child] = parent;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">RecordLeaf</span><span class="params">(<span class="type">const</span> SchemaField* leaf)</span> </span>&#123;</span><br><span class="line">    manifest-&gt;column_index_to_field[leaf-&gt;column_index] = leaf;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>注意，这里还是没有 <code>FieldId</code> 这个概念的，那么…什么地方有呢？答案很符合直觉：<code>::arrow::Schema</code>.</p><p>你肯定要骂娘了，<code>::arrow::Schema</code> 有，你为啥要讲这么多。这你就不对了，你去翻翻 <code>arrow::Schema</code>  的代码，肯定找不到 fieldId，怎么会是呢？记得我最早贴的不：</p><blockquote><p>The parquet format supports an optional integer field_id which can be assigned to a field. Arrow will convert these field IDs to a metadata key named PARQUET:field_id on the appropriate field.</p></blockquote><p>在 arrow schema 下，有一套这样的接口：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \defgroup arrow-to-parquet-schema-conversion Functions to convert an Arrow</span></span><br><span class="line"><span class="comment">/// schema into a Parquet schema.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// @&#123;</span></span><br><span class="line"></span><br><span class="line">PARQUET_EXPORT</span><br><span class="line">::<span class="function">arrow::Status <span class="title">FieldToNode</span><span class="params">(<span class="type">const</span> std::shared_ptr&lt;::arrow::Field&gt;&amp; field,</span></span></span><br><span class="line"><span class="params"><span class="function">                            <span class="type">const</span> WriterProperties&amp; properties,</span></span></span><br><span class="line"><span class="params"><span class="function">                            <span class="type">const</span> ArrowWriterProperties&amp; arrow_properties,</span></span></span><br><span class="line"><span class="params"><span class="function">                            schema::NodePtr* out)</span></span>;</span><br><span class="line"></span><br><span class="line">PARQUET_EXPORT</span><br><span class="line">::<span class="function">arrow::Status <span class="title">ToParquetSchema</span><span class="params">(<span class="type">const</span> ::arrow::Schema* arrow_schema,</span></span></span><br><span class="line"><span class="params"><span class="function">                                <span class="type">const</span> WriterProperties&amp; properties,</span></span></span><br><span class="line"><span class="params"><span class="function">                                <span class="type">const</span> ArrowWriterProperties&amp; arrow_properties,</span></span></span><br><span class="line"><span class="params"><span class="function">                                std::shared_ptr&lt;SchemaDescriptor&gt;* out)</span></span>;</span><br><span class="line"></span><br><span class="line">PARQUET_EXPORT</span><br><span class="line">::<span class="function">arrow::Status <span class="title">ToParquetSchema</span><span class="params">(<span class="type">const</span> ::arrow::Schema* arrow_schema,</span></span></span><br><span class="line"><span class="params"><span class="function">                                <span class="type">const</span> WriterProperties&amp; properties,</span></span></span><br><span class="line"><span class="params"><span class="function">                                std::shared_ptr&lt;SchemaDescriptor&gt;* out)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// @&#125;</span></span><br></pre></td></tr></table></figure><p><code>FieldToNode</code> 完成了 <code>arrow</code> 的 <code>Field</code> (可能包含嵌套结构) 到 Parquet 的 Node 的转换。这里我们关注两个事情：</p><ol><li>FieldId 的填写</li><li>类型转化（尤其是嵌套类型）。</li></ol><p>关于 FieldId 填写，内容在最开始：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">FieldToNode</span><span class="params">(<span class="type">const</span> std::string&amp; name, <span class="type">const</span> std::shared_ptr&lt;Field&gt;&amp; field,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> WriterProperties&amp; properties,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> ArrowWriterProperties&amp; arrow_properties, NodePtr* out)</span> </span>&#123;</span><br><span class="line">  std::shared_ptr&lt;<span class="type">const</span> LogicalType&gt; logical_type = LogicalType::<span class="built_in">None</span>();</span><br><span class="line">  ParquetType::type type;</span><br><span class="line">  Repetition::type repetition = <span class="built_in">RepetitionFromNullable</span>(field-&gt;<span class="built_in">nullable</span>());</span><br><span class="line">  <span class="type">int</span> field_id = <span class="built_in">FieldIdFromMetadata</span>(field-&gt;<span class="built_in">metadata</span>());</span><br></pre></td></tr></table></figure><p>这个 <code>FieldIdFromMetadata</code> 就是我们一开始提的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">char</span> FIELD_ID_KEY[] = <span class="string">&quot;PARQUET:field_id&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="function">std::shared_ptr&lt;::arrow::KeyValueMetadata&gt; <span class="title">FieldIdMetadata</span><span class="params">(<span class="type">int</span> field_id)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (field_id &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> ::arrow::<span class="built_in">key_value_metadata</span>(&#123;FIELD_ID_KEY&#125;, &#123;<span class="built_in">ToChars</span>(field_id)&#125;);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">FieldIdFromMetadata</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::shared_ptr&lt;<span class="type">const</span> ::arrow::KeyValueMetadata&gt;&amp; metadata)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!metadata) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="type">int</span> key = metadata-&gt;<span class="built_in">FindKey</span>(FIELD_ID_KEY);</span><br><span class="line">  <span class="keyword">if</span> (key &lt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  std::string field_id_str = metadata-&gt;<span class="built_in">value</span>(key);</span><br><span class="line">  <span class="type">int</span> field_id;</span><br><span class="line">  <span class="keyword">if</span> (::arrow::internal::<span class="built_in">ParseValue</span>&lt;::arrow::Int32Type&gt;(</span><br><span class="line">          field_id_str.<span class="built_in">c_str</span>(), field_id_str.<span class="built_in">length</span>(), &amp;field_id)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (field_id &lt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// Thrift should convert any negative value to null but normalize to -1 here in case</span></span><br><span class="line">      <span class="comment">// we later check this in logic.</span></span><br><span class="line">      <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> field_id;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也就是说，这个会标记在 <code>arrow::Field</code> 的 <code>KeyValueMetadata</code> 上，在 Schema 上做额外的 KV，然后标注字段类型！</p><p>那么，SchemaManifest 怎么恢复呢…答案也有坑，你一定觉得我是说从 <code>SchemaDescriptor</code> 来恢复…实际不完全是的，看代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">SchemaManifest::Make</span><span class="params">(<span class="type">const</span> SchemaDescriptor* schema,</span></span></span><br><span class="line"><span class="params"><span class="function">                            <span class="type">const</span> std::shared_ptr&lt;<span class="type">const</span> KeyValueMetadata&gt;&amp; metadata,</span></span></span><br><span class="line"><span class="params"><span class="function">                            <span class="type">const</span> ArrowReaderProperties&amp; properties,</span></span></span><br><span class="line"><span class="params"><span class="function">                            SchemaManifest* manifest)</span> </span>&#123;</span><br><span class="line">  SchemaTreeContext ctx;</span><br><span class="line">  ctx.manifest = manifest;</span><br><span class="line">  ctx.properties = properties;</span><br><span class="line">  ctx.schema = schema;</span><br><span class="line">  <span class="type">const</span> GroupNode&amp; schema_node = *schema-&gt;<span class="built_in">group_node</span>();</span><br><span class="line">  manifest-&gt;descr = schema;</span><br><span class="line">  manifest-&gt;schema_fields.<span class="built_in">resize</span>(schema_node.<span class="built_in">field_count</span>());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Try to deserialize original Arrow schema</span></span><br><span class="line">  <span class="built_in">RETURN_NOT_OK</span>(</span><br><span class="line">      <span class="built_in">GetOriginSchema</span>(metadata, &amp;manifest-&gt;schema_metadata, &amp;manifest-&gt;origin_schema));</span><br><span class="line">  <span class="comment">// Ignore original schema if it&#x27;s not compatible with the Parquet schema</span></span><br><span class="line">  <span class="keyword">if</span> (manifest-&gt;origin_schema != <span class="literal">nullptr</span> &amp;&amp;</span><br><span class="line">      manifest-&gt;origin_schema-&gt;<span class="built_in">num_fields</span>() != schema_node.<span class="built_in">field_count</span>()) &#123;</span><br><span class="line">    manifest-&gt;origin_schema = <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(schema_node.<span class="built_in">field_count</span>()); ++i) &#123;</span><br><span class="line">    SchemaField* out_field = &amp;manifest-&gt;schema_fields[i];</span><br><span class="line">    <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">NodeToSchemaField</span>(*schema_node.<span class="built_in">field</span>(i), <span class="built_in">LevelInfo</span>(), &amp;ctx,</span><br><span class="line">                                    <span class="comment">/*parent=*/</span><span class="literal">nullptr</span>, out_field));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// TODO(wesm): as follow up to ARROW-3246, we should really pass the origin</span></span><br><span class="line">    <span class="comment">// schema (if any) through all functions in the schema reconstruction, but</span></span><br><span class="line">    <span class="comment">// I&#x27;m being lazy and just setting dictionary fields at the top level for</span></span><br><span class="line">    <span class="comment">// now</span></span><br><span class="line">    <span class="keyword">if</span> (manifest-&gt;origin_schema == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> origin_field = manifest-&gt;origin_schema-&gt;<span class="built_in">field</span>(i);</span><br><span class="line">    <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">ApplyOriginalMetadata</span>(*origin_field, out_field));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个地方会尝试 <code>origin_schema</code>，拿到 <code>FileMetadata</code> 的 <code>origin_schema</code>: 一个 <code>arrow::Schema</code> 。原来，这个狗屎 arrow 把自己 Schema 额外存了一份，惊喜不惊喜。</p><p>这里面的数据按照 <code>arrow::ipc</code> 的格式编码，构成了一个「编码后的 <code>arrow::Schema</code>」（有一种暴露给了用户又没有完全暴露的感觉），然后把 key-value-metadata 中 arrow schema 去掉，再拷贝了一份，就构成了 <code>origin_schema</code>. 当然，如果不包含 <code>origin_schema</code> 对应的 key，这里就什么都不做。</p><p>你可能会好奇，<code>arrow::schema</code> 有什么用呢？有了它，parquet 自己的 Schema 就不做数了嘛？</p><p>我们需要提前介绍一点：arrow Schema 和 Parquet Schema 的映射关系。Parquet 本身是 Java 社区的人搞出来的，而 arrow 的作者早期都是 Python kernel 那些作者。这两块的类型不一定也不应该一定完全匹配的。</p><p>这部分我们还是直接读代码，下面这里分为两部分：</p><ul><li>处理 nested type, 这里用了一个 <code>GetFactory</code> 函数，根据 leaf 的 vector，生成一个 nested schema</li><li>叶子: 比如，原来 Parquet 只有 String，那么 arrow 下意识转换成 <code>LargeString</code>，这里会做一些简单的类型修正</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Result&lt;<span class="type">bool</span>&gt; <span class="title">ApplyOriginalStorageMetadata</span><span class="params">(<span class="type">const</span> Field&amp; origin_field,</span></span></span><br><span class="line"><span class="params"><span class="function">                                          SchemaField* inferred)</span> </span>&#123;</span><br><span class="line">  <span class="type">bool</span> modified = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span>&amp; origin_type = origin_field.<span class="built_in">type</span>();</span><br><span class="line">  <span class="keyword">auto</span>&amp; inferred_type = inferred-&gt;field-&gt;<span class="built_in">type</span>();</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">int</span> num_children = inferred_type-&gt;<span class="built_in">num_fields</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (num_children &gt; <span class="number">0</span> &amp;&amp; origin_type-&gt;<span class="built_in">num_fields</span>() == num_children) &#123;</span><br><span class="line">    <span class="built_in">DCHECK_EQ</span>(<span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(inferred-&gt;children.<span class="built_in">size</span>()), num_children);</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> factory = <span class="built_in">GetNestedFactory</span>(*origin_type, *inferred_type);</span><br><span class="line">    <span class="keyword">if</span> (factory) &#123;</span><br><span class="line">      <span class="comment">// The type may be modified (e.g. LargeList) while the children stay the same</span></span><br><span class="line">      modified |= origin_type-&gt;<span class="built_in">id</span>() != inferred_type-&gt;<span class="built_in">id</span>();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Apply original metadata recursively to children</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; inferred_type-&gt;<span class="built_in">num_fields</span>(); ++i) &#123;</span><br><span class="line">        <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(</span><br><span class="line">            <span class="type">const</span> <span class="type">bool</span> child_modified,</span><br><span class="line">            <span class="built_in">ApplyOriginalMetadata</span>(*origin_type-&gt;<span class="built_in">field</span>(i), &amp;inferred-&gt;children[i]));</span><br><span class="line">        modified |= child_modified;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (modified) &#123;</span><br><span class="line">        <span class="comment">// Recreate this field using the modified child fields</span></span><br><span class="line">        ::<span class="function">arrow::FieldVector <span class="title">modified_children</span><span class="params">(inferred_type-&gt;num_fields())</span></span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; inferred_type-&gt;<span class="built_in">num_fields</span>(); ++i) &#123;</span><br><span class="line">          modified_children[i] = inferred-&gt;children[i].field;</span><br><span class="line">        &#125;</span><br><span class="line">        inferred-&gt;field =</span><br><span class="line">            inferred-&gt;field-&gt;<span class="built_in">WithType</span>(<span class="built_in">factory</span>(std::<span class="built_in">move</span>(modified_children)));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (origin_type-&gt;<span class="built_in">id</span>() == ::arrow::Type::TIMESTAMP &amp;&amp;</span><br><span class="line">      inferred_type-&gt;<span class="built_in">id</span>() == ::arrow::Type::TIMESTAMP) &#123;</span><br><span class="line">    <span class="comment">// Restore time zone, if any</span></span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; ts_type = <span class="built_in">checked_cast</span>&lt;<span class="type">const</span> ::arrow::TimestampType&amp;&gt;(*inferred_type);</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; ts_origin_type =</span><br><span class="line">        <span class="built_in">checked_cast</span>&lt;<span class="type">const</span> ::arrow::TimestampType&amp;&gt;(*origin_type);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If the data is tz-aware, then set the original time zone, since Parquet</span></span><br><span class="line">    <span class="comment">// has no native storage for timezones</span></span><br><span class="line">    <span class="keyword">if</span> (ts_type.<span class="built_in">timezone</span>() == <span class="string">&quot;UTC&quot;</span> &amp;&amp; !ts_origin_type.<span class="built_in">timezone</span>().<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (ts_type.<span class="built_in">unit</span>() == ts_origin_type.<span class="built_in">unit</span>()) &#123;</span><br><span class="line">        inferred-&gt;field = inferred-&gt;field-&gt;<span class="built_in">WithType</span>(origin_type);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">auto</span> ts_type_new = ::arrow::<span class="built_in">timestamp</span>(ts_type.<span class="built_in">unit</span>(), ts_origin_type.<span class="built_in">timezone</span>());</span><br><span class="line">        inferred-&gt;field = inferred-&gt;field-&gt;<span class="built_in">WithType</span>(ts_type_new);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    modified = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (origin_type-&gt;<span class="built_in">id</span>() == ::arrow::Type::DURATION &amp;&amp;</span><br><span class="line">      inferred_type-&gt;<span class="built_in">id</span>() == ::arrow::Type::INT64) &#123;</span><br><span class="line">    <span class="comment">// Read back int64 arrays as duration.</span></span><br><span class="line">    inferred-&gt;field = inferred-&gt;field-&gt;<span class="built_in">WithType</span>(origin_type);</span><br><span class="line">    modified = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (origin_type-&gt;<span class="built_in">id</span>() == ::arrow::Type::DICTIONARY &amp;&amp;</span><br><span class="line">      inferred_type-&gt;<span class="built_in">id</span>() != ::arrow::Type::DICTIONARY &amp;&amp;</span><br><span class="line">      <span class="built_in">IsDictionaryReadSupported</span>(*inferred_type)) &#123;</span><br><span class="line">    <span class="comment">// Direct dictionary reads are only supported for a couple primitive types,</span></span><br><span class="line">    <span class="comment">// so no need to recurse on value types.</span></span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; dict_origin_type =</span><br><span class="line">        <span class="built_in">checked_cast</span>&lt;<span class="type">const</span> ::arrow::DictionaryType&amp;&gt;(*origin_type);</span><br><span class="line">    inferred-&gt;field = inferred-&gt;field-&gt;<span class="built_in">WithType</span>(</span><br><span class="line">        ::arrow::<span class="built_in">dictionary</span>(::arrow::<span class="built_in">int32</span>(), inferred_type, dict_origin_type.<span class="built_in">ordered</span>()));</span><br><span class="line">    modified = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> ((origin_type-&gt;<span class="built_in">id</span>() == ::arrow::Type::LARGE_BINARY &amp;&amp;</span><br><span class="line">       inferred_type-&gt;<span class="built_in">id</span>() == ::arrow::Type::BINARY) ||</span><br><span class="line">      (origin_type-&gt;<span class="built_in">id</span>() == ::arrow::Type::LARGE_STRING &amp;&amp;</span><br><span class="line">       inferred_type-&gt;<span class="built_in">id</span>() == ::arrow::Type::STRING)) &#123;</span><br><span class="line">    <span class="comment">// Read back binary-like arrays with the intended offset width.</span></span><br><span class="line">    inferred-&gt;field = inferred-&gt;field-&gt;<span class="built_in">WithType</span>(origin_type);</span><br><span class="line">    modified = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (origin_type-&gt;<span class="built_in">id</span>() == ::arrow::Type::DECIMAL256 &amp;&amp;</span><br><span class="line">      inferred_type-&gt;<span class="built_in">id</span>() == ::arrow::Type::DECIMAL128) &#123;</span><br><span class="line">    inferred-&gt;field = inferred-&gt;field-&gt;<span class="built_in">WithType</span>(origin_type);</span><br><span class="line">    modified = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Restore field metadata</span></span><br><span class="line">  std::shared_ptr&lt;<span class="type">const</span> KeyValueMetadata&gt; field_metadata = origin_field.<span class="built_in">metadata</span>();</span><br><span class="line">  <span class="keyword">if</span> (field_metadata != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (inferred-&gt;field-&gt;<span class="built_in">metadata</span>()) &#123;</span><br><span class="line">      <span class="comment">// Prefer the metadata keys (like field_id) from the current metadata</span></span><br><span class="line">      field_metadata = field_metadata-&gt;<span class="built_in">Merge</span>(*inferred-&gt;field-&gt;<span class="built_in">metadata</span>());</span><br><span class="line">    &#125;</span><br><span class="line">    inferred-&gt;field = inferred-&gt;field-&gt;<span class="built_in">WithMetadata</span>(field_metadata);</span><br><span class="line">    modified = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> modified;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这里，就会产生带 field-id 的字段。</p><h4 id="回到-FieldToNode"><a href="#回到-FieldToNode" class="headerlink" title="回到 FieldToNode"></a>回到 FieldToNode</h4><p>我们再次回到 FieldToNode，给这节收尾一下。我们之前说过，<code>FieldToNode</code> 中，<code>arrow::Field</code> 数量可能少于 Parquet 的 Schema。那么这个映射是怎么实现的？缺失字段 fieldId 怎么填？答案是填了个寂寞：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">FieldToNode</span><span class="params">(<span class="type">const</span> std::string&amp; name, <span class="type">const</span> std::shared_ptr&lt;Field&gt;&amp; field,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> WriterProperties&amp; properties,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> ArrowWriterProperties&amp; arrow_properties, NodePtr* out)</span> </span>&#123;</span><br><span class="line">...</span><br><span class="line">    <span class="keyword">case</span> ArrowTypeId::FIXED_SIZE_LIST:</span><br><span class="line">    <span class="keyword">case</span> ArrowTypeId::LARGE_LIST:</span><br><span class="line">    <span class="keyword">case</span> ArrowTypeId::LIST: &#123;</span><br><span class="line">      <span class="keyword">auto</span> list_type = std::<span class="built_in">static_pointer_cast</span>&lt;::arrow::BaseListType&gt;(field-&gt;<span class="built_in">type</span>());</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">ListToNode</span>(list_type, name, field-&gt;<span class="built_in">nullable</span>(), field_id, properties,</span><br><span class="line">                        arrow_properties, out);</span><br><span class="line">    &#125;          </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们把视角切换到 <code>ListToNode</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">ListToNode</span><span class="params">(<span class="type">const</span> std::shared_ptr&lt;::arrow::BaseListType&gt;&amp; type,</span></span></span><br><span class="line"><span class="params"><span class="function">                  <span class="type">const</span> std::string&amp; name, <span class="type">bool</span> nullable, <span class="type">int</span> field_id,</span></span></span><br><span class="line"><span class="params"><span class="function">                  <span class="type">const</span> WriterProperties&amp; properties,</span></span></span><br><span class="line"><span class="params"><span class="function">                  <span class="type">const</span> ArrowWriterProperties&amp; arrow_properties, NodePtr* out)</span> </span>&#123;</span><br><span class="line">  NodePtr element;</span><br><span class="line">  std::string value_name =</span><br><span class="line">      arrow_properties.<span class="built_in">compliant_nested_types</span>() ? <span class="string">&quot;element&quot;</span> : type-&gt;<span class="built_in">value_field</span>()-&gt;<span class="built_in">name</span>();</span><br><span class="line">  <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">FieldToNode</span>(value_name, type-&gt;<span class="built_in">value_field</span>(), properties, arrow_properties,</span><br><span class="line">                            &amp;element));</span><br><span class="line"></span><br><span class="line">  NodePtr list = GroupNode::<span class="built_in">Make</span>(<span class="string">&quot;list&quot;</span>, Repetition::REPEATED, &#123;element&#125;);</span><br><span class="line">  *out = GroupNode::<span class="built_in">Make</span>(name, <span class="built_in">RepetitionFromNullable</span>(nullable), &#123;list&#125;,</span><br><span class="line">                         LogicalType::<span class="built_in">List</span>(), field_id);</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里插入了一个没 fieldId 的 List，对应 fieldId 为 <code>-1</code>，嘻嘻。</p><h4 id="嵌套结构兼容性解析"><a href="#嵌套结构兼容性解析" class="headerlink" title="嵌套结构兼容性解析"></a>嵌套结构兼容性解析</h4><p>这部分还是要到 arrow 的转换中：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">NodeToSchemaField</span><span class="params">(<span class="type">const</span> Node&amp; node, LevelInfo current_levels,</span></span></span><br><span class="line"><span class="params"><span class="function">                         SchemaTreeContext* ctx, <span class="type">const</span> SchemaField* parent,</span></span></span><br><span class="line"><span class="params"><span class="function">                         SchemaField* out)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Workhorse function for converting a Parquet schema node to an Arrow</span></span><br><span class="line">  <span class="comment">// type. Handles different conventions for nested data.</span></span><br><span class="line"></span><br><span class="line">  ctx-&gt;<span class="built_in">LinkParent</span>(out, parent);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Now, walk the schema and create a ColumnDescriptor for each leaf node</span></span><br><span class="line">  <span class="keyword">if</span> (node.<span class="built_in">is_group</span>()) &#123;</span><br><span class="line">    <span class="comment">// A nested field, but we don&#x27;t know what kind yet</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">GroupToSchemaField</span>(<span class="built_in">static_cast</span>&lt;<span class="type">const</span> GroupNode&amp;&gt;(node), current_levels, ctx,</span><br><span class="line">                              parent, out);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// Either a normal flat primitive type, or a list type encoded with 1-level</span></span><br><span class="line">    <span class="comment">// list encoding. Note that the 3-level encoding is the form recommended by</span></span><br><span class="line">    <span class="comment">// the parquet specification, but technically we can have either</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// required/optional $TYPE $FIELD_NAME</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// or</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// repeated $TYPE $FIELD_NAME</span></span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span>&amp; primitive_node = <span class="built_in">static_cast</span>&lt;<span class="type">const</span> PrimitiveNode&amp;&gt;(node);</span><br><span class="line">    <span class="type">int</span> column_index = ctx-&gt;schema-&gt;<span class="built_in">GetColumnIndex</span>(primitive_node);</span><br><span class="line">    <span class="built_in">ASSIGN_OR_RAISE</span>(std::shared_ptr&lt;ArrowType&gt; type,</span><br><span class="line">                    <span class="built_in">GetTypeForNode</span>(column_index, primitive_node, ctx));</span><br><span class="line">    <span class="keyword">if</span> (node.<span class="built_in">is_repeated</span>()) &#123;</span><br><span class="line">      <span class="comment">// One-level list encoding, e.g.</span></span><br><span class="line">      <span class="comment">// a: repeated int32;</span></span><br><span class="line">      <span class="type">int16_t</span> repeated_ancestor_def_level = current_levels.<span class="built_in">IncrementRepeated</span>();</span><br><span class="line">      out-&gt;children.<span class="built_in">resize</span>(<span class="number">1</span>);</span><br><span class="line">      <span class="keyword">auto</span> child_field = ::arrow::<span class="built_in">field</span>(node.<span class="built_in">name</span>(), type, <span class="comment">/*nullable=*/</span><span class="literal">false</span>);</span><br><span class="line">      <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">PopulateLeaf</span>(column_index, child_field, current_levels, ctx, out,</span><br><span class="line">                                 &amp;out-&gt;children[<span class="number">0</span>]));</span><br><span class="line"></span><br><span class="line">      out-&gt;field = ::arrow::<span class="built_in">field</span>(node.<span class="built_in">name</span>(), ::arrow::<span class="built_in">list</span>(child_field),</span><br><span class="line">                                  <span class="comment">/*nullable=*/</span><span class="literal">false</span>, <span class="built_in">FieldIdMetadata</span>(node.<span class="built_in">field_id</span>()));</span><br><span class="line">      out-&gt;level_info = current_levels;</span><br><span class="line">      <span class="comment">// At this point current_levels has consider this list the ancestor so restore</span></span><br><span class="line">      <span class="comment">// the actual ancestor.</span></span><br><span class="line">      out-&gt;level_info.repeated_ancestor_def_level = repeated_ancestor_def_level;</span><br><span class="line">      <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      current_levels.<span class="built_in">Increment</span>(node);</span><br><span class="line">      <span class="comment">// A normal (required/optional) primitive node</span></span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">PopulateLeaf</span>(column_index,</span><br><span class="line">                          ::arrow::<span class="built_in">field</span>(node.<span class="built_in">name</span>(), type, node.<span class="built_in">is_optional</span>(),</span><br><span class="line">                                         <span class="built_in">FieldIdMetadata</span>(node.<span class="built_in">field_id</span>())),</span><br><span class="line">                          current_levels, ctx, parent, out);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里会走到 <code>ListToSchemaField</code>，然后根据 <code>node</code> 来解析对应的逻辑。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>今天这段写的有点乱。这些内容并不像 btr 那么逻辑上复杂，但是还是充满了复杂性：两个系统间的 Schema 转义层也是很复杂的。</p><p>当我们审视这套的时候，我们会发现，不仅是 arrow，所有用 Parquet 的系统都会遇到这些问题，这些代码实际上是「通用代码」。并且还有很多兼容性问题。也希望这篇文章能帮读者识破一些拼凑系统的吹嘘。</p><p>再次感叹现实世界工程的无限复杂度。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>SIGMOD&#39;22: SingleStore</title>
      <link href="/2023/02/05/SIGMOD-22-SingleStore/"/>
      <url>/2023/02/05/SIGMOD-22-SingleStore/</url>
      
        <content type="html"><![CDATA[<p>SingleStore 的前身是差不多和 Snowflake 同一时间开始做的 MemSQL，最早他们是做一个快速的内存数据库，但是事实证明，做这套的 VoltDB 呀什么的都混得不太好（SAP Hana 商业做的好，混得还行，其它貌似都没怎么卷出来？）。然后他们还做专有部署/Shared-nothing，没有和 snowflake 一样选择做 Cloud（shared-nothing 和 cloud 不一定有冲突，不过懂我意思就行）。这两个合起来，得了，商业上就没那么成功呗。不过事情没做成，技能是不会丢的，一群人积累的经验也不容易丢，何况线下部署呀 debug 呀什么的其实挺考验能力的。</p><p>SingleStore 自称卖的是 HTAP，他支持两种模式：Shared Nothing 部署和绑定 BLOB Storage(类似 S3) 部署。尽管 AWS EBS 提供了比较可靠的块存储服务，但是感觉是因为成本和性能的原因，也因为它们比较熟悉 Shared-Nothing 这套，（不知道是不是也有在一套代码上做异地的原因），所以没用 EBS。它承诺开 S3 的时候，成本也下来了，插入性能也好了。当然我实际感觉它开启 BLOB STORAGE 作为缓存的时候，插入侧能力没有那么好，P99 理论上应该会很受限于 S3 的性能。不过感觉对于大部分用户来说，插入 P99 是不是只要能发现原因就行，特殊的用户可以靠加钱来解决，让数据尽量做一个全缓存。我们在后面也会分析这一套架构和 CockroachDB / TiDB 之类 TP 架构的区别。</p><p>SingleStore 自称对手是「各种 domain-specific」的数据存储，它感觉有点类似国内在聊的「多模」这个词（产品见 Lindorm），它尝试的是 one-fit all。产品认为，多种数据库在实现层面要把一套东西做很多遍（包括 logging / ETL / 各种相似的优化），而用户需求不外乎是那几个：satisfying a breadth of requirements for transactional and analytical workloads。从结论来看，它也有一定对 flexible 的数据结构的支持。不过具体怎么样也得看市场的态度。笔者认为，这些内容有点大公司实现者视角，在大公司里面，多个团队收编为同一套组件能够提供比较好的组织架构优势，然后看各个组件分层，很多数据库可能做不到专有的类型组件那么优秀，但是很多优化也是通用的。但这些东西对用户来说我个人感觉没那么大意义？除了一套系统 ETL 之类的好做很多，好像用户还不是什么方便用什么？难道用户买它在上面写自己的系统吗（囧）。总之 SingleStore Database Engine 的前面可以是它 manage 的 Service，也可以是用户自己搞出来的安装 binary （还记得最早 MemSQL 是线下部署吗）。</p><p>上面是对 S2DB 的一个大致的 overview，下面部分会大改过一下论文中 SingleStore 的架构，先提前说一句这文章写的非常细，架构介绍还是很细致的。</p><h3 id="大致思路"><a href="#大致思路" class="headerlink" title="大致思路"></a>大致思路</h3><ul><li>Shared-nothing 模式不用提，肯定是 Cloud Blob Storage 相对 EBS 成本低。不过，S3 对外暴露数据不丢是靠谱的，但是不可用只有四个九，这表示需要做很多东西来 work around ( delta-io 似乎会尝试一直提交？）。所以引入了 local-disk。说没用 ebs 是因为 ebs 延迟 + 成本 + 不一定用的上它的复制。所以在这种情况下，SingleStore 自己做了一套复制，然后在单机上处理这些问题。（<em>不管做的好不好，这个理由应该还是说得过去的</em>）<ul><li>节点分为两种：aggregator , leaf. Aggregator 负责查询，Master Aggregator 负责 fail-over 相关的一些信息</li><li>用 Hash Partition 来分片</li><li>为了降低延迟，在 local disk 上做事务，然后 async 移动到 BLOB Storage 端。提交是靠多副本来保证正确性的<ul><li>BLOB 端包含数据（显而易见）和日志（支持 PITR）</li><li>可以设置类似 TiFlash 这样的 Learner，用来支持一些 AP 查询</li></ul></li><li>SingleStore 的本地复制（不包括 Read-Replica）只会维护 HA，不会维护读流量。见 Figure 2，S2DB 认为读流量走主就行，备只为了 HA，因为这部分不能减少负载（感觉相对于 TiDB，大致 idea 没问题，那对于热点请求、慢节点或者热分区呢？）</li><li>SingleStore 实现了异地异步复制，这个也有点类似 Read-Replica，可以被读。这里也允许从异地备份中 failover，但必须要 DBA 来操作</li></ul></li><li>在单机上，提供了 Unified table storage. 这里需要支持快速的 Scan，插入和点查。这块理论上可能非 HTAP 会写一堆对应的引擎，SingleStore 这里准备了单一的 table storage 做本地存储支持。它提供的概念类似 LSM-Tree，相对于传统的 LSM-Tree，应该更接近 Mesa 或者 Snowflake 那种概念。这里概念如下：sort keys, secondary keys, shard keys, unique keys 和 row-level locking（相对 Kudu 来说，它这些概念应该做的细和宽泛很多，<strong>对外</strong>形态有点点类似 SQL Server 的 Columnar 支持？）<ul><li>In-memory row store: lockfree skip list, 写写悲观锁、读写不冲突，Row 固定大小绑定 bookeeping 信息，变长字段额外存储<ul><li>有 Partition 级别的 Logging，会有一个进程来 checkpoint</li><li>（看下来感觉是 in-memory tp system，有点类似 Hekaton？哦结合他们之前做 MemSQL 的，感觉一切合理了起来…）</li></ul></li><li>列存表被组织为 [表 - segments - data files] 的三级概念，不过感觉 segment 是 frozen 的，元信息存储在一个 RowStore 中，包括这些文件的位置，encoding，Column min-max 等，<strong>也有一个 delete bit-vec</strong><ul><li>上面的部分是所有 AP 系统差不太多的，但是这里针对点查更新做了优化：允许 Seek，不需要 decoding 所有的 row （例如利用 LZ4 + RLE，见：<a href="https://www.singlestore.com/blog/winter-2022-universal-storage-part-5/">https://www.singlestore.com/blog/winter-2022-universal-storage-part-5/</a> ）</li><li>Sort Key 可以手动指定键排序</li><li>类似 snowflake，这里也会有后台的进程去做 Compaction</li></ul></li><li>每个 ColumnStore 中，都有一个行存的表作为前台写，然后有一个 background flusher 靠事务移动到 ColumnStore 中（这块我感觉和 SQL Server 没有什么区别，直接去看那篇好了）。</li></ul></li><li>执行层 co-locate JOIN 请求，分区裁剪，也支持 Codegen</li></ul><p><img src="https://image.mwish.me/blog-image/f1.png" alt="f1"></p><h3 id="存算分离的架构"><a href="#存算分离的架构" class="headerlink" title="存算分离的架构"></a>存算分离的架构</h3><p>S2DB 允许本地多副本写来提交，然后声称这样更可控（确实）。在 Log 系统有下面一段，我复制一下原文，因为不是百分百确定意思：</p><blockquote><p>The in-cluster replication is fast and log pages can be replicated out-of-order and replicated early without waiting for transaction commit. Replicating out-of-order allows small transactions to commit without waiting for big transactions, guaranteeing that commits have low and predictable latency.</p></blockquote><p>我个人猜测，这个应该是有个 mtr 或者操作级别的日志组，然后复制的时候不需要等事务完成，而是等待 Page 或者 Log Buffer 攒满，不知道我理解对不对，感觉很 trivial 嘛…</p><p>这里写多份的时候，为了低延迟开了个挂，只要3副本内存写完了就行。这里论文说了还是有一定概率会丢内存数据的。这里它写了个很有意思的原因：</p><blockquote><p>While SingleStore supports synchronously committing to local disk as well, this tradeoff often doesn’t make sense in cloud environments where loss of a host often implies loss of the local storage attached to that host. For this reason, S2DB doesn’t synchronously commit transactions to local disk by default.</p></blockquote><p>考虑到它不挂载 EBS，确实很有意思…</p><p><img src="https://image.mwish.me/blog-image/f2.png" alt="f2"></p><p>观察上面几张图，这里 (a) -&gt; (b) 是一个 flush，(b) -&gt; (c) 是一个删除，我们稍微详细一点介绍流程：</p><ul><li>Flush: 这里首先有一点 Log is database 的感觉，先创建 Create data file LSN 的标记，然后 name datafile，数据文件也可以从 Log 中恢复</li><li>Column 中的删除：可以注意到，这里<strong>删除标记到了 Meta 里面</strong>。其实 Doris / StarRocks 的主键模型删除也是标记到 Meta 的 RocksDB 存储中的，Delta-IO 可写 Log 可写额外文件，iceberg spec 得写文件。而在 SingleStore 中，<strong>Meta 被存储在 RowStore 中</strong>。</li></ul><p>上述是一个单机写入的流程，考虑到共享存储层，这里需要再次前进：</p><p><img src="https://image.mwish.me/blog-image/f3.png" alt="f3"></p><ul><li>Committed Log 会被上传到远端，应该有一个 Safe LSN 的机制（类似 Aurora），能够把某个 LSn 之后的上传到远端。</li><li>新的 ColumnStore 数据文件会被异步尽快上传到远端。然后 Cold Data 就可以被隔离了（我有一点比较好奇，就是这个文件是 master 声称然后同步给所有节点的，还是 replica 接到日志也可以声称？不过一下没找到。就是，LSN 提交之后，数据文件没上传，感觉也要能恢复？这个时候也要 detact 出文件在本地还是在远端吧？感觉这个没描述的很清楚？）</li><li>Master 可以上传 RowStore 的 Snapshot。</li><li>这里还有个 workspace 的抽象，允许对一份数据有不同的资源。上图有一个 Read-only workspace。这里会从 Blob 拉文件 / RowStore 的 snapshot，<strong>然后允许从远端机器 tail log(感觉是因为提交本身和共享存储不绑定，所以要这么搞）</strong></li></ul><p>论文的评估中，文章 novelty 在于不需要在 Shared-Storage 做提交，降低了系统稳定性中对共享存储的依赖。这本来是好的，不过文章也说了，这个感觉相当于要自己多管理一层状态，尤其是在 failover、membership change 的时候。文章提了个很有意思的数字，Aurora Storage 成本大概是 S3 的四倍。</p><blockquote><p>笔者认为这算是工程上大力出奇迹。S3 / EBS 上存储能抽象掉很多麻烦。比如写在 EBS 上，可能你就当成数据本身很靠谱了。SingleStore 这样需要手动管 SSD，而且还有很多问题。不过鉴于他们做 MemSQL 出身，可以能比较熟悉这一套。再次感叹一下工程基础好的好处。</p></blockquote><h4 id="架构带来的收益"><a href="#架构带来的收益" class="headerlink" title="架构带来的收益"></a>架构带来的收益</h4><ul><li>本地 SSD 的性能（本质上是把容错、下层依赖的东西试着一定程度上从主读写链路干掉了，这块性能我其实没测过，懂的可以讲讲）</li><li>BLOB存储日志带来的功能。这里它觉得即吃到了 SSD 写的好，又能用廉价存储来存操作日志。可以 PITR、Time Travel</li><li>创建 Read Only 节点</li></ul><p>这些感觉大家都做了，不过他们要是能做的很好，那确实真的很厉害啊…</p><h3 id="Unified-Table-Storage"><a href="#Unified-Table-Storage" class="headerlink" title="Unified Table Storage"></a>Unified Table Storage</h3><p>SingleStore 的特点是要支撑 HTAP 的负载。压缩呀什么的大家都是一个做法，也没啥新东西。但是它在 Secondary Indexes 这里描述应该是比较详细的，看完大致可以摸清楚这方面的一些详细设计。此外它还提供了 Row-level Locking 来避免冲突。这些东西本身并不是很新，但是它这里写的还是比较完善的。再次注意，这边语义还是快速的点查/插入/Scan.</p><p>简单来说，在 ColumnStorage 层，它做的优化是：</p><ul><li>Delete + Insert 给 key 标记删除取代 Merge-on-Read（在新层写 Tombstone），因为在新层写 tombstone 对(blind的)写入本身友好一些，但是对点查很不好。所以感觉一般支持 pk 模型之类的分析数据产品都是 Delete + Insert。</li><li>Delete 被标记在 Meta 中（感觉它这里设计是不会有大批 Delete，比如某个 Select 每隔2行删一个数据，还是这种能被他们非常好的压缩？不然这里写入 Meta 会很大。Delta-io 在这方面格式设计上做了一些 workaround）</li></ul><h4 id="Secondary-Indexes"><a href="#Secondary-Indexes" class="headerlink" title="Secondary Indexes"></a>Secondary Indexes</h4><p>LSM 上做 Seconday Index 一直比较 hack，在 <strong>LSM-based Storage Techniques: A Survey</strong> 里面也有提到。S2DB 这里的亮点是提供了一个分布式上的索引解决方案：</p><ul><li>在 Segment 层引入 inverted index，提供[索引列 — row-offset-within-segment]的映射</li><li>在全局引入 <Key Hash, Segment> 的 Global Hash Index，索引指向这个 key 的 Location. 没有支持 Ordered Index 是因为…还没实现。物理结构上 Global Hash Index 也是个 LSMTree。<ul><li>当 Compaction 发生的时候，这里允许 Lazy Deletion。即物理上删除的文件还在 GHI 中（估计访问的时候还要回查 Meta），来通过一部分的读减小写放大</li><li>写放大是 $O(log(N))$ 的级别</li><li>只存储 Hash 和 Unique Value。Value 存储在对应的 Inverted index 里，看图。</li><li>（其实我有点好奇，GHI 放大这么大，以至于要这么优化吗…）</li><li>这个架构大大优化了 Point Read on Secondary Index，因为只需要 O(log(Segment))  的 Complexity，减少了对 Segment 的访问（比如每个 Segment 访问 Bloom Filter）。</li><li>允许并发读多个索引然后 merge，类似 PostgreSQL 访问多个索引那套？</li><li>考察这个结构，这里数据 Layout 都是到具体位置的映射，而不是指向某个 key。这个部分分别有不同的好处坏处：<ul><li>好处：读对应的 Secondary Index 不需要回表，减少一次查询</li><li>坏处：物理结构变更带来的后台写放大（merge inverted index，处理 deleted）和前台读放大</li></ul></li></ul></li></ul><p><img src="https://image.mwish.me/blog-image/f4.png" alt="f4"></p><p>下面介绍两个在这套上面的扩展：</p><ul><li>Multi-column secondary index</li><li>Uniqueness enforcement</li></ul><p>这两个都用同一套模型实现。</p><p>（不过比较好奇 RowStore 这套怎么做的，硬 Scan？）</p><h4 id="Row-Level-Locking"><a href="#Row-Level-Locking" class="headerlink" title="Row-Level Locking"></a>Row-Level Locking</h4><p>（感觉这块类似 SQL Server）</p><ul><li>需要均衡 Flusher，Merge 任务和前台工作</li><li>在 RowStore 上实现了 row-level locking. 这里考虑到一个事实：提交之前写都会在 RowStore 中标记（Meta 删除呢？答案是会先进 RowStore。感觉这块有点点类似 Kudu.）这里做的类似 ARIES/IM：严格把 RowStore 的 Primary Key 当锁。</li><li>允许 Flush / Merge 和前台操作 Reorder，这块它说的比较虚，我感觉其实也类似 Kudu，先前台操作，然后后台把前台操作移动到新的 Segment 上</li></ul><h3 id="Adaptive-query-execution"><a href="#Adaptive-query-execution" class="headerlink" title="Adaptive query execution"></a>Adaptive query execution</h3><p>这里支持分片请求，分区裁剪，也支持 Codegen</p><p>访问 S2DB Unified Table Storage 有下面几层：</p><ul><li>找到需要读的 Segments</li><li>下推 Filter</li><li>选择性 Decoding</li></ul><p>感觉所有 AP 产品都一个样，呵呵了。</p><h4 id="Segment-Skipping"><a href="#Segment-Skipping" class="headerlink" title="Segment Skipping"></a>Segment Skipping</h4><ol><li>GHI 和 min-max 都可以使用</li><li>O(log(N)) 的时间，N -&gt; Segment</li><li>S2DB 会 adaptively 的选用 Secondary Index，如果 lookup 太多，他就会转化成硬 Scan。</li><li>如果小表 Join 大表，而且可以用到 Secondary Index，那么 S2DB 会用 Join Index Filter 来做 Dynamic Filter。</li></ol><h4 id="Filtering"><a href="#Filtering" class="headerlink" title="Filtering"></a>Filtering</h4><p>在执行层，S2DB 有下列不同的 Filter，假设有一个 (col1 = val1) 的 eq expr:</p><ul><li>Regular Filter: 根据前一个表达式的执行结果，来 (masked) decode col1，执行表达式</li><li>Encoded Filter: 直接在 compressed value 上执行。<ul><li>对于 Dictionary 这样的数据来说，如果 ndv 很小，那么效果非常好，反之不怎么好</li></ul></li><li>Group Filter: 先一把 decode 所有 filtered column，然后全部执行。如果 Selectivity 很高的话（即 filter 过滤性能不太好），这样性能很好。同时，只有某几个中间的 Filter 过滤好的话，也会比较好</li><li>Secondary index Filter: 走 Secondary index 读</li></ul><p>S2DB 会对表达式执行做采样，然后根据采样结果来 Exec。此外，这里还会 Reorder Filters，来加快相关的执行。</p><p>(这几套除了 Secondary Index Filter, Velox 或多或少都有？)</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><h3 id="SingleStore"><a href="#SingleStore" class="headerlink" title="SingleStore"></a>SingleStore</h3><ul><li>[SIGMOD’22] Cloud-Native Transactions and Analytics in SingleStore</li><li>SingleStore Blog: <a href="https://www.singlestore.com/blog/winter-2022-universal-storage-part-5/">https://www.singlestore.com/blog/winter-2022-universal-storage-part-5/</a></li></ul><h3 id="CRDB"><a href="#CRDB" class="headerlink" title="CRDB"></a>CRDB</h3><ul><li><a href="http://link.zhihu.com/?target=https%3A//www.cockroachlabs.com/blog/how-we-built-cockroachdb-serverless/">How we built a forever-free serverless SQL database</a></li></ul><h3 id="TiDB"><a href="#TiDB" class="headerlink" title="TiDB"></a>TiDB</h3><ul><li>什么？比 MySQL 性价比更高的 TiDB Cloud Serverless Tier 来了？<a href="https://zhuanlan.zhihu.com/p/596570801">https://zhuanlan.zhihu.com/p/596570801</a></li><li>基于 Raft 打造物理一致性云原生存储引擎 <a href="https://www.bilibili.com/video/BV1B44y1o7H5/">https://www.bilibili.com/video/BV1B44y1o7H5/</a></li></ul><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><ul><li>Andy Pavlo 关于复制的一些评论，可以帮助理解这篇文章：<a href="https://ottertune.com/blog/how-amazon-rds-replication-works-and-why-the-faas-database-problem-wont-happen-in-aws/">https://ottertune.com/blog/how-amazon-rds-replication-works-and-why-the-faas-database-problem-wont-happen-in-aws/</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>mwish 2022 acgn summary</title>
      <link href="/2023/01/29/mwish-2022-acgn-summary/"/>
      <url>/2023/01/29/mwish-2022-acgn-summary/</url>
      
        <content type="html"><![CDATA[<h2 id="Anime"><a href="#Anime" class="headerlink" title="Anime"></a>Anime</h2><p>今年看的动画比较少。就提一下值得一提的作品。</p><h3 id="Cyberpunk-Edgerunners"><a href="#Cyberpunk-Edgerunners" class="headerlink" title="Cyberpunk: Edgerunners"></a>Cyberpunk: Edgerunners</h3><p>作为一名 Trigger 黑…我承认我其实对这部作品还算满意。netflix 和 trigger 最近的最佳作品，风格上 trigger 的风格和 tears in the rain 的 cyberpunk 感结合的比较好，脚本上虽然有些地方比较粗糙，但是大概逻辑还是通顺的，trigger 和原作编剧都互相做了克制，给出了一个很不错的小品作品。</p><p>五十岚海的演出（在 dynazenon ep10 之后）再次给我留下了比较深的印象。年轻人大有可为。</p><h3 id="ガールズ-amp-パンツァー-劇場版（少女与战车-剧场版）"><a href="#ガールズ-amp-パンツァー-劇場版（少女与战车-剧场版）" class="headerlink" title="ガールズ&amp;パンツァー 劇場版（少女与战车 剧场版）"></a>ガールズ&amp;パンツァー 劇場版（少女与战车 剧场版）</h3><p>拖拖沓沓的剧情，天马行空的战斗。看美少女动物园口胡飙坦克还真挺爽，水岛努确实是懂的。</p><h3 id="ニンジャスレイヤー-フロムアニメイシヨン（忍者杀手）"><a href="#ニンジャスレイヤー-フロムアニメイシヨン（忍者杀手）" class="headerlink" title="ニンジャスレイヤー フロムアニメイシヨン（忍者杀手）"></a>ニンジャスレイヤー フロムアニメイシヨン（忍者杀手）</h3><p>狂放的 cult 片，一个语言学实例，实际好看！故事本身倒是比较平凡的正邪对抗那一套，但是奈何风格上实在太有趣味了：口胡风格、风格化而奇怪的语言，演出方面的奇怪方法。yeaaaaaart！王守义！</p><h3 id="ゆるキャン△"><a href="#ゆるキャン△" class="headerlink" title="ゆるキャン△"></a>ゆるキャン△</h3><p>这一年啃了摇曳露营 S2 和剧场版…怎么说呢，其实有那么点点失望：</p><ul><li>1-4, 8 这几集还不错。相对第一季淡淡的人际关系，这一季明显热闹了很多。</li><li>剧场版：前半段五分，后半段接近7分。片子大意是打工人的爱好，以一腔热血开始，挫折与回归生活为转折，继续推进为尾。露营作为并不算有主线的动画，其实在剧场里看节奏是不太行的，看前面有种小仙女公款开party的奇妙观感，倒是后半段回归生活有了点味道：在生活的忙碌中慢慢坚持的才是爱好嘛。片子还是挺菜的，主要还是感觉露营这个节奏做剧场版安个故事就不合适。</li></ul><p>说来我为什么没看完向山进发，我有罪我有罪我有罪我有罪我有罪</p><h3 id="生徒会の一存"><a href="#生徒会の一存" class="headerlink" title="生徒会の一存"></a>生徒会の一存</h3><p>葵关南 + 狗姐 的 Neta 片。看的非常之乐。JFRX 老师推荐的时候说，单元剧讲相声最乐呵，进了主线就一般了——果真如此。算是靠 neta 撑起来的作品吧，非常值得一看。</p><h3 id="BLEACH-千年血戦篇"><a href="#BLEACH-千年血戦篇" class="headerlink" title="BLEACH 千年血戦篇"></a>BLEACH 千年血戦篇</h3><p>放在这里没什么别的原因，只是真的只有感叹…想说的有很多，包括小丑社给的好资源，过了几年再看这部作品的冷静，民工漫的巨大号召力。最后只能轻叹一声，还是民工漫有号召力。</p><h3 id="86―エイティシックス"><a href="#86―エイティシックス" class="headerlink" title="86―エイティシックス"></a>86―エイティシックス</h3><p>对我来说最大的惊喜，每周等着看的片。严格来说原作其实很多地方挺菜的，安里小姐显然是那种想好一个浪漫的场景（比如花海相遇或者在纪念碑见面）然后再去写故事的，本身她的设定之类的都很简单甚至简陋。但这份气质和 A1 的年轻演出家们渴望表现的气质结合在了一起，就成了一种淳朴而有朝气的美。这让很多缺点看上去都很可爱。真好啊。</p><h3 id="メイドインアビス-烈日の黄金郷（来自深渊-烈日的黄金乡）"><a href="#メイドインアビス-烈日の黄金郷（来自深渊-烈日的黄金乡）" class="headerlink" title="メイドインアビス 烈日の黄金郷（来自深渊 烈日的黄金乡）"></a>メイドインアビス 烈日の黄金郷（来自深渊 烈日的黄金乡）</h3><p>分数是设 Ep.1，Ep.7-Ep.10 为高分，然后别的集一分分往下扣的。属于纯粉丝向作品。可以看到整个故事还是比较精妙的，但是被拖的太长了，稍微短一点反而会好不不少。结尾几集该血腥、该冲击的地方的地方反而绕过了，落点放在了母亲-女儿-黄金这对关系上，只能说有点遗憾吧。后知后觉的是，最巧妙的设定是愿望蛋的设定，无比巧妙的扭曲。</p><h3 id="かぐや様は告らせたい-ウルトラロマンティック-（辉夜大小姐想让我告白-超级浪漫-）"><a href="#かぐや様は告らせたい-ウルトラロマンティック-（辉夜大小姐想让我告白-超级浪漫-）" class="headerlink" title="かぐや様は告らせたい-ウルトラロマンティック-（辉夜大小姐想让我告白-超级浪漫-）"></a>かぐや様は告らせたい-ウルトラロマンティック-（辉夜大小姐想让我告白-超级浪漫-）</h3><p>顶尖的恋爱喜剧日常演出，日常回的各种表现让人印象深刻，我真诚建议可以把这里几集乐子演出回拉去看看。但是可能出于原作的瓶颈，感情的爆发非常的无力。</p><p>说真的，回头回顾一下，几个地方演出真的很不错，也有乐子。但是感觉从头到尾人物塑造还是几乎一样的单薄。导致中间我很开心，解决的时候我一脸懵逼：你们在搞啥？</p><h3 id="イノセンス（攻壳机动队2-无罪）"><a href="#イノセンス（攻壳机动队2-无罪）" class="headerlink" title="イノセンス（攻壳机动队2 无罪）"></a>イノセンス（攻壳机动队2 无罪）</h3><p>押井守的盛大演出，绝无仅有的豪华阵容。东方哲学、掉书袋、恶趣味融合在一部作品中。整个故事的逻辑还是很清晰的，但是作品几乎没有让你很关注这个主线，而是关注影像、符号和细节：人偶、记忆、动物、ghost。</p><p>有个外挂是 《无罪 METHODS 押井守演出笔记》，开个挂回来看体验会好不少。</p><h3 id="イリヤの空、UFOの夏（伊里野的天空、UFO的夏天）"><a href="#イリヤの空、UFOの夏（伊里野的天空、UFO的夏天）" class="headerlink" title="イリヤの空、UFOの夏（伊里野的天空、UFO的夏天）"></a>イリヤの空、UFOの夏（伊里野的天空、UFO的夏天）</h3><p>年度最喜欢、最惊喜的几部作品之一。世界系的代表作之一，从夏天的结束到夏天真正结束的漫长旅行。Ep.3 和 Ep.4 是非常值得一看的演出回：异质的时间感、光影、写实。</p><h3 id="フタコイ-オルタナティブ（双恋-Alternative）"><a href="#フタコイ-オルタナティブ（双恋-Alternative）" class="headerlink" title="フタコイ オルタナティブ（双恋 Alternative）"></a>フタコイ オルタナティブ（双恋 Alternative）</h3><p>青涩狂放的 ufo. 第一集氛围和演出类似 FLCL，而后续又有悠长深沉的浪漫，想必找 UFO 的场景会在我的脑海驻留很久。</p><h3 id="この世界の（さらにいくつもの）片隅に-（在这世界-更多一些-的角落）"><a href="#この世界の（さらにいくつもの）片隅に-（在这世界-更多一些-的角落）" class="headerlink" title="この世界の（さらにいくつもの）片隅に （在这世界(更多一些)的角落）"></a>この世界の（さらにいくつもの）片隅に （在这世界(更多一些)的角落）</h3><p>知名反战败大毒草（误）。在年底回顾来看感觉洞察力真强。以无知享受幸福，以温和联系彼此，以察觉来发现痛苦，以生命力和新的生命来面对死亡。能够感受到生命极度顽强的生命力。</p><p>其实关于这部作品的反战败，我认为它多少讲述的是「在谎言中生存的人」这样一个故事。「我们屋子里还有五个人，我还有一只手」到发现这一切都是掠夺来的谎言，有什么能比这个更讽刺呢？</p><h3 id="ブラック・ジャック-OVA（怪医黑杰克-OVA）"><a href="#ブラック・ジャック-OVA（怪医黑杰克-OVA）" class="headerlink" title="ブラック・ジャック OVA（怪医黑杰克 OVA）"></a>ブラック・ジャック OVA（怪医黑杰克 OVA）</h3><p>久闻出﨑統监督大名，看五点老师写的帖子里这部 ova 是比较好的入门作品。看的时候感觉一言以蔽之，就是「力量」：情节的冲突、影相的光影体现、生命意志。表现出来无比的伟力。</p><h2 id="Novel"><a href="#Novel" class="headerlink" title="Novel"></a>Novel</h2><h3 id="Flowers-for-Algernon（献给阿尔吉侬的花束）"><a href="#Flowers-for-Algernon（献给阿尔吉侬的花束）" class="headerlink" title="Flowers for Algernon（献给阿尔吉侬的花束）"></a>Flowers for Algernon（献给阿尔吉侬的花束）</h3><p>其实我觉得…挺菜的。好的一点在于，作品诞生的时代点子还真的不错。坏的一点在于，较篇幅而言节奏冗余的太多了。自我/记忆/关系/爱都是很重要的部分，但是感觉这些其实在中段重复的过多了。</p><h3 id="なめらかな世界と、その敵（平滑世界和它的敌人）"><a href="#なめらかな世界と、その敵（平滑世界和它的敌人）" class="headerlink" title="なめらかな世界と、その敵（平滑世界和它的敌人）"></a><strong>なめらかな世界と、その敵（平滑世界和它的敌人）</strong></h3><p> 非常日本SF的作品：SF元素中，对往昔作品的致敬占到多数，但没有形成一种互文式的全新体验或者完全贴合故事的设定；反倒是心怀鬼胎的人物简单的追求比较有意思。几个故事基本都6分吧，不过越后面越有意思。</p><p>BTW，我是真不知道日本人为啥这么喜欢伴名练…</p><h3 id="お隣の天使様にいつの間にか駄目人間にされていた件"><a href="#お隣の天使様にいつの間にか駄目人間にされていた件" class="headerlink" title="お隣の天使様にいつの間にか駄目人間にされていた件"></a><strong>お隣の天使様にいつの間にか駄目人間にされていた件</strong></h3><p>很菜，但很有教育意义，看完第一卷我立马开始了3天打扫一次卫生的生活。本书在功能性上可以说对我第一了（误）。</p><h3 id="黄昏色の詠使い（黄昏色的咏使）"><a href="#黄昏色の詠使い（黄昏色的咏使）" class="headerlink" title="黄昏色の詠使い（黄昏色的咏使）"></a>黄昏色の詠使い（黄昏色的咏使）</h3><p>满足了我对轻小说的想象，色彩与歌咏的美好设定，加上刻板人物和简短的意林小故事。没啥兴趣的也可以先把第一卷看了。设定、文字、插画和轻小说这种题材契合度高，故事本身很简陋，但是足够了。</p><h3 id="戦う司書（战斗司书）"><a href="#戦う司書（战斗司书）" class="headerlink" title="戦う司書（战斗司书）"></a>戦う司書（战斗司书）</h3><p>又土又好又土又好。故事算是一卷一篇。故事的节奏按照1/2-6/7-8/9-10 错开，可以当作是卷为切分的中篇集。除开第一卷的奇幻感，其余卷一般按照解密 + 战斗的形式展开。架构和故事并不新颖，但人物描写非常出色并合乎逻辑，以 1/5/6 三卷为代表。收尾篇虽然感觉架构和之前对不上，故事架构也很老套，但是人物和对话描写的相当有信服力。纯论分数的话，这个收尾是不值这个分的，但就当作给我看到的幻光加一星吧。</p><h3 id="Kongres-Futurologiczny（未来学大会）"><a href="#Kongres-Futurologiczny（未来学大会）" class="headerlink" title="Kongres Futurologiczny（未来学大会）"></a>Kongres Futurologiczny（未来学大会）</h3><p>看到一个评论说：莱姆和 PKD 嗑的是不是不同…</p><p>何等狂气的作品！何等蓬勃的想象！从未来学大会开始，到来的事件和观点像博物馆、像一波又一波的浪潮一般狂涌而来。想法像潮水一样涌出，随着药品一步步告诉你：什么是简单的、什么是困难的，最后将大幕揭开，展现出一个深邃的疯狂的讽刺世界。而未来尚未开始，我们还站在一切的端点上！这是何等的狂气、冷静与浪漫啊！</p><p>不过话说回来，感觉莱姆本人其实也挺「大男孩的」，虽然黑屁段子信手拈来，跨学科功底也有一些，但是相对于科技理论，更注重科技影像、人口和人文。</p><h3 id="人類は衰退しました（人类衰退之后）"><a href="#人類は衰退しました（人类衰退之后）" class="headerlink" title="人類は衰退しました（人类衰退之后）"></a>人類は衰退しました（人类衰退之后）</h3><p>虽然我不是田中信徒…但是这部确实饶有趣味！该打田中 + key 的萝卜了！</p><p>1-6卷是欢乐日常，前面写的像很多谐音meme的少儿作品，随着越写约转向一些 sf 和田中味的东西。7-9卷有一种快乐而朦胧的美感和探索的浪漫。作品提供了梦幻般的剧场、sf 的浪漫感和缓缓流畅的温情，相对田中其它作品又是偏构造且偏轻的（P.S. 5卷之后在结尾还在聊自己在写 Rewrite）。真好啊！</p><h3 id="科幻文学论纲"><a href="#科幻文学论纲" class="headerlink" title="科幻文学论纲"></a><strong>科幻文学论纲</strong></h3><p>在吴岩这里，科幻本身的性质被带着目的和想象被塑造，但这种方法其实是和性质多而泛的不同时代科幻割裂的，因此作者希望在文化中反过来考察科幻在其中的含义。作者把科幻作家分为作家簇以考察（本人觉得其实谱系的方法会更科学一点），介绍了女性、大男孩、边缘、落伍者作家簇，并且用对科学的、对社会的态度来考察这些作者，得出了一些结论。但我觉得这些划分本身很有意思，但没那么严谨。但本书还是给了很详实的介绍的，而且金句频出。最后介绍完之后，作者还是总结并展望了一下 SF 和主流文学。感觉不是很好的科幻史，但确实是值得简介的分析材料。</p><h3 id="The-Gnostic-Religion（诺斯替宗教）"><a href="#The-Gnostic-Religion（诺斯替宗教）" class="headerlink" title="The Gnostic Religion（诺斯替宗教）"></a>The Gnostic Religion（诺斯替宗教）</h3><p>「那些没有家乡的人有祸了」！从古代被排挤的、彷徨无措的人们的诺斯替运动，与遥远现在的存在主义/虚无主义之间连接了起来。在城邦文化破灭、罗马兴起的时候，对世界、规律怀有恐惧的人们孕育了深邃的设定：不可知的神明、破败的宇宙、灵和知识的信仰、对世界和规律的厌倦、逃避与反抗。同时又有匹配的详细世界观。张新樟的序言可真难读，把约纳斯和虚无主义—存在主义的诊断、二元论等价值挂钩，写的不错，奈何真的长…</p><h2 id="Comic"><a href="#Comic" class="headerlink" title="Comic"></a>Comic</h2><h3 id="よつばと-（四叶妹妹）"><a href="#よつばと-（四叶妹妹）" class="headerlink" title="よつばと!（四叶妹妹）"></a>よつばと!（四叶妹妹）</h3><p>太好看啦！作者画画透视功底太强了！四叶妹妹是那种真正的熊孩子，在作品里你能感受到她同时具有调皮的破坏性和孩童的本真性，但这股破坏力本质上也是本真的一部分。她长大可能会成为各种各样的小朋友，就让我们珍惜蹦蹦跳跳的四叶妹妹吧（况且她只折腾自己人，不会折腾读者）。</p><h3 id="Berserk（剑风传奇）"><a href="#Berserk（剑风传奇）" class="headerlink" title="Berserk（剑风传奇）"></a>Berserk（剑风传奇）</h3><p>作品没有完结，但是因为众所周知的原因，还是标个已读吧。</p><p>几个篇章中，故事和结构都很完美，整个作品故事浑然一体：黄金时代篇的完美悲剧、断罪塔篇绝佳的结构、极端细腻的人物关系。再次致敬三浦。</p><h3 id="ほしのさみだれ（惑星公主蜥蜴骑士）"><a href="#ほしのさみだれ（惑星公主蜥蜴骑士）" class="headerlink" title="ほしのさみだれ（惑星公主蜥蜴骑士）"></a>ほしのさみだれ（惑星公主蜥蜴骑士）</h3><p>长板和短板都很明显的作品。少年向的毁灭世界与拯救世界，各种各样的成长，以及一口气推进下去的最终战。绝大部分登场人物都能留下非常深刻的印象。但这里很多部分细节也没能完整的推进下去。</p><h2 id="Game"><a href="#Game" class="headerlink" title="Game"></a>Game</h2><p>这部分写的很少，因为手头一堆打了一半没打完的游戏，可以说欠了一屁股债…</p><h3 id="Ys-VIII-Lacrimosa-of-DANA"><a href="#Ys-VIII-Lacrimosa-of-DANA" class="headerlink" title="Ys VIII -Lacrimosa of DANA-"></a>Ys VIII -Lacrimosa of DANA-</h3><p>挺可惜的，近乎于没有的演出和90%都是断节奏的驱逐战把一个arpg和快乐探索的流程切的稀碎。第二章又臭又长，第三章开始渐入佳境，古代线好评，黄色丹娜好爽，第四章结尾、第六章前面、最后一章boss几个地方还有点印象。</p><p>说真的，我玩空轨的时候都感觉演出该有的都有，玩伊苏8的时候感觉演出好点我眼泪就掉下来了，可惜不仅没有好演出，还要拉我赶紧去保卫村庄，村口通马桶。</p><h3 id="Ruina-廃都の物語"><a href="#Ruina-廃都の物語" class="headerlink" title="Ruina 廃都の物語"></a>Ruina 廃都の物語</h3><p>14 小时打完一周目法师线，带的青梅竹马 + 盗贼 + 龙女。别的剧情是云完的…老实说云不完，因为很多细节夹杂在支线中了</p><p>放在 2022 的视角看，Ruina 大部分暗示还是很简单的，叙事也是虽然有一定暗线，但是还是很一本道的。系统也比较简单。被夸耀比较多的文本确实比较精细，在风格上缝合了 罗马 + 各地的神话故事，对这些部分熟悉的人可能会相对有乐子一些。在碎片化叙事已经很大程度上被科普了的今天，其实这个故事还是有那么一点点老旧的。不过很多细节还是藏在人物小小的对话中的，玩起来倒是饶有趣味。</p><p>作品比较好的地方就是感觉，虽然是同人作品，但是作者制作的却是非常有耐心，整个作品浑然一体。相对来说打磨的还是很不错的</p><h3 id="ゼノブレイド3（异度神剑3）"><a href="#ゼノブレイド3（异度神剑3）" class="headerlink" title="ゼノブレイド3（异度神剑3）"></a>ゼノブレイド3（异度神剑3）</h3><p>把我玩魔怔了，刃批变刃黑（误）。其实作品大纲从头开始揣测作者意思的话，大概是知道高桥要讲啥的，同时指引系统和画面质量史诗级提升，这真的是 switch 上的渲染质量吗？但相对来说脚本力下降太严重了，同时剧情编排感觉问题挺大的，感觉想讲的东西太多，反而酿成了项目灾难，导致没头没尾的，加上脚本力下降，导致能讲好的东西都没讲好。</p><p>本来本作核心人物在核心的对谈中应该是揭示整个叙事的意图的，但是因为此人已经沦落为了喜剧人物，所以显得作品过于爆笑。</p><h3 id="Baldr-Sky"><a href="#Baldr-Sky" class="headerlink" title="Baldr Sky"></a>Baldr Sky</h3><p>（天国的 giga…）Steam 半价入本体。重复对话不是很多，记忆溯行也有一些新剧情，有的网友吐槽的一些不能跳过的问题，在 Steam 版本应该修复了。作品的魅力来源于世界观、良好的学院篇/现代篇切换、丰富的剧情和战斗演出。 前三条线感情相对细腻一些，蕾线/记忆溯行是 Sora 为数不多塑造的地方（但俗话说的好，死人是不可战胜的），蕾线有着丰富的立场介绍，菜叶线则很细腻的展现了一个凡人视角下的世界，千夏线将前面的矛盾激化并点燃。亚季线浪漫来自于「Hello World」，而真线结尾确实感动了我。而空线完成了写得很吃力，但是确实做完了的故事。战斗系统非常有意思，不过我基本只用民工连招 Normal 和 Hard 混着打。</p><h3 id="BLACKSOULSII-愛しき貴方へ贈る不思議の国"><a href="#BLACKSOULSII-愛しき貴方へ贈る不思議の国" class="headerlink" title="BLACKSOULSII -愛しき貴方へ贈る不思議の国-"></a><strong>BLACKSOULSII -愛しき貴方へ贈る不思議の国-</strong></h3><p>今年最大的惊吓+惊喜之一…dlsite 入的，完成度高的不可思议，游戏阴间的不可思议，很多地方不看攻略还是挺吃力的，不过总觉得数值竟然最后也没崩（或者都换成机制怪了），叙事相对非常巧妙。Blacksouls2 用一种疯狂、猎奇的方式来讲述了不可思议国度与爱。</p><p>该玩神之天平了，go！</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>mwish 2022 summary</title>
      <link href="/2023/01/28/mwish-2022-summary/"/>
      <url>/2023/01/28/mwish-2022-summary/</url>
      
        <content type="html"><![CDATA[<p>激荡的 2022 年结束了。人年龄大了的一个感受就是，感觉时间的流动快了很多，明明是一样的一年，却明显感觉做的事情变少了（我也在想有没有一种可能是我做的事情真的变少了，这个可能性太过可怕，导致我不敢往下想了）。虽然没做什么事情，这 365 天还是硬着过活了过去，总得憋点文字出来。这一年，对我来说主题应该是「深入、选择与自由」。</p><p>这一年扩展的知识面确实不太多，我还是啥都不会。不过在以前浮光掠影看过的几个领域稍微花了一点精力，做到了 Revisit:</p><ul><li>Btree 上详细 Survey 了一下 PostgreSQL / InnoDB / WiredTiger 的实现，也了解了一下新鲜的 Bw-Tree 和 LLAMA，然后对其中部分设计大概知道了一些套路，也和 FTL 之类的知识对接上了。用这些知识去 Revisit LSM 甚至 WiscKey 的时候，发现了很多说法其实是有问题的。很多 pros and cons 在存储引擎上其实不完全是很抽象的最外层设计，而是外层设计 + 实现的贴合。这让我想起了 rsygg 之前对我说的话：「其实这些都没有什么区别」。当时还不理解，现在想来，大师果然是大师。</li><li>深入去做了一些格式相关的东西。其实本来做的类似分布式系统上搞各种 sync 和花活，对 Log 和并发写这些比较敏感，被派去做格式其实有那么点点小小的不甘心，不过接下来确实发现了很多问题，现在我感觉我差不多都能默写出 Parquet 的 standard 和这个格式的一些问题了，感觉很多时候 get hands dirty 才能发现其中很多实现的困难在什么地方。</li><li>大概过了一遍西方现代史。以前草草的看过一些政治哲学和社会学，但是并不清楚背景和文化语境，大概看了一遍西方现代史之后，去 Revisit 之前看的政治哲学、社会学和西方历史，很多地方大概能理解其中的年代和语境了（这方面也是看书太困难，比如之前看《路易波拿马的雾月十八日》的时候，完全看不懂人头，然后看一些利维坦之类的书的时候，也不太懂背景）。感觉之后看西方/国内文学的时候，也应该先过一遍对应的基础（圣经、荷马史诗、史记等等），要不然很多地方会完全失去味道、失去看懂隐喻的能力和品味文字魅力的高妙。</li></ul><p>其实这些东西都不是很难，但是还是要摒弃浮躁的想法，相对于看20篇博客或者单一的小视频，要抽出时间去啃一些代码/专著，才能更好的去回顾之前的内容，大概知道它们在讲什么，以免上了知识分子的骗。回过头来说，知识分子是真的很能骗人的，倒不能说大家都是故意的。我试图这样描述：</p><ul><li>每个论述可能包含于某一种叙事（SSD 的性能，社会运行的静态条件）</li><li>这个叙事通常有正确的一面（SSD 确实能靠并发上吞吐量，有的静态条件确实会影响社会）</li><li>但是它们忽略了很多别的问题，导致这个结论并非完全的 Solid（io 的影响，社会本身性质是相关联的、历史性的）</li></ul><p>网上很多论述都包含于某一种叙事，这种叙事并非完全正确的，支持者会完全相信这一种叙事、反对者会根据这个结论并非完全 solid 而全面驳斥这种论述，甚至进行人身攻击。但我觉得事情还是很复杂的：</p><ul><li>一个论述，如果抓住了一些结构性、功能性甚至是历史性的特征，就是有价值的</li><li>一些叙事不免会带上一些哲学性质（哪怕是物理 cs 这样比较扎实的领域）寻找一些完全正确的叙事在 CS 甚至物理领域都有困难，更不要说一些社会学科了，但是因此否定上述论述的…水平也就菜到那里了，没必要辩论了。</li></ul><p><img src="https://image.mwish.me/blog-image/Fku9KPrUYAAep7m.jpeg" alt="Fku9KPrUYAAep7m"></p><p>所以结论还是：多看多方面的论述、完整的材料，你就会发现互联网其实是分层的，之前觉得都很厉害的人其实一大半是水货（当然我也是水货，是水货没啥不好的，哈哈）。当然不太好的地方是我今年脾气确实暴躁了不少，这个得改…</p><p>不过老实说，上述说的都是很多正经论述的人了。很多人喜欢脱离文本，然后发散到一些和文本没啥关系的东西。如果这是同人创作的话，那我是很欢迎的（比如各种游戏的同人创作）。但是正经讨论问题的时候，随意比喻、脱离问题、脱离文本，基本上可以认为没有讨论问题的能力，直接拉黑就行了。</p><p>有一个比较开心的事情是，今年做上了狗群主，有了自己的 QQ 群。之前建过几个群，都因为没管下去，导致最终没人了，今年自己建了个读书有关的群，目前吸引了不少好玩的群友：有翻译莎士比亚的老哥、也有 galgame 大师、写 galgame 的脚本家、历史和哲学爱好者、SF大师。作为一个狗群主，我感觉自己什么都不如他们，所以也能在交流中学到很多。比较开心的就是，即使群里有矛盾，我作为群主也能比较好协调下去，然后这个小群真的给我运营下来了，每天都能学到新的（没用的）知识和有一些有价值的讨论（还有每天的快乐黑屁）。其实我从来不敢创建什么码农群，感觉码农互相吹黑的氛围还是很浓厚的，不是动辄x神就是互相黑屁，其实没啥意思。我今年也不怎么在知乎发文章了，因为全是点赞的，几乎没有人对你进行批判。怎么会喜欢被批判呢？答案是很多东西你发出来也不是完全懂，要经过不少讨论，才能再在原文本上形成一些有价值的、solid 的结论，全是夸耀和全是拉踩一样，都没有什么价值和力量。</p><p><img src="https://image.mwish.me/blog-image/FnZGSdfaEAIXJ0I.jpeg" alt="FnZGSdfaEAIXJ0I"></p><p>接下来一个话题是「选择与自由」。这是一个很大的话题，我必须只聚焦在个人上。这一年我还是换了个工作（大概是在写<a href="https://blog.mwish.me/2022/07/03/%E6%AF%95%E4%B8%9A%E4%B8%A4%E5%B9%B4%E8%AE%B0/">这篇博客</a>的时候）。那个时候我从北京跑到了杭州，然后换了个工作。其实按职业发展看，北京互联网和城市金融是比杭州好的，看了陆铭的书，我也知道了大国大城的意义。同时，在之前的组我过的还算舒服，老板和同事都很好，我干的活也不算杂活，很多时候自由度比我现在高多了，现在我做的反而相对杂一些。我是想说，并不能说我换个工作就什么问题都解决了，很多东西不是万灵药，但这是在说，选择的结果并不都是自己想要的，但是这是你选出来的，所以也没啥抱怨的。重要的是「能选」和「愿意选」：「我能，我也愿意从北京换到杭州，这是因为我不是那么 Care 这点职业发展前景，我更喜欢南方的舒适氛围和离家近，在这里我可以轻松几周回一次家」「我有点希望换一份工作，然后接触到一些不同的人和不同的工作环境，这也能让我 revisit 一些之前做的事情」。</p><p><img src="https://image.mwish.me/blog-image/C9D52720-75AB-4C50-9BDF-C3BF86CD37ED.png" alt="C9D52720-75AB-4C50-9BDF-C3BF86CD37ED"></p><p>这个时候读者可能会觉得「你 tm 在放屁，这些不是想当然的吗」。我觉得还真不是，做选择的时候，人是会被很多观念束缚的，可能被动被选择结果上会更好。自己选东西有一种随风漂泊的感觉，你知道很可能是错的，而且错了就没有可以抱怨的对象了：你不那么好把你的问题甩给别人，这是孤独和自己的对抗了。但是我觉得，选择的权力和自由还是很重要的，你必须自己做抉择，然后对此负责了。社会毕竟是由人组成的，即使有社会和家庭的阻力，你自己也是自由的，你是你自己的选择，你也要意识到，你不是没有选择。</p><p><img src="https://image.mwish.me/blog-image/C5CE8D59-4533-4D96-BADD-38D6F49FAD51.png" alt="C5CE8D59-4533-4D96-BADD-38D6F49FAD51"></p><p>最后，2022 年是很动荡的一年。大家被封了很久，在封控后，可能也失去了自己爱的亲人。在这里向大家的痛苦致意，为逝去的同胞默哀。希望大家 2023 年能少失去一些，一切为了美好的记忆。</p><p><img src="https://image.mwish.me/blog-image/FC2245C9-1DB2-411C-8C40-4818A699C181.png" alt="FC2245C9-1DB2-411C-8C40-4818A699C181"></p><p>预祝大家 2023 快乐。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Fast21 RocksDB Design</title>
      <link href="/2023/01/22/Fast21-RocksDB/"/>
      <url>/2023/01/22/Fast21-RocksDB/</url>
      
        <content type="html"><![CDATA[<p>离 Google 开源 leveldb，给我们一个很精巧的玩具实现，已经过去了很久很久。Facebook 开源的 RocksDB 成了工业界使用 KV 构建软件的默认标准。RocksDB 是一个功能非常完备的 KV 引擎，它被使用在各种大规模的分布式系统中和单机引擎中。</p><p>本文是 FAST’21 中 Facebook 发表的文章，描述了 RocksDB 在 2012 - 2020 的演进。</p><p>10年前，Facebook 的工程师拿到 LevelDB，只是针对 SSD 和大规模分布式系统使用，同时想优化一下 Compaction，于是他们添加了 Compaction。很多年后的今天，RocksDB 有了非常丰富的功能、非常丰富的 Tunning 体验。或许这也给了我们一些构建软件上的暗示：先做好一件事情，再慢慢做好别的事情。</p><p>论文的尾部附了一张 2012 - 2020 的 RocksDB 功能年表，读起来令人感叹：「前往无限的彼方，那是成为神的漫长道路」</p><p><img src="https://image.mwish.me/blog-image/output.png" alt="output"></p><p>文章的开始介绍了 RocksDB 的一些经验：</p><ol><li>在写入/读取等各个方面的配置/tuning</li><li>不同负载上都能支持</li><li>配置 / Metrics / 完善的 debug tools 和迁移工具等</li></ol><p>RocksDB 本身非常配置化。网上很多地方介绍的是它的主要链路，但是它很多组件都是可配置的（论文只提了亮点，我后面会提更多）：</p><ol><li>WAL Treatment</li><li><strong>Compaction Strategy</strong><ol><li>RUM Conjunction</li><li>Dostoyevsky</li><li>可以有高读写吞吐</li></ol></li></ol><p>这里 RocksDB 也有不同的 workload:</p><ol><li>Database (最主要的应用): crdb, tidb, MyRocks…<ol><li>读写混合负载</li><li>读：点查 + Iterator</li><li>会有 Transaction 和 Backup</li></ol></li><li>Stream Processing: eg, Flink, Kafka Stream, Samza, Facebook Stylus<ol><li>重写</li><li>读：点查 / Iterator</li><li>会有时间窗口和 ckpt (其实我不是很熟悉，之后可以看看 Flink）</li></ol></li><li>Logging / queueing service: Facebook LogDevice, Uber Cherami, Iron.io<ol><li>重写</li><li>读：点查 / Iterator</li><li>支持 HDD，比如 Logging 根本不用那么好性能，不过感觉 queue 还好（话说我感觉 queue 和 Stream 本质区别是啥样的呢…）</li></ol></li><li>Index Service: Facebook Dragon, Rockset<ol><li>应该是类似分析 / 训练用的 Servicing 引擎</li><li>重读</li><li>读 Pattern 为 Iterator，相当于是 batch scan</li><li>负载应该是训练出来的东西 bulk load，灌入数据</li></ol></li><li>Caching on SSD: Netflix EVCache ( 这里还写了 Pika，但我感觉 Pika 不完全是 in-memory cache 了，还是算 DB）<ol><li>重写</li><li>读：点查</li><li>可以丢弃存储的对象</li></ol></li></ol><p>下面给了个负载表格，其实很有参考价值</p><p><img src="https://image.mwish.me/blog-image/output-1.png" alt="table-2"></p><p>可以看到，RocksDB 这些负载都可以支持，非常强悍。</p><p>同时，所有系统都需要 checksum（虽然 RocksDB 可能会要求用户自己在上层维护正确性），同时也要把错误合理抛给上层。这些东西 xjb 写软件是不会碰到的，但是做一套严格的存储系统，还是非常必要的。RocksDB 会做一些逐个key的 checksum，也会后台检验、发送数据的时候校验等。</p><p>除了上述存储系统功能，这里还有：</p><ul><li>Monitoring framework</li><li>Performance profiling</li><li>Debug tools</li></ul><p>这里 RocksDB 本身可以上报一些信息，然后被使用到框架中。</p><p>上述这些东西都是 RocksDB 漫长开发的一部分，本论文讲述了 RocksDB 八年的开发史和 design choice.</p><p>文章的编排是：</p><ol><li>SSD / LSM 的基础 / LSM 怎么适配各种应用</li><li>主要的优化在 12 - 20 年的流变</li><li>RocksDB 在大规模分布式系统（shared-nothing 系统，多租户，升级，备份等）中的经验教训</li><li>Failure Handling / CRC 等处理，这部分实际上是非常工程经验的。RocksDB 的部署中出现了很多 failure 相关的经验教训，在构建鲁邦系统中，这些都需要学习的</li></ol><h2 id="SSD-LSM"><a href="#SSD-LSM" class="headerlink" title="SSD / LSM"></a>SSD / LSM</h2><p><img src="https://image.mwish.me/blog-image/output-2.png" alt="Figure-1"></p><p>LSM 本身被认为是顺序写，相对来说对 SSD 会友好一些（不提 WiscKey）。RocksDB 的主要架构如上图：</p><ol><li>WAL</li><li>MemTable</li><li>SSTable<ol><li>（在任何 Compaction 下）L0 都允许重复的 Range</li><li>SST 有对应的 BF （后面也摸出了很多别的索引）</li><li>多种 Compaction，如下图。RocksDB 用 Compaction 的方式来协调 RUM / 写放大之类的参数，来实现一些具体的 tunning / 优化。<ol><li>Level: 正常的 LevelDB 那种压缩。</li><li>Tiered: Universal Compaction。RocksDB 使用了 L0 层的特性来实现它</li><li>FIFO: 对 In-memory caching 使用，按照一定顺序清量压缩，purge 掉一些旧的文件。适合用来实现一些类似 cache 这样可以 discard 的功能。</li></ol></li></ol></li></ol><h3 id="Compaction-优化史"><a href="#Compaction-优化史" class="headerlink" title="Compaction 优化史"></a>Compaction 优化史</h3><p><img src="https://image.mwish.me/blog-image/output-3.png" alt="output (3)"></p><p>Compaction 方式的选择可以根据应用的性质甚至客户的 b 需求来选择。同时，论文以历史演化、时间顺序的方式，介绍了 RocksDB Compaction 的演进。</p><p>最早的时候，LevelDB 实现了 Leveled Compaction，这种方式自然 WA 很大。RocksDB 实现了并行 Compaction 后，磁盘受到的压力更是变大了。所以，最早期，RocksDB 优化的目标是 WA。关于 RocksDB 观察到的放大，除了 Table 3，还有下图：</p><p><img src="https://image.mwish.me/blog-image/79e23b93-13bc-4494-bfd6-000fb3e17a80.png" alt="79e23b93-13bc-4494-bfd6-000fb3e17a80"></p><p>这里统计了各层的 WA，更有意义。同时，WA 除了 LSM 层的放大，还有一些 WAL 的放大，因为 SSD Block 是 4/8/16KB 等大小对齐的，所以 WAL 写 + Sync 在 block-io 层其实是很重的，可能会有成百倍的写放大。同时，Leveled Compaction 会大概对应 10-30 倍写放大。总之，RocksDB 希望优化 WA。</p><p>这里 RocksDB 引入了 Tiered Compaction，即 <strong>Universal Compaction</strong>. 下面是 ZippyDB 和 MyRocks 引入 Tiered Compaction 之后的情景：</p><p><img src="https://image.mwish.me/blog-image/9838ec55-a634-4b87-a352-ec9ff85fdb81.png" alt="9838ec55-a634-4b87-a352-ec9ff85fdb81"></p><p>RocksDB 的使用者在写入剧烈的时候，通常会使用 Universal Compaction，读要求高会使用 Leveled Compaction。</p><p>WA 优化完了，下面优化 Space。读者可能懵逼了，Leveled Compaction 不是本来 Space 放大就很小吗？这里其实还涉及一篇论文: </p><p><a href="https://research.facebook.com/publications/optimizing-space-amplification-in-rocksdb/">https://research.facebook.com/publications/optimizing-space-amplification-in-rocksdb/</a></p><p>RocksDB 的设计者们认为，实际上，对大部分用户来说，RocksDB 上层和 SSD 写开销都用不到上限，<strong>大部分应用根本不会那么极端的去写。对大部分应用来说，利用空间是比较重要的事情，这样可能能提供更多的资源利用。</strong></p><p>因为 Leveled Compaction 已经是空间优化的了，所以 RocksDB 搞出了 <strong>Dynamic Leveled Compaction:</strong></p><ul><li>每层的大小会根据最后一层的大小动态调整</li><li>相对配置死的 Leveled Compaction，更有空间利用率</li><li>Leveled Compaction 如果配置死，很多时候会 fallback 到很奇怪的情况，比如先落深层，再落浅层，然后工程上放大其实比较大，RocksDB 说最大有大改 90%。对于 Dynamic Leveled Compaction，用户可以获得很稳定的压缩率</li><li>开启了这个功能之后，在 UDB 中，空间占用比 InnoDB 降低了 50%。</li></ul><p><img src="https://image.mwish.me/blog-image/Table-4.png" alt="Table-4"></p><p>RocksDB 接下来希望优化 CPU（我估摸着多少因为之前多线程写有些粗暴了）。不同配置的机器、不同的负载，CPU / SSD 瓶颈其实是不一样的。虽然这么说，不过以前 HDD 或者 SSD 比较糟心的时候，瓶颈一般会出现在盘上，但随着盘性能变好，在有些配置上，可能瓶颈会开始出现在 CPU 上了（RocksDB 论文里也说，他们盘一般不是那么好打满，大部分情况瓶颈不一定在盘上，不过我觉得瓶颈在盘上可能是个很古怪的事情，例如 queuing 算不算盘上 io 造成影响大呢？）。如图：</p><p><img src="https://image.mwish.me/blog-image/836223A7-DB77-45E3-885F-3AA6CF743929.png" alt="836223A7-DB77-45E3-885F-3AA6CF743929"></p><p><img src="https://image.mwish.me/blog-image/836223A7-DB77-45E3-885F-3AA6CF743929.png" alt="836223A7-DB77-45E3-885F-3AA6CF743929"></p><p>至少，在 Facebook 部署 ZippyDB 的场景中，CPU 开始一定程度上成为瓶颈：</p><p><img src="https://image.mwish.me/blog-image/A5A6FEC9-C5A8-404E-8FD5-D74CBAD3A627.png" alt="A5A6FEC9-C5A8-404E-8FD5-D74CBAD3A627"></p><p>在这种情况下：</p><ul><li>可能可以采用更轻的压缩策略</li><li>不适合 SSD，因为可能擦写太多搞坏 SSD 了</li></ul><p>RocksDB 可以配置压缩相关配置，和 Hash-map 相关的 memtable / File，来优化 CPU</p><h3 id="RocksDB-和新技术"><a href="#RocksDB-和新技术" class="headerlink" title="RocksDB 和新技术"></a>RocksDB 和新技术</h3><ol><li>Open-channel SSD, multi-stream SSD, ZNS:<ol><li>提供了更好的 SSD 管理，降低 Query Latency，减少 flash erase cycles</li><li>只有少数应用能有优化，同时维护麻烦很大</li><li>见 RFC： 这部分目前在外部维护。未来可能会抽出一个 FS 层（类似 arrow::fs? )</li><li><a href="https://github.com/facebook/rocksdb/pull/6961">https://github.com/facebook/rocksdb/pull/6961</a></li></ol></li><li>In-Storage Computing:<ol><li>并不知道收益有多大</li><li>API 相关的设计暂时不好决定</li></ol></li><li>Disaggregated (remote) storage:<ol><li>能够利用好 CPU / SSD 资源 （池化？）</li><li>需要处理 IO Latency 和下层 QoS</li><li>（是不是可以参考 CloudJump ?）</li></ol></li><li>Storage Class Memory (已经亡故的傲腾?）<ol><li>扩展 DRAM，但是实现 block cache 和 memtable 会比较难</li><li>设计为主要存储：通常 IO 没那么是瓶颈（虽然感觉延迟有问题，但是感觉因为延迟换，成本也太高了）</li><li>作为 WAL：可能需要额外设计一部分 Staging Area，类似 WAS?</li></ol></li></ol><h3 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h3><p>目前，SSD 的价格还没有那么低，尽管大家画饼他的价格会很低，但是 SSD 存储密度之类的还是不如 HDD，同时价格还是没有那么廉价，所以对大部分用户来说，节省空间和 WA 还是比较重要的。</p><p>不管怎么样，RocksDB 都提供了足够多的选项。此外，对于大 Value，RocksDB 还开发并重新开发了 BlobDB，来减少大 Value 造成的 WA。</p><h2 id="在大规模分布式系统上的经验"><a href="#在大规模分布式系统上的经验" class="headerlink" title="在大规模分布式系统上的经验"></a>在大规模分布式系统上的经验</h2><p>RocksDB 本身并不是一个大规模分布式系统，只是一个用到挂载盘的库。但是 RocksDB 的用户很多是需要妥善维护的大规模分布式系统，文章在下面几点上进行了介绍：</p><ul><li>资源管理</li><li>WAL 处理</li><li>文件批量删除</li><li>数据格式兼容性</li><li>Configuration Management</li></ul><h3 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h3><p>对于 Shared-nothing 架构，单台机器一般会有很多 RocksDB Instance，每个服务一个 Shard。在实践中，Shard 的量级一般是数十甚至数百的。这个时候，资源共享和限制就变得很重要了。这里可以配置的资源有：</p><ul><li>MemTable / Block Cache 的内存</li><li>Compaction 的 IO 带宽</li><li>Compaction 的线程数目</li><li>磁盘总用量</li><li><em>文件删除率</em><ul><li>这里和 SSD TRIM 状态有关，见后文</li></ul></li></ul><p>RocksDB 允许定义一个库的局部资源管理（Resource Controller），来管理资源，eg:</p><ul><li><a href="https://github.com/facebook/rocksdb/blob/main/db/write_controller.h">https://github.com/facebook/rocksdb/blob/main/db/write_controller.h</a></li></ul><p>这允许作出一些上层控制定义。此外，这里是库级别的处理，机器级别的处理会难得多，因为涉及一个全局资源的管理。因为每个 Instance 在当前实现也不会管别的信息，这里提到了两种 admission control 和资源策略：</p><ul><li>一开始使用 Compaction 率低，只有有 lag 才拉大频率<ul><li>不一定能控制好，而且这个会导致一般的资源利用率比预期低</li></ul></li><li>在多个 Instance 中间共享资源开销</li></ul><p>这里也提到，对于 CPU 资源，可以适当使用池化的内存，这样可以让系统线程数不至于过多。（感觉这种事要求做更精细的调度，然后从系统层移动到 RocksDB 层）。</p><h3 id="WAL-管理"><a href="#WAL-管理" class="headerlink" title="WAL 管理"></a>WAL 管理</h3><p>单机数据库通常需要开启 <code>sync</code> 模式，但是分布式数据库可能写了三副本，在单机的要求上，可能人家集群优化的不好，导致要开 async。同时，可能也有分布式系统只把 RocksDB 当成存储，然后<strong>写自己的日志</strong>，这个时候也会把 sync 关掉。这里引入了下列模式：</p><ul><li>NO-WAL</li><li>Buffered WAL</li><li>Sync</li></ul><h3 id="文件删除限制"><a href="#文件删除限制" class="headerlink" title="文件删除限制"></a>文件删除限制</h3><p>文件这个概念是在 os 和 fs 层引入的抽象。像 XFS 这样的 SSD 处理的比较好的 FS，一般可能会在删除文件的时候给 FTL 之类的发 TRIM。TRIM 可以透过文件层告诉 SSD，这部分数据已经不需要了，去 issue SSD 来进行可能的回收，降低需要的 OP 的开销</p><p>这种方法，在 Compaction 的时候也有问题，就是删除文件大量 TRIM 可能触发 SSD GC。这里通过用户测很奇怪的推断 batch del 的行为，来防止触发 GC，其实还是蛮怪的，网友评价：</p><p><img src="https://image.mwish.me/blog-image/4f1b4f01-d028-4611-a3b5-18a7461e2267.png" alt="4f1b4f01-d028-4611-a3b5-18a7461e2267"></p><h3 id="格式兼容性"><a href="#格式兼容性" class="headerlink" title="格式兼容性"></a>格式兼容性</h3><p>RocksDB 每隔一个月会发一次小版本，由于 CD 的情况，新版本如果有 bug，也需要回滚。这个提出了格式兼容性的要求。RocksDB 除了开发新功能一般会保证格式不变，同时，不能删除旧版本代码中对格式的兼容。</p><p>RocksDB 也会采取前向兼容，这个就更难了。这里会有一些类似 Protobuf 之类的机制来保证，RocksDB 至少能打开一年内的未来写的文件。这个感觉需要在设计上下功夫，同时感觉也可能和各种配置之类的有关。</p><p>（我个人的体验是：先写好新格式代码，测试完善后再上线，上线之前，新旧版本都支持读这份格式）。</p><h3 id="Manage-Configurations"><a href="#Manage-Configurations" class="headerlink" title="Manage Configurations"></a>Manage Configurations</h3><p>LevelDB 的配置管理是比较简单的，LevelDB 会把 Version 相关的逻辑做到 VersionSet 里头：</p><ul><li><a href="https://github.com/mapleFU/mwish-leveldb-notes/blob/master/db/version_set.h#L362-L363">https://github.com/mapleFU/mwish-leveldb-notes/blob/master/db/version_set.h#L362-L363</a></li></ul><p>RocksDB 有很多可以更改的配置，这些配置已经非常复杂了，首先，在正确性校验上，RocksDB 在 <code>New</code>之后可能会记录配置，然后，之后打开的时候，会根据用户的 Options 对比这些配置，查看：</p><ul><li>打开的配置和这个文件是否兼容</li><li>如果不兼容，可能会有一个 rewrite 工具，能够迁移到兼容的配置上</li></ul><p>此外，一个很复杂的事情是，RocksDB 的参数很复杂。本来这些东西可以默认参数（DynamoDB 论文里说他们都没啥对外参数，虽然我觉得很玄）。同时，他们作为一个库，只能提供参数出去，让上层去填。这个地方维护这些参数还是很复杂的。RocksDB 团队表示，会考虑 automatic adaptivity，但是这样动态调整参数也是非常复杂的。</p><h3 id="Backup-amp-Replication"><a href="#Backup-amp-Replication" class="headerlink" title="Backup &amp; Replication"></a>Backup &amp; Replication</h3><p>RocksDB 有几种 copying 方式：</p><ul><li>Logical Copying<ul><li>源端：Scan 出来（尽量不 fill cache 或者填充一些不需要的 Compaction Statistics）</li><li>目标端 Bulk Loading</li></ul></li><li>Physical Copying: Copying SST and Ingest<ul><li>提供自身的工具，去做 SST Ingest</li><li>这里需要借用文件的语义，所以 RocksDB 认为，Block Device 上做，这套便捷程度还是不如 FS 上做。</li></ul></li></ul><p>RocksDB 甚至提供了一个 Backup Engine，因为 Backup 可能有多份：<a href="http://rocksdb.org/blog/2014/03/27/how-to-backup-rocksdb.html">http://rocksdb.org/blog/2014/03/27/how-to-backup-rocksdb.html</a> 。用户可以在 Backup Engine 上做自己的实现。</p><p>这些东西在 API 上都有一定的复杂性：</p><ol><li>把一个 Ordered Seq 给重放</li><li>不是那么在意 Order 的重放</li></ol><p>这里有一个问题是，不同于 Dgraph 的 Badger，目前 RocksDB 还不能 Take 一个 user-defined Timestamp，然后 Out-of-Order 写。</p><h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><p>错误处理是只要在大公司碰过 SB 硬件就一定会遇到的问题。RocksDB 有比较多的经验来做相关的错误处理。</p><p>RocksDB 在错误处理上有两个层次：</p><ol><li>给所有可能 corrupt 的地方做 checksum</li><li>检查错误，尽早发现错误，防止静默错误影响副本或者在别的链路上影响集群</li><li>维护抛出错误的合适语义</li></ol><p>RocksDB 面临着下面的错误：</p><ul><li>SSD 盘故障<ul><li>由于性能原因，用户可能不会开启 DIF/DIX 等校验方式</li></ul></li><li>内存 / CPU 故障：发现原因较少，不过我姑且也碰到过几次</li><li>软件故障（嘿嘿，很常见的，我碰到过很蛋疼的）</li><li>网络传输的时候产生的问题（网卡等）</li></ul><p>根据 RocksDB 的统计：</p><ul><li>在 FB，每 100PB 数据，一个月会出现三次 corrupt<ul><li>40% 的情况下，这些 Corrupt 已经扩散到了别的机器上</li></ul></li><li>网络系统可能会有每 PB 17次 checksum mismatch （fb… 这么牛逼的吗）</li></ul><p>基于以上的情况，FB 认为，需要尽早找到 Corrupt，来减少因为 Corrupt 产生的 Downtime。在分布式系统中，还是能够用正确副本代替错误副本来修正数据的：</p><p><img src="https://image.mwish.me/blog-image/Figure-4.png" alt="Figure-4"></p><p>这里在 LevelDB 的 Block Checksum 和 WAL Checksum 之外，提供了不少层次的 Checksum，如上图。：</p><ol><li>Block Integrity:<ol><li>SST Block 和 WAL Block 会带有 crc</li><li>每次读，包括 SST Ingest，bulk loading 都要验</li></ol></li><li>File Integrity:<ol><li>SST 文件本身会被 Crc 一层，因为有的时候会走文件整个传输，但是 WAL 目前还没有</li></ol></li><li>Handoff Integrity:<ol><li>数据算完了会给 Write API 一份，在收到一端做 check。这个在 Oracle ASM 之类的系统实现了。</li></ol></li></ol><p>RocksDB 会做上面的保护。除此之外，内存逻辑上，MemTable 之类的没有保护。RocksDB 会编码 Per-Key-Value-Pair 的 checksum，来完成上层的保护，防止写入的时候出现错误。</p><p>此外，RocksDB 的哲学会：</p><ol><li>尽量返回错误</li><li>如果是无法单机恢复的错误，上报给用户。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>2020.1 - 2020.7</title>
      <link href="/2023/01/01/%E6%88%91%E7%9A%84-2020-%E5%B9%B4/"/>
      <url>/2023/01/01/%E6%88%91%E7%9A%84-2020-%E5%B9%B4/</url>
      
        <content type="html"><![CDATA[<p>2020 年是我在大学的最后一年，也是毕业走向社会的第一年，这一年对我来说非常跌宕起伏。每当我看到知乎的成功人士，都会想起我在那一年初的奇妙经历，然后产生一种痛苦和惆怅的感觉。个人的奇妙经历其实是不足为外人道也的，因为说出来就不止你自己觉得自己是傻逼，大家都觉得你是傻逼了。这有点像在互联网上脱裤子。不过事情都过去两年了，人放自己小时候不穿裤子的照片顶多也就骂骂你父母不文雅是不是。哎，也就是说我也不想让自己表现那么傻逼，不过既然我又蠢又疾世愤俗，那多输出点垃圾情绪也挺好的，好歹爽了</p><p>当时在一家很不错的数据库相关的公司实习，不过因为同事都太厉害了，而我那会儿完全不会写代码，所以生活的很痛苦。有一种大家人都很好，对我也很好，最大的错误就是我出现在人群里的感觉。虽然我比较努力的想跟上大伙儿，但是水平有限而天资不聪颖，我多少有一种奇妙的感觉。奇妙感觉一是感觉跟我一起实习的同事说的东西我一个都听不懂，第二个是前辈说的话我也不那么能听懂。印象很深的是，前辈去面试一个小伙儿，回头跟我说基础不太行，我为为啥基础不太行，前辈说：他竟然不懂「…」。这个名词我后来知道是什么意思，但对当时我来说是一个我指令集没有的指令，于是悲伤的感觉油然而生。想必那个时候 HR 应该把招我进去当作招聘事故了。当然，尽管如此，我作为公司的雇员，还是要去公司年会的，于是深夜坐着高铁摸去了北京。当时跟关系好的同事住一间宾馆，翻 IM 发现同事在聊我搞不懂的东西，于是就坐在宾馆里看 PPT，想着让自己不那么失败。年会的时候，大家都很热闹，我在 iPad Kindle 上看《在细雨中呼喊》，然后闷头看着菜。旁边的同事看着我这么能吃，再看看我肥胖的身材，感觉学到了一些教训。这会儿老板过来找我们聊天，看到牛逼的实习同事点了点头，看到我说「哎，你要努力呀」。</p><p>第二天离开北京的时候，因为我疏忽给高铁误点了。不过幸亏如此，我得以延迟了几个小时在北京的行程，穿着去年冬天来北京的时候和舍友 G 一起选购的棉袄，逛了逛兵器博物馆。这颇有点「 鸢飞戾天者，望峰息心；经纶世务者，窥谷忘反」的感觉。逛完之后，我看着中间的战斗机，感觉心情好多了。回家了，然后跟舍友约好开学的时候一起去 Kokia 的 Live。当然这个时候的我不知道我毕业之后回去北京，也不知道，影响我们这几年最大的事就要出现了。1月的时候疫情出现了，全国各地开始封着，第一次大过年的在家里和爸妈三个人吃饭，不过看动画还挺欢乐的。期间也有一些在公司写写代码，跑跑 k8s 的杂活。不过再怎么样不能影响过年嘛。在家里一边翻着毕业设计有关的东西一边快乐过年，期间一直在看《Heart Catch 光之美少女》。</p><p><img src="/Users/fuxuwei/Downloads/AD69FF47-A3DF-491C-8433-BE5EAE553ED7.png" alt="AD69FF47-A3DF-491C-8433-BE5EAE553ED7"></p><p>寒假过了之后，回到了一边上班一边准备毕设一边学习的生活。这里有个小插曲是，17楼的哥们往楼道上丢垃圾，被楼上的丢烟头点着了，结果楼上冒烟着火…算是我半个月第二次看到小区冒火，当时感觉日子过得太奇怪了。这会儿上班比较忙，然后我又在利用下班时间做 6.824，而我实在太菜了，受不了自己了。又因为关在家里，没法和同学交流，有点事实上的烦闷。在干了一个月之后，越来越被自己菜到不行。这个时候，舍友 G 告诉我他跑去头条了。我心想你之前不是签了三方吗，这春招找工作这么难，咋还去了呢，舍友 G 对我说：</p><blockquote><p>啊我觉得干着太无聊了，头条好歹有东西做，我也可以多写写代码</p></blockquote><p>然后我突然绷不住了，我就想找个工作，能接受我这种菜逼。这话听着有点扭曲，不是说去了大佬云集的地方一定好吗？当然好，前提是你跟的上。事实证明我跟不上，但我又想写代码。你别看我说这么别扭，人还是有想要证明自己的想法的，虽然很弱智。有句话怎么说的来着？「想做法师，无论是多么蹩脚的法师」。于是这会儿我决定跑去搞春招了。这也是我第一次去真的找工作。因为实习我就没面几家。于是充满挫折的春招开始了。</p><p>当时觉得自己好歹能加加油，然后一边刷 6.824、一边工作、一边准备春招，当时最敬仰阿里云和一些知道的做存储的小厂，然后把简历丢过去，于是有了下列经历：</p><ul><li>阿里云等了两个星期，没有笔试没有面试，流程变成了 Rejected</li><li>投的某个存储小公司，一面我其实面的不是很好，但是面试官说：你想的不够深，不过我放你去面下一个了。然后二面我觉得自己答的还行，然后…杳无音讯了（事后收到别人的评价，觉得我比较浮躁，我觉得评价的非常中肯）。</li></ul><p>搁着今天你看这些破事其实都没啥，你人菜嘛，就应该被挂。但是比较想去的地方都把自己 Rej 了，对心态打击其实真的不小的，咱们出去面试又不是理智动物对吧…</p><p>哦顺带一提我 leetcode 到今天只写了 90 题，大部分时候还是那会儿写的，哈哈。</p><p>这会儿我也只有总结经验了，把面试官问的东西好好学习，争取让上次问过的下次学会了对吧。那会儿我把 6.824 前三个 Lab 写完了（其实事后想画了很多时间，而且工业界做 Raft 的看我知识跟看着傻逼报菜名一样，哈哈），然后看了不少 LSM 和 Btree、操作系统 的材料，那个时候沉迷在什么牛客和知乎刷别人的面经。面经感觉就是这群尼玛大四大三的怎么啥都会，面 WXG 抖音 阿里巴巴之类的面经给我留下了非常长时间的心里阴影，感觉在大学这些人做了一万个 web 项目，从 Linux 内核精通到 Spring 标准再精通到中间件。我他妈却什么都不会，我他妈却什么都不会，我他妈却什么都不会。</p><p>然后接着面呗，投了网易呀商汤啊微软啊百度啊360啊什么的，里面一半没理我，有的面试比较难，我也尽力回答尽力做题，然后好好收集资料，好好准备。这段时间胖了不少，压力比较大，天天在家里嗯吃，吃了看什么剑指 offer 面经接着刷。还要上班来远程工作。做题这东西别看我只刷了七八十 lc（那会儿还没 90，哈哈），大部分题还是有思路能写的，不过有时候会漏边界条件，然后想起来抽自己嘴巴。有的面试官会问一些基础题，问的比较深我也答不出来，不过老实说当时大部分八股文背熟了，人家说啥你都能应两句（现在看来，我怀疑有的面试官可能也没那么懂，哈哈）。面试多了好处就是，你越面越…懂八股文了，除了对方聊的很深，不然你总能忽悠两句。这就是我们擅长的东郭先生之道吧。</p><p>说起来挺累的，其实身体不咋累，主要是心理有一种很折磨的感觉，每天在睡觉的时候否定自己。人们常说要和自己过的去，要降低要求，说真的，这些都是正确的废话，真到自己眼前除了焦虑还是焦虑，尤其是同学都手握 offer 的时候。每天躺在床上都有那么点怀疑自己的人生，妈的，我上大学都学了啥捏？</p><p>按理说这段时间应该 100% 投入在工作和学习中，不过抗压艰难，感谢 bangumi 和动画群的朋友，感谢日本动画，成了我找工作时候的调剂品。当然，我还记得面试某司的时候，因为看动画错过面试的时间，我赶紧发邮件过去说我家停电了，能不能晚半小时面试…这算是一个比较有意思的小插曲吧。你问我不是这段时间苦大仇深每天难受嘛？其实也没有，日子总得过下去是不是…人是很顽强的，一天总有那么多时间其实还蛮开心的。这会儿还是非常感谢家里人对我的支持，每天早上拉我去散步。呼吸一下路边新鲜空气之后，人上班坐牢的精神就没有那么强了。也感谢互联网的小伙伴和舍友。</p><p>在四月中旬的时候，拿到了 360 和网易的 offer，我永远感谢你们，虽然我没去，但真的太感谢了！这会儿有了着落，我感受到了一种喜悦，妈的，终于有人认可我了！我是备胎也无所谓，是三流选择也无所谓，他妈的有人认可我价值了，资本家愿意剥削我了！</p><p>四月底，学校允许我们回学校，在家肥了这么多，也毕竟得回去了。有了 offer 之后感觉心情好了一些，在公司我请了个长假，在路上把《许三观卖血记》看完了。兜兜转转到了心爱的学校，回到了宿舍，我们宿舍竟然没发霉，我的天。看见抱着西瓜打游戏的舍友 L，我心情不禁好了不少（舍友已经申请到了美国的学校了，不过看着他我就贼他妈开心）。于是我在宿舍继续了面试的生活，期间拿到了 TX 的 白菜 Offer。舍友 G 回来后看我胖了这么多，狠狠的嘲讽了我一顿。</p><p>（在宿舍面试的时候，也有不少小插曲，下午三点面试，然后舍友觉得我打扰他睡觉了，黑着脸把我从宿舍赶出去了，于是我到楼道里去完成面试了，令人感叹…）</p><p>五月，拿到了自己包最大的一个 offer，还是在学校的当地，不过老实说，面试官给我一种 30 岁的人 40岁的脸的沧桑感，又听说加班非常狠，胖了很多的我当时看着有点犯怵。这会儿感觉40%的公司没理自己，40% 公司把自己挂了，20% 的公司给自己发了 offer，但也非常纠结去哪。思前想后，社恐的我找了一圈关系好的网友，说「您好，我是在找工作的本科生，能给我一个面试机会嘛…」。</p><p>有一个网友听到了我的请求，然后把我简历投放了几家，我成功得到了面试机会。这也是我最终去的地方。不过据说面试面的不咋好。1年之后，我的一面面试官对我说：「当时看见一个肥宅在昏暗的灯光下说着我听不懂的话，絮絮叨叨，循环往复，我有点想直接把他挂了，不过老板说再看看，不知道怎么把你这个菜逼放进来了。」你看，人生就是这么戏剧性。拿到这家之后，我高兴的跳了起来说请客，被土豪同学拉着去请客吃日料，五个人吃了一千我还没吃饱，妈的，真黑。</p><p>然后我就选择了这家，感谢这个网友和不嫌弃我的同事，真的，非常感谢。</p><p>也很抱歉我的前同事们，我水平太差了，没有达到你们的预期，也没干成什么事情，这很令人遗憾。我还记得我当时说要跑路的时候，老板和带我的前辈都语重心长对我说了半天。不是要我留下，而是真切说工作的时候要注意怎么怎么样。因为我的原因拖累大家，很对不起。</p><p>然后就是毕业最后的时候了，我和同学逛了以前没去的动物园、图书馆、书店、吃东西的地方。说真的，人选择的时候，最终会知道自己错过了什么，我第一次感受到，自己学校所在的城市这么大，有这么多东西。当时我也看了很多动画片。哦说到毕设，我是之前花一个月在找工作期间做了个一半，找到工作后，大概高强度肝了2个星期。你看，本科生毕设就是这么水，我感觉我就是中国教育的败类，本科教育的漏网之鱼。怎么办呢，生活还得过下去。</p><p>毕业的下午是毕业典礼，上午学院拍毕业照。我看动画片看到六点没去。下午毕业典礼倒是印象很深。比较真挚的是学生代表，也是土木的，成绩不算好那种，跟我们讲自己找不到工作的事情，太有意思了。拨穗的时候，我忘记了自己的垃圾绩点，忘了自己学习上不好给学校抹黑，真切感受到「我他妈也是个学士了」。去拿毕业证的时候，我跟关系好的学长一直说，「我也是学士了，你对我尊重点」。哦对了为什么是学长，因为他在本校读研了…只见他用看傻逼的眼神看着我，但不知道为啥，我就是他妈很开心。</p><p>其实也没那么开心，有点惆怅，毕业典礼过完，大家就要收拾行李各奔东西了。有的同学去毕业旅行，但我真的很害怕自己因为太菜被裁员，所以决定早点入职，就准备了一周时间回家，在家呆几天就去北京。拿着行李箱离开宿舍的时候，感觉有很多话想和同学说，又什么都说不出来。这些寝室可能会留给别的校区过来的，也可能留给新生，但是再没有我们的身影，只有一个个同学离开。</p><p>其实我放这些话，不是抱着某种忆苦思甜或者教训现在找工作的人说什么话，虽然我确实有点像祥林嫂。现在找工作的，水平个个比我现在还强。我能教个锤子。这种经历是每个人独有的、碎片的，而且并不为外人道也。只是，如果有某个不那么成功的人看到了，能收到一些慰藉，想办法到最后都努努力，或者说用更加乐观的心态看自己的话，我觉得我就很开心了。你瞧，文章中提到的人，你别和我提起他们任何一个人，要不然我全都能想起来。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>[VLDB&#39;22] CloudJump: 存储层上云优化</title>
      <link href="/2023/01/01/VLDB-22-CloudJump-optimizing-cloud-databases-for-cloud-storages/"/>
      <url>/2023/01/01/VLDB-22-CloudJump-optimizing-cloud-databases-for-cloud-storages/</url>
      
        <content type="html"><![CDATA[<p>Aurora 风格系统用分布式块存储 / S3 等服务代替（或者加深了）了 SSD / HDD 的存储栈，获得了更深一层的存储栈、更大的存储可扩展性。但在这点上，了解这一层新的栈的性能就变得更加重要了。CloudJump 是 PolarDB 团队的在块存储上的一些研究产物，虽然论文主体研究对象是 InnoDB 为主的 Btree，但它也允许把这部分结果扩展到 LSM-Tree 上，论文描述了对 RocksDB 的一些修改。这篇文章提出的内容和解决方案是实在的，做的工作非常 Solid，但是，但看这篇文章感觉作者很多思路没有很好的告诉我们，或者是把内部黑话直接写外面了，很多东西我看的很懵逼，而且图片偶尔冒出两个错字，尼玛。文章最好的阅读方式是看 baotiao 的 talk 「<em>揭秘 PolarDB 计算存储分离架构性能优化之路</em>」和文末一个离职了的大佬写的评论。然后抱着这部分理解再去读原论文。</p><p>读本文之前，假定读者对 InnoDB 有着一定的了解。</p><p>本论文分了很多优化细节，但是核心点其实只有一个：</p><blockquote><p>云存储有着更高的延迟、更大的聚合带宽、更不好的 IO 调度能力、更好的随机读性能。需要<strong>利用带宽，优化延迟</strong>。</p></blockquote><p>在阿里云 NAS、块存储这些东西越来越好买的今天，我们应该把块存储当成新的版本答案，所以应该去看看这个文章是怎么写怎么优化的。</p><p>Block Storage 可以瞅一眼我之前写的 WAS: <a href="https://blog.mwish.me/2022/11/24/SOSP-11-Windows-Azure-Storage/">https://blog.mwish.me/2022/11/24/SOSP-11-Windows-Azure-Storage/</a></p><p>一般来说，云上块存储会提供：</p><ul><li>QoS</li><li>Admission Control</li><li>弹性计费</li><li>本身接口比较 general，可以避免 vendor in</li></ul><p><img src="https://image.mwish.me/blog-image/E9FE8C2B-8043-4F46-9A5F-3CDF3CBF7DEB.png" alt="E9FE8C2B-8043-4F46-9A5F-3CDF3CBF7DEB"></p><p>图上是一个对应的架构. 这套东西现在有：</p><ul><li>MySQL 等<ul><li>Aurora</li><li>PolarDB</li><li>Socrates</li></ul></li><li>LSM<ul><li>Anna</li><li>RocksDB-Cloud (Rockset)</li></ul></li></ul><p><em>注意一个很容易忽略的一点，DB node 上没有 Cache 相关的信息，这里是文章后面会提到的一个地方</em></p><p>这里还提供了一种 Aurora 的思路：在 Storage Tier 去 Apply Log，做到真正的 Log-is-database (可以想象一下为什么 PolarDB 不是完全的 Log-is-database) 通过减少存储通用性来减少带宽开销。这相当于定制存储层的实现。Socrates 其实也是一种这样的思路。这样减少了写带宽的限制，而提升了系统的上限。但是这种方案本身是作为一种特质化的存储，在 PolarDB 设计者思路中提到，PolarDB 这种抽出一个 FS 层可能在这个方面上并不优雅，但是可以提供更好的对 MySQL 适配的能力，同时，PolarDB 也可以依赖任意的块存储服务，这也提供了云上的扩展性。不过再说下去感觉就涉及一些类似阿里云政治问题或者产品售卖服务的问题了，思考这个就不是我这个技术员的专长了。有什么评论倒是可以提一下。</p><p>本论文提供了一种优化框架，通过对比 云上块存储服务和 SSD 的 bandwidth, latency, 弹性, 容量，来介绍它们对数据库实现的影响，然后进行相关的优化。下面有一个对比的硬件性能表格：</p><p><img src="https://image.mwish.me/blog-image/FD0FD85E-428C-4382-A83E-91FA7331F3BD.png" alt="FD0FD85E-428C-4382-A83E-91FA7331F3BD"></p><p>可以看到：</p><ul><li>从 baotiao 的演讲上看，Storage X 其实是 ebs 盘。为了避免 benchmark 碰瓷，这里会避免提到名字，不过这个测试应该是对 PolarDB 非常有利的</li><li>Latency 这里左边是平均，右边是方差。其他的都是氪金可以买的大小上限。这里可以提一下，阿里云的 ESSD 和 PolarStore 都走的是 RDMA，相对来说提供了很好的性能和暴力优化空间。</li><li>云存储有着更大的 Volume，更大的总带宽，但是 latency 可能会非常高. 据 baotiao 说，刷 Page 一般延时是 50us，在云盘上会升到 200us。和本文测试数据基本上是一个量级的。</li><li>在云存储中，多个节点之间的分散访问<strong>读写都可以</strong>利用更多的硬件资源，例如将单个大I/O并发分散至不同存储节点 ，充分利用聚合带宽。</li></ul><p>文章演示了一下带宽打满的场景，我感觉虽然属于拼凑，类似 WiscKey 讲 IO 串行和并行的，但是在迁移代码而不是很精细的从零开始写的时候，还是有一些道理的：</p><p>下面 Local SSD 和 Cloud storage 对比可以看看，同时 scattered I/O 是利用打散 IO 之后的策略。当然我个人觉得线程是 Polar 的工程，而不是严谨的 IO 测试术语，不过这个图已经能比较好的表示一些结论了。</p><p><img src="https://image.mwish.me/blog-image/4CA96E19-8F62-4A93-AEB6-2E2A87DF217B.png" alt="4CA96E19-8F62-4A93-AEB6-2E2A87DF217B"></p><p>同时，这里共享一组 IO 池子的话，如果并发上去了，把 IO-queue 打满了，延时可能会受到一定的影响，而 WAL 这种<strong>前台作业</strong>应该大部分时候是延时更敏感的（用户 SQL 可能卡在 Page 读和 WAL 写上），Flush Page 则带宽更加敏感，这里也做了一些实验。这里 Flush 占了 80% 的带宽，然后在带宽占瓶颈的场景下， Flush 卡了一下前台 Log 感觉就爆炸了：</p><p><img src="https://image.mwish.me/blog-image/28544914-5294-4B23-B7F9-B3103820E0D9.png" alt="28544914-5294-4B23-B7F9-B3103820E0D9"></p><p>CloudJump 面临以下技术挑战：</p><ul><li>远程分布式存储集群的访问导致云存储服务的<strong>I/O延迟高</strong>；</li><li>通常聚合I/O带宽未被充分利用，这个问题体现在比较多方面，后文细讲；</li><li>在具有本地存储的单机上运行良好但需要适应云存储而导致特性改变的传统设计，例如 page cache（这个地方应该是指 RW / RO 节点的 Page Cache，之间同步按照 CPU 那样设计相当于走一套 MESI 协议）；</li><li>长链路导致各种数据库I/O操作之间的隔离度较低（例如，日志刷写与大量数据I/O的竞争，一般日志刷写在用户前台链路上，数据 I/O 在后台的链路系统上）；<ul><li>我理解本身 SSD IO 也有这个问题，但是 SSD IO 带宽基本不那么能打满，上云加剧了这个问题，不知道 ScyllaDB 是怎么处理的。<a href="https://www.scylladb.com/2022/08/03/implementing-a-new-io-scheduler-algorithm-for-mixed-read-write-workloads/">https://www.scylladb.com/2022/08/03/implementing-a-new-io-scheduler-algorithm-for-mixed-read-write-workloads/</a> 看上去这个地方 CommitLog 应该会单独有一部分 IO</li></ul></li><li>云用户允许且可能使用非常大的单表文件（例如数十TB）而不进行数据切分，这加剧了I/O问题的影响。</li></ul><p>这里也引入了一些优化因素（下面论文的用词极其混乱，看内容比词汇更重要）：</p><ul><li><strong>Thread-level Parallelism</strong>：例如依据I/O特性实验，采用（更）多线程的日志、数据I/O线程及异步I/O模型，将<strong>数据充分打散到多个存储节点上</strong>。<ul><li>本质上这个其实和 InnoDB 应该关系很大，因为无论本身 InnoDB 还是 RocksDB，WAL 都是单线程写的，甚至有的库 Page 都是单线程刷的。这里会把这个单线程进行拆分。这里指的当然不是 Morsel Driven Database Exec 那种 Parallelism，下文 Task-Level Parallelism 同理</li><li>实际上，单线程的这种写，在单机环境可能可以打满存储，但是在云存储延迟爆炸的场景下，这个就很成问题了。这里会导致这个成为瓶颈。PolarDB 切分了日志大小，然后写入的时候去 log writer 会根据每个 Partition 的 Log 状况去做具体的 IO（可以回顾一下 InnoDB Redo Log，它本身也是分成不同不同小块的，见其 LSN 获取逻辑）。当然 baotiao 说这里有一些对齐块大小的优化，和不用 ftruncate 初始化块全0的优化，来降低用户链路上的开销。</li></ul></li><li><strong>Task-level Parallelism</strong>：例如对集中Log buffer按Page Partition分片，实现并行写入并基于分片进行并行Recovery。<ul><li>本质上，这个类似刷 Page 的时候的 IO。你如果走一条流，刷到一块盘上就很尴尬，这里也对这部分进行了切分，让不同的 Page (或者说 SST 甚至是 SST Block）能够刷到不同的 Chunk 上，来提供优化。</li><li>这个优化不仅是写链路上的，恢复链路上也可以以同样的方式得到读的 super bonus。</li></ul></li><li><strong>Reduce remote read and Prefetching</strong>：例如通过收集并聚合原分散meta至统一的superblock，将多个I/O合一实现fast validating；通过预读利用聚合读带宽、减少读任务延时；通过压缩、filter过滤减少读取数据量。与本地SSD上相比，这些技术在云存储上更能获得收益。<ul><li>这个地方是说，多个碎 I/O 合成一个真实对远端的 IO，Linux 的一些 deadline 之类的队列也会做 IO 合并，感觉是线上可能比较类似</li><li>当然，Prefetching 不是万灵药，本质上 Scan Task 会让 DB 层做 Prefetching，但是 Prefetching 也会占用系统的内存。感觉做起来是一个很难很精细的事情，又是嘴皮动一下，实现很难的东西。</li></ul></li><li><strong>Fine-grained Locking and Lock-free Data Structures</strong>：云存储中较长的I/O延迟放大了同步开销，主要针对Update-in-place系统，实现无锁刷脏、无锁SMO等。<ul><li>带锁 I/O 本来就比较重了，在云环境带锁 IO 感觉会重上加重。这个地方可以用一些方法来暴力优化。当然这部分是吹牛两个字，工程做死人的重要典范。</li></ul></li><li><strong>Scattering among Distributed Nodes</strong>：在云存储中，多个节点之间的分散访问可以利用更多的硬件资源，例如将单个大I/O并发分散至不同存储节点 ，充分利用聚合带宽。<ul><li>这个地方看上去和 Reduce Remote Read 矛盾，其实是小 IO 合并，大 I/O 猜测 Chunk 的分布来并行访问。感觉这个需要有一些对 Chunk 内容的先验知识。或者手动干预这中间的物理分布。</li><li>需要注意的是，这里读写都能从 Scatter 中受益。但本身 Scatter 也意味着很多奇怪的东西。我个人觉得这玩意在大公司能找到存储层的人正面 PVP 或者拉他们一起优化的话会比较好做。</li></ul></li><li><strong>Bypassing Caches</strong>：通过Bypassing Caches来避免分布式文件系统的cache coherence，并在DB层面优化I/O格式匹配存储最佳request格式。<ul><li>其实虽然 Parquet 是列存格式，但是你可以类比迁移到 Parquet 的 Footer。Footer 包含所有 rg 的信息。</li><li>这个地方应该是绕过分布式缓存，我个人理解是，对 TP 系统而言，分布式缓存本身不是那么好的东西，单机 cache 一下差不多得了</li></ul></li><li><strong>Scheduling Prioritized I/O Tasks</strong>：由于访问链路更长（如路径中存在更多的排队情况），不填I/O请求间的隔离性相对本地存储更低，因此需要在DB层面对不同I/O进行打标、调度优先级，例：优先WAL、预读分级。<ul><li>（对着 ScyllaDB 嗯抄！）</li><li>本质上，这个相当于设计 Log Page 等不同形式的 IO，在 db 层打标，fs 层处理。</li></ul></li></ul><p>需要注意的是，这里可以在实现层次明确一下语义。这里有的东西是 fs 层做的，有的东西是 db 层做的。fs 层可以合并或者操作一些在 fs 上连续的操作，但是很多东西其实是要 db 来打 tag 或者以一些方式来协同完成的。</p><p>这里在下图进行了评估：</p><p><img src="https://image.mwish.me/blog-image/685DC7F0-FD35-4EEB-B01C-3F1E0ECCD458.png" alt="685DC7F0-FD35-4EEB-B01C-3F1E0ECCD458"></p><p>（你看这里全都是黑话，我不给你解释一遍你还在这嗯想他在搞什么花招呢，你是不是得感谢一下我）</p><p>这里还有一个细节，是经典的 btr 和 LSM 大战。这个地方可以 Ref 一下作者在知乎上的一点 Notes，不保证对，但是看着确实有自己的思考：</p><blockquote><p>从论文的角度，我们需要追求讨论的完备性，处处都会对比 B-tree 和 LSM-tree，看起来是在回答一个存储引擎技术选型的问题。具体的内容欢迎大家到文章里去看。此处我想区分一个概念，就是产品优先的选型和技术优先的选型是不一样的。</p><p>从技术角度来说，LSM-tree 难以提供稳定的性能，其读写放大都太大了。为了做成一个好的产品，像 OB 这样用 LSM-tree 用得比较好的系统，其实是使用了一些成本较高的架构才实现的这一点。比如大家如果点开 OB 的 TPC-C 结果，会发现它的单个数据库节点坐拥 712 GB 内存，而整个集群像这样的大节点一共有 1557 个。如果没有比较大的规模，像 OB 这样的分布式数据库很难实现 8 小时内 tpmC 性能波动小于 2% 这样的性能稳定性要求。在云上，OB 需要使用多租户这样的形式来降低单个用户的使用成本。</p><p>OB 做这样的设计是因为他们一开始就假设了充足的内存，充足到一个数据库的内存可以充分缓存一天之内的所有变更，以至于每天只需要在夜深人静的时候做一次 compaction 将内存里面的变更与磁盘上的基线数据合并。这样不仅性能稳定，而且 compaction 对资源的占用也被尽可能地隐藏了，OB 甚至还在同一个 paxos group 内搞轮转合并，进一步隐藏 compaction 的影响。这套设计挺厉害的，就是太贵了。</p><p>如果大家了解公共云数据库的话就会知道，绝大部分用户的数据库节点一般是 4C8G 或者 8C16G 这样的小规格，与 OB 的节点规模相差非常大。</p><p>同一个 LSM-tree subtable 内部不同的分层之间因为存在数据耦合，为了做一个 get，如果我们只定位一个 extent，是没办法确定其中存储的数据是不是我们所需要的 key 的完整 value。这样不利于 LSM-tree 的数据像 page 一样在分布式存储集群里面自由地摆放。如果 extent 打散了，每次查询的时候都需要做跨界点的 merge。</p></blockquote><p>（上文摘自知乎文章：<a href="https://zhuanlan.zhihu.com/p/548215678"> https://zhuanlan.zhihu.com/p/548215678</a> 上云是存储引擎技术的分水岭。本人保留态度。感觉 LSM-Tree 本质上是把这个开销从 btr 的 implicit 的平常的重操作中暴露给了用户。至于读写，实际上这是一个很古怪的问题，因为 DB 并不是 kv 引擎，有大量的 RWN 场景。直觉和网上关于 LSM 的一句话说清楚的对比材料实际上我觉得都是真空球型对比。<em>我个人觉得，我们只能关注，在具体实现上，每个链路 IO 是什么样的，什么在前台，什么在后台</em>。）</p><h2 id="PolarDB-的优化"><a href="#PolarDB-的优化" class="headerlink" title="PolarDB 的优化"></a>PolarDB 的优化</h2><p><img src="https://image.mwish.me/blog-image/2e5f67c2-763c-49b3-926e-7b795df30525.png" alt="2e5f67c2-763c-49b3-926e-7b795df30525"></p><p>这里的 P 是采用的优化，在 RW 节点上，主要和写链路有关。这里最多可以有 15 个 RO 节点，在 RO　节点上，采取了一些读相关的和恢复相关的优化。一些优化两边都有，包括 Page 和 Log 的 Read。</p><h3 id="Accelerating-Persistent-WAL"><a href="#Accelerating-Persistent-WAL" class="headerlink" title="Accelerating Persistent WAL"></a>Accelerating Persistent WAL</h3><p>这里观察到，大部分 mtr 串行拷贝，而且只写一个 Page，这里用 Link_buf 来 Merge 对下层的 IO，转化为大块的可能跨 Block 的顺序 IO</p><p>这里采取的优化是，切分 Log Buffer，按照 Page_ID 做一些尽量细的切分。</p><p><img src="https://image.mwish.me/blog-image/9e4b54b1-9bf1-470a-82df-8b0b7d62d08c.png" alt="9e4b54b1-9bf1-470a-82df-8b0b7d62d08c"></p><p>这里引入了一个类似向量时钟的概念，然后把 InnoDB 的日志写切分成了几个阶段：</p><p>前台：</p><ul><li>Reserve RLSN</li><li>Copy 多个部分的日志（可能绝大部分时候只有一份？）</li><li>标记拷贝完成</li></ul><p>Log 相关的线程：</p><ul><li>刷的时候，推高 PLSN</li><li>拿到 BLSN，然后刷 PLSN - BLSN 的数据</li><li>并行去刷不同的日志，这里有一些细节要在后面 IO 层讨论。</li></ul><p>原先的 LSN 被设计为 GPLSN。这里相当于从原来 LSN 再扩展了一套机制，而不是用向量时钟完全取代 GPLSN。这个地方的正确性感觉是比较 trickey 的，因为我感觉其实有一个 LSN 和日志完整性的问题，<em>因为如果 round-robin 的话还好，不 round-robin 的话，LSN 感觉不太好直接映射到所有的 PLSN</em>，不过感觉工程上也是可以解决这些问题的，看文章似乎是 Log File 有 GLSN — Log 的映射。</p><p>这里还设计了 Rw 到 Ro 的 Redo Log RDMA 写，来避免 fetchlog 来大幅度影响 RO 节点（日志流是无限的，一直拉本身是个很 trickey 的事情），不过感觉这部分就很 trickey 了，有点天顶星科技。</p><p>Log Writer 实现如下图：</p><p><img src="https://image.mwish.me/blog-image/ee256e3c-e296-43a2-80ea-01a62fc16ac7.png" alt="ee256e3c-e296-43a2-80ea-01a62fc16ac7"></p><p><img src="https://image.mwish.me/blog-image/13e355c9-774f-46bc-9f05-c5da334c38a9.png" alt="13e355c9-774f-46bc-9f05-c5da334c38a9"></p><p>这里会把单段切碎的 Log Buffer 再分成细小的 Log Slice，然后单个打 Buffer 可能会分配给单个线程，找它的 Log Writer 走 async io 发送。达到了即聚合 IO（log 本身是一种聚合）又切碎 IO 的方式。不过 IO 任务多了，本质上也是一种很 trickey 的事情。我感觉这种方法类似大力出奇迹。</p><h3 id="Fast-Recovery"><a href="#Fast-Recovery" class="headerlink" title="Fast Recovery"></a>Fast Recovery</h3><p>InnoDB 的 Log Replay 有两种形式：</p><ol><li>Crash recovery</li><li>Log Apply in RO node</li></ol><p>传统的 DB 恢复需要读 HDD/SSD 散在各处的元信息，然后根据这些信息，再走 ARIES 协议恢复。PolarDB 中心化了 InnoDB / MySQL 的元数据，进了一个 Superblock （可以想象一下 Parquet 的 Footer 部分作为对比？）</p><p>这里和写日志一样，恢复也可以并行恢复，然后在 Log File 的 Header 做了一些 GLSN — Log 的映射，来保证 Fast Seeking。</p><p><img src="https://image.mwish.me/blog-image/cd9f6315-8e55-41f0-a28a-f9178e8506aa.png" alt="cd9f6315-8e55-41f0-a28a-f9178e8506aa"></p><p><img src="https://image.mwish.me/blog-image/54a1cd01-ec78-4265-a749-2dcb9984f520.png" alt="54a1cd01-ec78-4265-a749-2dcb9984f520"></p><p>这里回复的时候，如果某个 mtr 涉及了多个 Page，导致涉及了多个 Partition，也要原子恢复。这里的做法是，把所有的逻辑操作和文件操作放在 Log Partition 0，导致有复杂的事务必须由 Log Partition 0 来做一些全局的恢复流程，然后通知 Applier。这里再恢复的时候维护了一个 recover GLSN 来实现这套逻辑。</p><p>（卧槽牛逼牛逼牛逼牛逼）</p><h3 id="Prefetching"><a href="#Prefetching" class="headerlink" title="Prefetching"></a>Prefetching</h3><p><img src="https://image.mwish.me/blog-image/d1121804-646f-4184-a010-367088987e93.png" alt="d1121804-646f-4184-a010-367088987e93"></p><p>Prefetch 也是个工程上做起来实际上非常恶心的事情，这里有几种 Pattern：</p><ul><li>Cluster Index 上的 Scan，肯定 prefetch</li><li>Secondary Index 的 Scan，Batch Key prefetch</li><li>Locality: 某个 Page 经常被查大概率经常被更新，所以很可能有 SMO，可能需要 Prefetch SMO 需要的 Page</li></ul><h3 id="Fine-grained-Locking"><a href="#Fine-grained-Locking" class="headerlink" title="Fine-grained Locking"></a>Fine-grained Locking</h3><p>这里分成两部分：</p><ul><li>Index optimization: PolarDB 优化成了无敌无敌无敌的 Bw-Tree。本质上还是处理复杂的协议和 SMO 问题。</li><li>Shadow Page: 本质上感觉是一种内存换锁开销。因为这里的问题不是更新，而是带 Page 锁 IO。</li></ul><h3 id="Multiple-I-O-Queues-and-Scheduler"><a href="#Multiple-I-O-Queues-and-Scheduler" class="headerlink" title="Multiple I/O Queues and Scheduler"></a>Multiple I/O Queues and Scheduler</h3><p>这算是 IO 共享层很常见的策略了。不过这里不是靠存储层根据付费 QoS，而是一个优先级调度层。</p><p><img src="https://image.mwish.me/blog-image/765baf88-ad76-4f7a-ad19-2614d260d25a.png" alt="765baf88-ad76-4f7a-ad19-2614d260d25a"></p><ul><li>Log IO 本身是优先的，放到 Private Queue</li><li>Private 满了走到全局的 Queue</li><li>Page 这种操作资源比较重，不能抢占 Log-IO 的资源，但是可以在自己的资源池里面进行。</li></ul><h3 id="Aligned-I-O"><a href="#Aligned-I-O" class="headerlink" title="Aligned I/O"></a>Aligned I/O</h3><p>这里分成几个部分。因为块存储的 Block 可能很大，PolarFS 是 4-128 KB，这个地方需要调整对应的 大小：</p><ol><li>Log I/O 需要对齐一定的大小和格式</li><li>Data I/O 需要考虑 Compressed Page 和非 Compressed Page，做一些 IO 处理</li><li>Vanilla MySQL 会合并相邻的 Page 写，这里可能会阻止这种合并来利用聚合带宽</li></ol><p>（其实 1/2 我没有完全看懂细节，懂的可以讲讲）</p><h3 id="Experiments-and-Evaluation"><a href="#Experiments-and-Evaluation" class="headerlink" title="Experiments and Evaluation"></a>Experiments and Evaluation</h3><p><img src="https://image.mwish.me/blog-image/99e39b0b-dda9-466a-a858-38277d404bdb.png" alt="99e39b0b-dda9-466a-a858-38277d404bdb"></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a><strong>References</strong></h2><ul><li>PolarDB-CloudJump：优化基于云存储服务的云数据库(发表于VLDB 2022) <a href="http://mysql.taobao.org/monthly/2022/06/01/">http://mysql.taobao.org/monthly/2022/06/01/</a></li><li>过去5年，PolarDB云原生数据库是如何进行性能优化的？ <a href="https://zhuanlan.zhihu.com/p/535421993">https://zhuanlan.zhihu.com/p/535421993</a></li><li><a href="https://zhuanlan.zhihu.com/p/548215678"> https://zhuanlan.zhihu.com/p/548215678</a> 上云是存储引擎技术的分水岭</li><li>Talk: <em>揭秘 PolarDB 计算存储分离架构性能优化之路</em></li><li><a href="https://zhuanlan.zhihu.com/p/547171082">https://zhuanlan.zhihu.com/p/547171082</a> 网易的云原生数据库，提到了这里带来的性能优化</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>SQL Server Columnar Stores</title>
      <link href="/2022/12/24/SQL-Server-Columnar-Stores/"/>
      <url>/2022/12/24/SQL-Server-Columnar-Stores/</url>
      
        <content type="html"><![CDATA[<p>SQL Server 在 2012 年 - 2015 年间推出了好几篇有关列存的论文。在差不多同一时间，它还有一系列内存数据库引擎相关的讨论。在 2015 年的论文中，这些内容被合并起来了。随后，SQL Server 又有一些评估对应效率的论文，这里提到的列表如下：</p><ul><li>[SIGMOD’11] SQL server column store indexes</li><li>[SIGMOD’13] Enhancements to SQL Server Column Stores</li><li>[VLDB’15] Real-Time Analytical Processing with SQL Server</li></ul><p>同时，在内存数据库方面，论文其实还更多一些：</p><ul><li>[CIDR’11] Deuteronomy: Transaction Support for Cloud Data</li><li>[VLDB’11] High-Performance Concurrency Control Mechanisms for Main-Memory Databases</li><li>[SIGMOD’13] Hekaton: SQL server’s memory-optimized OLTP engine</li><li>[ICDE‘13] The Bw-Tree: A B-tree for New Hardware Platforms</li><li>[PVLDB’14] Trekking Through Siberia: Managing Cold Data in a Memory-Optimized Database</li><li>[IEEE’14] Compilation in the Microsoft SQL Server Hekaton Engine</li></ul><p>在 VLDB’15 的论文中，这些东西终于被结合到一起，可以在 Hekaton 上跑列存引擎了。</p><p>这些东西也可以被放到所谓的 HTAP 宏大叙事中：</p><p><img src="https://image.mwish.me/blog-image/628BF470-2E67-426B-B1BA-E6203D36421E.png" alt="628BF470-2E67-426B-B1BA-E6203D36421E"></p><p>当然我们可以认可 HTAP 是个商业概念，但是技术是真的，我们还是要看看这些东西是怎么做的。</p><p>先回顾一下列存的三篇论文，简单介绍一下他们的包含的内容：</p><ul><li>SQL Server Column Store Indexes 这篇文章是最早的，介绍了 Column Store Indexes，值得注意的是，这里基本上是没有更新的 handling 的，应该只有 Batch 插入，这里功能应该类似 Secondary 的覆盖索引，用户的查询如果可能的话，可以直接走这个 Index，然后可以不走主表。这篇文章也描述了执行和优化器上做的一些优化工作</li><li>Enhancements to SQL Server Column Stores 这篇文章支持了更新和把它当作覆盖索引，同时，增加了 UPDATE Handling 和一些 Join 算子的细微实现。现在 SQL Server 引擎把数据的 schema 组装成 RowGroups 和 Delta-in-row-group。这里有一些 hacking 还没贴出来。这里应该是支持了操作很重的 Update</li><li>Real-Time Analytical Processing with SQL Server 结合了 Hekaton 引擎，同时，给 Column Stores 做了再增强，现在可以支持 Primary 和 Secondary 的 Column Index 上 Update，然后内存对接 Hekaton 引擎，这套操作在 Delta-in-row-group 上再封了一层逻辑。</li></ul><p>我将循序渐进简单介绍一下，这套系统是怎么实现的</p><h2 id="SQL-Server-Column-Store-Indexes"><a href="#SQL-Server-Column-Store-Indexes" class="headerlink" title="SQL Server Column Store Indexes"></a>SQL Server Column Store Indexes</h2><p>这个版本是相当于给 SQL Server 添加一个 secondary index 版本，然后设计了一个类似 Parquet 的格式。</p><p>这里定义列存为一种新的索引类型，这个索引我推测不是 RDBMS 那种索引，感觉是一个仅支持插入对部分列的一个 mv 。这里主要任务还是给 AP 查询。它基于 SQL Server 做的 BLOB(LOB) 功能（感觉这套单机和分布式都研究得比较透彻了）。基于 BLOB，它有如下的视图：</p><p><img src="https://image.mwish.me/blog-image/1280X1280.png" alt="1280X1280"></p><p>和</p><p><img src="https://image.mwish.me/blog-image/1280X1280-1.png" alt="1280X1280 (1)"></p><ul><li>Page：基本概念可以平移自 Parquet 的 Page，变长</li><li>(Column) Segment: Parquet Column Chunk</li><li>RowGroup: 对应 Parquet 的 RowGroup，在这篇论文里面大概有百万行级别的数据</li><li>Directory: 类似 Parquet 的 Metadata / Footer</li></ul><p>上层的一些 Locking / Logging / Recovery / Partition 之类的策略尽量用 SQL Server 的代码</p><h3 id="Data-Encoding-and-Compression"><a href="#Data-Encoding-and-Compression" class="headerlink" title="Data Encoding and Compression"></a>Data Encoding and Compression</h3><p>Encoding 部分很草台，没啥说的，我相信微软，不过这篇文章描述确实很糙。微软后面好像出了一些 CompressDB 之类的论文，这里不介绍了</p><p>后面还描述了一些 RLE + Bit-packing 相关的，可以直接参考 Parquet 的 RLE 格式，总的来说是没有什么新东西的。</p><h4 id="Optimal-Row-Ordering"><a href="#Optimal-Row-Ordering" class="headerlink" title="Optimal Row Ordering"></a>Optimal Row Ordering</h4><p>这部分比较有意思，其实某种程度上有点 Auto Clustering 的味道，我们考虑以下逻辑：</p><ul><li>数据有一致性的情况下，encoding 性能和效率会很好，一个非常好的例子是 RLE / DELTA</li><li>因为只会在这个索引上跑一些分析，所以 Order 并不重要</li></ul><p>所以会根据数据来重新组织，提高性能</p><p>当然，对多列数据进行这样的操作是个比较复杂的问题，因为本质上需要一个衡量措施来保证这个东西对用户是有效的，多列的某个 optimal 的策略可能损害单列的性能。</p><p>论文说这里采用了 Vertipaq™ algorithm。好像 auto clustering 会使用 z-ordering 一类的算法。</p><h4 id="Caching-和-IO"><a href="#Caching-和-IO" class="headerlink" title="Caching 和 IO"></a>Caching 和 IO</h4><p>BLOB 因为是变长的，在 Disk 上可能会跨多个 Disk Page。这里设计了一个 Buffer Pool （感觉类似 TUM 新项目那套？）来缓存对象</p><p>这里会有两种 read-ahead:</p><ul><li>Column Segment 内部的 Read-ahead</li><li>Column Segment 间的 Read-ahead</li></ul><p>我个人感觉这个还是很难做的。</p><h3 id="Query-Handling-and-Optimization"><a href="#Query-Handling-and-Optimization" class="headerlink" title="Query Handling and Optimization"></a>Query Handling and Optimization</h3><p>这里作者基于下列逻辑推断：</p><ul><li>Column Store Index 会大大减少读 Disk 的 IO 开销</li><li>所以，CPU 可能会成为一个瓶颈点</li></ul><p>这里会采用 vectorize 的方式做计算。</p><p>这套东西本身比较复杂，不过尽量简单的说：</p><ul><li>复用了之前的 SQL Engine<ul><li>减少实现开销，保持用户透明度，同时 Query 可以同时包含 Row 和 Column 的处理模式</li><li>允许 Query 在运行期<strong>动态变更</strong>执行模式（这里目的写了一些奇怪的东西，感觉上是早期实现原因，不过这个姑且也很诱惑人）</li><li>允许列存为正交 feature，为事后搞别的事情做出铺垫</li></ul></li></ul><p>在执行的时候有一些 tricks，考虑到这些 tricks 实际上还是挺重要的，具体列存是不是可以参考一下 Velox：</p><ul><li>添加了 Batch Operator<ul><li>Access Method 允许下推 bitmap filter 和谓词</li><li>尽量直接在压缩的数据上做操作</li></ul></li><li>使用 Delayed String Materialization</li><li>Bitmap Filter 被改成一种很泛用的格式，根据数据分布的不同，执行不同的逻辑（类似 Roaring Bitmap?）</li><li>做了 Runtime Resource Management</li></ul><p>在 Query Optimization 阶段，Query Optimizer 可以根据 RowGroup 的大小来估算一些 IO 开销，来进行优化。在这篇论文里面，感觉 RowGroups 都比较静态，都是 immutable 的，所以感觉这块做的会不算很复杂</p><p>直观感受是，Column Store Indexes 对 Point Get 和 Range Scan 性能比较差。</p><p>实现上，Batch 操作会被定义成 Batch 是一个 Physical Property，用这个来保证查询的性质。</p><p>在 Join 中，这里会尝试在 Build 阶段构建 bitmap，类似 dynamic-filter，然后下推到 Probe-Side。这里如果有多张表 Join，它会抽取出 Join 的条件，查看哪些表是事实表，哪些表是维度表，根据这个构建 DF.</p><p>下面举几个查询的例子：</p><p><img src="https://image.mwish.me/blog-image/6a37acef-9139-498f-b3aa-fad333d99bf0.png" alt="6a37acef-9139-498f-b3aa-fad333d99bf0"></p><h2 id="Enhancements-to-SQL-Server-Column-Stores"><a href="#Enhancements-to-SQL-Server-Column-Stores" class="headerlink" title="Enhancements to SQL Server Column Stores"></a>Enhancements to SQL Server Column Stores</h2><p>这篇文章允许 Column Index 可以更新，并且可以作为 Primary Index(可以类比成 MySQL 的 Cluster Index） 存在。需要注意的是，这篇文章本身没太提，但是结合后面的论文可以看出来，它这个是给数仓型应用设计的</p><p>这文章前面逼逼叨叨了一下之前的设计：</p><p><img src="https://image.mwish.me/blog-image/76541149-7baa-4bac-a729-a4128f6f786e.png" alt="76541149-7baa-4bac-a729-a4128f6f786e"></p><h3 id="优化之前的设计"><a href="#优化之前的设计" class="headerlink" title="优化之前的设计"></a>优化之前的设计</h3><p>和 Parquet 不同的应该是字典的处理方式。论文感觉没特别详细指出不同列字典是怎么处理怎么 fallback 的，不过感觉也不 care 了。</p><p>SQL Server 有两种字典：</p><ul><li>Global Dictionary: 某个 Column 的全部字典</li><li>Local Dictionary: 某个 RowGroup 的字典</li></ul><p>这里的构建采取了这样的流程：</p><ul><li>采样，决定是否要构建 global index</li><li>构建 Index</li></ul><p>比较值得一提的是，Index Build 阶段内存开销会比较大，这里需要：</p><ul><li>提前申请好内存的一个阈值</li><li>根据内存，可以分配切 RowGroup 之类的大小，还可以切成多个 DOP 来构建，每个线程拿着一大块内存<ul><li>这个地方，线程过多，可能会切的过碎，造成一个次优的选项。所以这个地方会动态调整 DOP，来动态控制线程的数量。这里调整方式是根据系统每个线程实际占用的内存可以反映这批数据的分布，用这些情况来动态的决定，在预估的这些内存资源下，开多少个线程比较合适。</li></ul></li></ul><h3 id="SQL-Server-相关语义兼容"><a href="#SQL-Server-相关语义兼容" class="headerlink" title="SQL Server 相关语义兼容"></a>SQL Server 相关语义兼容</h3><h4 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h4><p>采样 / 统计是个比较常见的需求了，数据库内部需要采样来支持 statistics，ClickHouse / Snowflake 以及很多现代数据产品还要高效支持 SAMPLE 算子，来帮助那些不知道在做什么的科学家来高效的随机 SAMPLE 一些行。</p><p>SQL Server 的查询优化会需要统计信息，非 Primary Index 的索引不需要做 Statistic，因为它认为可以在 Primary Index 上做收集即可。这里有两种收集索引上信息的模式：</p><ul><li>高性能，低 Accuracy<ul><li>随机选中 RowGroup，在 RowGroup 内随机选中 Row。上面的选择率由采样比例来手动定义</li><li>在构建字典的时候尝试采样，选择这种方式</li></ul></li><li>高准确度，高 IO 和 CPU 开销<ul><li>扫描所有 Column Segmentsm，在里面随机选中一些 Row</li><li>在构建 Histogram 的时候使用这种方式。</li></ul></li></ul><h4 id="UUID-Bookmark-support"><a href="#UUID-Bookmark-support" class="headerlink" title="UUID(Bookmark) support"></a>UUID(Bookmark) support</h4><p>这里 Bookmark 类似 PG 的 <code>(page, slotId)</code>, query optimizer 之类的都会依赖这个 Bookmark。这里用 <code>(rowGroupId, rowId)</code>来代表 bookmark。</p><p>突然发现，本质上这个和 id 变更或者 WiscKey GC 是一样的场景。</p><h3 id="Update-Handling"><a href="#Update-Handling" class="headerlink" title="Update Handling"></a>Update Handling</h3><p><img src="https://image.mwish.me/blog-image/f6140d49-24e8-4203-81ce-ea28c77d939a.png" alt="f6140d49-24e8-4203-81ce-ea28c77d939a"></p><p>Columnar 的直接更新是一个很大的性能下降，这里希望在不损害压缩性能（有的格式，像一些 HTAP 的格式，通过 micro-block 之类的方式来做直接更新。感觉压缩率肯定比不过这些列的格式）。这里还是希望写比较快。</p><p>这里表格更多是 data warehouse 的事实表，数据一般会有大量的插入和比较少量的更新和删除。这里可以看上图：</p><ul><li>内存中：<ul><li>新插入的记录被写道 delta store 中，这是一个 btree。这个阶段应该还没有产生一个 RowGroup Id，系统会给它生成一个 unique integer 的 key。</li><li>磁盘的删除记录被表示在 delete bitmap 中</li></ul></li><li>磁盘中：<ul><li>Delta Store 的 Btree 对应磁盘结构</li><li>包含多个 RowGroup 的 Column Store</li><li>内存中的 delete bitmap 在存储中可能是个 Btree</li></ul></li></ul><p>做不同操作的时候：</p><ul><li>Insert: 插入 delta store</li><li>Delete: 如果是 delta store 的记录，那么直接删除它。否则插入 delete bitmap</li><li>Update: 拆分成 Delete + Insert</li><li>Merge: 拆分成 Delete + Insert 等操作</li></ul><p>Delta Store 感觉上有那么一点类似 RocksDB 的 MemTable 或者 Kudu 的 MemRowSet，本身行存 + 1 份 active，后面的会被慢慢移动到 Disk 上的列存结构上。这里需要说明的是，和 RocksDB 的 MemTable 不同，这里的实际上都还是 active 的，但是 delete 可能还是会进来</p><p>在 move 阶段中，写正在 move 中的 Delta 会被 Block 住，直到 move 操作完成（其实这个 Kudu 好像都有实现）。move 和读取是可以并发的。在 move 完成之后，可以在元信息中做提交，队之后的事务，写入的 RoiwGroup 可见，然后 Delta 不可见。等待依赖 delta 的事务都完成后，这个 delta 就可以 GC 了</p><p>Bulk Insert 会被额外处理，通常 Bulk Insert 可能是某个 ETL Job 的一部分，Row 很多会直接构成一个 RowGroup。如果 Row 不够多，这个地方会先 Build 出一个 Delta Store。这里 SQL Server 强调了一下，希望保证每个 RowGroup 有百万行数据。</p><p>这个地方，Scan 可以做的非常干净，因为对 Delete 的处理可以完全在算子层（Scan Operator）解决。不过我想了下，比方说查询优化本来可以简单从 Zone Map 读 Count(*)，但是现在需要 Zone Map 的 Count 记录减去 Delete 对应的数目，这个流程稍微变得 Trick 了一些。总之上层做一些优化的时候要考虑到这一个流程。</p><p>有大量删除记录的 row 会大大降低性能，在大量的删除后可以做一个 Compaction 来提高性能，不过我感觉 Compaction 流程也类似 Kudu 的 Compaction 或者 WiscKey 的 GC，需要注意映射关系的维护。</p><p>不同的 delta store 可以分给不同的线程去读，因为读 delta store 很慢。</p><p>在执行的时候，这里会尝试推一些 bitmap 下来，类似 dynamic-filter。存储层会处理这个 BF，来优化扫描（感觉 BF 字典之类的可以合作）：</p><blockquote><p>To avoid this explosion, hash join operators now store information about bitmaps and their estimated selectivity. At implementation time, the selectivity information is passed to the child, enabling it to adjust its cost to account for the bitmap selectivity. In order to limit the amount of optimization requests to child groups the optimizer does not treat each request as different, but rather clusters requests based on their selectivity thus being able to reuse far more than it would otherwise.</p></blockquote><p>这里对很少访问的分区，还会采取更激进的方式去压缩，来节约空间。</p><h2 id="Real-time-analytical-processing-with-SQL-server"><a href="#Real-time-analytical-processing-with-SQL-server" class="headerlink" title="Real-time analytical processing with SQL server"></a>Real-time analytical processing with SQL server</h2><p><img src="https://image.mwish.me/blog-image/6b4dfa96-ee75-4097-a568-b6c2ca127a48.png" alt="6b4dfa96-ee75-4097-a568-b6c2ca127a48"></p><p>这篇论文大概的结构可以看上图。图片没有什么意思，一些细节还是很值得一提的。</p><p>文章作于 2015，算是有个 Hekaton 内存 + Disk 逻辑了。内存数据库不是已经够快了吗？论文认为，这样还是可以优化一些 AP 查询。在之前，添加 CSI 会让表只读，13 年的论文让主表可以是一个 Column Index Store，来给数据仓库提供负载。这篇文章算是提供了一个可更新的 Secondary Index。这个有什么区别呢？答案是他们认为更新 Primary Index，说明整个表都是 Column Index，本身是个数据仓库。Secondary Index 可能主表是个 Btr，是优化某一类 AP 查询，所以希望更新有更好的适配 TP 的性能。SQL Server 用了个很巧妙的方法来操作。</p><p>我们可以从结论上推断，类似 TiDB 用 TiFlash 达到了 HTAP，这篇文章设想是准备一个索引，然后用内存中的索引来实现 HTAP，实际上这样不需要 Log 流来同步，但是需要隔离相关的查询负载，同时也要注意对主链路性能的影响。</p><p><img src="https://image.mwish.me/blog-image/e7e704b2-004c-4572-ae2b-c6fcf5d88fac.png" alt="e7e704b2-004c-4572-ae2b-c6fcf5d88fac"></p><h3 id="CSI-On-In-Memory-Tables"><a href="#CSI-On-In-Memory-Tables" class="headerlink" title="CSI On In-Memory Tables"></a>CSI On In-Memory Tables</h3><p><img src="https://image.mwish.me/blog-image/c4d3a298-df8d-4c9f-aa58-5260cadd7e22.png" alt="c4d3a298-df8d-4c9f-aa58-5260cadd7e22"></p><p>这里所有靠谱的内容都在内存中，Tail Index 部分的内存没有被写入 Column Store。这里相当于用 In-memory Table 部分代替了 Delta Store 的部分，来提高了更新性能。删除的数据会被放到 Deleted Rows Table 中，这也并不全同于 Delete Bit Map。有一个 Data Migration Task 会迁移 Tail Index （没有写入 Column Store ）到 Column Store 中，这部分有一个很 Trick 的地方，就是本身 Hekaton 引擎就处理了 MVCC，然后数据不刷下去正确性也是保证的，所以，<strong>这里为了不让 deleted rows 被频繁更新，所以不会希望某些被频繁更新的行被刷下去，而是希望这些部分能够一直被 Keep 在内存中</strong>。</p><p>被实现成了两部分：</p><ul><li>Stage1: 线程把非 hot 的部分刷下去，这个时候使用一个读事务，写完之后这些记录都相当于是删除的。<ul><li>这个地方有个 Hack 是，Deleted Rows Table 应该是个特化的实现，可以 mark 一整个范围的删除，通过这个来减小插入的时候 mark as deleted 的开销。</li></ul></li><li>Stage2: 用多个事务回填 row-id 和 mark as undeleted。这部分可能和用户事务冲突。这部分的内部事务做了特殊处理，让它尽量不影响用户的事务。</li></ul><p>同时，在 flush 的时候可能会顺带执行一些 RowGroup Cleanup，如果一些 Row Group 被删除的差不多了，那么，在 Flush 的时候可能相当于会把它们合起来（感觉上，这个表示所有 Row Group 都在同一层，没有 L1 L2 的概念）。</p><h2 id="Updating-Secondary-Column-Stores"><a href="#Updating-Secondary-Column-Stores" class="headerlink" title="Updating Secondary Column Stores"></a>Updating Secondary Column Stores</h2><p>Primary 的一个问题是，需要 Hekaton Table 高度配合。Secondary 相当于 Hekaton Table 没有那么好的能力去配合你。所以这里需要一些别的方式来处理这部分逻辑。</p><p><img src="https://image.mwish.me/blog-image/2b26a32a-fb5c-4890-8978-eeeaed4454d7.png" alt="2b26a32a-fb5c-4890-8978-eeeaed4454d7"></p><p>这部分中，相当于添加了一个 Delete Buffer，这是一个类似 InnoDB Change Buffer 的东西，因为找到原记录是非常昂贵的，需要一次点查。这里引入了一个 delete buffer，来专门处理这类场景。Delete Buffer 本身是一个包含删除 key 的 Btree。它的格式是 <code>&lt;Key, Delete-Generation&gt;</code>，这个 Generation 是 Delta move 的 Generation，删除的时候，会用最高的 Generation 来删除。</p><p>查询 Delete Buffer 的时候，这套逻辑没有再封在转换层，而是插入了一个 Join 算子（anti-semi-join），来带上 Delete Buffer。这里在 Build 阶段会算出 key 的 min-max 是否在这个 row-group 中，来跳过 delete-buffer 对一些 RowGroup 的访问。</p><p>注意，这个 delete bitmap 更接近上一篇论文的定义，而不是 primary index 中那个使用的定义。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>InnoDB Link_buf</title>
      <link href="/2022/12/10/InnoDB-Link-buf/"/>
      <url>/2022/12/10/InnoDB-Link-buf/</url>
      
        <content type="html"><![CDATA[<p>InnoDB 在 MySQL 8.0 之后，提供了 Lock-Free WAL 的机制，顺序申请 LSN，然后把内容拷贝到 Log 应该写入的 Buffer 中，最后写入 Disk，然后通知上层。同时，Page Flush 和这套机制是联动的，FlushList 和这套日志流程需要联动。</p><p>为什么需要贴这块呢？相对于一般的 mpmc，mpsc 等队列，WAL 是一个在数据库中很常用，与 concurrent-queue 有共同点，但是也有不同的内容。因为它涉及内存拷贝和 IO。</p><p>我们先简短介绍一下从别的文章抄来的代码入口，InnoDB 对内容的修改会走 mtr，mtr 会有对 buffer 的锁和 Page Change 的 Logs，Log 在 mtr 执行阶段会 buffer 在 mtr 的内存中，在 commit 阶段会移动到 <code>log_sys_t::buf</code> 中，这里会通过 <code>log_sys_t::buf</code> 来写，日志会被拷贝在 Log Buffer 中，当配置 <code>innodb_flush_log_at_trx_commit=1</code> 的时候，这里会在 txn-commit 的时候持久化日志。</p><p>写入 Log 是在 mtr 提交的时候：</p><ul><li>分配 LSN</li><li>等待内存的 Ring Buffer 匀出足够的空间，然后 Link 到对应的结构中</li><li>拷贝到内存 Buffer 中</li></ul><p>在这之后，Page 的写入就被写入到内存的 Log Buffer 了，随后，脏页需要被加入 flush list，这个时候，为了维护脏页写入的顺序，会有：</p><ul><li><code>redo_log_mark_dirty_pages</code>: 标记页面为 dirty</li><li>Link 到对应的结构中</li><li>由 Recent Closer 线程来处理</li></ul><p>需要说明的是，Flush 和 LSN 强相关，因为 ckpt 依赖 LSN，这个可以说是 Recover 层的原因，InnoDB 的 Page 会有下面两个参数：</p><ul><li><p><code>oldest_modification</code></p></li><li><p><code>newest_modification</code></p></li></ul><p>这两个词含义和字面意思差不多，mtr 修改单颗 index 可能会修改多个 Page（虽然概率上可以当成大部分乐观的场景，它只会修改一个 Page，但是涉及 SMO 或者什么的时候，可能会修改多个 Page），它在 mtr commit 的拷贝 log 阶段需要持有这些页面的锁。这个地方会尽量让 flush list 按照 oldest modification 的时间下刷，在 8.0 之前的版本，甚至是按照这个顺序下刷的：</p><p><img src="https://image.mwish.me/blog-image/ca7f50ef0815b17696656e1a27259016.png" alt="ca7f50ef0815b17696656e1a27259016"></p><p>这个和 checkpoint 的和 Recover 的处理有关，checkpoint 的时候，从某个 Checkpoint LSN 中恢复，可能要考虑 LSN 和恢复之间的关系：</p><p><img src="https://image.mwish.me/blog-image/15a26426373819f5d7028880cf357f51.png" alt="15a26426373819f5d7028880cf357f51"></p><p>否则的话，这个可能恢复的时候，需要一些特殊的处理机制：</p><p><img src="https://image.mwish.me/blog-image/577871cca6c66b0c091720e103568f7b.png" alt="577871cca6c66b0c091720e103568f7b"></p><p>在新的 Design 中，这里大概会维护一些乱序度，然后让对应 Page 在 L 的区间内保证一定的 Order。</p><p>系统中，维护了下面的变量：</p><ul><li>(<code>Link_buf</code>) <code>recent_written</code>: 记录内存拷贝的 write. 护写log buffer的完成状态, <code>recent_written</code>中维护的最大LSN, M表示, 所有小于这个M的LSN都已经将它的redo log写入log buffer. 而这个M也是(如果这下crash, 可能会触发的)崩溃恢复的截止位点, 同时也是下一个写log buffer操作的开始位点.</li><li>(<code>Link_buf</code>) <code>recent_closed</code>: 维护 flush LSN 的递增性质</li><li>额外的后台线程(<code>log_writer</code>/ <code>log_flusher</code>, <code>log_flush_notifier</code>, <code>log_checkpointer</code>, …</li></ul><p>这篇文章不会介绍太多 Buffer Pool 无锁 flushing 的细节，因为写文章的时候我也没完全搞懂。</p><h2 id="代码入口"><a href="#代码入口" class="headerlink" title="代码入口"></a>代码入口</h2><p>具体而言，这块相关的代码在 <code>log0buf.cc</code> 里面，这里面也有不少的描述，然后一些头文件定义在 <code>log0log.h</code> 里面，<code>log_t</code> 类型在 <code>log0types.h</code> 里面. 外界调用在 mtr 的代码中：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Write the redo log record, add dirty pages to the flush list and release</span></span><br><span class="line"><span class="comment">the resources. */</span></span><br><span class="line"><span class="type">void</span> <span class="type">mtr_t</span>::Command::<span class="built_in">execute</span>() &#123;</span><br><span class="line">  <span class="built_in">ut_ad</span>(m_impl-&gt;m_log_mode != MTR_LOG_NONE);</span><br><span class="line"></span><br><span class="line">  ulint len;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> UNIV_HOTBACKUP</span></span><br><span class="line">  len = <span class="built_in">prepare_write</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (len &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="type">mtr_write_log_t</span> write_log;</span><br><span class="line"></span><br><span class="line">    write_log.m_left_to_write = len;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> handle = <span class="built_in">log_buffer_reserve</span>(*log_sys, len);</span><br><span class="line"></span><br><span class="line">    write_log.m_handle = handle;</span><br><span class="line">    write_log.m_lsn = handle.start_lsn;</span><br><span class="line">    write_log.m_rec_group_start_lsn = handle.start_lsn;</span><br><span class="line"></span><br><span class="line">    m_impl-&gt;m_log.for_each_block(write_log);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">ut_ad</span>(write_log.m_left_to_write == <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">ut_ad</span>(write_log.m_lsn == handle.end_lsn);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">log_wait_for_space_in_log_recent_closed</span>(*log_sys, handle.start_lsn);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">DEBUG_SYNC_C</span>(<span class="string">&quot;mtr_redo_before_add_dirty_blocks&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">add_dirty_blocks_to_flush_list</span>(handle.start_lsn, handle.end_lsn);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">log_buffer_close</span>(*log_sys, handle);</span><br><span class="line"></span><br><span class="line">    m_impl-&gt;m_mtr-&gt;m_commit_lsn = handle.end_lsn;</span><br><span class="line"></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">DEBUG_SYNC_C</span>(<span class="string">&quot;mtr_noredo_before_add_dirty_blocks&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">add_dirty_blocks_to_flush_list</span>(<span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> <span class="comment">/* !UNIV_HOTBACKUP */</span></span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">release_all</span>();</span><br><span class="line">  <span class="built_in">release_resources</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="LSN-分配"><a href="#LSN-分配" class="headerlink" title="LSN 分配"></a>LSN 分配</h3><p>我们不过度牵涉 mtr 的细节，首先这里需要 reserve 对应的 lsn:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@see @ref sect_redo_log_buf_reserve</span><br><span class="line">@param[in,out]logredo log</span><br><span class="line">@param[in]lennumber of data bytes to reserve <span class="keyword">for</span> write</span><br><span class="line">@<span class="keyword">return</span> handle that represents the reservation */</span><br><span class="line">Log_handle <span class="built_in">log_buffer_reserve</span>(<span class="type">log_t</span> &amp;log, <span class="type">size_t</span> len);</span><br></pre></td></tr></table></figure><p>这里会利用 <code>fetch_add</code> 来拉大对应的内容，这里有个区别是 sn 和 lsn:</p><ul><li>sn 是逻辑的 bytes</li><li>lsn 是物理上的 bytes bias</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Log_handle <span class="title">log_buffer_reserve</span><span class="params">(<span class="type">log_t</span> &amp;log, <span class="type">size_t</span> len)</span> </span>&#123;</span><br><span class="line">  Log_handle handle;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Reserve space in sequence of data bytes: */</span></span><br><span class="line">  <span class="type">const</span> <span class="type">sn_t</span> start_sn = log.sn.<span class="built_in">fetch_add</span>(len);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Ensure that redo log has been initialized properly. */</span></span><br><span class="line">  <span class="built_in">ut_a</span>(start_sn &gt; <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Headers in redo blocks are not calculated to sn values: */</span></span><br><span class="line">  <span class="type">const</span> <span class="type">sn_t</span> end_sn = start_sn + len;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">LOG_SYNC_POINT</span>(<span class="string">&quot;log_buffer_reserve_before_sn_limit_for_end&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Translate sn to lsn (which includes also headers in redo blocks): */</span></span><br><span class="line">  handle.start_lsn = <span class="built_in">log_translate_sn_to_lsn</span>(start_sn);</span><br><span class="line">  handle.end_lsn = <span class="built_in">log_translate_sn_to_lsn</span>(end_sn);</span><br><span class="line"></span><br><span class="line">  ...</span><br></pre></td></tr></table></figure><p>可以看到，这里用 <code>fetch_add</code> 添加了对应的 sn / lsn，分配了日志对应的 <code>start_lsn</code> 和 <code>end_lsn</code>，然后这部分算是 LSN 分配完成了，不过，在同一个函数中，还有：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">if</span> (<span class="built_in">unlikely</span>(end_sn &gt; log.sn_limit_for_end.<span class="built_in">load</span>())) &#123;</span><br><span class="line">    <span class="built_in">log_wait_for_space_after_reserving</span>(log, handle);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">ut_a</span>(<span class="built_in">log_lsn_validate</span>(handle.start_lsn));</span><br><span class="line">  <span class="built_in">ut_a</span>(<span class="built_in">log_lsn_validate</span>(handle.end_lsn));</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> (handle);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这一部分是要等待 Log 分配足够的空间。这个空间大小是怎么会是呢？</p><h3 id="等待-LSN"><a href="#等待-LSN" class="headerlink" title="等待 LSN"></a>等待 LSN</h3><p>(这里可以参考 InnoDB REDO LOG BUFFER管理 - 丁凯的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/358690853">https://zhuanlan.zhihu.com/p/358690853</a> 这篇文章，写得比较细)</p><p><code>log.sn_limit_for_end</code> 是个 atomic variable，它的更新受锁保护，但是读的时候可以直接 fastpath 读，来保证读的性能:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">/** @&#123; */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/** Maximum sn up to which there is free space in both the log buffer</span></span><br><span class="line"><span class="comment">    and the log files. This is limitation for the end of any write to the</span></span><br><span class="line"><span class="comment">    log buffer. Threads, which are limited need to wait, and possibly they</span></span><br><span class="line"><span class="comment">    hold latches of dirty pages making a deadlock possible.</span></span><br><span class="line"><span class="comment">    Protected by: writer_mutex (writes). */</span></span><br><span class="line">    <span class="type">atomic_sn_t</span> sn_limit_for_end;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Maximum sn up to which there is free space in both the log buffer</span></span><br><span class="line"><span class="comment">and the log files for any possible mtr. This is limitation for the</span></span><br><span class="line"><span class="comment">beginning of any write to the log buffer. Threads check this limitation</span></span><br><span class="line"><span class="comment">when they are outside mini transactions and hold no latches. The formula</span></span><br><span class="line"><span class="comment">used to calculate the limitation takes into account maximum size of mtr</span></span><br><span class="line"><span class="comment">and thread concurrency to include proper margins and avoid issue with</span></span><br><span class="line"><span class="comment">race condition (in which all threads check the limitation and then all</span></span><br><span class="line"><span class="comment">proceed with their mini transactions).</span></span><br><span class="line"><span class="comment">Protected by: writer_mutex (writes). */</span></span><br><span class="line"><span class="type">atomic_sn_t</span> sn_limit_for_start;</span><br></pre></td></tr></table></figure><p>这里在 <code>log_wait_for_space_after_reserving</code> 里面，会走：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">log_wait_for_space_after_reserving</span><br><span class="line">- log_wait_for_space_in_log_buf(log, start_sn)</span><br><span class="line">- - log_write_up_to (等待 start_lsn - log.write_lsn &lt;= log.buf_size)</span><br><span class="line">查看 Log 是否比较大, 要分配 Log 的 Buffer, 也可能走 log_write_up_to</span><br><span class="line">- log_wait_for_space_in_log_buf(log, end_sn)</span><br><span class="line">- - log_write_up_to (等待 end_lsn - log.write_lsn &lt;= log.buf_size)</span><br></pre></td></tr></table></figure><p>这个地方，关键的函数是 <code>log_write_up_to</code>, <code>write_lsn</code> 是写入 buffer 的 LSN，这里保证这部分内容能够被写入.</p><p>这里其实有个很 confusing 的地方，就是这个地方保证的是环状 Log 的总空间和 Log Buffer 的空间，出现问题概率非常低。这个和后问 Link_buf 之类的空间不完全一致（严格来说应该比它大很多，</p><h3 id="Link-buf"><a href="#Link-buf" class="headerlink" title="Link_buf"></a>Link_buf</h3><p>我们提前介绍一下 <code>Link_buf</code>, 首先，我们可以看到，上面的拷贝是一个申请 LSN，然后各个 mtr 分小段 copy 的模式，那么，这个地方势必有几个 Log 水位，不考虑 ckpt 那些东西，就看内存的话：</p><ul><li>已经 Flush 的 WAL</li><li>拷贝完了的 WAL</li><li>正在拷贝和分配了没拷贝的 WAL</li></ul><p>这个时候，会有下面的水位图：</p><p><img src="https://image.mwish.me/blog-image/1eae15078668ccd0d3e54e11f1783dfc.png" alt="1eae15078668ccd0d3e54e11f1783dfc"></p><p>Link_buf 用来维护和推进这些水位，它把数据划分为 slot，并且保证数组元素(slot)更新是原子的, 以环形形式复用已经释放的空间，并启用单独的线程负责数组的遍历和空间回收, 线程在遇到空元素(empty slot)时暂停。</p><p>和：</p><p><img src="https://image.mwish.me/blog-image/843bc5776c34866f20b5dc0086474bfc.png" alt="843bc5776c34866f20b5dc0086474bfc"></p><p>这里可以维护 write_lsn 和 ready-for-write 的连续 LSN：</p><p><img src="https://image.mwish.me/blog-image/1dc4e6fcece341ee62383b4ab87d95d0.png" alt="1dc4e6fcece341ee62383b4ab87d95d0"></p><p>这里它维护了几个水位和一些中间的状态。</p><p>关于 <code>Link_buf</code>，这个类型只有三百余行，内容可以参考：<a href="http://mysql.taobao.org/monthly/2019/05/08/">http://mysql.taobao.org/monthly/2019/05/08/</a> 。需要特别注意的是，<code>Link_buf</code> 很多约束是需要上层来保证的。</p><p><code>Link_buf</code> 会分配一块比较大的内存（见后文）然后用于 Link，我们先看看 API:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Add a directed link between two given positions. It is user&#x27;s</span></span><br><span class="line"><span class="comment">responsibility to ensure that there is space for the link. This is</span></span><br><span class="line"><span class="comment">because it can be useful to ensure much earlier that there is space.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">@param[in]fromposition where the link starts</span></span><br><span class="line"><span class="comment">@param[in]toposition where the link ends (from -&gt; to) */</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add_link</span><span class="params">(Position from, Position to)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Advances the tail pointer in the buffer by following connected</span></span><br><span class="line"><span class="comment">path created by links. Starts at current position of the pointer.</span></span><br><span class="line"><span class="comment">Stops when the provided function returns true.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">@param[in]stop_conditionfunction used as a stop condition;</span></span><br><span class="line"><span class="comment">                                (lsn_t prev, lsn_t next) -&gt; bool;</span></span><br><span class="line"><span class="comment">                                returns false if we should follow</span></span><br><span class="line"><span class="comment">                                the link prev-&gt;next, true to stop</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">@return true if and only if the pointer has been advanced */</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Stop_condition&gt;</span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">advance_tail_until</span><span class="params">(Stop_condition stop_condition)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Advances the tail pointer in the buffer without additional</span></span><br><span class="line"><span class="comment">condition for stop. Stops at missing outgoing link.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">@see advance_tail_until()</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">@return true if and only if the pointer has been advanced */</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">advance_tail</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** @return capacity of the ring buffer */</span></span><br><span class="line"><span class="function"><span class="type">size_t</span> <span class="title">capacity</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** @return the tail pointer */</span></span><br><span class="line"><span class="function">Position <span class="title">tail</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Checks if there is space to add link at given position.</span></span><br><span class="line"><span class="comment">User has to use this function before adding the link, and</span></span><br><span class="line"><span class="comment">should wait until the free space exists.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">@param[in]positionposition to check</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">@return true if and only if the space is free */</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">has_space</span><span class="params">(Position position)</span> <span class="type">const</span></span>;</span><br></pre></td></tr></table></figure><p>我们可以借助官网的图片来理解这些 API:</p><p><img src="https://image.mwish.me/blog-image/b704115a35af372c5c5c57fc1b2fa78e.png" alt="b704115a35af372c5c5c57fc1b2fa78e"></p><ul><li><code>tail</code>: 其实是连续的队列的开头，用来开始跳转，这个是一个 atomic 的 lsn 或者别的位置标记</li><li><code>has_space</code> 判断有没有连续空间，因为 <code>Link_buf</code> 这块的内存可能会少于可分配 LSN 的内存</li><li><code>advance_tail_until</code> 和 <code>advance_tail</code> 都会尝试推进 tail，其实相当于推进空间。这个可能会传一个停止条件进去。</li><li><code>add_link</code>: 添加一个 Link, Link 是什么呢？就是如上文所述的 4-&gt;, 4-&gt; 的标记。</li></ul><p>还有一些内部实现的 API:</p><ul><li><code>next_position</code>: 跳转到下一个地址</li><li><code>clain_position</code>: 把本地址置 0</li></ul><p>这里感觉 lock-free 也不难，因为假设</p><ol><li>并发 <code>add_link</code><ol><li>上层保证了 from - to 的分配是 sn 分配的，同时，用户插入的一定是 <code>has_space</code> 的，之前没有 overflow 的之后必定不可能 overflow，所以操作成功的没有冲突</li></ol></li><li>在 <code>advance_tail</code> 的情况下，已经存在的写是已经 <code>has_space</code> 的，这里只会消除完成的写。极端情况并发 <code>advance_tail</code> 的时候，可能推进不原子，所以只能有一个线程在 <code>advance_tail</code>，观察下列代码可以轻松得出这个结论</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Position&gt;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Stop_condition&gt;</span><br><span class="line"><span class="type">bool</span> Link_buf&lt;Position&gt;::<span class="built_in">advance_tail_until</span>(Stop_condition stop_condition) &#123;</span><br><span class="line">  <span class="keyword">auto</span> position = m_tail.<span class="built_in">load</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    Position next;</span><br><span class="line"></span><br><span class="line">    <span class="type">bool</span> stop = <span class="built_in">next_position</span>(position, next);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (stop || <span class="built_in">stop_condition</span>(position, next)) &#123;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Reclaim the slot. */</span></span><br><span class="line">    <span class="built_in">claim_position</span>(position);</span><br><span class="line"></span><br><span class="line">    position = next;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (position &gt; m_tail.<span class="built_in">load</span>()) &#123;</span><br><span class="line">    m_tail.<span class="built_in">store</span>(position);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Copying-Redo-Log"><a href="#Copying-Redo-Log" class="headerlink" title="Copying Redo Log"></a>Copying Redo Log</h3><p>这节内容可以参考：<a href="http://mysql.taobao.org/monthly/2021/09/04/">http://mysql.taobao.org/monthly/2021/09/04/</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">write_log.m_handle = handle;</span><br><span class="line">write_log.m_lsn = handle.start_lsn;</span><br><span class="line">write_log.m_rec_group_start_lsn = handle.start_lsn;</span><br><span class="line"></span><br><span class="line">m_impl-&gt;m_log.for_each_block(write_log);</span><br></pre></td></tr></table></figure><p><code>write_log</code> 是一个函数对象，这里对每个 block 写入这个内容，具体的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Write the block contents to the REDO log */</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">mtr_write_log_t</span> &#123;</span><br><span class="line">  <span class="comment">/** Append a block to the redo log buffer.</span></span><br><span class="line"><span class="comment">  @return whether the appending should continue */</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> <span class="type">mtr_buf_t</span>::<span class="type">block_t</span> *block)</span> </span>&#123;</span><br><span class="line">    <span class="type">lsn_t</span> start_lsn;</span><br><span class="line">    <span class="type">lsn_t</span> end_lsn;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">ut_ad</span>(block != <span class="literal">nullptr</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (block-&gt;<span class="built_in">used</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> (<span class="literal">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    start_lsn = m_lsn;</span><br><span class="line"></span><br><span class="line">    end_lsn = <span class="built_in">log_buffer_write</span>(*log_sys, m_handle, block-&gt;<span class="built_in">begin</span>(),</span><br><span class="line">                               block-&gt;<span class="built_in">used</span>(), start_lsn);</span><br><span class="line"></span><br><span class="line">    m_left_to_write -= block-&gt;<span class="built_in">used</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (m_left_to_write == <span class="number">0</span></span><br><span class="line">        &amp;&amp; m_rec_group_start_lsn / OS_FILE_LOG_BLOCK_SIZE !=</span><br><span class="line">               end_lsn / OS_FILE_LOG_BLOCK_SIZE) &#123;</span><br><span class="line">      <span class="built_in">log_buffer_set_first_record_group</span>(*log_sys, m_handle, end_lsn);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">log_buffer_write_completed</span>(*log_sys, m_handle, start_lsn, end_lsn);</span><br><span class="line"></span><br><span class="line">    m_lsn = end_lsn;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (<span class="literal">true</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  Log_handle m_handle;</span><br><span class="line">  <span class="type">lsn_t</span> m_lsn;</span><br><span class="line">  <span class="type">lsn_t</span> m_rec_group_start_lsn;</span><br><span class="line">  ulint m_left_to_write;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>首先介绍一下 <code>mtr_buf_t</code>:</p><blockquote><p>mtr_buf_t是由一个双向链表组成的动态buffer，每个元素是512B大小的buffer（512B刚好匹配一个log block大小）。随着mtr_buf_t存储的数据的增加，它会自动生成新的512B的buffer，并加入双向链表中。</p></blockquote><p>这里会走 <code>log_buffer_write</code> ，拷贝内容到 log_buffer 中。</p><p>也就是说，这个内容不是完全「一次性拷贝」的，而是按照 <code>block</code> 粒度拷贝到公共 log buffer，然后调用 complete 的，这里涉及两个函数：</p><ul><li>log_buffer_write</li><li>log_buffer_write_completed</li></ul><p><code>log_buffer_write</code> 会完成拷贝，拷贝有什么难的呢？答案是这里会把 block 转化成 innodb 物理 Redo Log 的格式，还是要一些转化的。这里会拷贝到公共的 log buf 中。</p><p><code>log_buffer_write_completed</code> 相对来说复杂一些，我们首先看一些别的定义：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Default value of innodb_log_recent_written_size (in bytes). */</span></span><br><span class="line"><span class="keyword">constexpr</span> ulong INNODB_LOG_RECENT_WRITTEN_SIZE_DEFAULT = <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Minimum allowed value of innodb_log_recent_written_size. */</span></span><br><span class="line"><span class="keyword">constexpr</span> ulong INNODB_LOG_RECENT_WRITTEN_SIZE_MIN = OS_FILE_LOG_BLOCK_SIZE;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** Maximum allowed value of innodb_log_recent_written_size. */</span></span><br><span class="line"><span class="keyword">constexpr</span> ulong INNODB_LOG_RECENT_WRITTEN_SIZE_MAX = <span class="number">1024</span> * <span class="number">1024</span> * <span class="number">1024UL</span>;</span><br></pre></td></tr></table></figure><p>和:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Number of slots in a small buffer, which is used to allow concurrent</span></span><br><span class="line"><span class="comment">writes to log buffer. The slots are addressed by LSN values modulo number</span></span><br><span class="line"><span class="comment">of the slots. */</span></span><br><span class="line">ulong srv_log_recent_written_size = INNODB_LOG_RECENT_WRITTEN_SIZE_DEFAULT;</span><br></pre></td></tr></table></figure><p>这里会等待有足够的空间然后 <code>add_link</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">log_buffer_write_completed</span><span class="params">(<span class="type">log_t</span> &amp;log, <span class="type">const</span> Log_handle &amp;handle,</span></span></span><br><span class="line"><span class="params"><span class="function">                                <span class="type">lsn_t</span> start_lsn, <span class="type">lsn_t</span> end_lsn)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Let M = log.recent_written_size (number of slots).</span></span><br><span class="line"><span class="comment">  For any integer k, all lsn values equal to: start_lsn + k*M</span></span><br><span class="line"><span class="comment">  correspond to the same slot, and only the smallest of them</span></span><br><span class="line"><span class="comment">  may use the slot. At most one of them can fit the range</span></span><br><span class="line"><span class="comment">  [log.buf_ready_for_write_lsn..log.buf_ready_ready_write_lsn+M).</span></span><br><span class="line"><span class="comment">  Any smaller values have already used the slot. Hence, we just</span></span><br><span class="line"><span class="comment">  need to wait until start_lsn will fit the mentioned range. */</span></span><br><span class="line"></span><br><span class="line">  <span class="type">uint64_t</span> wait_loops = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (!log.recent_written.<span class="built_in">has_space</span>(start_lsn)) &#123;</span><br><span class="line">    ++wait_loops;</span><br><span class="line">    <span class="built_in">os_thread_sleep</span>(<span class="number">20</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">unlikely</span>(wait_loops != <span class="number">0</span>)) &#123;</span><br><span class="line">    <span class="built_in">MONITOR_INC_VALUE</span>(MONITOR_LOG_ON_RECENT_WRITTEN_WAIT_LOOPS, wait_loops);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Disallow reordering of writes to log buffer after this point.</span></span><br><span class="line"><span class="comment">  This is actually redundant, because we use seq_cst inside the</span></span><br><span class="line"><span class="comment">  log.recent_written.add_link(). However, we&#x27;ve decided to leave</span></span><br><span class="line"><span class="comment">  the seperate acq-rel synchronization between user threads and</span></span><br><span class="line"><span class="comment">  log writer. Reasons:</span></span><br><span class="line"><span class="comment">          1. Not to rely on internals of Link_buf::add_link.</span></span><br><span class="line"><span class="comment">          2. Stress that this synchronization is required in</span></span><br><span class="line"><span class="comment">             case someone decided to weaken memory ordering</span></span><br><span class="line"><span class="comment">             inside Link_buf. */</span></span><br><span class="line">  std::<span class="built_in">atomic_thread_fence</span>(std::memory_order_release);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Note that end_lsn will not point to just before footer,</span></span><br><span class="line"><span class="comment">  because we have already validated that end_lsn is valid. */</span></span><br><span class="line">  log.recent_written.<span class="built_in">add_link</span>(start_lsn, end_lsn);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Log-Writer-amp-amp-Log-Flusher"><a href="#Log-Writer-amp-amp-Log-Flusher" class="headerlink" title="Log Writer &amp;&amp; Log Flusher"></a>Log Writer &amp;&amp; Log Flusher</h3><p>这部分代码在 <code>log0write.cc</code>，这里为了冲突，拆分成了多个线程来做 Log 的写入。</p><p><img src="https://image.mwish.me/blog-image/innodb_notify.png" alt="innodb_notify"></p><p>(图片来自 CatKang 的博客)</p><p>首先，我们关注 Log-Writer Thread，他会用 <code>Link_buf</code> 去追那些完成的操作，把它们 Link 起来，具体的条件是：</p><ul><li>遇到的都是连续的（见 <code>Link_buf</code> 的图）</li><li>不大于一定大小（可能 4k）</li></ul><p>收集完之后，它会标记出对应的数据，然后映射到磁盘结构上，标记 Header 之类的内容。这里有个小细节是 <code>incomplete block</code> 在其中的处理，具体可见：InnoDB：redo log（1） - Skywalker的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/386710765">https://zhuanlan.zhihu.com/p/386710765</a></p><p>这里 Log Writer 会通过：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">log_advance_ready_for_write_lsn</span><br><span class="line">- advance_tail_until</span><br></pre></td></tr></table></figure><p>等调用来推进。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://mysqlserverteam.com/mysql-8-0-new-lock-free-scalable-wal-design/">https://mysqlserverteam.com/mysql-8-0-new-lock-free-scalable-wal-design/</a></li><li><a href="http://mysql.taobao.org/monthly/2018/06/01/">http://mysql.taobao.org/monthly/2018/06/01/</a> (上面这篇的翻译)</li><li><a href="https://catkang.github.io/2020/02/27/mysql-redo.html">https://catkang.github.io/2020/02/27/mysql-redo.html</a> InnoDB Redo Log 的一个 general，包括各层，本文只是其中一个小碎片</li><li>InnoDB Redo Log 调整，允许动态调整 Redo Log：<a href="http://mysql.taobao.org/monthly/2022/09/03/">http://mysql.taobao.org/monthly/2022/09/03/</a></li><li>Rsygg 神文 InnoDB 确定 checkpoint-lsn 的一处细节：<a href="https://github.com/rsy56640/triviality/tree/master/content/innodb-ckpt-lsn">https://github.com/rsy56640/triviality/tree/master/content/innodb-ckpt-lsn</a></li><li>InnoDB 5.7 版本的实现，没全部看完，简单过了一遍，拥有一定参考和对比价值：<a href="http://liuyangming.tech/06-2019/LogBufferAndBufferPool.html">http://liuyangming.tech/06-2019/LogBufferAndBufferPool.html</a></li><li>InnoDB REDO LOG BUFFER管理 - 丁凯的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/358690853">https://zhuanlan.zhihu.com/p/358690853</a></li><li><a href="http://mysql.taobao.org/monthly/2021/09/04/">http://mysql.taobao.org/monthly/2021/09/04/</a></li><li><a href="http://mysql.taobao.org/monthly/2019/05/08/">http://mysql.taobao.org/monthly/2019/05/08/</a></li><li>InnoDB：redo log（1） - Skywalker的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/386710765">https://zhuanlan.zhihu.com/p/386710765</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>[SOSP&#39;11] Windows Azure Storage</title>
      <link href="/2022/11/24/SOSP-11-Windows-Azure-Storage/"/>
      <url>/2022/11/24/SOSP-11-Windows-Azure-Storage/</url>
      
        <content type="html"><![CDATA[<p>现代系统中，对象存储正在成为越来越重要的系统基本组件。以 S3 为首的对象存储提供了平台的层级近乎无限的存储空间。阿里云产品这里有一个比较简单的介绍：<a href="https://help.aliyun.com/document_detail/140812.html">https://help.aliyun.com/document_detail/140812.html</a></p><p>相对于没什么介绍的 S3，Windows Azure Storage 在 SOSP’11 提供了比较详细的描述。据 References 中的小道消息，本文很多作者去了阿里云，参与了阿里云 pangu 的制作。这篇论文细节比较多，虽然网上有很多的介绍材料，但我无论如何都看不太懂，所以看了一遍原论文。这篇文章还是相当硬核的，很详细的描述了 Windows Azure Storage 的内容，简单介绍一下本文的亮点：</p><ol><li>分层的系统：分布式块存储层（Streaming Layer），几乎无状态 Partition - 数据结构层（Partition Layer），无状态的 Front End</li><li>Stream Layer: 在 HDD 和 SSD Write Cache 上提供一致性和性能、后台 EC 节省成本，抽象了很好的 Block / Extent 模型，分布式一致性的语义（比 GFS 那坨答辩写的好很多）。一致性语义可以关注这个是一个 append only 的块，而非 k-v 这种内容，所以很多地方可以优化处理。同时，这块也是多租户的，因为对外提供的是块存储，所以这块相对不复杂，但论文没有深入讨论策略是怎么做的。</li><li>Partition Layer: 相当于 Stream Layer 上的应用层，和 Stream Layer 一些服务做 co-locate 部署，在分布式块存储上协同维护一致性（只靠 Stream Layer 的话，一些 corner case 语义是模糊的），在上面分别维护 wal 层和数据层，来保证性能。同时 Partition Layer 对外提供各种数据结构（可以简单类比 Redis），同时，它也用这个抽象服务内部，来完成内部元信息的存储。此外 Partition Layer 应该还会根据负载做一些 repartition, split, merge (论文记作 load balance)。论文没有讨论 admission control 和多租户的实现。</li></ol><p>此外，对于用户而言，系统是上层的 Windows Azure Storage，缩写为 WAS。WAS 会有地区间的(geographic)异步灾备、主和备，在单个地区内，它也有 stamp 的概念，去做一些内部的 replica。</p><p>文章亮点还是靠谱的架构和非常详细的内容，包括一致性语义之类的。我们需要关注实现端和应用端是怎么共同实现块存储语义的。上层的 WAS 会比较简单的略过。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>WAS 在论文中对外提供了几种结构：Blob, Queue, Tables。这几个相对来说都是很重要的产品，就不介绍了。按照 ref 中的暗示，感觉这几个功能都是组织上的考量，感觉这几种还是「被统一」到一起的（比如 queue tables 都可以用快的语义来实现，但是 workload 有一些很细微的差别，不过都做的很好估计也没啥关系) 。大厂看上去总是痴迷统一的架构…</p><p>WAS 声称提供了强一致性(Strong Consistency)、高可用性(HA)、分区容忍(Partition tolerant)；同时，它对外提供了 global 的 namespace (这个可以类比阿里云或者 aws 买 oss 的 bucket、账号那种概念)；此外它还有多地、但机房的灾备。WAS 还提供了多租户，对外提供了存储池的模型。</p><p>文章的逻辑顺序大概是：</p><ul><li>WAS 的 namespace 抽象和实现</li><li>WAS 的架构分层，这里介绍了 WAS 的三层架构</li><li>块存储层 Streaming Layer 的实现，包括单机和 replica、一致性语义</li><li>Partition Layer 的介绍</li><li>吹逼环节和内部使用</li><li>…</li></ul><h2 id="Global-Partitioned-Namespace"><a href="#Global-Partitioned-Namespace" class="headerlink" title="Global Partitioned Namespace"></a>Global Partitioned Namespace</h2><p>在这里，WAS 把对应 namespace 的内容做到了 URL 中:</p><p><img src="https://image.mwish.me/blog-image/745178C0-C27C-412C-85EE-347FC139C8CC.png" alt="745178C0-C27C-412C-85EE-347FC139C8CC"></p><p>然后，WAS 引入了一个 DNS 系统，来做对应的处理：</p><p><img src="https://image.mwish.me/blog-image/34EEDFD9-8268-4050-B5D9-DA34474BBFEA.png" alt="34EEDFD9-8268-4050-B5D9-DA34474BBFEA"></p><p>这个 URL 其实非常好理解：</p><ol><li>AccountName: 用户添加/选择的账户(或许包含子账户)的名称, 作为 dns 的 host name</li><li>PartitionName 具体定位 Storage 上的数据，这个 PartitionName 感觉类似子对象</li><li>ObjectName 不一定所有的内容都有，它用来定位确切的 object. <strong>在同一个 PartitionName 下的多个 Object 可以完成事务操作</strong></li></ol><p>具体而言，这个只是一个模型组织，不同数据结构会用不同的方式使用这个数据，已知上云肯定有 AccountName:</p><ol><li>BLOB 没有 ObjectName, 对应一个 PartitionName (<code>Blob: PartitionName</code>)</li><li>Table 中的一个 PrimaryKey 对应一个 PartitionName 和 ObjectName，这允许 Table 把表组织到不同的 Partition 下（感觉要涉及分布式事务了 orz）。(<code>Table: &#123;Partitions: &#123;objects&#125;</code>)</li><li>Queue 名称是 PartitionName ，对应的每个对象有一个 <code>ObjectName</code>: <code>&lt;PartitionName, [objectNames]&gt;</code></li></ol><h2 id="High-Level-Architecture"><a href="#High-Level-Architecture" class="headerlink" title="High Level Architecture"></a>High Level Architecture</h2><p>Windows Azure Storage 的服务被托管给 Windows Azure Fabric Controller，运行在各地，这个感觉类似一个云平台，做容器/节点的管控。WAS 本身负责各个容器/节点内数据的 replication 和 data placement。</p><p>如上面的 Figure 1, WAS 服务器包含 Storage Stamp 和 Location Service。</p><p>Storage Stamp 是一个物理一些的概念，感觉像是部署在一起的一组高密存储机器组成的容错的集群，拥有一个虚拟 ip (VIP)，我们摘录一下详细的定义：</p><blockquote><p>Storage Stamps – A storage stamp is a cluster of N racks of storage nodes, where each rack is built out as a separate fault domain with redundant networking and power. Clusters typically range from 10 to 20 racks with 18 disk-heavy storage nodes per rack. Our first generation storage stamps hold approximately 2PB of raw storage each. Our next generation stamps hold up to 30PB of raw storage each.</p></blockquote><p>同时，Storage Stamp 会希望多租户来保证占用，系统会保证 70% 左右的容量 / 事务(tps?) / 带宽利用率。Storage Stamp 会尽量避免磁盘占用达到 80% 以上，来避免一些突发的错误导致 stamp 内容量不足，同时，因为当时硬件大多是 HDD，HDD 外道比内道快（分过硬盘懂的都懂），所以 它也更希望用外道上的空间。当单个 Storage Stamp 资源利用率超过 70%，这里可能会尝试在 Partition Layer 做一些调度。</p><p>Location Service (LS) 是一个元信息或者 Catalog 性质的系统，它会存放区域的 account namespace，同时管理各个 Storage Stamp 的集群信息。类似 BigTable，LS 自己会把数据落在 Storage Stamp 上，然后也有备份和恢复的流程。</p><p>LS 会知道有哪些地区哪些机房，然后会 track 一下对应机房的情况和存储占用。当一个新的创建账户请求过来的时候，它需要指定 location affinity（用户在什么地方用），LS 会根据这个请求的 location affinity，来预测并决定这个资源的 primary storage stamp。它会在这个 stamp 记录元信息，然后更新 DNS 路由，把资源 url 的 domain 指向 storage stamp 的 VIP。</p><h3 id="Storage-Stamp-内的三层架构"><a href="#Storage-Stamp-内的三层架构" class="headerlink" title="Storage Stamp 内的三层架构"></a>Storage Stamp 内的三层架构</h3><p>这里自底向上的介绍 Storage Stamp 的三层架构：</p><ol><li><p>Stream Layer: Storage Stamp 内的分布式块存储. 它有几个概念</p><ol><li>Stream:一个大的可以 append 的 bit stream</li><li>Extents: 不固定大小的 Chunk (可以对比 GFS Chunk)</li></ol></li><li><p>Partition Layer: 这里机器可能和 Stream Layer 做 co-locate 部署，它提供了</p><ol><li>单机<ol><li>Blob, Table, Queue 的语义管理</li><li>和上层的 dns 协同处理 PartitionName 等逻辑，毕竟 dns 只会 resolve host</li><li>Transaction Ordering / Strong Consistency，部分和 Stream Layer 协统管理，部分自己管理</li><li>Storing/Caching 各种数据</li></ol></li><li>分布式: 类似 TiKV HBase，对数据按照 PartitionName 进行 Range Partition，并做了可能的 Merge / Split 等管理</li></ol></li><li>Front-End Layer: 由 stateless 的服务器组成，接受请求，然后把请求路由到 Partition Layer 的服务器。系统会有一个 Partition Map 来维护相关的 Partition 的映射区间。FE 会缓存这个 map，然后转发请求。感觉这个某种程度上相当于一个内部 Proxy 或者客户端</li></ol><h3 id="Two-Replication-Engines"><a href="#Two-Replication-Engines" class="headerlink" title="Two Replication Engines"></a>Two Replication Engines</h3><ul><li>Stream Layer 会做 stamp 内部的 <strong>同步复制</strong>，来保证 stamp 内的数据安全。这个会在 critical path 上进行，需要等待复制完成才能返回用户 success。它关注的是复制的 bits。因为这个在主链路上，它的主要优化点在 latency 上。</li><li>Partition Layer 会做 stamp 和 stamp 的复制。它会在主链路之外<strong>异步复制</strong>给别的机器。它关注 Transaction 之类的语义，和 Objects，但可能不太关注具体 layout。相对于 Stream Layer，它提供的是机房的可靠容灾。因为这个不在主链路上，但可能数据量比较大，优化点则在 bandwidth 上。</li></ul><p>这里还有个别的问题是，两个 layer 之间管理的对象不同（用论文的话说就是 namespace 不同）在 stamp 内复制的时候，这里需要管理的信息都在同一个 storage stamp 内部，元信息大小相对可控，可以 cache 在内存中。</p><p>作为对比，Partition Layer 元信息其实是依赖上层的，这似乎并不在意你怎么分片路由的，只在于 global object namespace 管理的其余 replica，然后把对应信息（我猜类似 binlog）丢过去。</p><h2 id="Stream-Layer"><a href="#Stream-Layer" class="headerlink" title="Stream Layer"></a>Stream Layer</h2><p>在介绍 Stream Layer 之前，我们可以简短回顾一下 GFS 的 consistency:</p><ol><li>客户端给 primary 发请求，请求以 chain replica 的形式复制</li><li>数据以 Chunk 的单元存储，Chunk 大小大概是 64MB 或者数倍，meta 在 master 作为内存中的一棵树</li><li>如果存在并发，那么可能需要重试，可以保证，写入成功的时候，偏移量在所有副本上都是一样的</li></ol><p>WAS Stream Layer 提供了更加清晰的定义和抽象，在单机存储上，引入了 Block - Extent - Stream 这一个多级别的结构概念。分布式存储上，引入了更加详细的描述语义。</p><p><img src="https://image.mwish.me/blog-image/33E6F3A9-02C5-46BD-ABC7-346D10ADE99E.png" alt="33E6F3A9-02C5-46BD-ABC7-346D10ADE99E"></p><ul><li>Block 是用户 Append 和读取的基本单元，用户可以 append 一个或者多个 Block，Block 也不需要有固定大小，Block 会被 checksum。读取的时候，也需要做 checksum validation (这里似乎是前台读取的时候做的)。同时，除了前台验证，这里也会有一个天级的后台线程做 validation。</li><li>Extent 包含一个或多个 Block，Extent 的大小不固定，它只有一个 appendable 的 Extent (Unsealed)，其余都是 Sealed 的，里面的 <strong>逻辑的 bits 内容</strong> 是不可更改的。Extent 是 Stream Layer 复制的基本单元。在论文发表的时候，extent 会被存储在一个 NTFS 文件上，（这个可能是因为实现完成度问题？因为感觉 fs 自己也会写 log，基本 log-on-log 了…）。<ul><li>上层使用的时候，Partition Layer 会定一个 1GB 左右的 Target Extent size，然后可能会 batch 多个小对象的写到同一个 Block 中 append 过来。如果要写一个很大的对象，可能会拆分成很多中等大小的（GB）的 Block 去写。</li></ul></li><li>Stream 是 Stream Layer 对上层提供的抽象，它本身是指向多个 Extent 的指针 <code>[Pointer-to-Extents]</code>，这个状态由 Stream Master 管理。这个抽象有点类似 fp，因为 Extent 是不可修改的，Stream 可以等于 Stream + Append Operations。只有最后一个 Extent 是可写的</li></ul><h3 id="Stream-Manager-and-Extent-Nodes"><a href="#Stream-Manager-and-Extent-Nodes" class="headerlink" title="Stream Manager and Extent Nodes"></a>Stream Manager and Extent Nodes</h3><p><img src="https://image.mwish.me/blog-image/BBC19237-042E-4534-B1B9-D29495FE4C70.png" alt="BBC19237-042E-4534-B1B9-D29495FE4C70"></p><p>Stream Manager (SM) 管理 Extent 的抽象，而相对而言，数据存储在 Extent Node( EN ) 上。类似 Chubby，它是一个 Paxos 集群，因为元数据数量相对可控（问题：如果有很多很小的 Extent 感觉这个会疯狂劣化，不过应该不是常见场景）。SM 负责做的事情相当于管控的 master:</p><ol><li>负责响应 client 的 create extent 请求，挑选对应的主备机器，然后创建 Extent</li><li>维护 Stream - Extent 的映射和状态</li><li>监控 EN 的状态</li><li>(3) 中 EN 状态出问题，或者出现 corrupt 等情况的时候，去拉起备然后修复数据，维护多副本</li><li>GC 掉没有被 reference 的 Extent</li><li>做一些后台操作，把 Sealed Extent 给 EC 优化（现在应该有很多不需要这样，在前台写的时候直接 EC）</li></ol><p>论文里提到了几个点：</p><ul><li>SM 会周期性拉 EN 的数据，然后来检查是否一致</li><li>对于 Extent 的 Replacement 策略，这里 SM 挑选 EN 是 randomly 的，但不会挑选在同一个 fault domains 中，不知道为啥选 random</li></ul><p>SM 只管理 Extent，不管理 block（实际上 SM 不去 aware block 信息），用户 append 的时候，这里一般不会跟 SM 打交道，直接走最后一个 Extent 去 append，所以绝大部分情况下，SM 不会 block critical path。</p><p>下面论文提供了一个 SM 管理元数据的简单计算，这里使用了 32GB 内存的节点，然后 SM 打交道的 client 只会有 Partition Layer，在论文估算中，Stream 不会多于 100K 个，Extent 不会大于 50M 个，所以总内存可以限制在 32GB 内。</p><p>EN 则不知道 Stream 的概念，它会知道 SM assign 给它的 primary / backup 的 topology，</p><ul><li>单个 Extent 存储上，Extent 会被存储成一个文件，每个 block 会有 checksum，然后还会有一个 Block Index，来映射 Block 的位置 (我猜类似 LevelDB?).</li><li>在 EN服务器中，服务器会有个自己管理的 Extent 列表，每个列表包含对应的 Peers.</li></ul><h3 id="Append-Operation-and-Sealed-Extents"><a href="#Append-Operation-and-Sealed-Extents" class="headerlink" title="Append Operation and Sealed Extents"></a>Append Operation and Sealed Extents</h3><p>首先我感觉一般要明确一点，我个人感觉比较合适多见的块存储场景都是单写者，然后有一个分布式锁 / epoch 之类的逻辑来保证只有单个 writer，有的块存储也会在服务内置一套 cas 或者 leader 机制，然后方便用户保证 Single Writer。这里可以参考 <a href="https://github.com/opencurve/curve/blob/master/docs/cn/CurveFS%E6%94%AF%E6%8C%81%E5%A4%9A%E6%8C%82%E8%BD%BD.pdf">Curve 的调研文档</a> , 这里对多挂载和 leader 做了一些概述，应该比较接近工业界的情况。</p><p>回到 WAS Stream Layer，这里 append 会保证：</p><ul><li><p>单个 append，即使是多个 block 的 append，也是 atomic 的。</p></li><li><p>如果出现错误，客户端可能需要 Seal Extent (感觉现在很多 Truncate + Seal) 然后接着写，或者直接重试。发论文的时候 WAS Stream Layer 应该是没有 Truncate + Seal 语义的，所以如果要重试，可能会和 GFS 一样，需要处理重复记录</p><ul><li>对 Metadata 或者 Commit Log，这个会在 Partition Layer 根据 LSN 之类的东西去重</li><li>对 row data 或者 blob, 只有最后一个成功的写会被上层 ref，空白的内容等待 GC（这个地方还是有点奇怪的，因为如果没 Seal Extent 的话，有的内容还在同一个 Extent 里面，这个感觉得暗示有 WiscKey 之类的 GC 机制了，或者单纯就留在那，等待整个 Extent 没有被 Ref 了）</li></ul></li><li><p>Extent 到达一定大小或者主动 Seal 后，里面逻辑内容不能改，但是实际内容可以被 EC 条带化之类的方式优化</p></li></ul><h3 id="Stream-Layer-Intra-Stamp-Replication"><a href="#Stream-Layer-Intra-Stamp-Replication" class="headerlink" title="Stream Layer Intra-Stamp Replication"></a>Stream Layer Intra-Stamp Replication</h3><p>Stream Layer 和 Partition Layer 需要协作，来保证靠谱的 replication。Stream Layer 提供了如下保证：</p><ul><li>record 返回成功之后，后续的读一定可以读到这条记录，对应的记录是 immutable 的(感觉如果支持 truncate, 这个语义也会变得略微有点奇怪, 只能说上层可以约束需要 truncate 的数据是未决的，不会被读取)</li><li>从 sealed extent 读，永远会读到相同的内容</li></ul><p>这个地方 replication 是为了处理软件错误或者各种错误：</p><blockquote><p>We consider faults ranging from disk and node errors to power failures, network issues, bit-flip and random hardware failures, as well as software bugs. These faults can cause data corruption; checksums are used to detect such corruption.</p></blockquote><p>（哎，突然想起在前司碰到的傻逼事情，集群软件 bug 把所有副本写入了 bug 数据😅块存储这块还是要非常小心写代码的…）</p><h4 id="Replication-Flow"><a href="#Replication-Flow" class="headerlink" title="Replication Flow"></a>Replication Flow</h4><p>这里会以 chain-replica 或者星型的形式写入，peers 在 Extent 还活跃的时候不会变更，client 会缓存 active extent，然后直接写 primary，这里必须写 Primary，但是可以从 replica 读。这个地方有个地方，感觉是说需要保证 uncommitted 的数据没啥读者，因为这个内容是 appendable byte stream，所以比 kv 好保证这些。</p><p>写入的时候，因为都要走 primary，所以需要 primary 做一些写相关的决策：</p><ol><li>在本 Extent 中，请求的 append 对应的 offset</li><li>多个客户端并发 append 的时候，这些 append 的 ordering (我感觉本质和 1 是一个问题)</li><li>在所有 secondary 都保证成功的时候，才返回 success<ol><li>同时，因为有 (2) 的约束，这里会按序 ack （看着各台机器也是按序 append + ack 的）。最后成功 append 的位置会是这个 replica 的 <strong>commit length</strong> ，根据简单推理可以知道，这个 commit length 可能比 client ack 大，所以会有 corner case 处理</li></ol></li></ol><p>client 发现错误的时候，需要以最小的 commit length 去 seal，然后 allocate 新的 extent，论文说这个平均时间会有个 20ms（不知道系统自己能不能有个 double buffer?）。被 Seal 的 Extent 如果发现后台掉备份了，SM 会帮它拉起靠谱的 replica，如前文所述。</p><p>（不禁翻了一篇自己两年前写的 blog: <a href="https://blog.mwish.me/2020/08/06/notes-on-craq/">https://blog.mwish.me/2020/08/06/notes-on-craq/</a> ，时间过得真快啊）</p><h4 id="Sealing"><a href="#Sealing" class="headerlink" title="Sealing"></a>Sealing</h4><p>SM 会在 Partition 帮助下去做 Sealing，这里会有可能有三机器 commit length 不一致的情况（论文提到会有两台机器或者有相同的 commit length，我感觉这个暗示了相关的复制流程，不过我觉得这个具体写代码还是很容易三个不一致的）。我个人觉得一个比较理想的状态是 client-side 选出一个状态，当然，client 也有挂掉的时候，回到论文中，论文这里选择方式可以看下面。</p><p>SM 会按照 <strong>能联系到的机器的 minimal commit length</strong> 去 Seal。这个地方我感觉还是暗示就是最短的提交了才是全部集群中提交的长度，然后依靠 2/3 的 safety 去保证这里面最短的一定大家都有、一定已经提交。</p><p>在 Seal 之后，这里的长度会被 SM force 然后再也不会改变。所有的 replica 都是 bitwise-identical 的。</p><h4 id="Interaction-with-Partition-Layer"><a href="#Interaction-with-Partition-Layer" class="headerlink" title="Interaction with Partition Layer"></a>Interaction with Partition Layer</h4><p>client 会缓存 active extent 的信息，并且，在读取 extent 的时候，会有两种模式：</p><ul><li>读指定位置的内容，读 <code>(extent + offset, length)</code>。这里只会读取 <strong>之前返回 success 的内容</strong></li><li>Partition Load 的时候去 seq scan，因为 Partition Layer 会保证这个阶段没有 append 进来，所以可以相对安全的来完成这个阶段的操作。这个会给 Primary EN 发请求，来查询 commit length. 如果出现 commit length 不一致的情况，client 会 seal extent （对照上一节），然后读只会读 sealed extent。</li></ul><h4 id="Erasure-Coding-Sealed-Extent"><a href="#Erasure-Coding-Sealed-Extent" class="headerlink" title="Erasure Coding Sealed Extent"></a>Erasure Coding Sealed Extent</h4><p>WAS 会把 Sealed Block EC 化，来节省成本。</p><h4 id="Read-Load-Balancing-amp-amp-Spindle-Anti-Starvation"><a href="#Read-Load-Balancing-amp-amp-Spindle-Anti-Starvation" class="headerlink" title="Read Load-Balancing &amp;&amp; Spindle Anti-Starvation"></a>Read Load-Balancing &amp;&amp; Spindle Anti-Starvation</h4><p>首先可以复习一下前两节的读语义，这里可以保证：</p><ul><li>对于 active extent 读的时候可以读 replica。</li><li>对于 ec 条带化的 sealed blob，这里会给所有机器发请求，然后收到能恢复状态的请求就返回给用户</li></ul><p>读取的时候还有一些分布式系统和 io 的 tricks。WAS 会有一些类似流控的机制，它会：</p><ul><li>请求带上 deadline，预估请求是否会超时，如果判断超时会提前返回给用户</li><li>原则上，WAS 会尝试优化请求吞吐而牺牲公平性，在 HDD 上尽量做 seq scan。这里有一个 io 排队观察的策略，不过论文提的策略比较简单，而且感觉是给 SSD 优化的，感觉可以参考之后的一些论文吧</li></ul><h4 id="Durability-and-Journaling"><a href="#Durability-and-Journaling" class="headerlink" title="Durability and Journaling"></a>Durability and Journaling</h4><p>这里 WAS 利用 SSD 充当一个高性能持久化写缓存，这我不禁想起了刚刚凉凉的 Optane 那套 NVM…这里依靠双写的方式写 SSD，然后SSD写完就可以提前返回，来降低 latency。SSD 在这里只充当快速写的硬件，一旦写在 HDD 上完成，之后的请求都在 HDD 上 serving。论文指出，这点将 e2e stream append latency avg 从 30ms 降低到 6ms。</p><h2 id="Partition-Layer"><a href="#Partition-Layer" class="headerlink" title="Partition Layer"></a>Partition Layer</h2><p>Stream Layer 虽然年代所限，有的地方在 2022 年看来还是有优化空间的，但是提供了很多至今还在用的抽象，描述语义也比 GFS 那草台玩意具体多了。</p><p>Partition Layer 则是展现了怎么在 Stream Layer 这个分布式块存储层上做抽象，来满足用户的需求，这里即展示了数据，又展示了 WAL，同时也有一些 Partition 相关的抽象，展现了一个半共享存储的系统是怎么实现的。</p><p>Partition Layer 抽象出了一个叫做 Object Table (OT) 的结构，这是一个 scalable 的 range partition 的 <code>key-&#123;schema&#125;</code> 的表，被分成数个 RangePartition，部署在 Partition Server 上。因为是 ，所以这部分 range 不会重叠。</p><p>Partition Layer 利用 OT 的抽象，制作了下面的结构来支持上层的逻辑。这些结构确实很多地方应该用相关逻辑支持，不过看上去，这个架构确实为统一的一份代码干很多事付出了努力：</p><ul><li>Account Table: Storage Stamp 会上层提供的账户信息</li><li>Schema Table: 存放各种数据的 Schema</li><li>Partition Map Table: 存放 Partition 相关的信息</li><li>有一堆子数据结构的表格：<ul><li>Blob Table: 为 Blob 使用，存储相关元信息</li><li>Entity Table: 为 Row 的 Table 结构使用，存放数据</li><li>Message Table</li></ul></li></ul><p>FE 可以访问这些 table，来提供对应的抽象。每个 OT 都有固定的 Schema，并在 Schema Table 里面存放了对应的 Schema。具体而言，这里会有 pk: <code>(AccountName, PartitionName, ObjectName)</code> ，看，是不是很熟悉…</p><p>OT 还支持了同一个 PartitionName 的事务操作和 SI。</p><h3 id="Partition-Layer-Architecture"><a href="#Partition-Layer-Architecture" class="headerlink" title="Partition Layer Architecture"></a>Partition Layer Architecture</h3><p><img src="https://image.mwish.me/blog-image/8F4B0A5E-6353-4EFA-93AA-226DB58DE0C4.png" alt="8F4B0A5E-6353-4EFA-93AA-226DB58DE0C4"></p><p>Partition Layer 可以类比为 <code>HBase</code> 或者 BigTable 的架构：</p><ul><li>Partition Master (PM) 负责 track / merge / split / assign 对应的 Range Partition. 类似 HBase，这些信息也被存放到下层的 Partition Map Table。PM 有多台服务，根据 Lock Service 确定 Leader</li><li>Partition Server (PS) 把数据存放到 Stream 中，然后自己会有 Cache。对于 Range Partition 的分配，单机也会持有 Lock Service 来确保这一点（感觉有的时候可以靠调度层强行 fencing？不过这样应该也能做一个很好的保证，相当于带了个 epoch 了）</li><li>Lock Service: 类似 chubby / zk…</li></ul><p>接下来我们关注 Partition Server 对应的单机结构是怎么实现的。这里的结构是一个 LSM-Tree，然后论文没提到有 CF 这样的抽象。Stream 只属于一个 RangePartition，而不像 HBase / BigTable 会多流合一。感觉这个既有好处又有问题吧。</p><p><img src="https://image.mwish.me/blog-image/9BE70021-EB5E-4BD9-BC74-28BA9E001236.png" alt="9BE70021-EB5E-4BD9-BC74-28BA9E001236"></p><p>这里区分了几种 Stream:</p><ul><li><p>Metadata Stream: 整个 Stream 的元信息，可以用来 load 别的所有的 Stream，类似传统数据库 Catalog / MetaBlock，PM 靠提供 metadata stream 的名称来提供信息。这个信息包含：</p><ul><li>Stream 的名称</li><li>类似数据库日志的 ckpt，表示有效区域的 extent + offset</li></ul></li><li>Commit Log Stream: 不知道是物理还是逻辑的 commit 日志</li><li>数据层面的 Stream:</li><li>Row Data Stream: data 和 index 对应的 checkpoint，单个 RangePartition 只有一个 data stream<ul><li>Blob Data Stream: 专门给 Blob 使用</li></ul></li></ul><p>在内存中还有 index cache , row data cache, bf，但我觉得…都没啥意思。具体可以参考论文 5.3 - 5.4 节，都是比较 trivial 的东西。</p><h4 id="RangePartition-Load-Balancing"><a href="#RangePartition-Load-Balancing" class="headerlink" title="RangePartition Load Balancing"></a>RangePartition Load Balancing</h4><p>这节介绍调度 / merge / split，本来挺没意思的，不过可以关注一下对应的语义和维护流程：</p><ul><li>在维护的时候，WAS 会记录 Partition 的数量，并保持在 low watermater - hight watermark 之间，这个数量大概是 partition server 的十倍。这里会尽量来维护这个值，并且按照读写流量和 watermark 来触发 merge - split。典型的 stamp 会有 75次 split / merge, 200 个 RangePartition</li><li>这里会 track tps / pending transaction count / 限流 / CPU 使用率 / 网络 / 延迟 来决定是否 split / merge</li><li>split / merge 类似 <code>hbase</code>，我们关注区别：<ul><li>下层 Streaming 实现了对 Extent 的 Ref-Counting</li><li>在 Split 的时候，同样会触发 ckpt。Split 的时候也是现在同一台服务器上分裂成两份，再调度走；Merge 的时候也会先调度到同一台机器上</li><li>PS 定义了 MultiModify, 根据需要 Split 的流，fork 两个 ref，然后调度流量即完成。没有 HBase 那么复杂</li><li>Merge 操作感觉比较草台，MultiModify单纯合并两个 commit 流，感觉对 Truncate 不太友好？</li></ul></li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li>Blogs<ul><li><a href="https://fuzhe1989.github.io/2021/05/02/windows-azure-storage-a-highly-available-cloud-storage-service-with-strong-consistency/">https://fuzhe1989.github.io/2021/05/02/windows-azure-storage-a-highly-available-cloud-storage-service-with-strong-consistency/</a> (作者提了一些他看到的相对细一些的地方，然后也介绍了这个论文里面很多大佬去了阿里云)</li><li><a href="https://zhuanlan.zhihu.com/p/33951960">https://zhuanlan.zhihu.com/p/33951960</a> (作者是阿里云表格存储的，感觉介绍相对来说有一些内部一些的观点)</li></ul></li><li><a href="https://bluexp.netapp.com/blog/azure-storage-behind-the-scenes">https://bluexp.netapp.com/blog/azure-storage-behind-the-scenes</a></li><li>阿里云的盘古，公开材料也比较值得看：<a href="https://developer.aliyun.com/article/291207">https://developer.aliyun.com/article/291207</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Introduction to velox</title>
      <link href="/2022/11/13/Introduction-to-velox/"/>
      <url>/2022/11/13/Introduction-to-velox/</url>
      
        <content type="html"><![CDATA[<p>Velox 是 facebook 内部开源出的一套单机的向量化执行引擎，facebook 希望 Velox 能够代替各大 AP 系统的执行层，并尝试用它来做 ML 系统和 ad-hoc 分析查询甚至 batch 查询的执行引擎。同时，在执行之外，它也提供了一点小小的优化能力。暂时不考虑有人提出的 RFC 中和写入、事务有关的部分，它负责的内容如下：</p><ol><li>IO，读取 <em>dwio</em>，Parquet, ORC 等内容（主要是 dwio 格式），同时也包括硬件介质（s3, ssd..）和本地的 cache；和远端资源交互</li><li>通用的、高性能、可扩展的 vectorize computing 算子、库实现（IO 的 Scan, Sink 也是一部分，但是我们暂且分开了）<ol><li>Type system, columnar memory data, expression evaluation, operators</li></ol></li><li>资源管理：管理 memory arenas, buffer management, tasks, drivers, CPU 线程池和线程执行 and thread execution, spilling 和缓存</li></ol><p>原则上，velox 接受 Query Optimizer 优化后的单机 Plan，用单机节点上的资源。上层要使用它可能要有一个转义层（例如，Presto 据说在尝试用，就起了个单独的项目 Prestissimo），用于要把转义的数据丢进来。当然，它还想处理类似 ML 等场景，这里有点类似前辈 <a href="从 Weld 论文看执行器的优化技术 - Eric Fu的文章 - 知乎 https://zhuanlan.zhihu.com/p/56138380">Weld</a></p><p>Velox 比较大的贡献是提供了一套比较好的实际范本，东西算不上有什么新东西，但是在比较干净的情况下，把各点都做到了，项目也比较整洁。虽然行数比较多，但是大头还是在 <code>functions</code> 之类的很细节的东西上。部分代码虽然不算特别好（感觉是开源没开净或者留了坑），但是也算有比较高的完成度了。</p><p>Meta 把 Velox 开源出来希望能够共建，目前 Ahana, Intel, Voltron Data 之类的公司在共建 Velox，看了下 commit 频率，不比国内几个明星开源公司提交频率低。他们也希望，这波能一起嫖到标准化语义和新硬件的羊毛（这么看 Influxdb-io 上 arrow-datafusion 贼船是不是有点亏）。尽管有人认为，这东西可能会因为各种 API 都要写个转义层搞得非常恶心，但是这几家现在还是比较期待 Velox 能整出一个好活的</p><p>总而言之，闲扯这么多，我们还是介绍一些 Velox 的主要贡献。这里没有研究上的贡献，全都是工程上的：</p><ol><li>完善的各类 expression / operator / io 实现</li><li>一些 adaptive 的算子选择、Lazy Eval 等</li><li>实验的 codegen</li></ol><p>下面可以简单介绍一些，也贴一些简单的用户代码。</p><h2 id="Type-System"><a href="#Type-System" class="headerlink" title="Type System"></a>Type System</h2><p>这里支持了 Scalar Type 和 Complex Type: <a href="https://facebookincubator.github.io/velox/develop/types.html">https://facebookincubator.github.io/velox/develop/types.html</a></p><p>基本上都是从需求来的，从 Spark 和 Presto 里面弄来的各个类型。值得一提的是，有些个类型就特别纠结：</p><ul><li>（各种编码的）字符串</li><li>（各种精度的）Decimal</li><li>（各种）Timestamp</li></ul><p>值得一提的是，对类型的检查被放到了表达式的 Compilation 阶段：<a href="https://facebookincubator.github.io/velox/develop/expression-evaluation.html#compilation">https://facebookincubator.github.io/velox/develop/expression-evaluation.html#compilation</a> 。而执行的时候，通常都已经做好了转型，要么就直接报错了。这块本来应该在后面介绍，但是鉴于这其实是 type system 的一部分，所以应该在 type system 这节介绍。</p><p>Velox 会有个 <code>resolveVectorFunction</code> 函数，它有个函数名称的 <code>map</code> 工厂，输入一个 <code>ITypedExpr</code>，然后可以拿到一个表达式里面所有的参数，然后走对应的列表，找到名称下所有的函数组，进行类型匹配，匹配通过就用，没有就找下一个，都没有就告诉用户。</p><p>用户还可以添加自己的类型扩展，比如 Presto 添加了 HyperLogLog，eg: <a href="https://github.com/facebookincubator/velox/commit/1e8e0d7c1db3f11ff322f702322070a968dab3df">https://github.com/facebookincubator/velox/commit/1e8e0d7c1db3f11ff322f702322070a968dab3df</a> 。简而言之，用户可以比较方便的在 Velox 上封装类型和对应的实现。</p><h3 id="Vectors"><a href="#Vectors" class="headerlink" title="Vectors"></a>Vectors</h3><p>类似 Arrow 的 Array (这篇博客有很多不错的图：<a href="https://blog.mwish.me/2022/10/04/Parquet-Part2-arrow-Parquet-code-path/">https://blog.mwish.me/2022/10/04/Parquet-Part2-arrow-Parquet-code-path/</a> )，Velox 也有一套表示列存的格式：Vector，内容和 arrow 差不多，我们主要关注区别：</p><ol><li>数据从 MemoryPool 中申请（记得 arrow 的 memory pool 吗？申请数据 64B 对齐那个），数据会被引用计数管理，只有一个 owner 的数据才可更改，否则要拷贝，不过允许 cow。</li><li>提供了 encoding 支持，类似 abadi 论文的 expression on compressed data:<ol><li>支持 flat, dictionary, constant  (前几种 arrow 也支持), Sequence(RLE), bias(FOR) 的编码</li><li>提供了 <code>DecodedVector</code> 的抽象，来避免写一些 <code>if (XXEncoding) then ComputeOnEncoded() else if (encoding ) flatten</code> 的面条代码</li></ol></li><li>支持 Lazy Evaluation。这个类似我们在 Presto 论文提到的，可以减少一定的 filter 量，同时甚至可能减少 IO ，比如（减少 io 是个很 hack 的事情，尤其是你如果做了 prefetch…我对论文的态度抱有苦笑般的怀疑）<ol><li>这里还支持 pushdown，这个感觉像是和上面 encoding 有点重复，相当于把计算下推来避免 materialize 的开销</li></ol></li><li>在字符串处理上，参考了 TUM 的 Umbra，如下面的读。这里相当于在数据库方面做了短路负载，让大部分操作熔断在短字符串处。此外，arrow 的 string 本身要求是在一个 buffer 中连续的，处理方式类似 array。Velox 认为这也能加速 substr 之类的操作，让对应长字符串减少 copy。</li><li>Out-of-order write: 对于 switch case 或者 if else，在向量化中，会算出一组位置或者 true/false 向量，然后让对应的地方写。这个对一般的类型优化不大，但是对变长类型可以有一定的优化。比如说，有一组 if else 向量，然后写 string 类型。对于 arrow 来说，因为内容在 buffer </li><li>Velox 还提供了转成 arrow 的 api，我觉得这用来拉屎非常方便</li></ol><p><img src="https://image.mwish.me/blog-image/3049626C-606E-40C1-8281-3C980FDD3603.png" alt="3049626C-606E-40C1-8281-3C980FDD3603"></p><p><img src="https://image.mwish.me/blog-image/string-views.png" alt="string-views"></p><p><img src="https://image.mwish.me/blog-image/string-vector.png" alt="string-vector"></p><h2 id="Expression-Eval"><a href="#Expression-Eval" class="headerlink" title="Expression Eval"></a>Expression Eval</h2><p>Velox 的查询最早会是一个 Plan Node 组成的树，经过 Planner 成为一个 Pipeline + Operator 的结构。</p><p><img src="https://image.mwish.me/blog-image/local-planner.png" alt="local-planner"></p><p>而在 <code>FilterNode</code>, <code>ProjectNode</code>, <code>AggregationNode</code>, 各种 Join 的 Node 和 OrderBy 的 Node 中，会有各种 Expressions。在 Velox 中，处理前的 Expression <code>core::ITypedExpr</code> 会在 compile 后绑定执行需要的 <code>core::Expr</code>. Expressions 包含：</p><ul><li>FieldAccessTypedExpr</li><li>ConstantTypedExpr</li><li>CallTypedExpr<ul><li>前几个都比较简单，这个包含了 and, or, if, switch, cast, try(try 一个表达式，有问题返回 null）, coalesce (返回第一个非 null 的表达式)</li></ul></li><li>CastTypedExpr</li><li>LambdaTypedExpr</li></ul><p>这些 <code>ITypedExpr</code> 会组织成一个表达式树的关系，从 root 连接到子节点，可能是个 AND 树之类的。同时，表达式也会有一些 metadata 作为标记，比如是否 <code>determinstic</code>、<code>null propagation</code> 的性质，见：<a href="https://facebookincubator.github.io/velox/develop/expression-evaluation.html#expression-metadata">https://facebookincubator.github.io/velox/develop/expression-evaluation.html#expression-metadata</a></p><p>表达式树的执行不是 push / pull 的单向流，而是每个 batch 自 root 到叶节点的求值，然后根据下层节点的结果，最后产生一组某个类型的 Vector。</p><ol><li>表达式是否是 <em>deterministic</em> 的（rand, shuffle 外的大部分函数都是）</li><li><em>propagatesNulls</em>: 输入为 null 的时候，输出是否为 null，可以在输入为 null 的时候免去一些计算</li><li>…</li></ol><p>这些 attributes 能在执行端在表达式上给出很大的优化的空间。举个例子，如果输入被发现，虽然有很多行，但是限定在字典内等，就会有很大的优化空间。或者发现会 propagate null 的话，是 null 的表达式就不用再被折腾一茬子，直接 null set 传递。</p><h3 id="Compilation"><a href="#Compilation" class="headerlink" title="Compilation"></a>Compilation</h3><p>Compile 阶段会拿到一个或多个表达式树，首先会进行类型匹配的计算（详见之前的 Type System 一节），然后会进行一些简单的表达式优化。这一点其实有那么点点怪，有的优化是执行上的，因为 Velox 自己执行的时候可以抽出很多上面所说的 attributes，然后利用里面的特性来优化。感觉一般的系统中，因为没有这种 plan - plan 之间的 gap，所以没有这么一个「再优化」的转换层。</p><p>这里他会把 <code>TypedExpr</code> 转成具体的 expr，具体链路如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">- compileExpressions // 处理多组 (vector&lt;ITypedExpr&gt;)</span><br><span class="line">  - compileExpression // 处理单个 ITypedExpr 树</span><br><span class="line">    走表达式编译缓存, 尝试从 scope 捞到相同的子表达式</span><br><span class="line">    compileInput, 先从输入数据的类型开始编译, 对子表达式可能做一些常量折叠，表达式折叠</span><br><span class="line">    根据 root 表达式的类型, 分发处理</span><br><span class="line">    根据类型和函数名称(字符串) 拿到 candidate 函数</span><br><span class="line">    完成</span><br></pre></td></tr></table></figure><p>在这个流程中，还有一些特殊的优化：</p><h4 id="Common-SubExpression-Detection"><a href="#Common-SubExpression-Detection" class="headerlink" title="Common SubExpression Detection"></a>Common SubExpression Detection</h4><p><img src="https://image.mwish.me/blog-image/cse.png" alt="cse"></p><p>在 Expression 编译的时候，会有一个 <code>Scope</code> 做上下文。Scope 间也有父级关系。这里它会把编译好的表达式丢到 Scope 中，当表达式生成了两遍 <code>upper(a)</code> 的时候，他们会被用同一个表达式进行计算。</p><h4 id="Flatten-ANDs-and-ORs"><a href="#Flatten-ANDs-and-ORs" class="headerlink" title="Flatten ANDs and ORs"></a>Flatten ANDs and ORs</h4><p>表达式会标注可否 fold。velox 会尝试去 fold 这些表达式树，这一部分发生于 Compile 阶段</p><p><img src="https://image.mwish.me/blog-image/flatten-and.png" alt="flatten-and"></p><h5 id="flatten-concat-like-functions"><a href="#flatten-concat-like-functions" class="headerlink" title="flatten concat-like functions"></a>flatten concat-like functions</h5><p>这里和上面类似，比如 <code>f(x1, f(x2, f(x3, x4))) == f(x1, x2, x3, x4)</code>，这里会尝试折叠，避免深栈</p><h4 id="Constant-Folding"><a href="#Constant-Folding" class="headerlink" title="Constant Folding"></a>Constant Folding</h4><p>做一些常量折叠，相当于提前计算。</p><h3 id="Adaptive-Conjunct-Reordering-in-AND-and-OR"><a href="#Adaptive-Conjunct-Reordering-in-AND-and-OR" class="headerlink" title="Adaptive Conjunct Reordering in AND and OR"></a>Adaptive Conjunct Reordering in AND and OR</h3><p>这个在官网上是一个执行端策略，而在代码里…我在 compile 没看到，在 <code>ConjunctExpr::evalSpecialForm</code> 里面，发现了相关的方法 <code>maybeReorderInputs()</code>。看来论文也存在吹牛逼成分？还是后面被移走了？</p><p>这里会根据 and or 的 selectivity 选择，计算的时候，这里会统计 selectivity，<code>and</code> 会尽量前置 <code>false</code> 的表达式，<code>or</code> 会尽量前置 <code>true</code> 的表达式，来动态适应性熔断表达式计算。</p><h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><p>在执行端，<code>FilterProject</code> 的 operator 会一次性完成 <code>Filter + Project</code> 的执行，输入是 <code>EvalCtx</code>，包含 <code>RowVector</code> 和 <code>SelectivityVector</code>. <code>::eval</code> 方法用来评估表达式。</p><p><code>ExprSet</code> 包含一个或者多个 <code>Expr</code>, 它会调用 <code>Expr::eval</code>。执行的时候，这里会判断是否是一个重复的子表达式，如果是。这里会缓存计算结果。</p><p>当输入是字典编码的时候，确定性的表达式可以只算字典中的 distinct value。文章举了个例子，<code>UPPER(colors)</code>, 然后 colors 只有 <code>red, blue, yellow</code> 三种，但有很多值的时候，算这三种就行了。这种技术具体执行大概如下：</p><p><code>Expr::peelEncodings ()</code>: <code>f(g(input))</code> 中，进入表达式，表达式发现这一点，然后把输入换成字典的 distinct 输入了</p><p>这里还有字典的 memorizing，结果就比较简单：字典没变更就一直用同一个字典对象。</p><p>会 propagate null 的话，是 null 的表达式就不用再被折腾一茬子，直接 null set 传递，如果是字典的话，允许把字典里一些东西设置成 null。</p><p>Velox 官网有个一图速通，我看了下，和代码是对的上的：</p><p><img src="https://image.mwish.me/blog-image/expression-evaluation.png" alt="expression-evaluation"></p><h3 id="Flat-No-Nulls-Fast-Path"><a href="#Flat-No-Nulls-Fast-Path" class="headerlink" title="Flat No-Nulls Fast Path"></a>Flat No-Nulls Fast Path</h3><p>和我们刚才的 <code>propagateNulls_</code> 和处理相对，这里如果全部非空，那么可以 skip 一些 null handling，根据原文，在小于 1000 rows 的短表达式中，这种优化相对能起到比较好的效果。在 Velox 中，Vector functions (后面会介绍) 会提供一个 <code>supportsFlatNoNullsFastPath()</code> 的语义，来帮助评估走 fastPath</p><h4 id="Evalution-If-Switch"><a href="#Evalution-If-Switch" class="headerlink" title="Evalution If/Switch.."></a>Evalution If/Switch..</h4><p>先执行 condition，然后去按序执行 cases： <a href="https://facebookincubator.github.io/velox/develop/expression-evaluation.html#evaluation-of-if-switch">https://facebookincubator.github.io/velox/develop/expression-evaluation.html#evaluation-of-if-switch</a></p><h3 id="Codegen"><a href="#Codegen" class="headerlink" title="Codegen"></a>Codegen</h3><p>在论文写作的时候，Velox 会讲表达式生成 C++ 代码，然后动态链接到程序中。日前，Velox 采用的还是直接用编译器编译，而没有用时髦的 LLVM-codegen。文章认为 codegen 对 ETL 这种大 job 可能效果好一些，因为表达式整体都不会变，而 ETL job 反正会很大。</p><p>目前，Velox 基本还是全部向量化的方式，codegen 代码在 <code>experimental</code> 下面。</p><h2 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h2><p>用户可以认为，某种程度上 functions 是 expr 的一个小部分(<code>Call</code> 有关的 Expr)。Velox 内部提供了不少该有的函数，同时，用户也可以相对方便的添加函数。比较恶心的是，这帮人感觉没那么那么懂 C++，所以…加起来也有点小蛋疼。这体现在什么地方呢？一来 Velox 区分了 Vector 的函数和 Simple Functions，然后还有之前我们提到的各种 determine 等等，这些东西叠起来，加上类型系统做的比较糙，总的来说加东西也没有那么方便。当然，相对自己从头开始写，肯定是很丝滑的。</p><p>对于接收单个输入返回单个输出，确定类型的函数，即 Scalar Functions。 Velox 认为，Simple Function 不是那么好优化，而且向量化也容易出错的情况下，可以使用 Simple Functions + 向量化的方式来处理问题。Velox 会使用一套框架来包装 Simple Functions，然后尽量让其能自动向量化。</p><p><img src="https://image.mwish.me/blog-image/D40EF3D5-58F5-4B04-9E20-423639A128F8.png" alt="D40EF3D5-58F5-4B04-9E20-423639A128F8"></p><p>Velox 在编程框架上也做了很多优化，比如标注是否 nullable，使用 zero-copy，处理 deterministic。论文还提到了一项关于编码的优化：让用户指定 ASCii, Utf8 等编码，同时可以尽量优化其中的拷贝，可以 ref 原内容的地方不需要拷贝。</p><p><img src="https://image.mwish.me/blog-image/E4BA6100-A4CF-4EF4-B41D-906E4A3EFCE1.png" alt="E4BA6100-A4CF-4EF4-B41D-906E4A3EFCE1"></p><p>（越写我觉得越像 TiKV Coprocessor 了，想起我的青春年华和失败记忆了）</p><p>（论文甚至没怎么提 Vectorize functions，估计是觉得跟用户介绍最简单的就行，不过我觉得 Vectorize 的部分也挺有意思的：<a href="https://facebookincubator.github.io/velox/develop/scalar-functions.html#vector-functions">https://facebookincubator.github.io/velox/develop/scalar-functions.html#vector-functions</a> ）</p><h3 id="Aggragations"><a href="#Aggragations" class="headerlink" title="Aggragations"></a>Aggragations</h3><p>Aggragations 在 Agg 相关的 Operator 下头，使用 <code>HashAggregation</code> 进行相关的计算</p><p><img src="https://image.mwish.me/blog-image/7A390174-95B3-4BB9-A979-73B5F5907A34.png" alt="7A390174-95B3-4BB9-A979-73B5F5907A34"></p><ul><li>Partial: 类似 shuffle 中使用的，根据数据生成一些中间结果</li><li>Final: 处理 <code>Partial</code> 的结果</li><li>Single: 数据很小不用 shuffle，或者数据已经被按照 group key 来做 partition</li><li>Intermediate: 类似 MR 中的 shuffle，从中间数据生成中间数据，在 Partial 和 Final 之间</li></ul><p>Sum, min, max 中，partial 和 final 做的是同一种计算，而有的操作则不同。比如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT a, b, count(c) FROM t GROUP BY 1, 2</span><br></pre></td></tr></table></figure><p>partial 会做一些分区操作，Final 则是将 partial 数据合并起来。</p><h4 id="Aggregations-结果的内存管理"><a href="#Aggregations-结果的内存管理" class="headerlink" title="Aggregations 结果的内存管理"></a>Aggregations 结果的内存管理</h4><p>这里类似行存的数据库，会有如下的格式：</p><p><img src="https://image.mwish.me/blog-image/aggregation-layout.png" alt="aggregation-layout"></p><p>Velox 会识别出操作是否是定长操作，然后做处理。</p><h4 id="如何添加一个-Aggregator"><a href="#如何添加一个-Aggregator" class="headerlink" title="如何添加一个 Aggregator"></a>如何添加一个 Aggregator</h4><p>为啥这个要专门写呢？因为这个我们可以考虑一下，Agg 很多时候是带一些上下文的，比如对列的 map。论文里面连 function 都只介绍了 simple…</p><p>（这个地方我又想起了 TiKV Coprocessor 那堆 proc macro 和我那失败的青春）</p><p>参考：<a href="https://facebookincubator.github.io/velox/develop/aggregate-functions.html#aggregate-class">https://facebookincubator.github.io/velox/develop/aggregate-functions.html#aggregate-class</a></p><p>这里会考虑几种 agg:</p><p>Global aggregation, two aggregates: “count” and “sum”:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">count</span>(<span class="operator">*</span>), <span class="built_in">sum</span>(b) <span class="keyword">FROM</span> t</span><br></pre></td></tr></table></figure><p>Aggregation with three aggregates: “count” and two “sum”s.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> a, <span class="built_in">count</span>(<span class="operator">*</span>), <span class="built_in">sum</span>(b), <span class="built_in">sum</span>(c) <span class="keyword">FROM</span> t <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><p>首先，需要考虑各个阶段，比如 <code>Prepare</code>阶段的数据准备，其次考虑中间数据是否是定长的，这个会影响行相关的访问和写入（Accumulator size）。然后可以分别实现对应 global aggregation 和 groupby aggregation 相关的内容了。</p><h2 id="Plan-Nodes-and-Operators"><a href="#Plan-Nodes-and-Operators" class="headerlink" title="Plan Nodes and Operators"></a>Plan Nodes and Operators</h2><p><img src="https://image.mwish.me/blog-image/velox-logical-planner.png" alt="velox-logical-planner"></p><p>Plan Node 和 Operator 的映射几乎是一对一的，当然有几个例外：</p><ol><li>Filter node + Project node 会被折叠成 <code>FilterProject</code> ( 我们之前还提到过它，嘿 )</li><li>多于两个子节点的会被拆分，比如说 HashJoin 会拆成 HashBuild 和 HashProbe</li></ol><p>有一些特殊的地方可以参考：<a href="https://facebookincubator.github.io/velox/develop/operators.html">https://facebookincubator.github.io/velox/develop/operators.html</a></p><p>类似 Presto 的概念，里面的执行单元上层概念叫 Top ( Presto 的 Job 是一个带点分布式意味的单元，而 Velox 则是单机的)。Task 数据可能来源于 TableScan 或者 Exchange，然后可能以另一个 Exchange 结尾。这里会有 Pipeline 来驱动执行，每个 Pipeline 可能有一到多个执行的 Driver，Driver 可能 bound 在一个线程上，并管理执行的状态。这部分类似 Presto 了，感兴趣可以回头看看。我们就专门挑一些 Velox 介绍细一点的概念图来贴吧，都读到这了，高低得学点新东西是不。</p><p>这里举了一些 HashJoin 和 Local Exchange 的例子，这些都是为了扩大并发，注意，下文为例子，不代表实现一定会这样：</p><p><img src="https://image.mwish.me/blog-image/join.png" alt="join"></p><p>这里 Build 和 Probe 都是并发的，Build 有三个线程，Probe 有两个线程去执行。然后结果被放到 <code>JoinBridge</code> 中。</p><p>在 Velox 中，Local Exchange 可以从多个线程/一个线程 &lt;-&gt; 多个线程/一个线程中转换，帮忙完成这个工作。</p><h3 id="Split"><a href="#Split" class="headerlink" title="Split"></a>Split</h3><p>在 Velox 中，系统也有 Split，Velox 不负责分布式，但是外部可以通过<code>Task::addSplit(planNodeId, split)</code> api 来添加 Split，Split 被组织在队列中消费：</p><p><img src="https://image.mwish.me/blog-image/task-splits.png" alt="task-splits"></p><p>Local Exchange 等操作也会被从 Queue 中消费</p><h3 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h3><p>读取算子和 FilterProject 可以和 IO 整合在一起。Presto 侧重去读远端的数据源和开放的接口，Velox 则是有一套 IO。它默认使用 dwio 格式可以很好的去做算子下推等操作，同时，这里也有 adaptive 调整算子顺序的操作（如前文所述）。</p><p>最近 Velox 也在做一些 Parquet Native 的优化，见：<a href="https://github.com/facebookincubator/velox/discussions/2411">https://github.com/facebookincubator/velox/discussions/2411</a></p><h3 id="Hash-Joins"><a href="#Hash-Joins" class="headerlink" title="Hash Joins"></a>Hash Joins</h3><p>对于 HashJoin，Velox 有 kInner, kLeft, kRight, kFull, kLeftSemi, kRightSemi, kAnti 这几种。</p><p><img src="https://image.mwish.me/blog-image/hash-join-node.png" alt="hash-join-node"></p><p>Velox 在 Agg 和 HashJoin 中，都使用 <code>velox::exec::HashTable</code>. 它根据是否忽略 null keys 做了一些特化，JOIN KEY 等会呗存成一个行存的 <code>RowContainer</code> 来处理</p><p>Velox 会使用 <code>velox::exec::VectorHasher</code> 来 hash 对应的 key，当 key 空间可以被简单整理到 u64 中时，Velox 会使用这些优化，来避免嗯算哈希。</p><p> <code>velox::exec::HashTable</code> 是一个单线程的哈希表，这里有一些下面的策略：</p><ol><li><a href="https://github.com/facebookincubator/velox/commit/765cc2d793cc194f5f44b97ad011e29666ceed70">https://github.com/facebookincubator/velox/commit/765cc2d793cc194f5f44b97ad011e29666ceed70</a> (每个 executor 去处理不同的部分)</li><li><a href="https://github.com/facebookincubator/velox/commit/0d38da85bae9c6e87a4bbdbc42d428c6c3cd4d87">https://github.com/facebookincubator/velox/commit/0d38da85bae9c6e87a4bbdbc42d428c6c3cd4d87</a> (合并多组 hash build)</li></ol><p>题外话，folly 这里说实现参考了 F14，这里使用行存的 hashtable，作者认为这里 hash 相关的 attributes 还是存一起好，然后会使用 <code>prefetch</code> 等方式交错内存读取。Databend 最近实现了字符串特攻的 SAHA，优化效果贼好，感觉这种就是特化场景特化实现一定是无敌的。</p><h4 id="Dynamic-Filter-Pushdown"><a href="#Dynamic-Filter-Pushdown" class="headerlink" title="Dynamic Filter Pushdown"></a>Dynamic Filter Pushdown</h4><p>对于 inner, left semi, right semi 这几种 JOIN，Velox 允许使用 Dynamic Filter Pushdown:</p><p><img src="https://image.mwish.me/blog-image/join-dynamic-filters.png" alt="join-dynamic-filters"></p><p>HashProbe 中，VectorHasher 如果发现对象集合很少，可以把信息推到存储上，来做相关的优化。</p><h4 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h4><p>这里还实现了 broadcast join, anti joins 等，此外，这里还有 statistics 相关的数据，防止做负优化：<a href="https://facebookincubator.github.io/velox/develop/joins.html#execution-statistics">https://facebookincubator.github.io/velox/develop/joins.html#execution-statistics</a></p><p>这里还实现了 merge join，不过感觉篇幅不长：</p><p><img src="https://image.mwish.me/blog-image/merge-join-pipelines.png" alt="merge-join-pipelines"></p><h2 id="Memory-Management"><a href="#Memory-Management" class="headerlink" title="Memory Management"></a>Memory Management</h2><p>Velox 的 caching 的内存管理有点类似 umbra。它表示：</p><ol><li>小对象会从 heap 上申请</li><li>data cache, hash table, 读数据的 buffer 会使用 mmap 和 madvise 来管理</li></ol><p>这里会有层级的 MemoryTracker，来管理这些内存，然后上层可以通过 <code>spilling</code> 来让内存写出。Spill 相关的部分和 Presto 论文描述的差不多，没有什么特别的，都要在 Drive / Operator 上开洞.</p><p>值得一提的是缓存部分，Velox 写了一套稍稍复杂的大对象缓存（没用 CacheLib，感觉是没啥小对象需求？我不懂啊）。类似 Umbra，它会有不同大小的 mmap 空间做内存池，当没有人 pin 这些内存的时候，这部分可以换出。</p><p>Velox 还能够合并 IO，读取 S3，HDFS，然后丢到内存/SSD 缓存。Velox 读取远端的时候，会合并相邻读，对 SSD 会合并读到 20K ，对 SSD 会合并读到 500K。这几个感觉可以参考 arrow 去玄学调参。</p><p>Velox 还会做 Prefetch，这里，访问列存对象的方式如下：</p><ol><li>读 metadata，这个通常不会很大，通过 metadata 可以拿到对象大概的大小</li><li>读具体的 buffer</li></ol><p>Velox 这里会记录各列的 selectivity，然后尝试去 prefetch selectivity 高的，来降低延迟。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>尽管 Velox 这个项目的未来尚不明晰，同时没有数据写和事务相关的部分，但是它给我们展现了一个单机测的完整查询引擎，包括 IO, Executor, Operator, Driver, Pipeline 和各个算子。</p><p>Velox 代码注释算不得好，感觉作者们也没有那么懂 C++，我看的时候非常蛋疼的一点是，这些人传参数感觉都是瞎几把写的，一点都不管读者的感觉，但是 fb 相关的经验确实很丰富，虽然待完善，但确实给他们搞出来了，还搞的不错。还是要虚心学习，看看他们是咋搞的。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://facebookincubator.github.io/velox/develop">https://facebookincubator.github.io/velox/develop</a></li><li>Facebook Velox源码浅读 - 不要叫醒我的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/438656081">https://zhuanlan.zhihu.com/p/438656081</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>x86 and SIMD programming Part0: Background</title>
      <link href="/2022/11/05/x86-and-SIMD-programming/"/>
      <url>/2022/11/05/x86-and-SIMD-programming/</url>
      
        <content type="html"><![CDATA[<p>作为指令集并行的一部分，SIMD 已经被大幅度用来提高程序的性能了。而在数据库系统中，分析型数据库也大量使用 SIMD 来做 vectorize，来提高性能。本栏尽量介绍一下基本的 SIMD 的历史、需求和基础，然后后面也会讲到 AVX2 的入门、xsimd 库和让编译器自动来做向量化。在这里，了解硬件和指令集是比较重要的组成部分，而虽然 ARM 平台也有自己的 SIMD 指令集，但作为 db 研发，我们还是以 x86 的为准（倒不是看不起 arm，就单纯先不花时间吧）。</p><p>CPU 有一些技术来帮忙优化，比如 Hyper Threading / Super Scalar，CPU 也有专门的 SIMD 处理单元。这使得人们可以给出更好的实现。在数据库里面，近年来卷到爆炸的分析型数据库领域也希望能够利用好 SIMD。</p><p>言归正传，程序员早期其实是没那么懂并发编程的，原因大概在 <a href="https://blog.mwish.me/2022/05/04/perfbook-notes-hardware/">perfbook 那节</a> 也讲过，以前硬件提升都是可以直接反映到程序上，啥都不做性能就提升了，但是现在的程序员必须 get hands dirty，来了解一下下层的抽象，来一把捅下去获得性能。同时，有的时候性能、生产力、通用性是个不肯能三角，这个在 perfbook 那节也有提到。这话有点太俗了，下面的图其实是比较好理解的：</p><p><img src="https://image.mwish.me/blog-image/0EDCEC2A-2361-4560-91DD-68FE51B150D8.png" alt="0EDCEC2A-2361-4560-91DD-68FE51B150D8"></p><p>这里还有一张关于内存带宽和频率有关的图：</p><p><img src="https://image.mwish.me/blog-image/5FC1C556-0F2B-474B-B12E-4A6EAC8405FF.png" alt="5FC1C556-0F2B-474B-B12E-4A6EAC8405FF"></p><p>（实际上，可以看 ref 4，单线程已经跑不满内存带宽了，不过内存带宽仍然受到限制）</p><p>关于性能，这里还有一些 hints:</p><ol><li>cache miss 可能很重，可能相当于几十几百条指令，当然，IO 就更重了</li><li>需要利用 SIMD、多核、多线程甚至 GPU 甚至特殊硬件来改善性能</li><li>写 fastcode 可能涉及代码量大、多线程协调、不跨平台（比如单平台 SIMD 的问题），同时，Compiler 可能也不一定能够生成合适的代码。多线程必不多说，SIMD 可能也没法生成很好的选项，实际上很多地方（例如 TiFlash、ClickHouse）都是写便于向量化的代码，尽量让编译器自动向量化然后加一些编译参数来检查，一些关键路径也得自己手搓 SIMD 或者用 SIMD 库。</li></ol><p><img src="https://image.mwish.me/blog-image/18C67A41-F361-4853-8F9E-E1F4E5F61D01.png" alt="18C67A41-F361-4853-8F9E-E1F4E5F61D01"></p><h2 id="硬件发展和硬件基础"><a href="#硬件发展和硬件基础" class="headerlink" title="硬件发展和硬件基础"></a>硬件发展和硬件基础</h2><p><img src="https://image.mwish.me/blog-image/D8C704E9-F29C-48E4-8B8E-E9387C8DBE44.png" alt="D8C704E9-F29C-48E4-8B8E-E9387C8DBE44"></p><p>X86-64 平台是 x86-32 的一个扩展。当然，这里 x86 指的是 ISA，与之等同的是 RISC-V、ARM、POWER、MISC 等。而不同的是下层的实现和 microarch，比如 cacheline 的长度。x86 是一个 CISC 指令集，但是它的指令会被处理成 RISC 的，以获取性能：</p><p><img src="https://image.mwish.me/blog-image/AFA12812-C13B-4C01-BA95-E6E92971B7E5.png" alt="AFA12812-C13B-4C01-BA95-E6E92971B7E5"></p><p>下面是一个 Intel 芯片的图，来自 wiki:</p><p><img src="https://image.mwish.me/blog-image/IntelProcessorRoadmap-4v.svg.png" alt="IntelProcessorRoadmap-4v.svg"></p><p>Intel 在 06 年提出 tick-tock 模型: Tick 一次代表制程（Process）更新，利用硬件提升；Tock 代表作出新的架构。这个策略后来被更新为 Process–architecture–optimization 模型：</p><p><img src="https://image.mwish.me/blog-image/A5C7244A-F0A4-4EFE-8C73-B02694C904D8.png" alt="A5C7244A-F0A4-4EFE-8C73-B02694C904D8"></p><p>最早出现的芯片是 16位的 Intel 8086, Intel 8088, Intel 80186, Intel 80286。游戏的开端是 1985 年的 Intel 80386，它最初采用了 32位的 IA-32 架构（ 此外，还有个名字很像的、创造者同样包含 Intel 的 IA-64，则是另一个指令集。），它有各种寄存器、4GB 的虚拟地址空间、基于页的虚拟内存。80386 有独立的 80387 FPU。在 80486 中，这些被集成到了系统中，即 x87 FPU。实际上，FPU 和 SIMD 很多处理的逻辑类似，一定程度上，它们是被整合到一起的。</p><p>x86-32 平台在 93-95 年推出的 P5 microarchitecture 中，MMX 技术出现，它用 64-bits 位宽的寄存器来同时处理多个整数。</p><p>在 P6 架构的 Pentium Pro (1995) 和 Pentium II (1997) 中，Intel 引入了 superscalar，decode / dispatch / execute 可以乱序执行。Pentium 有个你可能很熟悉的名字，叫「奔腾」。</p><p>99 年引入的 P6 架构的 Pentium III 中，SSE（Streaming SIMD extensions） 指令集被引入了，它加入了一组 128bits 的寄存器，可以进行 SIMD 的单精度浮点运算.</p><p>一年后，2000 年，Intel 推出了 Netburst 架构，并引入了 SSE2，它补全了 SSE 处理双精度浮点数的能力，同时，它在 SSE 引入的寄存器上补齐了整数运算的能力。04 年，SSE3 推出，并运行在制程 90nm 的 Pentium 和 Xeon 架构上，这一代架构有 hyper-threading. 06年推出的 Core 架构（酷睿）做了不少优化、降低了能耗，同时引入了 SSSE3 指令集和 SSE4.1，他们没有引入新的寄存器，同时，hyper-threading 也被去除了。2008 年的 Nehalem 再次引入了 hyper-threading，同时也引入了 SSE 最后的 SSE4.2 指令集，这个指令集扩展了 SSE 寄存器上的字符串/文本处理。</p><p>2011 年 Intel 推出了 Sandy Bridge 架构，它引入了 Advanced Vector Extensions (AVX) 这一 SIMD 指令集，它用 256-bits 的寄存器来处理数据，这提升了寄存器的宽度，一定程度上减小了开销.</p><p>2013 年 Intel 推出了 Haswell 架构，同时，它引入了 AVX2，实际上，现在比较常用的编译参数包含 <code>-mavx2 -march=haswell</code>，同时，它提供了一组 data transfer 相关的指令：</p><ul><li>broadcast: 把一个值广播到多个位置</li><li>gather: 把多个不连续位置的内存加载</li><li>permute: 给出一组 index, 按照 index 来加载数据</li></ul><p>Haswell 还引入了 FMA 操作，FMA 代表 Fused Multiply-Add, eg:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* matrix multiplication; A, B, C are n x n matrices of doubles */</span> </span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">  <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; n; j++) </span><br><span class="line">    <span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; n; k++) </span><br><span class="line">      C[i*n+j] += A[i*n+k]*B[k*n+j];</span><br></pre></td></tr></table></figure><p>这种 <code>x = x + y * z</code> 的操作，只会舍入(rounding) 一次。</p><p>2017 年，Intel 的 Skylake-X 中，引入了 AVX512，使用 512-bits 的寄存器。</p><p>作为 Intel 之外最大的 x86 厂商，AMD 也对 SIMD 进行过支持， zen 架构支持了 AVX2，而之前的 K8 架构支持了 MMX、SSE、SSE2、SSE3，AMD 引入了 SSE4a 和 FMA4 等 Intel 不太支持的指令集。</p><p>在 ARM 芯片上，也存在 SIMD 指令集。NEON 有 128-bit 的寄存器。此外还有 NEON64 等指令集。</p><p>在 RISC-V 上，<a href="https://github.com/riscv/riscv-v-spec">Vector</a> 扩展前几个月刚刚 stable，不过编译器还有一些 instrinct 没有定下来，有待多方继续推进。</p><h2 id="Intel-and-Skylake"><a href="#Intel-and-Skylake" class="headerlink" title="Intel and Skylake"></a>Intel and Skylake</h2><p>Intel 机器执行指令的时候，大致逻辑如下：</p><p><img src="https://image.mwish.me/blog-image/02878185-F1E5-4D59-850D-1D898DE7B4CD.png" alt="02878185-F1E5-4D59-850D-1D898DE7B4CD"></p><p>这是一个 Superscalar 的模型，这里可以参考我们之前的 notes:</p><p><a href="https://blog.mwish.me/2020/10/21/SDS-Intro-RISC-V-Datapath-4-Pipeline/#Multiple-issue-%E2%80%9CSuperscalar%E2%80%9D">https://blog.mwish.me/2020/10/21/SDS-Intro-RISC-V-Datapath-4-Pipeline/#Multiple-issue-%E2%80%9CSuperscalar%E2%80%9D</a></p><p>这里，指令被解码后，你会看到一组 ports，来帮助进行程序的执行</p><p><img src="https://image.mwish.me/blog-image/EE09112C-4AB4-44EC-8BBD-DC9A51B04448.png" alt="EE09112C-4AB4-44EC-8BBD-DC9A51B04448"></p><p>可以回顾一下之前 notes 里面 OoO 的图，这里又一些 SIMD/fp 等的执行单元。</p><p>每条指令执行的效率是不一样的，同时如上图，fp fma、SIMD log 可能有多个执行单元，这不会影响延迟，但会影响吞吐：</p><p><img src="https://image.mwish.me/blog-image/3A279C0B-9D87-498A-9B44-9649281E2475.png" alt="3A279C0B-9D87-498A-9B44-9649281E2475"></p><p>关于相关指令，可以访问：<a href="https://www.agner.org/optimize/instruction_tables.pdf">https://www.agner.org/optimize/instruction_tables.pdf</a></p><p>你也许会发现 div 特别慢，可以参考 ref 11 来学习。这个也可以计算出各个指令的 flops/cycle</p><h2 id="衡量应用-Besides-O-N"><a href="#衡量应用-Besides-O-N" class="headerlink" title="衡量应用: Besides O(N)"></a>衡量应用: Besides O(N)</h2><p>complexity 是程序员都很熟悉的东西，有一个很好的入门回答：</p><ul><li>为什么时间复杂度中可以忽略常数? - 伊莉雅SAMA的回答 - 知乎 <a href="https://www.zhihu.com/question/361692674/answer/2635594762">https://www.zhihu.com/question/361692674/answer/2635594762</a></li></ul><p>这里，程序的分析可以引入对内存 - 计算的访问，区分操作是 memory bound 还是 compute bound:</p><p><img src="https://image.mwish.me/blog-image/CF950F53-1EA1-4CC7-B961-E8B11A7A8FB6.png" alt="CF950F53-1EA1-4CC7-B961-E8B11A7A8FB6"></p><p>和</p><p><img src="https://image.mwish.me/blog-image/999085C9-F9CB-42C3-A8FB-2BB92F4A60EB.png" alt="999085C9-F9CB-42C3-A8FB-2BB92F4A60EB"></p><p>有一个很有趣的 case 在 ref 4:  <a href="https://stackoverflow.com/questions/18159455/why-vectorizing-the-loop-does-not-have-performance-improvement/18159503">https://stackoverflow.com/questions/18159455/why-vectorizing-the-loop-does-not-have-performance-improvement/18159503</a></p><h2 id="查看你的机器"><a href="#查看你的机器" class="headerlink" title="查看你的机器"></a>查看你的机器</h2><p>学以致用，笔者有一台搭载了 Apple M1 的 Mac 和 AMD 3800X 芯片的台式机，可以看到，下面对应的参数：</p><ol><li><a href="https://en.wikichip.org/wiki/amd/ryzen_7/3800x">https://en.wikichip.org/wiki/amd/ryzen_7/3800x</a></li><li><a href="https://en.wikichip.org/wiki/apple/mx/m1">https://en.wikichip.org/wiki/apple/mx/m1</a></li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li>Intel tick-tock: <a href="https://zh.wikipedia.org/wiki/Intel_Tick-Tock">https://zh.wikipedia.org/wiki/Intel_Tick-Tock</a></li><li>Mircoarch cheatsheet: <a href="https://github.com/akhin/microarchitecture-cheatsheet/">https://github.com/akhin/microarchitecture-cheatsheet/</a></li><li>Micro arch 有关的博客: </li><li>一个非常有趣的问题: <a href="https://stackoverflow.com/questions/18159455/why-vectorizing-the-loop-does-not-have-performance-improvement/18159503">https://stackoverflow.com/questions/18159455/why-vectorizing-the-loop-does-not-have-performance-improvement/18159503</a></li><li>x86 wiki: <a href="https://zh.wikipedia.org/wiki/X86">https://zh.wikipedia.org/wiki/X86</a></li><li>VLIW wiki: <a href="https://zh.wikipedia.org/wiki/%E8%B6%85%E9%95%BF%E6%8C%87%E4%BB%A4%E5%AD%97">https://zh.wikipedia.org/wiki/%E8%B6%85%E9%95%BF%E6%8C%87%E4%BB%A4%E5%AD%97</a></li><li>指令级并行，线程级并行，数据级并行区别？线程的概念是什么？ - 用心阁的回答 - 知乎 <a href="https://www.zhihu.com/question/21823699/answer/172571488">https://www.zhihu.com/question/21823699/answer/172571488</a></li><li>FMA wiki: <a href="https://en.wikipedia.org/wiki/FMA_instruction_set">https://en.wikipedia.org/wiki/FMA_instruction_set</a></li><li>Intel’s Haswell CPU Microarchitecture: <a href="https://www.realworldtech.com/haswell-cpu/">https://www.realworldtech.com/haswell-cpu/</a></li><li>Instruction table: <a href="https://www.agner.org/optimize/instruction_tables.pdf">https://www.agner.org/optimize/instruction_tables.pdf</a></li><li>Div: <a href="https://stackoverflow.com/questions/26907523/branch-alignment-for-loops-involving-micro-coded-instructions-on-intel-snb-famil">https://stackoverflow.com/questions/26907523/branch-alignment-for-loops-involving-micro-coded-instructions-on-intel-snb-famil</a>  和 <a href="https://stackoverflow.com/questions/4125033/floating-point-division-vs-floating-point-multiplication">https://stackoverflow.com/questions/4125033/floating-point-division-vs-floating-point-multiplication</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Kudu: Storage for Fast Analytics on Fast Data</title>
      <link href="/2022/10/30/Kudu-Storage-for-Fast-Analytics-on-Fast-Data/"/>
      <url>/2022/10/30/Kudu-Storage-for-Fast-Analytics-on-Fast-Data/</url>
      
        <content type="html"><![CDATA[<p>Kudu 是一个声称「既能快速更新、又能快速查询」的分布式存储。它由 Cloudera 开发，作为 Hadoop 生态中存储的替代品，并在 2013 年开源。Cloudera 使用了 Impala + Kudu 的架构来作为一些替代（ Impala 可以视作 Presto 类似的产品，支持在 HDFS/Hive 上做高效的查询，国内的 Apache Doris 也是早期从 Impala fork 过来的）。</p><p>Tips: Kudu 和 Impala 都是羊，Kudu 是 「捻角羚」，Impala 是小一些的黑斑羚。</p><p>Kudu 的模型以 Primary Key 为主，类似 StarRocks 的主键模型。之后我们也会介绍，不按 Primary Key 查询的时候，Kudu 的性能会光速拉胯。论文写于 2015 年，相对于 Presto 这种同样 2013 左右放出来，但是 2019 年才发表论文的系统而言，Kudu 很多地方显得没有那么详尽。很多地方翻一些工业界使用者的 blog 也能发现一些问题。不过 Kudu 使用好像相对少一些，国内看到网易应该有人用。</p><p>Kudu 使用的还是 shared-nothing 的处理方式，同时，Kudu 的文件写入之后也是不可更新的。Base + Delta 的方式被采用以处理这个模型。Kudu Delta 处理的方式相对来说有点类似 Position Delta Tree。阅读 Kudu 论文，我认为应该主要关注「Tablet 存储」的部分，其他部分有的不是很重要，有的我甚至认为非常草台。</p><p>Cloudera 当时希望的 workload 是：</p><ol><li>需要有 streaming ingest 的数据管线，同时支持一些 updates</li><li>有一些定时作业来分析</li><li>高吞吐的存储</li><li>low-latency random access</li></ol><p><img src="https://image.mwish.me/blog-image/v2-86f0de0018e144b5d5b7335dc5002e75_r.jpeg" alt="v2-86f0de0018e144b5d5b7335dc5002e75_r"></p><p>Kudu 提供了对应的 api:</p><ol><li>Row-level inserts / updates / deletes</li><li>Table Scan</li></ol><p>Kudu 内部使用 <code>Cfile</code> 格式存储文件。这是 Kudu 给自己搞的适合自己的列存文件格式。</p><p>下面是论文的部分，在阅读的时候，我会尽量以论文为主轴，但是参考 Kudu 最新的实现。</p><h2 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h2><p>Table: 有定义好 Schema 的格式的表，一个 subset 的字段会被定义为 primary key。primary key 模型上必须是 unique 的，对 primary key 的删除被定义为快速的操作，否则可能会扫全表，因为它不支持 secondary index。</p><p>Schema 中，可以视作 <code>&lt;varchar: T&gt;</code> 的映射，Kudu 似乎不支持嵌套结构，如果有嵌套的结构，应该把这部分内容展开。关于 Kudu 的类型可以参考：<a href="https://kudu.apache.org/docs/schema_design.html#column-design">https://kudu.apache.org/docs/schema_design.html#column-design</a></p><p>关于 DDL，Kudu 支持一些基本的 schema change，在用户层面需要执行 alter table，Kudu 会给每个 column 维护一个 id，同时 Primary Key 是不能变更的。这里 Kudu 的 Schema Change 系统感觉还是比较简陋的，感觉类型提升什么的支持都不是很好，nested 也不太支持，令人唏嘘。不过，同其他列存系统一样，Kudu 对列也会做一些 encoding，来提升对应的压缩率。</p><p>对于写来说，Kudu 前台可以用对 pk 的 <code>Insert</code>, <code>Delete</code>, <code>Update</code> 几种 API。论文成文的时候，系统尚未支持分布式事务，只能在单个 <code>Tablet</code> 内执行事务（可以支持单行事务）。目前 Kudu 已经支持分布式事务，不过支持的好不好另说。</p><p>Kudu 有一个 HLC 时间戳系统，参考了文章：</p><p>它的写有两种模式：</p><ol><li><code>CLIENT_PROPAGATED</code> Consistency: 没啥同步，client 生成时间戳做事务</li><li><code>COMMIT_WAIT</code> : 会做同步，它声称自己做到了外部一致性。这是一个实验性功能，不鼓励在生产环境打开，同时，多 tablets 事务目前只支持 rc，然后单个 tablet 只支持一个事务。</li></ol><p>而读也有不同的模式：</p><ol><li><code>READ_LATEST</code></li><li><code>REAT_AT_SNAPSHOT</code></li><li><code>READ_YOUR_WRITES</code></li></ol><p>kudu 在读的时候支持 Scan / Projection / Filter。</p><p>Kudu 可以用 HLC 生成内部的时间，但也允许用户自己写时间然后给一个时间查询。</p><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p><img src="https://image.mwish.me/blog-image/BFA1827EA0FEB0E7FB3E455EB07D2502.jpg" alt="BFA1827EA0FEB0E7FB3E455EB07D2502"></p><p><img src="https://image.mwish.me/blog-image/23BFF20A-4E90-4062-8248-38F9C0A416CA.png" alt="23BFF20A-4E90-4062-8248-38F9C0A416CA"></p><p>其实上面的架构有点类似 HBase，不同的是，这里还是走了 Raft 而不是 ZK 来管理集群。见：<a href="https://github.com/apache/kudu/tree/master/src/kudu/consensus">https://github.com/apache/kudu/tree/master/src/kudu/consensus</a> 。走 Raft 管理感觉性能容易拉，但是相对来说能写的比较简单，而且依赖也少了。</p><p>当然，如果需要把 Kudu 暴露给 Impala 或者给外部查询，可能这里会需要 Hive Metastore 来暴露这些数据。</p><p>Master 节点运行的也是 tablet。和存储数据的节点跑着同一套代码，但建议还是跑在更好的服务器上。</p><p>对于 Tablet 服务器，之前有一些配置上的建议：</p><ol><li>为了获得对大事实表的最优扫描性能，建议保持一个tablet对应一个CPU核的比例。不要将被复制的表计算在内，应该只考虑Leader tablet的数量。对于小维度的表，可以只分配几个tablet</li><li>建议每个 tablet 最多包含 2000个 tablets，论文中推荐每台机器 10-100 个 tablets，我估摸着可以按照 CPU 和 Disk 数量拍</li></ol><p>需要注意的是，Kudu 的 WAL 是 Tablet 级别的（作为对比，写在 HDFS 上的 HBase 最初是一条 WAL 流，然后被小米扩展到多条）。相对而言，Kudu Tablet 间恢复可能比较独立，但是估计 IO 的 admission control 会相对复杂一些。</p><h3 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h3><p>Kudu 的 Partition 属于 「没啥意思但是很实用」的类型，它首先会按照 Primary key 来分 partition 到不同 tablets 上。它提供了一种 hash - range 混合的 Partition 策略:</p><ol><li>Range partition</li><li>hash partition</li><li>multilevel partition</li></ol><p>本质上，其实 Kudu 抽象比较简单，用户可以想象成：</p><ol><li>走一到几组不同的 hash</li><li>然后对 hash 后的 binary 进行 range 分片</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">用户指定一个 fn, 把 pk 列 (pk1, pk2, ...) 映射到一个 binary</span><br></pre></td></tr></table></figure><h4 id="Range-Partition"><a href="#Range-Partition" class="headerlink" title="Range Partition"></a>Range Partition</h4><p>对于 range partition，例子如下：</p><p><img src="https://image.mwish.me/blog-image/range-partitioning-example.png" alt="range-partitioning-example"></p><p>使用的时候，也可以参考 sample: <a href="https://docs.cloudera.com/cdp-private-cloud-base/7.1.6/impala-reference/topics/impala-kudu-partitioning.html#pnavId2">https://docs.cloudera.com/cdp-private-cloud-base/7.1.6/impala-reference/topics/impala-kudu-partitioning.html#pnavId2</a></p><p>Kudu 也允许动态插入 Range Partition。</p><h4 id="Hash-Partition"><a href="#Hash-Partition" class="headerlink" title="Hash Partition"></a>Hash Partition</h4><p>Hash Partition 会把行分配到 bucket 中，如下图：</p><p><img src="https://image.mwish.me/blog-image/hash-partitioning-example.png" alt="hash-partitioning-example"></p><p>这里可以指定 <code>PARTITION BY HASH(...) PARTITIONS 50</code> 这样。</p><h4 id="Multi"><a href="#Multi" class="headerlink" title="Multi"></a>Multi</h4><p><img src="https://image.mwish.me/blog-image/1DE6DE48-5A42-48A2-81FE-2443BB0367CA.png" alt="1DE6DE48-5A42-48A2-81FE-2443BB0367CA"></p><p>这里，可以按照手动指定 range + hash 或者 hash + hash 做分片：</p><p><img src="https://image.mwish.me/blog-image/hash-range-partitioning-example.png" alt="hash-range-partitioning-example"></p><p> 直观的感受还是，Tablet / Partition / Bucket 还是定的比较死的，在网易的博客里讨论过，当数据很少的时候，Kudu 也会按照给定的 Bucket 数量去分区。网易在他们的博客里提到了这个问题。注意，虽然不同 Partition 的 bucket-id 是相同的，但是它们存储在不同的 Tablet 上。</p><p>Hash Parition 方式类似静态分片，从代码可以看到：</p><ul><li><a href="https://github.com/apache/kudu/blob/77d3ea465bb1a1fa778cccd8432553032f51bd27/src/kudu/common/partition.cc#L1361-L1384">https://github.com/apache/kudu/blob/77d3ea465bb1a1fa778cccd8432553032f51bd27/src/kudu/common/partition.cc#L1361-L1384</a> </li><li><a href="https://github.com/apache/kudu/blob/77d3ea465bb1a1fa778cccd8432553032f51bd27/src/kudu/common/partition.h#L136">https://github.com/apache/kudu/blob/77d3ea465bb1a1fa778cccd8432553032f51bd27/src/kudu/common/partition.h#L136</a></li></ul><p>这里针对 hash 设置了 range，然后对提前切分好的 hash range 来分片</p><p>Kudu 的 Parition 可以引入一些 Pruning: <a href="https://github.com/apache/kudu/blob/master/docs/design-docs/scan-optimization-partition-pruning.md">https://github.com/apache/kudu/blob/master/docs/design-docs/scan-optimization-partition-pruning.md</a> . 这个 Pruning 类似不把 Task 发给被裁剪的 bucket。</p><p>Partition 还有一些小问题，对于 Kudu 的热点写，如果写的是某一个 Partition，那么 WAL 能比较好的处理。有一种 <code>backfill</code> 的场景，即 scan 数据回填，这种场景因为低缓存命中率，所以性能会比较差。</p><h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><p>Kudu 走的是 shared-nothing + Raft 的模式，其实我不理解为啥走 Raft… Kudu Raft 实现应该比较简单，它的 WAL 走的是 Raft，各台机器的状态机允许不一致。</p><p>虽然表面说走了 Raft，但是 Kudu 实际上类似 ZooKeeper 的 A-linearizable，写的时候走 Raft，读的时候可以本地读。不知道它这个和事务怎么协同设计的（直观感受就是看这玩意不如花时间去折腾 MongoDB，因为它这几方面的设计都非常草台，让我们不要折磨自己，跳过它们吧）。</p><p>相对来说，Kudu 的 Compaction 是个本地的程序，不涉及全局的 Raft。似乎这个是各个机器自己处理的：</p><blockquote><p>Kudu does not replicate the on-disk storage of a tablet, but rather just its operation log. The physical storage of each replica of a tablet is fully decoupled.</p></blockquote><p>比较傻逼的是，在它的文档里，对 config change，它还是靠单步变更实现的…额我只能说他开心就行：<a href="https://github.com/apache/kudu/blob/master/docs/design-docs/raft-config-change.md">https://github.com/apache/kudu/blob/master/docs/design-docs/raft-config-change.md</a></p><h3 id="Kudu-Master"><a href="#Kudu-Master" class="headerlink" title="Kudu Master"></a>Kudu Master</h3><p>之前说到了，Kudu 的 Tablet 由 Raft 来同步 WAL，因为 Raft 的存在，所以其实 Tablet 的分配是比较靠谱的，集群能够从这里面建立出信息，同时相对 HBase 来说，少了处理 RIT 的麻烦。</p><p><img src="https://image.mwish.me/blog-image/B195D594-DC70-42BC-B5DC-237A192FBBA2.png" alt="B195D594-DC70-42BC-B5DC-237A192FBBA2"></p><p>这里 master 可以：</p><ol><li>作为 tablet directory</li><li>存储元数据，作为一个 meta service，并处理 DDL 等操作<ol><li>在创建表的时候，这里会异步的 pick TabletServer 去 Assign Tablet</li><li>在删除表和 DDL 的时候，这里会需要让子节点状态完成</li><li>类似 HBase，这里的状态推进是幂等的</li></ol></li><li>监控 tablet server，适当的调度 tablets</li></ol><p>在实现的时候，它类似 GFS Master，把目录信息全部缓存在内存中。然后不同于 Tablet，读在这里不可以走 Replica 去做不一致的读。</p><p>上面说到的部分我们可以进行稍微细致一些的描述，Kudu 的 Master 会维护成 <code>sys.catalog</code> 表。写、读严格遵照 Raft 的 syntax。这里维护了下列的信息：</p><ol><li>[Table Id] -&gt; TableInfo</li><li>[Table Name] -&gt; TableInfo</li><li>[Tablet Id] -&gt; TabletInfo</li></ol><p>而 TableInfo 则包含了 [tablet-start-key] -&gt; TabletInfo 的有序 key-range mapping。</p><p>创建和删除表都被视作原子的多个 step，创建包含 preparing, running 等多个状态，这里会先推进 preparing，再推荐 writing，然后返回给用户，然后这里不会创建 tablets。直到 <strong>Table Assignment</strong> 阶段才会删除</p><p>对于删表，情况也差不多，这里会对表标记 “deleted”，然后对表发送的请求将失败。但是 Tablet 会走 DeleteTablet 请求异步的进行删除。</p><p>在 Table Assignment 阶段，这里会挑选机器，然后发送 CreateTablet 请求，并带有一个超时。<code>CatalogManagerBgTasks</code> 会监听信息，如果返回了对应的心跳，那么 Tablet 创建成功，否则需要挑选另一个 Tablet Server 了。</p><p><code>CatalogManagerBgTasks</code> 是一个很重要的线程，它会维护心跳，然后根据心跳来：</p><ol><li>把很久没发心跳的 tablet 切成 replaced 状态</li><li>给每创建的 tablet 挑选状态，启动 leader，然后启动它们</li><li>移动删掉了的 tablets</li></ol><p>Tablet 的故障恢复依赖 Raft，除此之外，这里还有个类似 DNS 的服务，当拉起新的 master 的时候，需要让 leader 指向同一个 DNS CNAME。</p><p>Master 还负责当 Tablet Directory，client 的缓存有可能是旧的，这里没讲述有没有 epoch 来维护这些信息。只是说，发到的不是 tablet master 的话，会重新访问 Master。</p><h2 id="Tablet-Storage"><a href="#Tablet-Storage" class="headerlink" title="Tablet Storage"></a>Tablet Storage</h2><p>tablet storage 是 Kudu 最重要的一部分，因为…这是有自己东西的一部分，你看前面的内容不是烂大街的吗（笑）（当然要做好也要一番功夫）。Tablet Storage 是 Kudu 比较独特的一部分，它可以被视为一个单机的引擎，因为感觉除了 WAL，不是很 Care 分布式的那堆逻辑。</p><p>看 Tablet Storage 的时候，需要注意这个模型还是有限制的，Primary Key 在其中占有非常重要的地位</p><p>Tablet Storage 是每个 Table 下的每个 Tablet 一份的。主要支持：</p><ol><li>Fast Columnar Scans: 这里实现了 CFile，自己的列存格式，然后引入了 bitshuffle 等 encoding 方式来做编码</li><li>Random Updates: 对 primary key 能够快速更新，random access 希望有 $O(lg n)$ 的 complexity</li></ol><p><img src="https://image.mwish.me/blog-image/E9F57C87-0442-42C1-8F8B-620615781030.png" alt="E9F57C87-0442-42C1-8F8B-620615781030"></p><p>类似 LSM Tree，Kudu 组织了 RowSets:</p><ol><li>MemRowSets: 在内存里的 RowSets</li><li>DiskRowSets: 盘上的 RowSets</li></ol><p>MemRowSets 采用了一个 MVCC 的 B-tree 实现，参考了 MassTree，具体实现于：<a href="https://github.com/apache/kudu/blob/master/src/kudu/tablet/concurrent_btree.h">https://github.com/apache/kudu/blob/master/src/kudu/tablet/concurrent_btree.h</a></p><p>其实这个实现有点类似 SkipList，基本上也是 append 作为写。然后需要注意的是，这里利用了 SIMD 和 JIT 加速（或许类似 ART ），然后 MemRowSets 是一个行存。</p><blockquote><p>NOTE: other systems such as C-Store call the MemRowSet the “write optimized store” (WOS), and the on-disk files the “read-optimized store” (ROS).</p></blockquote><h3 id="DiskRowSet"><a href="#DiskRowSet" class="headerlink" title="DiskRowSet"></a>DiskRowSet</h3><h4 id="CFile"><a href="#CFile" class="headerlink" title="CFile"></a>CFile</h4><p>DiskRowSets 由 CFile 组成，准确的说，在一个 DiskRowSet 内，每列都会有一个 CFile。CFile 是一个逻辑文件，Kudu 引入了一个 BlockManager 层，可能会把多个 CFile 映射到同一个物理文件上。</p><p>它由不同的部分组成，包括：</p><ol><li>Header</li><li>Footer</li><li>不同种类的 Block: 类似 data blocks, nullable data blocks, index blocks, dictionary blocks</li></ol><p>压缩和 encoding 以 Block (类似 Parquet 的 Page) 为粒度进行。每个 Block 可以选择自己的 encoding 方式。此外，这里还有对应的 Index:</p><p>这里用类似 Position Delta Tree 的方式组织 Index，有下面两种对应的 Index:</p><ol><li>Positional Index: 类似 PDT 或者 Parquet 中某列的 Offset Index</li><li>如果对应的数据有 sorted order，那会有这些数据的稀疏索引</li></ol><p>数据会写到 「Leaf Block」上，Kudu 会维护逻辑的 Internal Block，然后最后按 Post-Order 写入：</p><p><img src="https://image.mwish.me/blog-image/D045E99C-2BA6-4E14-9129-0D90345BB981.png" alt="D045E99C-2BA6-4E14-9129-0D90345BB981"></p><p>例如下面就会写 <code>[Int 2] [Int 1] [Int 0]</code></p><p>我从网上抄了个好心人画的图（Ref 5）：</p><p><img src="https://image.mwish.me/blog-image/014448C5-6AAA-4654-9C92-1B94A9030255.png" alt="014448C5-6AAA-4654-9C92-1B94A9030255"></p><p>其实和 Parquet 差不多，不过 Parquet 估摸着没 Btr，得线性或者二分</p><h5 id="BloomFile"><a href="#BloomFile" class="headerlink" title="BloomFile"></a>BloomFile</h5><p>BloomFile 是独立的 CFile 文件，额外存了一份，作为需要的列的 BloomFilter。有了 BF，那么上面那图操作进行之前，还要查一下对应的 BF 了。</p><p>BF 会被处理到 4KB 的 Page 中，然后快速查询。</p><h3 id="DeltaRowSet"><a href="#DeltaRowSet" class="headerlink" title="DeltaRowSet"></a>DeltaRowSet</h3><p>DiskRowSet 由 MemRowSet flush 而来，类似 RocksDB，我们也能知道对应的 min-max 值，用以支持后续的 compaction。</p><p>作为 Primary Key 模型，不同于 RocksDB / LevelDB，虽然 DiskRowSet 可以跨范围，但是单个 Primary Key 只可能出现在一个文件中：</p><p><img src="https://image.mwish.me/blog-image/8a52d89f9e118ec3d5899cf0c7cfc560.webp" alt="8a52d89f9e118ec3d5899cf0c7cfc560"></p><p>Kudu 区分了几种更新操作：</p><ol><li>Update</li><li>Delete</li><li>REINSERT</li></ol><p>Update 和 Delete 没有落在 MemRowSet，这点需要注意。然后 REINSERT 是和 Delete 对应的，如果有删除数据后来又重新插回去了，会纪录一条 REINSERT。这里保证了 BloomFilter 查到的东西相对靠谱，归属同一个 DiskRowSet。</p><p>这里更新记录 也是从 Mem 来的，如下：</p><p><img src="https://image.mwish.me/blog-image/48396E10-749F-4E6C-88EE-E79637ED0AC9.png" alt="48396E10-749F-4E6C-88EE-E79637ED0AC9"></p><p>Delta MS 是内存的部分，这里会按照 <code>(row_id, timestamp, RowChangeList)</code> 维护：</p><ol><li>RowId 很特殊，类似 PDT 中的概念，是文件中对应的行号。注意，某一行被删除，这个 RowId 仍然留着</li><li>timestamp 很好懂</li><li>RowChangeList 是对这一行各个列操作的物理日志</li></ol><p>Mem 的变更也是存放在同样的 btree 中，同时，这里可以根据 index 来找到对应的行号。这里可以 Flush 成对应格式的 Redo 文件，如下图：</p><p><img src="https://image.mwish.me/blog-image/5FECFBF7-8589-485D-B69A-4702C316B1BE.png" alt="5FECFBF7-8589-485D-B69A-4702C316B1BE"></p><p><img src="https://image.mwish.me/blog-image/8F9B8DCC-3A58-434D-AE05-2C45C0CB5D7B.png" alt="8F9B8DCC-3A58-434D-AE05-2C45C0CB5D7B"></p><h3 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h3><p>Compaction 的时候，可能会有多个 RowSet 做 Compaction，也可以是单个文件做 Compaction。这里需要注意的是，为了满足 MVCC，Base + Redo 文件可能会变成 Base + Undo 文件</p><p>Redo 记录我们之前应该介绍过，下面简单讲讲 Undo:</p><p><img src="https://image.mwish.me/blog-image/D38B3E53-8A9D-4AA6-ABAC-1133EC3E799E.png" alt="D38B3E53-8A9D-4AA6-ABAC-1133EC3E799E"></p><p>不同于 ARIES，一般 Kudu 会生成单向的 Redo 记录，然后当 Compaction 发生的时候，RDBMS，如 PG，可能会存一堆 Redo，然后找到一个最近版本恢复。在 Kudu 中，文件生命周期大概是：</p><ul><li>Redo -&gt; Base / Undo -&gt; 被合并或者回收</li></ul><p>这样避免了维护每个旧版本的文件视图和对它们的 ref（作为对比，RocksDB 的 VersionSet）</p><h4 id="Compaction-1"><a href="#Compaction-1" class="headerlink" title="Compaction"></a>Compaction</h4><p>Compaction 可以被分为 Major 和 Minor 的</p><h5 id="Delta-Compaction"><a href="#Delta-Compaction" class="headerlink" title="Delta Compaction"></a>Delta Compaction</h5><p><img src="https://image.mwish.me/blog-image/63B946FB-CF2B-4E44-878C-8B735690EFC9.png" alt="63B946FB-CF2B-4E44-878C-8B735690EFC9"></p><p>Minor REDO delta compaction: 合并 delta redo 成一个 redo，量级很轻，减小对应对 Delta 的 IO。实现逻辑就是原封不动的合并多个 Delta，应该能通过 IO 来提升压缩率，减少多文件 IO 和 fds</p><p><img src="https://image.mwish.me/blog-image/7D2628DB-2089-4B26-9465-29DBBC1A304C.png" alt="7D2628DB-2089-4B26-9465-29DBBC1A304C"></p><p>Major Redo Delta Compaction 如上图，这个地方要重写 base 文件，然后把原本的 redo 变成 undo。同时，这个地方也不会改变 row id。这里有一个特殊的地方，就是可以单独处理频繁更新的列，剩下的仍然在 redo delta 中。</p><p>需要注意的是，compaction 完成之后，即可以移除之前的文件。</p><h5 id="Range-Compactions"><a href="#Range-Compactions" class="headerlink" title="Range Compactions"></a>Range Compactions</h5><p><img src="https://image.mwish.me/blog-image/924AD8CD-2483-4F80-B792-32BB4F45E41E.png" alt="924AD8CD-2483-4F80-B792-32BB4F45E41E"></p><p>这个有点类似 RocksDB 的 Compaction，但它的操作其实相当重，我们可以讨论一下对应的问题：row_id 会改变，假设：</p><ol><li>某个模型跑的好好的，需要 Compaction 了</li><li>Compaction 进行的时候，写入还在不断进来</li><li>Compaction 完成了，RowSet 的写基于了之前的 row_id</li><li>寄！</li></ol><p>Kudu 采用了如下的实现策略：</p><p><img src="https://image.mwish.me/blog-image/77BE0595-D501-4CCA-80CC-15F14CED8FD0.png" alt="77BE0595-D501-4CCA-80CC-15F14CED8FD0"></p><p>这里，它加入了一个双写的 RowSet，然后Compaction 的时候，对应的变更会即写旧的又尝试写入新的，相当于把旧的写在新的 row_id 重放一遍。</p><h4 id="机制"><a href="#机制" class="headerlink" title="机制"></a>机制</h4><p>在 Kudu 中，Compaction 被建模为一个最优化模型，这里会根据 width 和 depth 来进行压缩：</p><p><img src="https://image.mwish.me/blog-image/231397D0-122C-491B-A7B3-809D440BFA07.png" alt="231397D0-122C-491B-A7B3-809D440BFA07"></p><p>如上图，这里会挑选合适的范围，然后去 compaction</p><p>具体的讨论见：<a href="https://github.com/apache/kudu/blob/master/docs/design-docs/compaction-policy.md">https://github.com/apache/kudu/blob/master/docs/design-docs/compaction-policy.md</a></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li>Kudu paper</li><li>Index Skip Scan Optimization: <a href="https://kudu.apache.org/2018/09/26/index-skip-scan-optimization-in-kudu.html">https://kudu.apache.org/2018/09/26/index-skip-scan-optimization-in-kudu.html</a></li><li>Apache Kudu 在网易的实践 <a href="https://www.infoq.cn/article/kgwyqb5wer5wl8cquweq">https://www.infoq.cn/article/kgwyqb5wer5wl8cquweq</a></li><li><a href="https://www.slideshare.net/cloudera/apache-kudu-technical-deep-dive">https://www.slideshare.net/cloudera/apache-kudu-technical-deep-dive</a></li><li>Kudu CFile 解读：<a href="https://www.jianshu.com/p/789c286e7077">https://www.jianshu.com/p/789c286e7077</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ICDE&#39;19: Presto: SQL on Everything</title>
      <link href="/2022/10/21/Presto-SQL-on-Everything/"/>
      <url>/2022/10/21/Presto-SQL-on-Everything/</url>
      
        <content type="html"><![CDATA[<p>本栏想介绍一些大数据和 OLAP 相关的东西，因为本人对大数据相对没有存储那么熟悉，所以很多地方可能早期写作的时候不会有太多自己的理解，以后读代码或者什么的时候会尽量补充一下。这里的 Ref 段也会引用一些国内介绍的二手文章，来便于做一些简单理解。</p><p>Presto 在 facebook 内部比较早的时候会在 Hadoop 系的系统上查询。13 年左右的时候开源出来了，据说 facebook 自己没那么管，然后 fb 出来一波人搞了个 Presto DB，后来更名为 Trino。在国内使用者中，用户会使用 Presto 来做一些 ad-hoc 的 AP 查询，然后用 Spark 做一些 batch job。本文在 19 年发表于 ICDE，作为 Presto 的总结。论文比较简单直接，没有扯很多花头，而是比较简单的介绍了一下 Presto 都在做什么。文章细节还是很多的，基本上可以作为一个引擎的详细介绍。</p><p>论文的标题是 SQL on Everything，用户可以设置 connector (数据源) 之后，运行 SQL。源头包括 HDFS、S3，也包括一些对应的外表。它会解析 SQL，然后去分布式的执行它们。Presto 包括了</p><ol><li>SQL 对应的解析和优化。这里的重点应该关注这个 Plan 是怎么分布式调度和执行的。</li><li>Connector，对应类型丰富的数据源。新数据源应该也可以编写自己的 connector。</li></ol><p>接下来上论文吧</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Presto 认为自己的关键字是：adaptive / extensible / flexible:</p><ul><li>Adaptive: 多租户、可扩展到数千节点庞大的集群中、能处理 memory / io / cpu bound 的各种优化。</li><li>Extensible: 允许用户对接各种数据源的数据，只要 connector 靠谱</li><li>Flexible: 支持各种类型的负载</li></ul><p>此外，它还要求支持高性能：新的查询不会起新的 JVM 容器，而是在单机 worker 的 long running JVM 进程中运行。这用调度和资源管理的复杂度来优化了 response time。</p><p>这篇论文描述了：</p><ol><li>Presto 的架构和实现</li><li>一些关键优化对性能的提升指标。</li></ol><h2 id="Use-cases"><a href="#Use-cases" class="headerlink" title="Use cases"></a>Use cases</h2><p>论文描述了几个 use cases:</p><ol><li>Interative analytics:<ol><li>处理少量数据 ( 50GB-3TB 的压缩数据)</li><li>并发 50-100</li><li>对<strong>响应时间</strong>比较敏感</li><li>可能会 kill， 或者 limit 来限制查询结果</li></ol></li><li>Batch ETL<ol><li>transformation 带来的 CPU 开销大、aggregation 和 Join 内存开销可能大致数 TB</li><li><strong>吞吐量</strong>很重要，响应时间没那么重要</li></ol></li><li>A/B Testing:<ol><li>数小时内完成分析</li><li>结果完整且准确</li><li><strong>可以拿到各个时间段的分析</strong>，所以预聚合可能不太适合</li><li>可能需要 JOIN 几个非常大的数据集，比如 user, device, test, event attributes</li><li>查询相对之前几个比较固定</li></ol></li><li>开发者/广告 分析 (好家伙，我用的 Google analytics 应该就是这种)<ol><li>给用户而非开发者使用</li><li>查询相对比较固定，包括 Join / Aggregation with window </li><li>数据总量很大，但是可以过滤掉非常多的数据</li><li>查询时间尽量在 ~50ms - 5s</li></ol></li></ol><h2 id="Architecture-overview"><a href="#Architecture-overview" class="headerlink" title="Architecture overview"></a>Architecture overview</h2><p><img src="https://image.mwish.me/blog-image/2B26F07F-6136-4021-960C-D6A68CEBB857.png" alt="2B26F07F-6136-4021-960C-D6A68CEBB857"></p><p>Presto 的进程分为两种：</p><ol><li>Coordinator</li><li>Worker</li></ol><p>这个 Coordinator 和 2PC 那个不是一个东西，它负责解析 SQL、分发查询（可能一些特别轻的 SQL，或者在 meta 直接处理完的、schema 相关的不会发给 worker？）。它负责：</p><ol><li>请求的 queue</li><li>生成、优化 distributed execution planner</li></ol><p>Worker 则负责读取数据、执行 Coordinator 产生的各个算子，它也负责读取对应数据源的各种数据。最底层的 worker 会分配到对应的 split，split 是外部存储系统的对应数据/数据范围。执行的时候有下列几个基本组成部分：</p><ol><li>Statement: 用户对应的 SQL 查询</li><li>Query: Presto 收到用户查询的时候，生成的 Query，这里可以当成 Presto 处理 sql 后的结构</li><li>Stage: SQL 会被拆成多个 stage</li><li>Task：单个 Stage 内会有多个 Task</li></ol><p>单机的并发中，机器靠并发执行 Task 来做到并发，Execution 尽量是 pipeline 执行的。Stage 间的数据会尽量存储在 memory 中，当在 node 间 shuffle 数据的时候，也会尽量用 buffer 来降低 latency (recall: Spark RDD)。</p><p>Presto 提供了很多 Plugin API，包括：</p><ol><li>Data types / functions / ACL / event consumer / queuing policies</li><li>最重要的是，它开放了对应数据源的 connector 接口：<ol><li>Metadata  API: Data 对应的元数据，比如 schema 等，其实是一组繁杂的 api</li><li>Data Location API: 数据分布的 api</li><li>Data Source API: 读取数据的 API</li><li>Data Sink AP: 写入数据的 API</li></ol></li></ol><p>实际上，Presto 不仅可以借助这些 API 完成和优化对数据源的查询，甚至可以借助这套 api，比较轻松完成一些任务，比如说联邦查询</p><h2 id="System-Design"><a href="#System-Design" class="headerlink" title="System Design"></a>System Design</h2><p>Presto 接受 SQL 查询，同时，有 RESTful HTTP 客户端和包括 JDBC 在内的各种连接，查询生成包括你们都听到腻的几部分：</p><ol><li>Parsing: 用基于 Antlr 的 Parser 来将 SQL 转成 ast，然后做一些语义上的分析</li><li>Logical Planning: 处理 ast，生成 PlanNode 的树，如下图（这个 SQL 要用到很后面）</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> </span><br><span class="line">  orders.orderkey, <span class="built_in">SUM</span>(tax) </span><br><span class="line"><span class="keyword">FROM</span> orders</span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> lineitem</span><br><span class="line">  <span class="keyword">ON</span> orders.orderkey <span class="operator">=</span> lineitem.orderkey </span><br><span class="line"><span class="keyword">WHERE</span> discount <span class="operator">=</span> <span class="number">0</span> </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> orders.orderkey</span><br></pre></td></tr></table></figure><p><img src="https://image.mwish.me/blog-image/1B137B26-BBA4-4044-8828-EE73D637522C.png" alt="1B137B26-BBA4-4044-8828-EE73D637522C"></p><p>然后进入 Optimization 阶段。论文里 Optimizer 描述的比较简单，CMU Talk 2021 <a href="https://www.youtube.com/watch?v=ZwaVZplVmVA&amp;ab_channel=CMUDatabaseGroup">介绍</a>了一些 Trino Optimizer 的设计。它有 rbo 和 cbo 部分，会根据代价算各种 MPP 优化，之后我应该会专门介绍。比较关键的是这里会根据下列信息作决策：</p><ol><li>Data Layouts: 根据 Data Layout API 拿到 partitioning, sorting, grouping, indices 相关的 properties。</li><li>Predicate Pushdown: 根据 connector 选择是否下推 range / equality，提升查询性能<ol><li>这包括可能推一些 selection filter 之类的东西，或者要不要推一些东西到存储上，connector 会提供一些相关的信息，还是很管用的</li></ol></li><li>inter-node parallelism (增大 node 间并发): 可以并行的部分可以拆分成专门的 stage，举个最简单的例子，扫描大量简单数据，然后 agg。这个因为扫描大量简单数据在有些情况下拆分开来并行扫描是可能更优的，所以这里可以唱分成一个 stage，每个 stage 在部分 input data 上执行同样的操作。stage 计算完毕结果会放到本地的内存 buffer 中。Stage 之前依靠 Shuffle 来进行交互。Shuffle 将带来比较重的 CPU 和网络开销，所以 Optimizer 应该慎重作出抉择。Figure 3 表示了 Optimizer 大概生成的内容（后面会对这个再优化）：</li></ol><p><img src="https://image.mwish.me/blog-image/A4D930D9-5D5D-4E27-B570-06206A282597.png" alt="A4D930D9-5D5D-4E27-B570-06206A282597"></p><p>生成之后，优化器需要根据一些 API 来进行优化，包括：</p><ol><li>Data Layout Properties: 可以根据 partition 之类的，来做一些 co-located join 相关的优化；或者如果发现某个 Join Column 是 Index 的时候，走 index nested loop join；也可以根据 MySQL 的 Partition 和连接的性质来做优化。在 Batch ETL 或者 AP 查询中，这里也可以做很多的数据裁剪。</li><li>Node Properties: 这里 Node 是指 PlanNode，这个类似 Cascades 模型提到的 Properties，节点会有 partition / sorting / bucketing 之类的信息。查询也可以设置 Preference，表示亲和的、必要的 properties，在优化 shuffle 的时候，Presto 会尽量满足更多的 Properties。可以根据这些信息来和 Data Layout Properties 一样优化查询、减少 shuffle。这样当然也可能会导致一定的 da ta skew，因为本来是有一定 dop 被分成 stage 的，现在 stage 合并了，所以倾斜的概率也会提高。这个 Figure3 中的表达式，如果有一些 layout properties 是可以尝试合并的。</li></ol><p>还有一些 intra-node parallelism 的处理：在单个 node 中，可能会因为 skew （比如用户随便写了个 SQL，没咋优化，也没咋设计 partition，就很容易 skew）或者 job 本身太大（在少量节点执行重 ETL）导致 Task 很重，然后 Task 的 Executor 没法快速消费下游生成的数据，这也不太行。节点内并行能稍微缓解一些这些症状，如下图：</p><p><img src="https://image.mwish.me/blog-image/8ECB9443-012A-41F5-A956-E9A331423D2E.png" alt="8ECB9443-012A-41F5-A956-E9A331423D2E"></p><p>这里在 Hash Join 的 Build Side 中，在 Pipeline 1 和 Pipeline 2 中引入了并发（我感觉这个相当于识别到不需要多 stage 处理，但是执行的时候会在一些 operator 里尝试并发？），原本的 Scan -&gt; Hash 被拆分成了两个 pipeline。</p><p>所以回顾一下，Optimizer 大概会：</p><p><img src="https://image.mwish.me/blog-image/7B7E3B3A-0D27-4EBA-AC39-244B61584C69.png" alt="7B7E3B3A-0D27-4EBA-AC39-244B61584C69"></p><h3 id="Scheduling"><a href="#Scheduling" class="headerlink" title="Scheduling"></a>Scheduling</h3><p>Coordinator 会把 Plan Stage 产生的 Executable Tasks 分发给 workers，然后也会有 task stages -&gt; task stages 的数据通路，让最后有一个执行树。</p><p>Task 可能包含一个或多个 Pipeline，Pipeline 是 Operator 的链（like HyPer)，当 Optimizer 发现一个 Pipeline 需要内部并行来提高性能的时候，就会尝试并行（我觉得基本上就是 Figure 4）。其实这里可以视作在<strong>不同级别</strong>做拆分操作：</p><ol><li>Probe Build 可能被拆分成 Stage1 -&gt; Shuffle -&gt; Stage2</li><li>这里在同一个 Stage 中，成了 Pipeline2 -&gt; LocalShuffle -&gt; Pipeline1</li></ol><p>顺带一提，我搜了下 google，竟然没搜到 LocalShuffle 这个词。</p><p>上述是 Optimizer 的部分行为，然后 Execution 的时候，调度行为如下：</p><ol><li>看那些 Stages 需要被调度</li><li>看多少人物需要被调度，被放置到哪些 node 上</li></ol><p><strong>Stage Scheduling</strong> 有 all-at-once 和 phased 两种策略：</p><ol><li>All-at-once 全部调度，减少了一定的 latency（但是资源开销可能比较大？）</li><li>Phase Scheduling 需要避免死锁，比如避免 Probe 比 Build 先运行。在 Batch ETL 场景大大减少了内存开销。</li></ol><p>当 Scheduler 需要执行某个 Stage 的时候，这里需要 assign 一定数目的 tasks 到对应的 nodes 上。Stage 被分为 Leaf Stage 和 Intermediate Stage。Leaf Stage 从 Connector 里面读取数据，而 intermediate stage 会拿到别的 Stage 生成的数据。</p><p>对于 Leaf Stage，这里会根据 Connector 和 network 相关的配置，来分配任务到各个节点上：</p><ol><li>极端的说，如果是 shared-nothing 部署，Leaf Stage 需要完全分配到对应的数据节点上</li><li>此外，会根据之前提到的 Connector Data Layout 相关的 API 做调度。</li></ol><p>分析场景有很大一部分开销在解压、decoding列存编码、过滤和数据类型转换上。这些任务算是 cpu + io bound 的，所以它们会被 dispatch 到<strong>尽量多</strong>的节点上（老实说，我觉得应该有个根据统计算的计算公式，比如：<a href="https://github.com/apache/arrow/blob/master/cpp/src/arrow/io/caching.cc#L52">https://github.com/apache/arrow/blob/master/cpp/src/arrow/io/caching.cc#L52</a> ）</p><p>这里也会根据网络来做一些配置，比如要求尽量读同一个机房的数据。</p><p>对于 Intermediate Stages，这里会根据 properties 和数据分布决定 worker / task 数量，甚至能够一定情况下动态更新 tasks 数目。</p><p>在 Leaf Stage 中的 worker 会被分配 Connector 中定义的 split，这个 split 相当于数据源中的一段数据，比如 Parquet / ORC 文件中的某段，或者是 Redis 的 server, key-value 等。Leaf Stage 需要被 assign 对应的 Split 才是可运行的，而中间节点在 assign 后一直可运行，并且在消费完上游数据或者 abort 之后完成。</p><p><img src="https://image.mwish.me/blog-image/E1FE9C7F-A989-48EE-A1C1-07BDC5B092BF.png" alt="E1FE9C7F-A989-48EE-A1C1-07BDC5B092BF"></p><p>关于 Task 的分发，这里会让 Connector 枚举对应的 split，然后一点点分发给 worker，这个地方希望：</p><ol><li>Hive 之类的 Connector 枚举可能需要很久，这里可以部分解耦查询时间</li><li>不处理完所有数据就生成查询结果</li><li>worker 上维护 split 队列，coordinator 会根据队列剩余长度来做一些调度，来一定程度避免 skew 和适配负载</li><li>split 搞完了就不一定要存在内存中了，在访问几白万个 split 的时候，降低内存和 tracking 的开销。</li></ol><p>当然，这个可能也会导致估计查询进度不准确。</p><h2 id="Execution"><a href="#Execution" class="headerlink" title="Execution"></a>Execution</h2><h3 id="单机执行"><a href="#单机执行" class="headerlink" title="单机执行"></a>单机执行</h3><p><img src="https://image.mwish.me/blog-image/066C1494-660B-4ABF-A322-2A673A75F354.png" alt="066C1494-660B-4ABF-A322-2A673A75F354"></p><p>Presto 在单机执行上有 Operator 和 Driver 两个概念，Driver 类似之前执行图中的单个 Pipeline 中的单个并行单元，在论文中，Driver 特点是：</p><ol><li>以 Page 为单位，处理数据，Page 类似 Figure 5</li><li>Pipeline 的处理 Operator，这里可以很简单的发现哪些是 blocking 状态，然后可以让出线程；非阻塞状态的 Page 可以在 Operator 之间移动</li></ol><p><img src="https://image.mwish.me/blog-image/42C83D4A-3E2B-465F-B378-99C5A866DF9D.png" alt="42C83D4A-3E2B-465F-B378-99C5A866DF9D"></p><h3 id="Shuffle"><a href="#Shuffle" class="headerlink" title="Shuffle"></a>Shuffle</h3><p>对于 Shuffle 而言，Presto 使用长轮询来拉取数据，即使数据很小，这样也有良好的不高的 latency。buffer 也需要一定的调整，buffer 太小或者消费跟不上导致 full 的话，split 处理就无法继续了，而且会占着大块内存；反之，如果 buffer 利用率不够，每次积攒了一些小 buffer 都被取走了，那么实际上网络这些开销就会比较大。</p><p>这里通过监控来调整消费端（下游）与输出端（上游）的数据：</p><ol><li>当上游 buffer 利用率持续比较高，这里会尝试减少分配给它的 split，来降低生产端数据产生。论文指出这样能优化不少对应的内存开销。</li><li>接收端会计算自己每个请求平均从下游获取了多少 bytes，然后来算一个合理的获取数据的并发。</li></ol><h3 id="写操作"><a href="#写操作" class="headerlink" title="写操作"></a>写操作</h3><p>对于写操作，Presto 也会调整对应的并发度。当写入 Buffer 占用过大的时候，这里会增大写的并发度，来调整对应的效率（这里举了个 S3 + Hive 的例子，但我没完全 get 到）。</p><h3 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h3><p>因为需要执行不同的 Task，Task 又包含各种 Pipeline，自然，做 Task 级别或者更下层的调度和资源管理也很重要。这里单个集群可能有数百的并发，同时也有一个资源管理系统。</p><h4 id="CPU-Scheduling"><a href="#CPU-Scheduling" class="headerlink" title="CPU Scheduling"></a>CPU Scheduling</h4><p>Presto 最关注的资源就是 CPU。node 级别的 scheduler 对 turnaround time 时间短的小查询做了特殊的优化，同时，对 CPU 资源需求差不多的查询做了公平共享(fair sharing)的调度。Task 的资源使用量等价于每个 split 的 CPU time 之和，同时，调度的时候，节点会记录自己 node 上 Task 执行的时间，然后做 Task-level 的调度。</p><p>在并发处理上，Presto 使用了协作多任务的模型。每个任务最多有一个 1秒钟的时间片，在运行完 1 秒后，它需要重新进入任务队列。当 output buffer 满了（下游消费数据慢）或者上游 buffer 空、系统没有足够内存的时候，系统会调度别的任务。</p><p>在调度策略上（即选择下一个调度的任务），Presto 使用了 MLFQ 来做调度，用 CPU Time 来做调度的指标。在执行上，这个依靠 connector 提供的 async api 和 yield signal，这样 io-task 就可以让出对应的 cpu 了。同时，相对来说，batch etl 调度优先级会低一些，而短的任务通常会被很快的执行</p><h4 id="Memory-Management"><a href="#Memory-Management" class="headerlink" title="Memory Management"></a>Memory Management</h4><p>内存申请需要走 Pool，然后被标记为 user memory 或者 system memory：</p><ol><li>user memory: 和用户的输入数据有关，能够反馈给用户</li><li>system memory: 系统内部的实现，大小和用户关系不大，比如 shuffle buffers</li></ol><p>这两个限制是分离的，同时，超过了节点级别内存限制或者各个节点总内存开销超过限制的 Query 会被 kill 掉。而如果机器内存不够，task allocate 不出内存，它会 blocking 直到能够申请内存。</p><p>节点级别内存和总内存可以限制并行度、防止 skew，这个都…莫名很好懂，感觉可以参考 DynamoDB 的 WCU / RCU。当然，这里 Batch ETL 会遇到内存不够用的情况，所以这里提供了 Spilling 和 Reserved Pool:</p><ol><li>Reserved Pool: 预留内存池，类似 DynamoDB 的 burst 资源池，已经<a href="https://github.com/trinodb/trino/issues/6677">无了</a>，因为 trino 讨论者认为这玩意没有起到实际的作用</li><li>spilling state to disk. <strong>Presto supports spilling for hash joins and aggregations.</strong><ol><li>However, we do not conﬁgure any of the Facebook deployments to spill. Cluster sizes are typically large enough to support several TBs of distributed memory, users appreciate the predictable latency of fully inmemory execution, and local disks would increase hardware costs (especially in Facebook’s shared-storage deployments).</li></ol></li></ol><h3 id="Fault-Tolerance"><a href="#Fault-Tolerance" class="headerlink" title="Fault Tolerance"></a>Fault Tolerance</h3><p>在论文发表的时候，Presto 似乎对 fault tolerance 支持不是很好：</p><ol><li>Task / Stage 之类的错误，会重试</li><li>Coorindator 的错误会导致整个服务不可用。在 fb，Interactive analytics 和 batch etl 用 standby coordinator，A/B 和 analysis 则用多个集群。</li><li>Presto 认为 ckpt 之类的策略都过重了，所以写文章的时候还没支持。听说还有用 Presto on Spark 支持 batch ETL 的，真的牛批</li></ol><h2 id="Query-Processing-Optimizations"><a href="#Query-Processing-Optimizations" class="headerlink" title="Query Processing Optimizations"></a>Query Processing Optimizations</h2><h3 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h3><p>利用 JIT，调整 GC。不懂 Java，不锐评了。</p><h3 id="Codegen"><a href="#Codegen" class="headerlink" title="Codegen"></a>Codegen</h3><p>不懂，不锐评了。</p><h3 id="File-Format-Features"><a href="#File-Format-Features" class="headerlink" title="File Format Features"></a>File Format Features</h3><p>这个我可太懂了…</p><p><img src="https://image.mwish.me/blog-image/862369FC-A797-4C3B-8959-D0CBFCA1A827.png" alt="862369FC-A797-4C3B-8959-D0CBFCA1A827"></p><p>这图有比较细节的部分：</p><ol><li>Page 是有不同的列的</li><li>Page 内列块为 block，可能是编码的数据</li><li>如果是字典编码，那么字典是可以 reuse 的</li></ol><h3 id="Lazy-Data-Loading"><a href="#Lazy-Data-Loading" class="headerlink" title="Lazy Data Loading"></a>Lazy Data Loading</h3><blockquote><p>Connectors can generate lazy blocks, which read, decompress, and decode data only when cells are actually accessed.</p><p>Given that a large fraction of CPU time is spent decompressing and decoding and that it is common for ﬁlters to be highly selective, this optimization is highly effective when columns are infrequently accessed.</p></blockquote><p>这里类似 <code>Select a where b &lt; xxx;</code> 的时候，如果过滤效率好，很多 a 相关的列就不用一起解压了，但实现起来其实是很多脏活的。</p><h3 id="Operating-on-Compressed-Data"><a href="#Operating-on-Compressed-Data" class="headerlink" title="Operating on Compressed Data"></a>Operating on Compressed Data</h3><p>参考 abadi 的论文，我之前博客也提到过：<a href="https://blog.mwish.me/2022/01/15/format-thinking-2/#DB-%E7%9B%B4%E6%8E%A5%E5%9C%A8%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97">https://blog.mwish.me/2022/01/15/format-thinking-2/#DB-%E7%9B%B4%E6%8E%A5%E5%9C%A8%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%95%B0%E6%8D%AE%E4%B8%8A%E8%BF%9B%E8%A1%8C%E8%AE%A1%E7%AE%97</a></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li>Trino: The Definition Guide (这本书有第二版，但我没下载到靠谱的，所以翻了下第一版)</li><li>Presto概述：特性、原理、架构 <a href="https://zhuanlan.zhihu.com/p/260399749">https://zhuanlan.zhihu.com/p/260399749</a> </li><li>Presto Explain: <a href="https://prestodb.io/docs/current/sql/explain.html">https://prestodb.io/docs/current/sql/explain.html</a></li><li>分布式SQL查询引擎原理（以Presto SQL为例）<a href="https://zhuanlan.zhihu.com/p/293775390">https://zhuanlan.zhihu.com/p/293775390</a></li><li>Presto 是如何 schedule task 的? <a href="https://zhuanlan.zhihu.com/p/58959725">https://zhuanlan.zhihu.com/p/58959725</a></li><li>Presto 数据如何进行shuffle <a href="https://zhuanlan.zhihu.com/p/61565957">https://zhuanlan.zhihu.com/p/61565957</a></li><li><a href="https://docs.qq.com/slide/DZVhBRlhqc2dhVHda">https://docs.qq.com/slide/DZVhBRlhqc2dhVHda</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> bigdata </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Parquet Part3: read rep and def levels</title>
      <link href="/2022/10/19/Parquet-Part3-read-rep-and-def-levels/"/>
      <url>/2022/10/19/Parquet-Part3-read-rep-and-def-levels/</url>
      
        <content type="html"><![CDATA[<p>之前的 Part2 介绍了 Parquet 的 rep-level, def-level 的写入. Parquet 会根据用户输入的 <code>Array</code>，来根据 schema 的嵌套和中间的元数据，给一个 column 的数据构建对应的栈。在运行的时候，这里会找到连续的字段，然后给定对应的 rep-level 和 def-level 来填充数据。</p><p>在写入的时候，用户会给定一个 <code>Array</code>，然后让 Parquet 把 array 中的数据序列化成 <code>rep-level</code>, <code>def-level</code> 和值，这些东西会被编码到 <code>Page</code> 中，以 <code>DATA_PAGE_V2</code> 为例：</p><ol><li>会有个 PageHeader，告诉你有没有 rep-level 和 def-level，和对应长度</li><li>rep-level 和 def-level 被 rle/bit-packing 编码</li><li>Page 可能被编码与压缩，会记录相关的内容</li></ol><p>读取的时候，这些东西也会按照 schema 解析，但是需要回过头来注意一下，读取的时候也是一个层次读取，但是需要从一组 rep-level / def-level 来恢复多层的信息了。</p><p>我们可以再回顾一下，<code>parquet</code> 在 arrow 项目的路径是：<code>cpp/src/parquet/</code>:</p><ol><li><code>cpp/src/parquet/</code>：目录下有基本的 parquet 的 schema 和实现，包括 Page 的处理、压缩、column 的处理，这里都是符合标准的，它会借用部分 <code>arrow</code> 的库和实现</li><li><code>cpp/src/parquet/arrow</code>：<code>arrow</code> 的转义层，能够把 arrow 的东西解析读、写到 parquet 上，这里的 <code>FileReader</code> 等都会包装 <code>cpp/src/parquet</code> 上的数据，然后处理 <code>rep-level</code> 和 <code>def-level</code>。<strong>上一篇博客里面 levels 的构建就是在 arrow 下面的 </strong>。</li></ol><p>Arrow 读取的对应链路大概如下：</p><ol><li><code>ParquetFileReader</code> 是最外层的数据，用 <code>ParquetFileReader::Open</code> 等相关的 api 来打开对应的文件。这里可以根据 <code>RowGroup(rgId)</code> 这个函数，创建对应的 <code>RowGroupReader</code></li><li><code>SerializedFile</code> 实现了 <code>ParquetFileReader::Contents</code>，具体实现了 <code>ParquetFileReader</code> 的对应逻辑，它可以加载 parquet 的 footer，然后解析 Footer。根据解析的 Footer 来加载对应的 <code>RowGroupReader</code><ol><li>在文件 IO 上，这里有一个 <code>::arrow::io::internal::ReadRangeCache</code> 表示对某个范围的 caching。然后有一组和这个有关的 api 表示是否缓存</li><li><code>ReaderProperties</code> 表示这个 Reader 的配置，比如是否使用 caching 等</li><li>有 <code>FileMetaData</code> 的 API，注意，这个相当于对 parquet 依赖的 thrift 生成的代码的 wrapper。Parquet 不对外暴露 thrift，而是暴露对应的自己的 API Wrapper，怎么说呢，可以说这个抽象比较好，但是性能也确实比较挫（考虑极端场景，只需要一个 count，也得把 Footer 整个解析）</li></ol></li><li><code>RowGroupReader</code>可以返回 <code>parquet::ColumnReader</code> 和某个 Column 的 <code>PageReader</code></li><li><code>SerializedRowGroup</code> 实现了 <code>RowGroupReader::Contents</code>，持有某个 RowGroup 的 MetaData</li><li><code>PageReader</code> 有 <code>SerializedPageReader</code> 这个实现，对外返回对应的解压之后的 <code>Page</code> 对象，这里可以是数据页、字典页面、Index Page。</li><li><code>parquet::ColumnReader</code> 在 <code>PageReader</code> 上包装了一层记录读取的 API，根据 <code>ReadBatch</code> 和 <code>ReadBatchSpaced</code> 之类的 api 来读取对应的数据，然后返回给上层。这里也会读取 <code>Page</code> 上的 Level，来恢复对应的记录</li><li><code>parquet::arrow</code> 模块会调用上文对应的东西，它有一个 <code>ColumnReader</code>，注意这个 <code>ColumnReader</code> 不要和上面 <code>ColumnReader</code> 搞混了，这是用来恢复 <code>Array</code> 的</li></ol><h3 id="读取-Parquet-中的链路"><a href="#读取-Parquet-中的链路" class="headerlink" title="读取: Parquet 中的链路"></a>读取: Parquet 中的链路</h3><p>这块读取比写入简单很多，大概是：</p><ol><li>每一列读 rep-level, def-level 自己就能恢复自己这层的数据</li><li>上层找到 children 的 level，然后可以恢复</li></ol><p>所有的恢复都经由 <code>ColumnReader</code>，叶子结点恢复实现在 <code>TypedRecordReader</code> 中，<code>LeafReader</code> 创建 <code>TypeRecordReader</code> 来读取。而上层在 <code>ListReader</code> 和 <code>StructReader</code> 中恢复，恢复的时候需要从子节点中挑选一个 <code>TypedRecordReader</code> 来恢复一些信息. <code>ColumnReader</code> 这个 API 只有叶子结点有。</p><p><code>ColumnReader</code> 的 API 非常简单，内容如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PARQUET_EXPORT</span> ColumnReader &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">ColumnReader</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">static</span> std::shared_ptr&lt;ColumnReader&gt; <span class="title">Make</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> ColumnDescriptor* descr, std::unique_ptr&lt;PageReader&gt; pager,</span></span></span><br><span class="line"><span class="params"><span class="function">      ::arrow::MemoryPool* pool = ::arrow::default_memory_pool())</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Returns true if there are still values in this column.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">HasNext</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Type::type <span class="title">type</span><span class="params">()</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">const</span> ColumnDescriptor* <span class="title">descr</span><span class="params">()</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Get the encoding that can be exposed by this reader. If it returns</span></span><br><span class="line">  <span class="comment">// dictionary encoding, then ReadBatchWithDictionary can be used to read data.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// \note API EXPERIMENTAL</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> ExposedEncoding <span class="title">GetExposedEncoding</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">protected</span>:</span><br><span class="line">  <span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">RowGroupReader</span>;</span><br><span class="line">  <span class="comment">// Set the encoding that can be exposed by this reader.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// \note API EXPERIMENTAL</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">SetExposedEncoding</span><span class="params">(ExposedEncoding encoding)</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里有一些别的结构，我们先来整理一下继承关系：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// 提供了 ReadBatch, ReadBatchSpaced 和 Skip, 便于用户读取某一列的具体数据.</span></span><br><span class="line"><span class="comment">/// 这个也是一个接口层, 相对 `ColumnReader` 提供了通用的接口, 这里提供了 Batch 读某个类型的接口. </span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DType&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TypedColumnReader</span> : <span class="keyword">public</span> ColumnReader &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// 实现了从某个 decoder 来读 values, 读 rep-level 和 def-levels.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// 这里也有一些列维护的信息, 比如对应的 decoder, 还有一些静态信息, 比如 Column 对应的最大的 def-level 和</span></span><br><span class="line"><span class="comment">/// rep-level, 记做 descr 和 level info.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// 这里是 Column Reader, 所以处理返回对应的是 ColumnChunk, 这里会维护需要处理的 value 数量 </span></span><br><span class="line"><span class="comment">///  (ColumnMetaData 会记录 `num_values`, 代表值而非行)</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// 这里也处理了 levels (rep-level 和 def-level) 的 decoder, 因为这两个和某个具体的类型是无关的.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DType&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ColumnReaderImplBase</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">using</span> T = <span class="keyword">typename</span> DType::c_type;</span><br><span class="line">  <span class="keyword">using</span> DecoderType = TypedDecoder&lt;DType&gt;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// 具体的 reader 实现, 实现了 ReadBatch, ReadBatchSpaced 和 Skip.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DType&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TypedColumnReaderImpl</span> : <span class="keyword">public</span> TypedColumnReader&lt;DType&gt;,</span><br><span class="line">                              <span class="keyword">public</span> ColumnReaderImplBase&lt;DType&gt; &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">using</span> T = <span class="keyword">typename</span> DType::c_type;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>也就是说，具体实现会在 <code>TypedColumnReader</code> 和 <code>TypedColumnReaderImpl</code> 中。对外接口有 <code>Skip</code>, <code>ReadBatch</code>，有一个比较复杂的 <code>ReadBatchSpaced</code> 的接口已经 deprecated 了。</p><p>我们专注在 <code>ReadBatch</code> 上：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// API to read values from a single column. This is a main client facing API.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DType&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TypedColumnReader</span> : <span class="keyword">public</span> ColumnReader &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">typedef</span> <span class="keyword">typename</span> DType::c_type T;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Read a batch of repetition levels, definition levels, and values from the</span></span><br><span class="line">  <span class="comment">// column.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Since null values are not stored in the values, the number of values read</span></span><br><span class="line">  <span class="comment">// may be less than the number of repetition and definition levels. With</span></span><br><span class="line">  <span class="comment">// nested data this is almost certainly true.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Set def_levels or rep_levels to nullptr if you want to skip reading them.</span></span><br><span class="line">  <span class="comment">// This is only safe if you know through some other source that there are no</span></span><br><span class="line">  <span class="comment">// undefined values.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// To fully exhaust a row group, you must read batches until the number of</span></span><br><span class="line">  <span class="comment">// values read reaches the number of stored values according to the metadata.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// This API is the same for both V1 and V2 of the DataPage</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// @returns: actual number of levels read (see values_read for number of values read)</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">int64_t</span> <span class="title">ReadBatch</span><span class="params">(<span class="type">int64_t</span> batch_size, <span class="type">int16_t</span>* def_levels, <span class="type">int16_t</span>* rep_levels,</span></span></span><br><span class="line"><span class="params"><span class="function">                            T* values, <span class="type">int64_t</span>* values_read)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里，会根据 <code>batch_size</code> 来填充数据，这里分为：</p><ol><li><code>def_levels</code> 和 <code>rep_levels</code>，两个 <code>i16</code> 数组，代表对应的 levels，可能没有读，这两个是等长的（不等长会抛出 exception）</li><li><code>values</code>，具体的值</li><li><code>values_read</code>, 代表具体从存储读了多少<strong>非 null 值</strong>。尽量从 rep_levels 和 def_levels 来判断这个值</li></ol><p>看看实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> DType&gt;</span><br><span class="line"><span class="type">int64_t</span> TypedColumnReaderImpl&lt;DType&gt;::<span class="built_in">ReadBatch</span>(<span class="type">int64_t</span> batch_size, <span class="type">int16_t</span>* def_levels,</span><br><span class="line">                                                <span class="type">int16_t</span>* rep_levels, T* values,</span><br><span class="line">                                                <span class="type">int64_t</span>* values_read) &#123;</span><br><span class="line">  <span class="comment">// HasNext invokes ReadNewPage</span></span><br><span class="line">  <span class="keyword">if</span> (!<span class="built_in">HasNext</span>()) &#123;</span><br><span class="line">    *values_read = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// TODO(wesm): keep reading data pages until batch_size is reached, or the</span></span><br><span class="line">  <span class="comment">// row group is finished</span></span><br><span class="line">  <span class="type">int64_t</span> num_def_levels = <span class="number">0</span>;</span><br><span class="line">  <span class="type">int64_t</span> values_to_read = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// 读 levels, 然后也判断出哪些是 null, 如果有 null 或者里面消费完了, 具体要读的值可能会小于 `batch_size`.</span></span><br><span class="line">  <span class="built_in">ReadLevels</span>(batch_size, def_levels, rep_levels, &amp;num_def_levels, &amp;values_to_read);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 读取非 null 的 value, 在没有读完这个 Page 的时候, values_read == values.</span></span><br><span class="line">  *values_read = <span class="keyword">this</span>-&gt;<span class="built_in">ReadValues</span>(values_to_read, values);</span><br><span class="line">  <span class="type">int64_t</span> total_values = std::<span class="built_in">max</span>(num_def_levels, *values_read);</span><br><span class="line">  <span class="type">int64_t</span> expected_values =</span><br><span class="line">      std::<span class="built_in">min</span>(batch_size, <span class="keyword">this</span>-&gt;num_buffered_values_ - <span class="keyword">this</span>-&gt;num_decoded_values_);</span><br><span class="line">  <span class="keyword">if</span> (total_values == <span class="number">0</span> &amp;&amp; expected_values &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    std::stringstream ss;</span><br><span class="line">    ss &lt;&lt; <span class="string">&quot;Read 0 values, expected &quot;</span> &lt;&lt; expected_values;</span><br><span class="line">    ParquetException::<span class="built_in">EofException</span>(ss.<span class="built_in">str</span>());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">this</span>-&gt;<span class="built_in">ConsumeBufferedValues</span>(total_values);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> total_values;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里会：</p><ol><li>根据 <code>batch_size</code> 和内部的状态，看看读多少值，然后解析对应的 <code>levels</code>。( <code>ReadLevels</code> )</li><li>读取对应的非 null 的 values (<code>ReadValues</code>, 里面会调用 <code>decoder-&gt;Decode</code>)</li><li>返回的是读的所有包括 null 的值的数目，<code>values_read</code> 会存放 <code>values</code> 中内容的长度 (<code>ConsumeBufferedValues</code> )</li></ol><p>这里我们重申一个比较 hack 的地方，就是变量名称问题，这个也涉及到一些 Decoder 内部的逻辑：</p><ol><li><code>num_buffered_values_</code>: Page 中的 <strong>values</strong> 的水位</li><li><code>num_decoded_values_</code>: decode 成功吐出去的 <strong>values</strong> 的水位</li></ol><p>你会发现我这里的用词是 Levels 而不是 Values…我们看看之前博客里的 <code>num_values</code> 的逻辑( <a href="https://blog.mwish.me/2022/09/18/Parquet-Part1-Basic/">https://blog.mwish.me/2022/09/18/Parquet-Part1-Basic/</a> )：</p><blockquote><p>DataPageV2 会有 <code>num_rows</code>，表示对应行的数量。<strong>在有嵌套的情况下，这个不等于 <code>num_values</code></strong>.</p><p>这里代表的是「包括 nulls，这个 <code>ColumnChunk</code> 对应值的数量」而非「这个 <code>ColumnChunk</code> 对应行的数量」。这个地方我说的可能有一点难理解，比如对于 <code>optional i32</code> 的平坦数据，这里等价于行数，而对于 <code>repeated &lt;optional i32&gt;</code>，这里代表内层的数量。<code>PageHeader</code> 的 <code>num_values</code> 也同理。</p></blockquote><p>这里会根据 page 来设置对应的值，同时跟 <code>HasNextInternal()</code> 这个接口联合使用，来不停 fetch page。（values, rows/record, levels 这些概念比较混乱，注意区分）。</p><p>这个地方解析了对应的东西，然后返回了对应的数值。当然，这里逻辑比较简单。</p><p>这个地方可以总结性质的放一张流程：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">类型组合:</span><br><span class="line">- ColumnReader(ColumnReaderImpl, TypedColumnReader): 包含数据 decoder, rep-level 和 def-level 的 Decoder, page reader</span><br><span class="line">- RecordReader(注册数据的 buffer, rep-level buffer, def-level buffer, page buffer)</span><br></pre></td></tr></table></figure><h4 id="TypedRecordReader-组织成输出行而不是输出-Value"><a href="#TypedRecordReader-组织成输出行而不是输出-Value" class="headerlink" title="TypedRecordReader: 组织成输出行而不是输出 Value"></a>TypedRecordReader: 组织成输出行而不是输出 Value</h4><p><code>TypedRecordReader</code> 提供了一组复杂一点的函数：<code>ReadRecords</code> 和 <code>ReadRecordData</code>，这个就相当于「读上层的几行」了。这个是给 <code>parquet::arrow</code> 准备的结构。</p><p>这套相当于把 Values 的读取交给 <code>ColumnReaderImpl</code> 层，然后在上面封装了 Row 的 Read。它相当于一个特种类型的记录组织器，能表示具体处理的「行」，而 <code>ColumnReader</code> 处理的内容是 “values”.</p><p>这部分相当于</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> internal &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// \brief Stateful column reader that delimits semantic records for both flat</span></span><br><span class="line"><span class="comment">/// and nested columns</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// \note API EXPERIMENTAL</span></span><br><span class="line"><span class="comment">/// \since 1.3.0</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RecordReader</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">static</span> std::shared_ptr&lt;RecordReader&gt; <span class="title">Make</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> ColumnDescriptor* descr, LevelInfo leaf_info,</span></span></span><br><span class="line"><span class="params"><span class="function">      ::arrow::MemoryPool* pool = ::arrow::default_memory_pool(),</span></span></span><br><span class="line"><span class="params"><span class="function">      <span class="type">const</span> <span class="type">bool</span> read_dictionary = <span class="literal">false</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">RecordReader</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Attempt to read indicated number of records from column chunk</span></span><br><span class="line">  <span class="comment">/// \return number of records read</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">int64_t</span> <span class="title">ReadRecords</span><span class="params">(<span class="type">int64_t</span> num_records)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Pre-allocate space for data. Results in better flat read performance</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Reserve</span><span class="params">(<span class="type">int64_t</span> num_values)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Clear consumed values and repetition/definition levels as the</span></span><br><span class="line">  <span class="comment">/// result of calling ReadRecords</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Reset</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Transfer filled values buffer to caller. A new one will be</span></span><br><span class="line">  <span class="comment">/// allocated in subsequent ReadRecords calls</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> std::shared_ptr&lt;ResizableBuffer&gt; <span class="title">ReleaseValues</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Transfer filled validity bitmap buffer to caller. A new one will</span></span><br><span class="line">  <span class="comment">/// be allocated in subsequent ReadRecords calls</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> std::shared_ptr&lt;ResizableBuffer&gt; <span class="title">ReleaseIsValid</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Return true if the record reader has more internal data yet to</span></span><br><span class="line">  <span class="comment">/// process</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">HasMoreData</span><span class="params">()</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Advance record reader to the next row group</span></span><br><span class="line">  <span class="comment">/// \param[in] reader obtained from RowGroupReader::GetColumnPageReader</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">SetPageReader</span><span class="params">(std::unique_ptr&lt;PageReader&gt; reader)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">DebugPrintState</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Decoded definition levels</span></span><br><span class="line">  <span class="function"><span class="type">int16_t</span>* <span class="title">def_levels</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">reinterpret_cast</span>&lt;<span class="type">int16_t</span>*&gt;(def_levels_-&gt;<span class="built_in">mutable_data</span>());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Decoded repetition levels</span></span><br><span class="line">  <span class="function"><span class="type">int16_t</span>* <span class="title">rep_levels</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">reinterpret_cast</span>&lt;<span class="type">int16_t</span>*&gt;(rep_levels_-&gt;<span class="built_in">mutable_data</span>());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Decoded values, including nulls, if any</span></span><br><span class="line">  <span class="function"><span class="type">uint8_t</span>* <span class="title">values</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> values_-&gt;<span class="built_in">mutable_data</span>(); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Number of values written including nulls (if any)</span></span><br><span class="line">  <span class="function"><span class="type">int64_t</span> <span class="title">values_written</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> values_written_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Number of definition / repetition levels (from those that have</span></span><br><span class="line">  <span class="comment">/// been decoded) that have been consumed inside the reader.</span></span><br><span class="line">  <span class="function"><span class="type">int64_t</span> <span class="title">levels_position</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> levels_position_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Number of definition / repetition levels that have been written</span></span><br><span class="line">  <span class="comment">/// internally in the reader</span></span><br><span class="line">  <span class="function"><span class="type">int64_t</span> <span class="title">levels_written</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> levels_written_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Number of nulls in the leaf</span></span><br><span class="line">  <span class="function"><span class="type">int64_t</span> <span class="title">null_count</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> null_count_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief True if the leaf values are nullable</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">nullable_values</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> nullable_values_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief True if reading directly as Arrow dictionary-encoded</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">read_dictionary</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> read_dictionary_; &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">protected</span>:</span><br><span class="line">  <span class="type">bool</span> nullable_values_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 内部状态, 表示现在的记录是否是在某行的行首, 用来推进 records_read</span></span><br><span class="line">  <span class="type">bool</span> at_record_start_;</span><br><span class="line">  <span class="comment">// 读的行数的计数</span></span><br><span class="line">  <span class="type">int64_t</span> records_read_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// values 状态的记录器.</span></span><br><span class="line">  <span class="comment">// 这部分也需要处理</span></span><br><span class="line">  <span class="type">int64_t</span> values_written_;</span><br><span class="line">  <span class="type">int64_t</span> values_capacity_;</span><br><span class="line">  <span class="type">int64_t</span> null_count_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 下面这里提供了一个 buffer</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 解析出的 levels</span></span><br><span class="line">  <span class="type">int64_t</span> levels_written_;</span><br><span class="line">  <span class="comment">// 行 Parsing 完的 records</span></span><br><span class="line">  <span class="type">int64_t</span> levels_position_;</span><br><span class="line">  <span class="type">int64_t</span> levels_capacity_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 变长记录的 value buffer</span></span><br><span class="line">  std::shared_ptr&lt;::arrow::ResizableBuffer&gt; values_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// In the case of false, don&#x27;t allocate the values buffer (when we directly read into</span></span><br><span class="line">  <span class="comment">// builder classes).</span></span><br><span class="line">  <span class="type">bool</span> uses_values_;</span><br><span class="line"></span><br><span class="line">  std::shared_ptr&lt;::arrow::ResizableBuffer&gt; valid_bits_;</span><br><span class="line">  std::shared_ptr&lt;::arrow::ResizableBuffer&gt; def_levels_;</span><br><span class="line">  std::shared_ptr&lt;::arrow::ResizableBuffer&gt; rep_levels_;</span><br><span class="line"></span><br><span class="line">  <span class="type">bool</span> read_dictionary_ = <span class="literal">false</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>可以看到，这里存放了各种内容，能切换 Page 然后解析道本地的 <code>values_</code> 上，是一个有状态的读者。</p><p><code>TypedRecordReader::ReadRecord</code> 读出具体的数据，这个地方会根据两个 level 选择从底层读多少行。最重要的函数在 <code>ReadRecordData</code>，这个会把对应的逻辑编组成 array，然后设置 null。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Return number of logical records read</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 读到 level 之后, 来读具体数据惹</span></span><br><span class="line"><span class="function"><span class="type">int64_t</span> <span class="title">ReadRecordData</span><span class="params">(<span class="type">int64_t</span> num_records)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Conservative upper bound</span></span><br><span class="line">  <span class="type">const</span> <span class="type">int64_t</span> possible_num_values =</span><br><span class="line">      std::<span class="built_in">max</span>(num_records, levels_written_ - levels_position_);</span><br><span class="line">  <span class="built_in">ReserveValues</span>(possible_num_values);</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">int64_t</span> start_levels_position = levels_position_;</span><br><span class="line"></span><br><span class="line">  <span class="type">int64_t</span> values_to_read = <span class="number">0</span>;</span><br><span class="line">  <span class="type">int64_t</span> records_read = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;max_rep_level_ &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// 有重复或者空的，走 delimit</span></span><br><span class="line">    records_read = <span class="built_in">DelimitRecords</span>(num_records, &amp;values_to_read);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;max_def_level_ &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// 没有重复，只有可空。那么 written - position 就是数目.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// No repetition levels, skip delimiting logic. Each level represents a</span></span><br><span class="line">    <span class="comment">// null or not null entry</span></span><br><span class="line">    records_read = std::<span class="built_in">min</span>(levels_written_ - levels_position_, num_records);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// This is advanced by DelimitRecords, which we skipped</span></span><br><span class="line">    levels_position_ += records_read;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    records_read = values_to_read = num_records;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 具体读值的逻辑</span></span><br><span class="line">  <span class="type">int64_t</span> null_count = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> (leaf_info_.<span class="built_in">HasNullableValues</span>()) &#123;</span><br><span class="line">    ValidityBitmapInputOutput validity_io;</span><br><span class="line">    validity_io.values_read_upper_bound = levels_position_ - start_levels_position;</span><br><span class="line">    validity_io.valid_bits = valid_bits_-&gt;<span class="built_in">mutable_data</span>();</span><br><span class="line">    validity_io.valid_bits_offset = values_written_;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// def level 拆分</span></span><br><span class="line">    <span class="built_in">DefLevelsToBitmap</span>(<span class="built_in">def_levels</span>() + start_levels_position,</span><br><span class="line">                      <span class="comment">/* level 的数量 */</span> levels_position_ - start_levels_position, leaf_info_,</span><br><span class="line">                      &amp;validity_io);</span><br><span class="line">    values_to_read = validity_io.values_read - validity_io.null_count;</span><br><span class="line">    null_count = validity_io.null_count;</span><br><span class="line">    <span class="built_in">DCHECK_GE</span>(values_to_read, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">ReadValuesSpaced</span>(validity_io.values_read, null_count);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">DCHECK_GE</span>(values_to_read, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">ReadValuesDense</span>(values_to_read);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;leaf_info_.def_level &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// Optional, repeated, or some mix thereof</span></span><br><span class="line">    <span class="keyword">this</span>-&gt;<span class="built_in">ConsumeBufferedValues</span>(levels_position_ - start_levels_position);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// Flat, non-repeated</span></span><br><span class="line">    <span class="keyword">this</span>-&gt;<span class="built_in">ConsumeBufferedValues</span>(values_to_read);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Total values, including null spaces, if any</span></span><br><span class="line">  values_written_ += values_to_read + null_count;</span><br><span class="line">  null_count_ += null_count;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> records_read;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里还是比较复杂的，本身是个多继承，<code>TypedRecordReader</code> 继承了 <code>ColumnReaderImpl</code> 和 <code>RecordReader</code>，这两个都是有状态的，状态又贼多，我觉得设计的让我看了头痛。但上面这段代码其实挺好懂的：</p><p>计算 <code>records_read</code> (读的行) 和 <code>values_to_read</code> 需要读的 <code>rep-level</code> 和 <code>def-level</code> 与值</p><ol><li>当 <code>max_def_level_</code> 和 <code>max_rep_level_</code> 都等于 0 的时候，schema 是平坦的，且没有值为 null，所以读的 行和记录数量都是固定的，也没有 rep-level 和 def-level</li><li>当 <code>max_def_level_ != 0</code> ，<code>max_rep_level_ == 0</code> 的时候，schema 是平坦的，但是有的值可能为 null，<strong>这里读取 num-record 条 def level 就行了</strong>, 可以解析这些行解析出 null，但不用处理重复的 rep/def.</li><li>否则，走 <code>DelimitRecords</code>，去解析行的数量. 这段应该是整个 Parquet 读流程最 hack 的一部分代码了</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// Process written repetition/definition levels to reach the end of</span></span><br><span class="line"><span class="comment">// records. Process no more levels than necessary to delimit the indicated</span></span><br><span class="line"><span class="comment">// number of logical records. Updates internal state of RecordReader</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 这个函数只会发生在 rep-level 和 def-level 都在的情况下. 这里会根据内部状态 `at_record_start_` </span></span><br><span class="line"><span class="comment">//  判断是否在一个行的开头. 目标是不越过 `levels_written_` 的情况下读 `num_records` 行.</span></span><br><span class="line"><span class="comment">// 返回读的行数和 values</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// \return Number of records delimited</span></span><br><span class="line"><span class="function"><span class="type">int64_t</span> <span class="title">DelimitRecords</span><span class="params">(<span class="type">int64_t</span> num_records, <span class="type">int64_t</span>* values_seen)</span> </span>&#123;</span><br><span class="line">  <span class="type">int64_t</span> values_to_read = <span class="number">0</span>;</span><br><span class="line">  <span class="type">int64_t</span> records_read = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="type">const</span> <span class="type">int16_t</span>* def_levels = <span class="keyword">this</span>-&gt;<span class="built_in">def_levels</span>() + levels_position_;</span><br><span class="line">  <span class="type">const</span> <span class="type">int16_t</span>* rep_levels = <span class="keyword">this</span>-&gt;<span class="built_in">rep_levels</span>() + levels_position_;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">DCHECK_GT</span>(<span class="keyword">this</span>-&gt;max_rep_level_, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Count logical records and number of values to read</span></span><br><span class="line">  <span class="comment">// 读 level_position 来判断内容</span></span><br><span class="line">  <span class="comment">// 这里的逻辑会先读 rep_level, 来查一下行的变更, rep_level == 0 一定切了行, 读完了就会返回.</span></span><br><span class="line">  <span class="comment">// 然后会检查 `def_level`, 看这个是否是 null. 不是 null 就会添加 `values_to_read`.</span></span><br><span class="line">  <span class="comment">// **非 0 的 rep-level 不会被这一层处理**</span></span><br><span class="line">  <span class="keyword">while</span> (levels_position_ &lt; levels_written_) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int16_t</span> rep_level = *rep_levels++;</span><br><span class="line">    <span class="comment">// rep_level == 0 的时候, 一定是整行的开头.</span></span><br><span class="line">    <span class="keyword">if</span> (rep_level == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// If at_record_start_ is true, we are seeing the start of a record</span></span><br><span class="line">      <span class="comment">// for the second time, such as after repeated calls to</span></span><br><span class="line">      <span class="comment">// DelimitRecords. In this case we must continue until we find</span></span><br><span class="line">      <span class="comment">// another record start or exhausting the ColumnChunk</span></span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      <span class="comment">// 上一次走完了这行, 就会 `!at_record_start_`.</span></span><br><span class="line">      <span class="keyword">if</span> (!at_record_start_) &#123;</span><br><span class="line">        <span class="comment">// We&#x27;ve reached the end of a record; increment the record count.</span></span><br><span class="line">        ++records_read;</span><br><span class="line">        <span class="keyword">if</span> (records_read == num_records) &#123;</span><br><span class="line">          <span class="comment">// We&#x27;ve found the number of records we were looking for. Set</span></span><br><span class="line">          <span class="comment">// at_record_start_ to true and break</span></span><br><span class="line">          at_record_start_ = <span class="literal">true</span>;</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// We have decided to consume the level at this position; therefore we</span></span><br><span class="line">    <span class="comment">// must advance until we find another record boundary</span></span><br><span class="line">    at_record_start_ = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int16_t</span> def_level = *def_levels++;</span><br><span class="line">    <span class="keyword">if</span> (def_level == <span class="keyword">this</span>-&gt;max_def_level_) &#123;</span><br><span class="line">      ++values_to_read;</span><br><span class="line">    &#125;</span><br><span class="line">    ++levels_position_;</span><br><span class="line">  &#125;</span><br><span class="line">  *values_seen = values_to_read;</span><br><span class="line">  <span class="keyword">return</span> records_read;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>读完之后，这里会具体把值读到 buffer 中。如果叶子结点非 <code>null</code>，那就直接 <code>ReadValuesDense</code> 了，符合逻辑，否则的话，这里会：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 具体读值的逻辑</span></span><br><span class="line"><span class="type">int64_t</span> null_count = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">if</span> (leaf_info_.<span class="built_in">HasNullableValues</span>()) &#123;</span><br><span class="line">  ValidityBitmapInputOutput validity_io;</span><br><span class="line">  validity_io.values_read_upper_bound = levels_position_ - start_levels_position;</span><br><span class="line">  validity_io.valid_bits = valid_bits_-&gt;<span class="built_in">mutable_data</span>(); <span class="comment">// 指向 `valid_bits_` 内部数组.</span></span><br><span class="line">  validity_io.valid_bits_offset = values_written_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// def level 拆分</span></span><br><span class="line">  <span class="built_in">DefLevelsToBitmap</span>(<span class="built_in">def_levels</span>() + start_levels_position,</span><br><span class="line">                    <span class="comment">/* level 的数量 */</span> levels_position_ - start_levels_position, leaf_info_,</span><br><span class="line">                    &amp;validity_io);</span><br><span class="line">  values_to_read = validity_io.values_read - validity_io.null_count;</span><br><span class="line">  null_count = validity_io.null_count;</span><br><span class="line">  <span class="built_in">DCHECK_GE</span>(values_to_read, <span class="number">0</span>);</span><br><span class="line">  <span class="built_in">ReadValuesSpaced</span>(validity_io.values_read, null_count);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的逻辑感觉写的…有点怪，它会根据 <code>values_read_upper_bound</code> 和 <code>valid_bits_offset</code> 来填充 <code>valid_bits</code> 和 <code>null_count</code> 和 <code>values_read</code>，这里应该相当于一个内部检查，毕竟 <code>values_read</code> 前面只有 <code>rep_level == 0, def_level != 0</code> 的时候没算过😅。这里会给出 Level，把对应的 count 用 simd 解析完，然后算到 <code>validity_io</code> 里面，然后用 <code>ReadValuesSpaced</code> 读取对应的数据。这一块状态传递非常乱，建议不改这块代码意会一下就好了。这块作者主要是 Micah Cornfield 和 Wesm，代码性能确实不错，但是写的好暴力啊。</p><p>总之，这里会拿到行数、<code>null_count</code> 和 <code>null-bitmap</code>，然后完成读取。</p><p>这里还有个比较 hack 的地方，就是 <code>levels_position_</code> 的处理，这段代码比较 hacking，它会：</p><ol><li>在底层的时候，就知道有多少行数据，record reader 解析出一个 record 数目</li><li>上层根据 Def-Rep 解析出 List / Map 的 size 和 nullable，恢复出上层的数据</li></ol><p>所以，解析的时候，有2个 levels:</p><ol><li>levels position: 目前读的行的 levels</li><li>levels written: 从 page 中捞出来的 levels</li></ol><h3 id="parquet-arrow-从-arrow-恢复-Array-数据"><a href="#parquet-arrow-从-arrow-恢复-Array-数据" class="headerlink" title="parquet/arrow: 从 arrow 恢复 Array 数据"></a>parquet/arrow: 从 arrow 恢复 Array 数据</h3><p>上面我们拿到了 api 和从 Column 中读数据的逻辑，下面这里需要从 Parquet 拿到的连续数据中恢复 arrow 的数据。对应的实现在 <code>parquet/arrow/reader</code> 中。再次提醒一下，这里 <code>namespace</code> 是 <code>parquet::arrow</code>，负责 <code>arrow</code> 一些复杂格式和 parquet 互转。</p><h4 id="ColumnReader"><a href="#ColumnReader" class="headerlink" title="ColumnReader"></a>ColumnReader</h4><p>头文件中，有一个 <code>ColumnReader</code>，作为读取接口</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// At this point, the column reader is a stream iterator. It only knows how to</span></span><br><span class="line"><span class="comment">// read the next batch of values for a particular column from the file until it</span></span><br><span class="line"><span class="comment">// runs out.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// We also do not expose any internal Parquet details, such as row groups. This</span></span><br><span class="line"><span class="comment">// might change in the future.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PARQUET_EXPORT</span> ColumnReader &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">ColumnReader</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Scan the next array of the indicated size. The actual size of the</span></span><br><span class="line">  <span class="comment">// returned array may be less than the passed size depending how much data is</span></span><br><span class="line">  <span class="comment">// available in the file.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// When all the data in the file has been exhausted, the result is set to</span></span><br><span class="line">  <span class="comment">// nullptr.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Returns Status::OK on a successful read, including if you have exhausted</span></span><br><span class="line">  <span class="comment">// the data available in the file.</span></span><br><span class="line">  <span class="keyword">virtual</span> ::<span class="function">arrow::Status <span class="title">NextBatch</span><span class="params">(<span class="type">int64_t</span> batch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">                                    std::shared_ptr&lt;::arrow::ChunkedArray&gt;* out)</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ColumnReaderImpl</span> : <span class="keyword">public</span> ColumnReader &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">GetDefLevels</span><span class="params">(<span class="type">const</span> <span class="type">int16_t</span>** data, <span class="type">int64_t</span>* length)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">GetRepLevels</span><span class="params">(<span class="type">const</span> <span class="type">int16_t</span>** data, <span class="type">int64_t</span>* length)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">const</span> std::shared_ptr&lt;Field&gt; <span class="title">field</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  ::<span class="function">arrow::Status <span class="title">NextBatch</span><span class="params">(<span class="type">int64_t</span> batch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">                            std::shared_ptr&lt;::arrow::ChunkedArray&gt;* out)</span> <span class="keyword">final</span> </span>&#123;</span><br><span class="line">    <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">LoadBatch</span>(batch_size));</span><br><span class="line">    <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">BuildArray</span>(batch_size, out));</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> x = <span class="number">0</span>; x &lt; (*out)-&gt;<span class="built_in">num_chunks</span>(); x++) &#123;</span><br><span class="line">      <span class="built_in">RETURN_NOT_OK</span>((*out)-&gt;<span class="built_in">chunk</span>(x)-&gt;<span class="built_in">Validate</span>());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ::<span class="function">arrow::Status <span class="title">LoadBatch</span><span class="params">(<span class="type">int64_t</span> num_records)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ::<span class="function">arrow::Status <span class="title">BuildArray</span><span class="params">(<span class="type">int64_t</span> length_upper_bound,</span></span></span><br><span class="line"><span class="params"><span class="function">                                     std::shared_ptr&lt;::arrow::ChunkedArray&gt;* out)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">IsOrHasRepeatedChild</span><span class="params">()</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里内容分为两部分:</p><ol><li><p><code>LoadBatch</code>: 利用之前讲的 <code>RecordReader</code> 来把一个 Batch 的行加载到 Values 的 Buffer 中</p></li><li><p><code>BuildArray</code>： 构建内存 array，可能会从子节点构建父节点</p></li></ol><p>这里其实还可能要转型，为什么要转型呢？parquet 基础类型其实没几个，比方说 int8，它也会用更大的 int 去压缩。所以这里要转型到内存的格式中</p><h4 id="LeafReader"><a href="#LeafReader" class="headerlink" title="LeafReader"></a>LeafReader</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Leaf reader is for primitive arrays and primitive children of nested arrays</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeafReader</span> : <span class="keyword">public</span> ColumnReaderImpl &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function">Status <span class="title">GetDefLevels</span><span class="params">(<span class="type">const</span> <span class="type">int16_t</span>** data, <span class="type">int64_t</span>* length)</span> <span class="keyword">final</span> </span>&#123;</span><br><span class="line">    *data = record_reader_-&gt;<span class="built_in">def_levels</span>();</span><br><span class="line">    *length = record_reader_-&gt;<span class="built_in">levels_position</span>();</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">Status <span class="title">GetRepLevels</span><span class="params">(<span class="type">const</span> <span class="type">int16_t</span>** data, <span class="type">int64_t</span>* length)</span> <span class="keyword">final</span> </span>&#123;</span><br><span class="line">    *data = record_reader_-&gt;<span class="built_in">rep_levels</span>();</span><br><span class="line">    *length = record_reader_-&gt;<span class="built_in">levels_position</span>();</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">IsOrHasRepeatedChild</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">final</span> </span>&#123; <span class="keyword">return</span> <span class="literal">false</span>; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">Status <span class="title">LoadBatch</span><span class="params">(<span class="type">int64_t</span> records_to_read)</span> <span class="keyword">final</span></span>;</span><br><span class="line"></span><br><span class="line">  ::<span class="function">arrow::Status <span class="title">BuildArray</span><span class="params">(<span class="type">int64_t</span> length_upper_bound,</span></span></span><br><span class="line"><span class="params"><span class="function">                             std::shared_ptr&lt;::arrow::ChunkedArray&gt;* out)</span> <span class="keyword">final</span> </span>&#123;</span><br><span class="line">    *out = out_;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">  &#125;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  std::shared_ptr&lt;ChunkedArray&gt; out_;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">NextRowGroup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::unique_ptr&lt;PageReader&gt; page_reader = input_-&gt;<span class="built_in">NextChunk</span>();</span><br><span class="line">    record_reader_-&gt;<span class="built_in">SetPageReader</span>(std::<span class="built_in">move</span>(page_reader));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  std::shared_ptr&lt;ReaderContext&gt; ctx_;</span><br><span class="line">  std::shared_ptr&lt;Field&gt; field_;</span><br><span class="line">  std::unique_ptr&lt;FileColumnIterator&gt; input_;</span><br><span class="line">  <span class="type">const</span> ColumnDescriptor* descr_;</span><br><span class="line">  std::shared_ptr&lt;RecordReader&gt; record_reader_;</span><br><span class="line">&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里我把 LoadBatch 实现摘出来了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">LoadBatch</span><span class="params">(<span class="type">int64_t</span> records_to_read)</span> <span class="keyword">final</span> </span>&#123;</span><br><span class="line">  BEGIN_PARQUET_CATCH_EXCEPTIONS</span><br><span class="line">  out_ = <span class="literal">nullptr</span>;</span><br><span class="line">  record_reader_-&gt;<span class="built_in">Reset</span>();</span><br><span class="line">  <span class="comment">// Pre-allocation gives much better performance for flat columns</span></span><br><span class="line">  record_reader_-&gt;<span class="built_in">Reserve</span>(records_to_read);</span><br><span class="line">  <span class="keyword">while</span> (records_to_read &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!record_reader_-&gt;<span class="built_in">HasMoreData</span>()) &#123;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int64_t</span> records_read = record_reader_-&gt;<span class="built_in">ReadRecords</span>(records_to_read);</span><br><span class="line">    records_to_read -= records_read;</span><br><span class="line">    <span class="keyword">if</span> (records_read == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="built_in">NextRowGroup</span>();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">RETURN_NOT_OK</span>(</span><br><span class="line">      <span class="built_in">TransferColumnData</span>(record_reader_.<span class="built_in">get</span>(), field_, descr_, ctx_-&gt;pool, &amp;out_));</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">  END_PARQUET_CATCH_EXCEPTIONS</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>这里会从 <code>record_reader_</code> 里面所要数据，然后切 Page 或者 row_group，直到读完或者满足 batch</li><li>利用 <code>TransferColumnData</code> 做转型，然后 <code>BuildArray</code> 没有任何开销</li></ol><p>它难一点的内部实现都在 <code>RecordReader</code> 了，哎，是真的又恶心又难呢…</p><h4 id="List-Struct"><a href="#List-Struct" class="headerlink" title="List / Struct"></a>List / Struct</h4><p>这个会找到一个靠谱的 child，然后从这里面拉 rep-level 和 def-level，来恢复对应的记录</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PARQUET_NO_EXPORT</span> StructReader : <span class="keyword">public</span> ColumnReaderImpl &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">StructReader</span><span class="params">(std::shared_ptr&lt;ReaderContext&gt; ctx,</span></span></span><br><span class="line"><span class="params"><span class="function">                        std::shared_ptr&lt;Field&gt; filtered_field,</span></span></span><br><span class="line"><span class="params"><span class="function">                        ::parquet::internal::LevelInfo level_info,</span></span></span><br><span class="line"><span class="params"><span class="function">                        std::vector&lt;std::unique_ptr&lt;ColumnReaderImpl&gt;&gt; children)</span></span></span><br><span class="line"><span class="function">      : ctx_(std::move(ctx)),</span></span><br><span class="line"><span class="function">        filtered_field_(std::move(filtered_field)),</span></span><br><span class="line"><span class="function">        level_info_(level_info),</span></span><br><span class="line"><span class="function">        children_(std::move(children)) &#123;</span></span><br><span class="line">    <span class="comment">// 找到靠谱的记录，来设置一个 `def_rep_level_child_`, 即有 level 的 child.</span></span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">Status <span class="title">LoadBatch</span><span class="params">(<span class="type">int64_t</span> records_to_read)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 递归让子节点 build batch</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> std::unique_ptr&lt;ColumnReaderImpl&gt;&amp; reader : children_) &#123;</span><br><span class="line">      <span class="built_in">RETURN_NOT_OK</span>(reader-&gt;<span class="built_in">LoadBatch</span>(records_to_read));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function">Status <span class="title">BuildArray</span><span class="params">(<span class="type">int64_t</span> length_upper_bound,</span></span></span><br><span class="line"><span class="params"><span class="function">                    std::shared_ptr&lt;ChunkedArray&gt;* out)</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">GetDefLevels</span><span class="params">(<span class="type">const</span> <span class="type">int16_t</span>** data, <span class="type">int64_t</span>* length)</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function">Status <span class="title">GetRepLevels</span><span class="params">(<span class="type">const</span> <span class="type">int16_t</span>** data, <span class="type">int64_t</span>* length)</span> <span class="keyword">override</span></span>;</span><br><span class="line">  <span class="function"><span class="type">const</span> std::shared_ptr&lt;Field&gt; <span class="title">field</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> filtered_field_; &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="type">const</span> std::shared_ptr&lt;ReaderContext&gt; ctx_;</span><br><span class="line">  <span class="type">const</span> std::shared_ptr&lt;Field&gt; filtered_field_;</span><br><span class="line">  <span class="type">const</span> ::parquet::internal::LevelInfo level_info_;</span><br><span class="line">  <span class="type">const</span> std::vector&lt;std::unique_ptr&lt;ColumnReaderImpl&gt;&gt; children_;</span><br><span class="line">  ColumnReaderImpl* def_rep_level_child_ = <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="type">bool</span> has_repeated_child_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>那么，我们看 <code>LoadBatch</code> 就 Load 了所有子节点，所以这里重点在 <code>BuildArray</code> 上，这里用到了我们之前看到的 <code>ValidityBitmapInputOutput</code> （我之前吐槽过的，在 <code>RecordReader</code> 那块代码那）。这里搞的到一个叶子结点的 rep-level 和 def-level，然后根据这一个叶子结点的 levels 就能恢复所有的信息，这里有一些解析函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 只考虑 def-level, 用于叶子结点.</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DefLevelsToBitmap</span><span class="params">(<span class="type">const</span> <span class="type">int16_t</span>* def_levels, <span class="type">int64_t</span> num_def_levels,</span></span></span><br><span class="line"><span class="params"><span class="function">                       LevelInfo level_info, ValidityBitmapInputOutput* output)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// It is simpler to rely on rep_level here until PARQUET-1899 is done and the code</span></span><br><span class="line">  <span class="comment">// is deleted in a follow-up release.</span></span><br><span class="line">  <span class="keyword">if</span> (level_info.rep_level &gt; <span class="number">0</span>) &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(ARROW_HAVE_RUNTIME_BMI2)</span></span><br><span class="line">    <span class="keyword">if</span> (CpuInfo::<span class="built_in">GetInstance</span>()-&gt;<span class="built_in">HasEfficientBmi2</span>()) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">DefLevelsToBitmapBmi2WithRepeatedParent</span>(def_levels, num_def_levels,</span><br><span class="line">                                                     level_info, output);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    standard::<span class="built_in">DefLevelsToBitmapSimd</span>&lt;/*has_repeated_parent=*/<span class="literal">true</span>&gt;(</span><br><span class="line">        def_levels, num_def_levels, level_info, output);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    standard::<span class="built_in">DefLevelsToBitmapSimd</span>&lt;<span class="comment">/*has_repeated_parent=*/</span><span class="literal">false</span>&gt;(</span><br><span class="line">        def_levels, num_def_levels, level_info, output);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DefRepLevelsToList</span><span class="params">(<span class="type">const</span> <span class="type">int16_t</span>* def_levels, <span class="type">const</span> <span class="type">int16_t</span>* rep_levels,</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="type">int64_t</span> num_def_levels, LevelInfo level_info,</span></span></span><br><span class="line"><span class="params"><span class="function">                        ValidityBitmapInputOutput* output, <span class="type">int32_t</span>* offsets)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">DefRepLevelsToListInfo</span>&lt;<span class="type">int32_t</span>&gt;(def_levels, rep_levels, num_def_levels, level_info,</span><br><span class="line">                                  output, offsets);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DefRepLevelsToList</span><span class="params">(<span class="type">const</span> <span class="type">int16_t</span>* def_levels, <span class="type">const</span> <span class="type">int16_t</span>* rep_levels,</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="type">int64_t</span> num_def_levels, LevelInfo level_info,</span></span></span><br><span class="line"><span class="params"><span class="function">                        ValidityBitmapInputOutput* output, <span class="type">int64_t</span>* offsets)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">DefRepLevelsToListInfo</span>&lt;<span class="type">int64_t</span>&gt;(def_levels, rep_levels, num_def_levels, level_info,</span><br><span class="line">                                  output, offsets);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 根据 def-rep 来算, 拿到叶子结点的 level 推断父亲的列表.</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DefRepLevelsToBitmap</span><span class="params">(<span class="type">const</span> <span class="type">int16_t</span>* def_levels, <span class="type">const</span> <span class="type">int16_t</span>* rep_levels,</span></span></span><br><span class="line"><span class="params"><span class="function">                          <span class="type">int64_t</span> num_def_levels, LevelInfo level_info,</span></span></span><br><span class="line"><span class="params"><span class="function">                          ValidityBitmapInputOutput* output)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// DefReplevelsToListInfo assumes it for the actual list method and this</span></span><br><span class="line">  <span class="comment">// method is for parent structs, so we need to bump def and ref level.</span></span><br><span class="line">  level_info.rep_level += <span class="number">1</span>;</span><br><span class="line">  level_info.def_level += <span class="number">1</span>;</span><br><span class="line">  <span class="built_in">DefRepLevelsToListInfo</span>&lt;<span class="type">int32_t</span>&gt;(def_levels, rep_levels, num_def_levels, level_info,</span><br><span class="line">                                  output, <span class="comment">/*offsets=*/</span><span class="literal">nullptr</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>offsets</code> 参数是给 <code>List</code> 这样内容准备的。不考虑 offset 情况下，struct 对应逻辑：</p><ol><li>当 <code>rep_levels</code> 比自身大的时候，说明是子节点在重复，skip</li><li>如果 rep-level 等于自身，说明在自己这层重复（对结构体是不可能的，所以不考虑）</li><li>如果 rep-level 小自身，说明父级重复。这里可以根据 def-level 来判断自己是否是 null</li></ol><p>我们简单看看，下面的代码删掉了 <code>offsets</code> 和 Struct 不会 touch 的逻辑：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> OffsetType&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DefRepLevelsToListInfo</span><span class="params">(<span class="type">const</span> <span class="type">int16_t</span>* def_levels, <span class="type">const</span> <span class="type">int16_t</span>* rep_levels,</span></span></span><br><span class="line"><span class="params"><span class="function">                            <span class="type">int64_t</span> num_def_levels, LevelInfo level_info,</span></span></span><br><span class="line"><span class="params"><span class="function">                            ValidityBitmapInputOutput* output, OffsetType* offsets)</span> </span>&#123;</span><br><span class="line">  OffsetType* orig_pos = offsets;</span><br><span class="line">  optional&lt;::arrow::internal::FirstTimeBitmapWriter&gt; valid_bits_writer;</span><br><span class="line">  <span class="keyword">if</span> (output-&gt;valid_bits) &#123;</span><br><span class="line">    valid_bits_writer.<span class="built_in">emplace</span>(output-&gt;valid_bits, output-&gt;valid_bits_offset,</span><br><span class="line">                              output-&gt;values_read_upper_bound);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> x = <span class="number">0</span>; x &lt; num_def_levels; x++) &#123;</span><br><span class="line">    <span class="comment">// Skip items that belong to empty or null ancestor lists and further nested lists.</span></span><br><span class="line">    <span class="keyword">if</span> (def_levels[x] &lt; level_info.repeated_ancestor_def_level ||</span><br><span class="line">        rep_levels[x] &gt; level_info.rep_level) &#123;</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (<span class="built_in">ARROW_PREDICT_FALSE</span>(</span><br><span class="line">              (valid_bits_writer.<span class="built_in">has_value</span>() &amp;&amp;</span><br><span class="line">               valid_bits_writer-&gt;<span class="built_in">position</span>() &gt;= output-&gt;values_read_upper_bound) ||</span><br><span class="line">              (offsets - orig_pos) &gt;= output-&gt;values_read_upper_bound)) &#123;</span><br><span class="line">        std::stringstream ss;</span><br><span class="line">        ss &lt;&lt; <span class="string">&quot;Definition levels exceeded upper bound: &quot;</span></span><br><span class="line">           &lt;&lt; output-&gt;values_read_upper_bound;</span><br><span class="line">        <span class="keyword">throw</span> <span class="built_in">ParquetException</span>(ss.<span class="built_in">str</span>());</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (valid_bits_writer.<span class="built_in">has_value</span>()) &#123;</span><br><span class="line">        <span class="comment">// the level_info def level for lists reflects element present level.</span></span><br><span class="line">        <span class="comment">// the prior level distinguishes between empty lists.</span></span><br><span class="line">        <span class="keyword">if</span> (def_levels[x] &gt;= level_info.def_level - <span class="number">1</span>) &#123;</span><br><span class="line">          valid_bits_writer-&gt;<span class="built_in">Set</span>();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          output-&gt;null_count++;</span><br><span class="line">          valid_bits_writer-&gt;<span class="built_in">Clear</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        valid_bits_writer-&gt;<span class="built_in">Next</span>();</span><br><span class="line">      &#125;</span><br><span class="line">    </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (valid_bits_writer.<span class="built_in">has_value</span>()) &#123;</span><br><span class="line">    valid_bits_writer-&gt;<span class="built_in">Finish</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (offsets != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    output-&gt;values_read = offsets - orig_pos;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (valid_bits_writer.<span class="built_in">has_value</span>()) &#123;</span><br><span class="line">    output-&gt;values_read = valid_bits_writer-&gt;<span class="built_in">position</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (output-&gt;null_count &gt; <span class="number">0</span> &amp;&amp; level_info.null_slot_usage &gt; <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="built_in">ParquetException</span>(</span><br><span class="line">        <span class="string">&quot;Null values with null_slot_usage &gt; 1 not supported.&quot;</span></span><br><span class="line">        <span class="string">&quot;(i.e. FixedSizeLists with null values are not supported)&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那对于 <code>List</code> 来说，我们会需要 <code>offsets</code>，来确定它没每段偏移量是多少。而且 <code>rep-level</code> 可能等于自身，我们再来看看这个函数的完整版（一个函数贴两遍，你水字数是真的牛逼）：</p><p>这里注意：</p><ol><li>当 <code>rep_levels</code> 比自身大的时候，说明是子节点在重复，skip</li><li>如果 rep-level 等于自身，说明在自己这层重复，给 list 添加一个元素，<code>*offset += 1</code></li><li>如果 rep-level 小自身，说明父级重复。这里向前移动 offsets，可以根据 def-level 来判断自己是否是 null。如果自己不是 null，说明有个新成员，得添加下 offsets</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> OffsetType&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DefRepLevelsToListInfo</span><span class="params">(<span class="type">const</span> <span class="type">int16_t</span>* def_levels, <span class="type">const</span> <span class="type">int16_t</span>* rep_levels,</span></span></span><br><span class="line"><span class="params"><span class="function">                            <span class="type">int64_t</span> num_def_levels, LevelInfo level_info,</span></span></span><br><span class="line"><span class="params"><span class="function">                            ValidityBitmapInputOutput* output, OffsetType* offsets)</span> </span>&#123;</span><br><span class="line">  OffsetType* orig_pos = offsets;</span><br><span class="line">  optional&lt;::arrow::internal::FirstTimeBitmapWriter&gt; valid_bits_writer;</span><br><span class="line">  <span class="keyword">if</span> (output-&gt;valid_bits) &#123;</span><br><span class="line">    valid_bits_writer.<span class="built_in">emplace</span>(output-&gt;valid_bits, output-&gt;valid_bits_offset,</span><br><span class="line">                              output-&gt;values_read_upper_bound);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> x = <span class="number">0</span>; x &lt; num_def_levels; x++) &#123;</span><br><span class="line">    <span class="comment">// Skip items that belong to empty or null ancestor lists and further nested lists.</span></span><br><span class="line">    <span class="keyword">if</span> (def_levels[x] &lt; level_info.repeated_ancestor_def_level ||</span><br><span class="line">        rep_levels[x] &gt; level_info.rep_level) &#123;</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (rep_levels[x] == level_info.rep_level) &#123;</span><br><span class="line">      <span class="comment">// A continuation of an existing list.</span></span><br><span class="line">      <span class="comment">// offsets can be null for structs with repeated children (we don&#x27;t need to know</span></span><br><span class="line">      <span class="comment">// offsets until we get to the children).</span></span><br><span class="line">      <span class="keyword">if</span> (offsets != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">ARROW_PREDICT_FALSE</span>(*offsets == std::numeric_limits&lt;OffsetType&gt;::<span class="built_in">max</span>())) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="built_in">ParquetException</span>(<span class="string">&quot;List index overflow.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        *offsets += <span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="built_in">ARROW_PREDICT_FALSE</span>(</span><br><span class="line">              (valid_bits_writer.<span class="built_in">has_value</span>() &amp;&amp;</span><br><span class="line">               valid_bits_writer-&gt;<span class="built_in">position</span>() &gt;= output-&gt;values_read_upper_bound) ||</span><br><span class="line">              (offsets - orig_pos) &gt;= output-&gt;values_read_upper_bound)) &#123;</span><br><span class="line">        std::stringstream ss;</span><br><span class="line">        ss &lt;&lt; <span class="string">&quot;Definition levels exceeded upper bound: &quot;</span></span><br><span class="line">           &lt;&lt; output-&gt;values_read_upper_bound;</span><br><span class="line">        <span class="keyword">throw</span> <span class="built_in">ParquetException</span>(ss.<span class="built_in">str</span>());</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// current_rep &lt; list rep_level i.e. start of a list (ancestor empty lists are</span></span><br><span class="line">      <span class="comment">// filtered out above).</span></span><br><span class="line">      <span class="comment">// offsets can be null for structs with repeated children (we don&#x27;t need to know</span></span><br><span class="line">      <span class="comment">// offsets until we get to the children).</span></span><br><span class="line">      <span class="keyword">if</span> (offsets != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        ++offsets;</span><br><span class="line">        <span class="comment">// Use cumulative offsets because variable size lists are more common then</span></span><br><span class="line">        <span class="comment">// fixed size lists so it should be cheaper to make these cumulative and</span></span><br><span class="line">        <span class="comment">// subtract when validating fixed size lists.</span></span><br><span class="line">        *offsets = *(offsets - <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span> (def_levels[x] &gt;= level_info.def_level) &#123;</span><br><span class="line">          <span class="keyword">if</span> (<span class="built_in">ARROW_PREDICT_FALSE</span>(*offsets == std::numeric_limits&lt;OffsetType&gt;::<span class="built_in">max</span>())) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="built_in">ParquetException</span>(<span class="string">&quot;List index overflow.&quot;</span>);</span><br><span class="line">          &#125;</span><br><span class="line">          *offsets += <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (valid_bits_writer.<span class="built_in">has_value</span>()) &#123;</span><br><span class="line">        <span class="comment">// the level_info def level for lists reflects element present level.</span></span><br><span class="line">        <span class="comment">// the prior level distinguishes between empty lists.</span></span><br><span class="line">        <span class="keyword">if</span> (def_levels[x] &gt;= level_info.def_level - <span class="number">1</span>) &#123;</span><br><span class="line">          valid_bits_writer-&gt;<span class="built_in">Set</span>();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          output-&gt;null_count++;</span><br><span class="line">          valid_bits_writer-&gt;<span class="built_in">Clear</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        valid_bits_writer-&gt;<span class="built_in">Next</span>();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (valid_bits_writer.<span class="built_in">has_value</span>()) &#123;</span><br><span class="line">    valid_bits_writer-&gt;<span class="built_in">Finish</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (offsets != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    output-&gt;values_read = offsets - orig_pos;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (valid_bits_writer.<span class="built_in">has_value</span>()) &#123;</span><br><span class="line">    output-&gt;values_read = valid_bits_writer-&gt;<span class="built_in">position</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (output-&gt;null_count &gt; <span class="number">0</span> &amp;&amp; level_info.null_slot_usage &gt; <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="built_in">ParquetException</span>(</span><br><span class="line">        <span class="string">&quot;Null values with null_slot_usage &gt; 1 not supported.&quot;</span></span><br><span class="line">        <span class="string">&quot;(i.e. FixedSizeLists with null values are not supported)&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇文章继续讲了 parquet 的 C++ 标准库怎么读取内容的。简单介绍了一下 文件 — Column 的读取流。<code>Column</code> 下面的编码这篇文章并没有涵盖。如果看不懂的话…感觉也很正常，因为感觉这块代码本身写的质量就…一般般（主要是感觉抽象程度太低了，而且抽的很令人困惑）？不过能把这套东西做出来还是蛮牛逼的，老实说我看着就头疼。这文章看懂能明白大概流程我觉得就很不错了，我也是半当笔记自己写的。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Parquet Part2: arrow Parquet and levels</title>
      <link href="/2022/10/04/Parquet-Part2-arrow-Parquet-code-path/"/>
      <url>/2022/10/04/Parquet-Part2-arrow-Parquet-code-path/</url>
      
        <content type="html"><![CDATA[<p>arrow 代码库包含了 Parquet 的 C++ 官方实现，尽管 impala 之类的第三方实现处理的功能要多一些，但是 back to basics，看看 parquet 这个也不是一件坏事。</p><p>需要声明的是，如 Velox 所说，使用 Parquet 来访问 IO 本身也需要一些复杂的项目。这些部分可能包括：</p><ol><li>谓词下推</li><li>IO 访问</li><li>Lazy Decoding</li><li>全局字典</li></ol><p>具体可以参考 abadi 的论文，其实没什么难的，工程上基本上也没啥花头，嗯写就是了。这些可能之后介绍的时候会讲，先就跳过吧。我们直接进入正题：Parquet 的 arrow 官方实现。</p><p>这一版本实现有一些须知：</p><ol><li>数据来源是 arrow (通常是 <code>arrow::Array</code>)，schema 也来自 arrow。</li><li>parquet 官方的 thrift 在：<a href="https://github.com/apache/parquet-format/blob/master/src/main/thrift/parquet.thrift">https://github.com/apache/parquet-format/blob/master/src/main/thrift/parquet.thrift</a> 。arrow 包装了一层访问层，位于 <code>src/parquet/metadata.h</code>。内部实现放在 <code>parquet/thrift_internal.h</code></li><li>对文件的访问包含在了 <code>src/parquet/platform.h</code>，其中，<code>::arrow::io::InputStream</code> 是对输入流的抽象、<code>::arrow::io::RandomAccessFile</code> 是对输入文件的抽象。关于这些，相关的内容实现在 <code>arrow/io</code> 下，部分实现者比如 mmap 文件、hdfs 文件。而 arrow 还有一套文件系统的抽象，比如 <code>arrow/filesystem</code>，实现了 <code>s3</code> 和 <code>local</code> 的文件系统抽象（不知道为啥 <code>HadoopFileSystem</code> 在目前版本没有放到 filesystem 下）。</li><li>输出被包装在 <code>::arrow::io::BufferOutputStream</code> 中，这个也支持 mmap, s3, hdfs 等</li><li>加密、默认值、配置值相关的配置在 <code>properties.h</code> 里面</li></ol><p>上面都是配置的逻辑。arrow 的代码实现大量采用了 pimpl 的逻辑，有一堆:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">XXX</span> &#123;</span><br><span class="line"> <span class="keyword">class</span> <span class="title class_">Contents</span> &#123;...&#125;;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line"> std::unique_ptr&lt;Contents&gt; contents_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>上面这样的 sb 逻辑</p><h2 id="Arrow-cheatsheet"><a href="#Arrow-cheatsheet" class="headerlink" title="Arrow cheatsheet"></a>Arrow cheatsheet</h2><p>虽然我们主题不是介绍 Arrow，不过可以简单介绍一下 arrow 的类型系统，提供一些简单的 cheatsheet。具体对 arrow 介绍估计也不多。</p><h3 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h3><p>Array 是其中最基本的类型，大概是「列式数组」的概念，支持 null、嵌套、变长、数组格式等。另外，可以从代码层面注意一下，这里的字符串 Buffer 可能并不需要 owned，但是需要是连续的，几个部分需要在同一个 buffer 里，之间没有 padding。数据因为需要 $O(1)$ 找到位置，所以是 null 的地方会是一个 undefined 的值，但是要占着内存。</p><p>下面的内容有两个来源：</p><ol><li>官方的 format，很快可以读完，大概30分钟：<a href="https://arrow.apache.org/docs/format/Columnar.html#fixed-size-list-layout">https://arrow.apache.org/docs/format/Columnar.html#fixed-size-list-layout</a> </li><li>In-Memory Analytics with Apache Arrow 第一章，这里的图片非常好。</li></ol><p><img src="https://image.mwish.me/blog-image/D113AFDFF7CD13071A3A407B9CED5CC3.png" alt="D113AFDFF7CD13071A3A407B9CED5CC3"></p><p>Build Blocks:</p><ol><li>Array lengths: 标准建议使用 64 bytes 的 i64，但是 32 bytes (i32) 也符合标准。文章提到如果元素特别多，建议拆分成多个 i32 可以表示的数组</li><li>Buffer<ol><li>官方建议按照 64 bytes 来对齐 Buffer，这方便使用 SIMD 和开启一些 SIMD 上的优化。目前 AVX512 寄存器宽度是 512 bits。</li></ol></li><li>null count / Validity bitmaps: null count  表示元素是 null 的个数，是 0 的时候可以不需要 validity bitmaps。如果非 0，可能有一个 64 bytes padding 的 bitmap。bitmap 按照 LSB 定义，大于 64B 的内容</li></ol><p>具体例子可以看看下图：</p><p><img src="https://image.mwish.me/blog-image/83EE405A-49D0-4A4A-89E7-9BB222B2505E.png" alt="83EE405A-49D0-4A4A-89E7-9BB222B2505E"></p><p><img src="https://image.mwish.me/blog-image/3139E767-4789-4593-B147-B2618FE224F7.png" alt="3139E767-4789-4593-B147-B2618FE224F7"></p><p>需要特别注意的是一些有「嵌套」性质的结构，举例子：<code>List&lt;T&gt;</code>, <code>List&lt;List&lt;T&gt;&gt;</code>，<code>Struct</code>：</p><p>嵌套逻辑中，我们需要小小的关注一下「父级是 null」是怎么处理的，在 Array 中，这个靠父级别 null 来解决。在 struct 中，这个靠父级别 null — 子级别 null 来区分。可以看到，这个比 dremel 那种还是简单了很多的。</p><p><img src="https://image.mwish.me/blog-image/C865616E-E6CF-47FD-8440-A0F5E5EF8F47.png" alt="C865616E-E6CF-47FD-8440-A0F5E5EF8F47"></p><p><img src="https://image.mwish.me/blog-image/0A39F9FA-54F7-4E5A-8FBC-FAD7AB5FE42B.png" alt="0A39F9FA-54F7-4E5A-8FBC-FAD7AB5FE42B"></p><p>额外需要提的是字典，它们会有指向字典的逻辑：</p><p><img src="https://image.mwish.me/blog-image/49EB35E6-7864-49CA-B433-FB985F598909.png" alt="49EB35E6-7864-49CA-B433-FB985F598909"></p><h2 id="Rep-Level-and-Def-Levels"><a href="#Rep-Level-and-Def-Levels" class="headerlink" title="Rep Level and Def Levels"></a>Rep Level and Def Levels</h2><p>理论讲了还是没意思，看代码吧</p><p>代码入口：</p><p>这是一个 Level Builder，外层的使用入口在：</p><ol><li><code>ArrowColumnWriterV2::Make</code>，创建对应的 <code>MultipathLevelBuilder</code>. <code>ArrowColumnWriterV2</code> 是某个具体的列的 writer。这个地方，Writer 会分 chunk 拿到不同的 Array，构建对应的 <code>MultipathLevelBuilder</code></li><li><code>MultipathLevelBuilder</code> 写入会返回一个 <code>MultipathLevelBuilderResult</code>，上层根据这个拿到 <code>rep-level</code> 和 <code>def-level</code>，然后写入</li></ol><p>下面简单看一下这些接口：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \brief Result for a single leaf array when running the builder on the</span></span><br><span class="line"><span class="comment">/// its root.</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">MultipathLevelBuilderResult</span> &#123;</span><br><span class="line">  <span class="comment">/// \brief The Array containing only the values to write (after all nesting has</span></span><br><span class="line">  <span class="comment">/// been processed.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// No additional processing is done on this array (it is copied as is when</span></span><br><span class="line">  <span class="comment">/// visited via a DFS).</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// leaf_array 是写入页面的整个 array, 即整列的数据</span></span><br><span class="line">  std::shared_ptr&lt;::arrow::Array&gt; leaf_array;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Might be null.</span></span><br><span class="line">  <span class="type">const</span> <span class="type">int16_t</span>* def_levels = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief  Might be null.</span></span><br><span class="line">  <span class="type">const</span> <span class="type">int16_t</span>* rep_levels = <span class="literal">nullptr</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Number of items (int16_t) contained in def/rep_levels when present.</span></span><br><span class="line">  <span class="comment">/// def-level 和 rep-level 长度是一样的, 所以需要一个 level 来提示</span></span><br><span class="line">  <span class="type">int64_t</span> def_rep_level_count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// \brief Contains element ranges of the required visiting on the</span></span><br><span class="line">  <span class="comment">/// descendants of the final list ancestor for any leaf node.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// The algorithm will attempt to consolidate visited ranges into</span></span><br><span class="line">  <span class="comment">/// the smallest number possible.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This data is necessary to pass along because after producing</span></span><br><span class="line">  <span class="comment">/// def-rep levels for each leaf array it is impossible to determine</span></span><br><span class="line">  <span class="comment">/// which values have to be sent to parquet when a null list value</span></span><br><span class="line">  <span class="comment">/// in a nullable ListArray is non-empty.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// This allows for the parquet writing to determine which values ultimately</span></span><br><span class="line">  <span class="comment">/// needs to be written.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// 写入的内容在 `leaf_array` 中的范围</span></span><br><span class="line">  std::vector&lt;ElementRange&gt; post_list_visited_elements;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/// Whether the leaf array is nullable.</span></span><br><span class="line">  <span class="comment">///</span></span><br><span class="line">  <span class="comment">/// leaf 是否是 nullable 的</span></span><br><span class="line">  <span class="type">bool</span> leaf_is_nullable;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>然后用 <code>Write</code> 接口去走 callback，来往 writer 写入数据：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">WriteColumnChunk</span><span class="params">(<span class="type">const</span> std::shared_ptr&lt;ChunkedArray&gt;&amp; data, <span class="type">int64_t</span> offset,</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="type">int64_t</span> size)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (arrow_properties_-&gt;<span class="built_in">engine_version</span>() == ArrowWriterProperties::V2 ||</span><br><span class="line">      arrow_properties_-&gt;<span class="built_in">engine_version</span>() == ArrowWriterProperties::V1) &#123;</span><br><span class="line">    <span class="built_in">ARROW_ASSIGN_OR_RAISE</span>(</span><br><span class="line">        std::unique_ptr&lt;ArrowColumnWriterV2&gt; writer,</span><br><span class="line">        ArrowColumnWriterV2::<span class="built_in">Make</span>(*data, offset, size, schema_manifest_,</span><br><span class="line">                                  row_group_writer_));</span><br><span class="line">    <span class="keyword">return</span> writer-&gt;<span class="built_in">Write</span>(&amp;column_write_context_);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">NotImplemented</span>(<span class="string">&quot;Unknown engine version.&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Writes out all leaf parquet columns to the RowGroupWriter that this</span></span><br><span class="line"><span class="comment">// object was constructed with.  Each leaf column is written fully before</span></span><br><span class="line"><span class="comment">// the next column is written (i.e. no buffering is assumed).</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Columns are written in DFS order.</span></span><br><span class="line"><span class="function">Status <span class="title">Write</span><span class="params">(ArrowWriteContext* ctx)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> leaf_idx = <span class="number">0</span>; leaf_idx &lt; leaf_count_; leaf_idx++) &#123;</span><br><span class="line">    ColumnWriter* column_writer;</span><br><span class="line">    <span class="built_in">PARQUET_CATCH_NOT_OK</span>(column_writer = row_group_writer_-&gt;<span class="built_in">NextColumn</span>());</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; level_builder : level_builders_) &#123;</span><br><span class="line">      <span class="built_in">RETURN_NOT_OK</span>(level_builder-&gt;<span class="built_in">Write</span>(</span><br><span class="line">          leaf_idx, ctx, [&amp;](<span class="type">const</span> MultipathLevelBuilderResult&amp; result) &#123;</span><br><span class="line">            <span class="type">size_t</span> visited_component_size = result.post_list_visited_elements.<span class="built_in">size</span>();</span><br><span class="line">            <span class="built_in">DCHECK_GT</span>(visited_component_size, <span class="number">0</span>);</span><br><span class="line">            <span class="keyword">if</span> (visited_component_size != <span class="number">1</span>) &#123;</span><br><span class="line">              <span class="keyword">return</span> Status::<span class="built_in">NotImplemented</span>(</span><br><span class="line">                  <span class="string">&quot;Lists with non-zero length null components are not supported&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="type">const</span> ElementRange&amp; range = result.post_list_visited_elements[<span class="number">0</span>];</span><br><span class="line">            std::shared_ptr&lt;Array&gt; values_array =</span><br><span class="line">                result.leaf_array-&gt;<span class="built_in">Slice</span>(range.start, range.<span class="built_in">Size</span>());</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> column_writer-&gt;<span class="built_in">WriteArrow</span>(result.def_levels, result.rep_levels,</span><br><span class="line">                                             result.def_rep_level_count, *values_array,</span><br><span class="line">                                             ctx, result.leaf_is_nullable);</span><br><span class="line">          &#125;));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">PARQUET_CATCH_NOT_OK</span>(column_writer-&gt;<span class="built_in">Close</span>());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以看到，这里走了 <code>MultipathLevelBuilder::Write</code>，然后里面走了回调，回调函数的参数就是之前提到的 <code>MultipathLevelBuilderResult</code>。这个函数给没有 rep-level 和 def-level 的输入加上了这两个 level，之后 <code>ColumnWriter</code> 就可以拿到 def-level, rep-level 和值去写了。那么，这里的关键应该就是 rep-level 和 def-level 是怎么构建的了。</p><p>这部分关键的内容在 <code>parquet/arrow/path_internal.cc</code> 下面。我们简单介绍一下对应的算法：</p><ol><li>输入是对应的 arrow Array 和相关的 schema</li><li>dfs 的方式推断出，「这个地方最大的 def-level 是什么，rep-level 是什么」</li><li>拿到用户的输入 array，进行计算</li></ol><p>在步骤 (2)，arrow 会根据输入数据构建出树，有两种节点：</p><ol><li>ListNode / StructNode / MapNode: 有子节点且非终止的节点</li><li>TerminalNode: 终止的节点。这里包括 <code>AllNullsTerminalNode</code>(所有成员都是 null）、<code>AllPresentTerminalNode</code>（全都有，且父级别没有 null 的节点），<code>NullableTerminalNode</code> 可能有 null 但不去为 null</li></ol><p>一般来说，可以理解 <code>TerminalNode</code> 为叶子结点，而其它节点为非叶子结点，但是也有一些特殊情况，比如父级就发现全部是 null 了，这里也可能是个 <code>TerminalNode</code>。</p><p>每个 <code>Node</code> 有一个 <code>Run</code> 方法，作为 (3) 需要的函数，但是参数并不相同，Node 之间也不是继承关系，而是组合关系，由 <code>variant</code> 包装：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Contains static information derived from traversing the schema.</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">PathInfo</span> &#123;</span><br><span class="line">  <span class="comment">// The vectors are expected to the same length info.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Note index order matters here.</span></span><br><span class="line">  <span class="keyword">using</span> Node =</span><br><span class="line">      std::variant&lt;NullableTerminalNode, ListNode, LargeListNode, FixedSizeListNode,</span><br><span class="line">                   NullableNode, AllPresentTerminalNode, AllNullsTerminalNode&gt;;</span><br><span class="line"></span><br><span class="line">  std::vector&lt;Node&gt; path;</span><br><span class="line">  std::shared_ptr&lt;Array&gt; primitive_array;</span><br><span class="line">  <span class="type">int16_t</span> max_def_level = <span class="number">0</span>;</span><br><span class="line">  <span class="type">int16_t</span> max_rep_level = <span class="number">0</span>;</span><br><span class="line">  <span class="type">bool</span> has_dictionary = <span class="literal">false</span>;</span><br><span class="line">  <span class="type">bool</span> leaf_is_nullable = <span class="literal">false</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>我们可以看看上面的 <code>PathInfo</code>，这里的目标就是构建一个这样的 <code>PathInfo</code>.</p><h3 id="PathBuilder-构建-Node-阶段"><a href="#PathBuilder-构建-Node-阶段" class="headerlink" title="PathBuilder: 构建 Node 阶段"></a>PathBuilder: 构建 Node 阶段</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// static</span></span><br><span class="line">::arrow::Result&lt;std::unique_ptr&lt;MultipathLevelBuilder&gt;&gt; MultipathLevelBuilder::<span class="built_in">Make</span>(</span><br><span class="line">    <span class="type">const</span> ::arrow::Array&amp; array, <span class="type">bool</span> array_field_nullable) &#123;</span><br><span class="line">  <span class="keyword">auto</span> constructor = std::<span class="built_in">make_unique</span>&lt;PathBuilder&gt;(array_field_nullable);</span><br><span class="line">  <span class="comment">// 递归分发给 PathBuilder 访问 arrow array, 捞到对应的 schema. 这里 leaf count 可能不止 1.</span></span><br><span class="line">  <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">VisitArrayInline</span>(array, constructor.<span class="built_in">get</span>()));</span><br><span class="line">  <span class="keyword">return</span> std::<span class="built_in">make_unique</span>&lt;MultipathLevelBuilderImpl&gt;(array.<span class="built_in">data</span>(),</span><br><span class="line">                                                     std::<span class="built_in">move</span>(constructor));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里可以看到，这里创建了一个 <code>PathBuilder</code>，然后访问了 <code>VisitArrayInline</code>，这里相当于自己定义了一个访问 array 的方法</p><p><code>PathBuilder</code> 提供了 <code>Visit(不同的 Array)</code> 的方法，能够完成动态分发。不过进入具体访问方式前，先来看看它的成员：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PathBuilder</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">PathBuilder</span><span class="params">(<span class="type">bool</span> start_nullable)</span> : nullable_in_parent_(start_nullable) &#123;</span>&#125;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  PathInfo info_;</span><br><span class="line">  std::vector&lt;PathInfo&gt; paths_;</span><br><span class="line">  <span class="type">bool</span> nullable_in_parent_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>nullable_in_parent_</code> 这个是表示，任何父亲的这个字段是否可能是 null。在代码里，丢给 PathBuilder 这玩意是这样的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">bool</span> nullable_root = <span class="built_in">HasNullableRoot</span>(schema_manifest, schema_field);</span><br><span class="line"><span class="keyword">if</span> (leaf_offset == <span class="number">0</span>) &#123;</span><br><span class="line">  is_nullable = nullable_root;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个看上去是 <code>HasNullableRoot</code>，但是丢给 path 的一般都是 root 的直接儿子，所以这里表示的就是 <code>parent</code> 的这个字段可能不可能是 null。</p><h4 id="处理父级别-null"><a href="#处理父级别-null" class="headerlink" title="处理父级别 null"></a>处理父级别 null</h4><p>有一个很常见的函数是 <code>MaybeAddNullable</code>，我们来看看：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 添加对应的 def-level,</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">MaybeAddNullable</span><span class="params">(<span class="type">const</span> Array&amp; array)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!nullable_in_parent_) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  info_.max_def_level++;</span><br><span class="line">  <span class="comment">// We don&#x27;t use null_count() because if the null_count isn&#x27;t known</span></span><br><span class="line">  <span class="comment">// and the array does in fact contain nulls, we will end up</span></span><br><span class="line">  <span class="comment">// traversing the null bitmap twice (once here and once when calculating</span></span><br><span class="line">  <span class="comment">// rep/def levels). Because this isn&#x27;t terminal this might not be</span></span><br><span class="line">  <span class="comment">// the right decision for structs that share the same nullable</span></span><br><span class="line">  <span class="comment">// parents.</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">LazyNoNulls</span>(array)) &#123;</span><br><span class="line">    <span class="comment">// Don&#x27;t add anything because there won&#x27;t be any point checking</span></span><br><span class="line">    <span class="comment">// null values for the array.  There will always be at least</span></span><br><span class="line">    <span class="comment">// one more array to handle nullability.</span></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 反正都没了，不如 terminal 了</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">LazyNullCount</span>(array) == array.<span class="built_in">length</span>()) &#123;</span><br><span class="line">    info_.path.<span class="built_in">emplace_back</span>(<span class="built_in">AllNullsTerminalNode</span>(info_.max_def_level - <span class="number">1</span>));</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  info_.path.<span class="built_in">emplace_back</span>(</span><br><span class="line">      <span class="built_in">NullableNode</span>(array.<span class="built_in">null_bitmap_data</span>(), array.<span class="built_in">offset</span>(),</span><br><span class="line">                   <span class="comment">/* def_level_if_null = */</span> info_.max_def_level - <span class="number">1</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里如果是父级 null，就会增加 <code>max_def_level</code>，然后添加对应的节点项。</p><h4 id="访问-struct"><a href="#访问-struct" class="headerlink" title="访问 struct"></a>访问 struct</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">Visit</span><span class="params">(<span class="type">const</span> ::arrow::StructArray&amp; array)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">MaybeAddNullable</span>(array);</span><br><span class="line">  PathInfo info_backup = info_;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> x = <span class="number">0</span>; x &lt; array.<span class="built_in">num_fields</span>(); x++) &#123;</span><br><span class="line">    nullable_in_parent_ = array.<span class="built_in">type</span>()-&gt;<span class="built_in">field</span>(x)-&gt;<span class="built_in">nullable</span>();</span><br><span class="line">    <span class="built_in">RETURN_NOT_OK</span>(<span class="built_in">VisitInline</span>(*array.<span class="built_in">field</span>(x)));</span><br><span class="line">    info_ = info_backup;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里代码应该非常好理解，就是递归访问。</p><h4 id="访问-ListArray"><a href="#访问-ListArray" class="headerlink" title="访问 ListArray"></a>访问 ListArray</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">::arrow::<span class="type">enable_if_t</span>&lt;std::is_same&lt;::arrow::ListArray, T&gt;::value ||</span><br><span class="line">                         std::is_same&lt;::arrow::LargeListArray, T&gt;::value,</span><br><span class="line">                     Status&gt;</span><br><span class="line"><span class="built_in">Visit</span>(<span class="type">const</span> T&amp; array) &#123;</span><br><span class="line">  <span class="comment">// 处理父级别带来的 def, 和自身场景</span></span><br><span class="line">  <span class="comment">// 对于 parquet 的 list, 这里相当于两组标记:</span></span><br><span class="line">  <span class="comment">// List &#123;</span></span><br><span class="line">  <span class="comment">//   repeatable member</span></span><br><span class="line">  <span class="comment">// &#125;</span></span><br><span class="line">  <span class="comment">// 这两层都是 rep/def 哦～</span></span><br><span class="line">  <span class="built_in">MaybeAddNullable</span>(array);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Increment necessary due to empty lists.</span></span><br><span class="line">  info_.max_def_level++;</span><br><span class="line">  info_.max_rep_level++;</span><br><span class="line">  <span class="comment">// raw_value_offsets() accounts for any slice offset.</span></span><br><span class="line">  ListPathNode&lt;VarRangeSelector&lt;<span class="keyword">typename</span> T::offset_type&gt;&gt; <span class="built_in">node</span>(</span><br><span class="line">      VarRangeSelector&lt;<span class="keyword">typename</span> T::offset_type&gt;&#123;array.<span class="built_in">raw_value_offsets</span>()&#125;,</span><br><span class="line">      info_.max_rep_level, info_.max_def_level - <span class="number">1</span>);</span><br><span class="line">  info_.path.<span class="built_in">emplace_back</span>(std::<span class="built_in">move</span>(node));</span><br><span class="line">  nullable_in_parent_ = array.<span class="built_in">list_type</span>()-&gt;<span class="built_in">value_field</span>()-&gt;<span class="built_in">nullable</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">VisitInline</span>(*array.<span class="built_in">values</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里 <code>max_rep_level</code> 和 <code>max_def_level - 1</code> 得回顾一下上一篇博客了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> RangeSelector&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ListPathNode</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">ListPathNode</span>(RangeSelector selector, <span class="type">int16_t</span> rep_lev, <span class="type">int16_t</span> def_level_if_empty)</span><br><span class="line">      : <span class="built_in">selector_</span>(std::<span class="built_in">move</span>(selector)),</span><br><span class="line">        <span class="built_in">prev_rep_level_</span>(rep_lev - <span class="number">1</span>),</span><br><span class="line">        <span class="built_in">rep_level_</span>(rep_lev),</span><br><span class="line">        <span class="built_in">def_level_if_empty_</span>(def_level_if_empty) &#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>VarRangeSelector</code> 则持有了 array 元素的 offsets，还记得前面的 <code>ListArray</code> 的图吗？</p><h4 id="访问叶子结点"><a href="#访问叶子结点" class="headerlink" title="访问叶子结点"></a>访问叶子结点</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//! 是平坦的 array, 可以当作找到了某个叶子.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">::arrow::<span class="type">enable_if_t</span>&lt;std::is_base_of&lt;::arrow::FlatArray, T&gt;::value, Status&gt; <span class="built_in">Visit</span>(</span><br><span class="line">    <span class="type">const</span> T&amp; array) &#123;</span><br><span class="line">  <span class="comment">// 在叶子层面加上 terminal info.</span></span><br><span class="line">  <span class="built_in">AddTerminalInfo</span>(array);</span><br><span class="line">  <span class="keyword">return</span> Status::<span class="built_in">OK</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的重点是 <code>AddTerminalInfo</code>，添加了对应的 <code>TerminalNode</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">AddTerminalInfo</span><span class="params">(<span class="type">const</span> T&amp; array)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 这里, leaf_is_nullable 经由 parent 实现, 表示「父级别的这个字段可能是 nullable」的。</span></span><br><span class="line">  info_.leaf_is_nullable = nullable_in_parent_;</span><br><span class="line">  <span class="keyword">if</span> (nullable_in_parent_) &#123;</span><br><span class="line">    info_.max_def_level++; <span class="comment">// (加上)这一层的 def-level</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 注意: rep-level 在底层是不会处理的，都是上层处理的。</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// We don&#x27;t use null_count() because if the null_count isn&#x27;t known</span></span><br><span class="line">  <span class="comment">// and the array does in fact contain nulls, we will end up</span></span><br><span class="line">  <span class="comment">// traversing the null bitmap twice (once here and once when calculating</span></span><br><span class="line">  <span class="comment">// rep/def levels).</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// 处理: 没有 null, 都是 null, 可以为 null 的 case. 把这个加入 info_.path 中.</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">LazyNoNulls</span>(array)) &#123;</span><br><span class="line">    info_.path.<span class="built_in">emplace_back</span>(AllPresentTerminalNode&#123;info_.max_def_level&#125;);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">LazyNullCount</span>(array) == array.<span class="built_in">length</span>()) &#123;</span><br><span class="line">    info_.path.<span class="built_in">emplace_back</span>(<span class="built_in">AllNullsTerminalNode</span>(info_.max_def_level - <span class="number">1</span>));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    info_.path.<span class="built_in">emplace_back</span>(<span class="built_in">NullableTerminalNode</span>(array.<span class="built_in">null_bitmap_data</span>(),</span><br><span class="line">                                                 array.<span class="built_in">offset</span>(), info_.max_def_level));</span><br><span class="line">  &#125;</span><br><span class="line">  info_.primitive_array = std::<span class="built_in">make_shared</span>&lt;T&gt;(array.<span class="built_in">data</span>());</span><br><span class="line">  <span class="comment">// 真正处理这个 dfs path, 把 fixup 的结果加入 paths. 这里面会处理 rep-level.</span></span><br><span class="line">  paths_.<span class="built_in">push_back</span>(<span class="built_in">Fixup</span>(info_));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个 <code>Fixup</code> 是处理 rep-level 的函数，我们再看看：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// FIXUP 会处理 rep-level.</span></span><br><span class="line"><span class="function">PathInfo <span class="title">Fixup</span><span class="params">(PathInfo info)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// We only need to fixup the path if there were repeated</span></span><br><span class="line">  <span class="comment">// elements on it.</span></span><br><span class="line">  <span class="keyword">if</span> (info.max_rep_level == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> info;</span><br><span class="line">  &#125;</span><br><span class="line">  FixupVisitor visitor;</span><br><span class="line">  visitor.max_rep_level = info.max_rep_level;</span><br><span class="line">  <span class="keyword">if</span> (visitor.max_rep_level &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    visitor.rep_level_if_null = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 从 0-最后的顺序访问, 变更 visitor, 这个地方会把最上层的 rep-level 带下来.</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">size_t</span> x = <span class="number">0</span>; x &lt; info.path.<span class="built_in">size</span>(); x++) &#123;</span><br><span class="line">    std::<span class="built_in">visit</span>(visitor, info.path[x]);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> info;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">FixupVisitor</span> &#123;</span><br><span class="line">  <span class="type">int</span> max_rep_level = <span class="number">-1</span>;</span><br><span class="line">  <span class="type">int16_t</span> rep_level_if_null = kLevelNotSet; <span class="comment">// (第一个) 为 null 的时候, 需要处理 rep-level 的.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 遇到了中间的会找到 rep-level</span></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">HandleListNode</span><span class="params">(T&amp; arg)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (arg.<span class="built_in">rep_level</span>() == max_rep_level) &#123;</span><br><span class="line">      arg.<span class="built_in">SetLast</span>();</span><br><span class="line">      <span class="comment">// after the last list node we don&#x27;t need to fill</span></span><br><span class="line">      <span class="comment">// rep levels on null.</span></span><br><span class="line">      rep_level_if_null = kLevelNotSet;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      rep_level_if_null = arg.<span class="built_in">rep_level</span>();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(ListNode&amp; node)</span> </span>&#123; <span class="built_in">HandleListNode</span>(node); &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(LargeListNode&amp; node)</span> </span>&#123; <span class="built_in">HandleListNode</span>(node); &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(FixedSizeListNode&amp; node)</span> </span>&#123; <span class="built_in">HandleListNode</span>(node); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// For non-list intermediate nodes.</span></span><br><span class="line">  <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">HandleIntermediateNode</span><span class="params">(T&amp; arg)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (rep_level_if_null != kLevelNotSet) &#123;</span><br><span class="line">      <span class="comment">// 只有 AllNullsTerminalNode 和 NullableTerminalNode 可能有这个</span></span><br><span class="line">      arg.<span class="built_in">SetRepLevelIfNull</span>(rep_level_if_null); <span class="comment">// 如果这层是空的时候，rep-level 是什么，就是找到一个父级的 rep-level</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(NullableNode&amp; arg)</span> </span>&#123; <span class="built_in">HandleIntermediateNode</span>(arg); &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(AllNullsTerminalNode&amp; arg)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Even though no processing happens past this point we</span></span><br><span class="line">    <span class="comment">// still need to adjust it if a list occurred after an</span></span><br><span class="line">    <span class="comment">// all null array.</span></span><br><span class="line">    <span class="built_in">HandleIntermediateNode</span>(arg);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(NullableTerminalNode&amp;)</span> </span>&#123;&#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">(AllPresentTerminalNode&amp;)</span> </span>&#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个 <code>visitor</code> 会把 <code>rep-level-if-null</code> 给带下去。</p><h3 id="Write-阶段"><a href="#Write-阶段" class="headerlink" title="Write 阶段"></a>Write 阶段</h3><p>Write 阶段核心函数在 WritePath 上：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">::<span class="function">arrow::Status <span class="title">Write</span><span class="params">(<span class="type">int</span> leaf_index, ArrowWriteContext* context,</span></span></span><br><span class="line"><span class="params"><span class="function">                      CallbackFunction write_leaf_callback)</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line">  <span class="built_in">DCHECK_GE</span>(leaf_index, <span class="number">0</span>);</span><br><span class="line">  <span class="built_in">DCHECK_LT</span>(leaf_index, <span class="built_in">GetLeafCount</span>());</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">WritePath</span>(root_range_, &amp;path_builder_-&gt;<span class="built_in">paths</span>()[leaf_index], context,</span><br><span class="line">                   std::<span class="built_in">move</span>(write_leaf_callback));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>WritePath</code> 比较复杂，我们看之前先介绍一下算法：</p><h4 id="WritePath-的算法"><a href="#WritePath-的算法" class="headerlink" title="WritePath 的算法"></a>WritePath 的算法</h4><p>现在我们有了一组 node 栈，然后我们假设一个场景：<code>List&lt;List&lt;int&gt;&gt;</code> 和 <code>[[1, 2, null], null, [], [null, 1, 2]]</code>。这个本身不难，但是这个 def 和 rep 都是会变动的. 这个在 arrow 中大概会被实现成:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ListArray: [[]], valid bitmap, offsets</span><br><span class="line">  ListArray: [], valid bitmap, offsets</span><br><span class="line">     IntArray: buffer, valid bitmap, offsets</span><br></pre></td></tr></table></figure><p>这里会构造一个 range 栈，大概是这样的：</p><ol><li>拿到根结点</li><li>Nullable -&gt; List -&gt; Nullable -&gt; List -&gt; Int ，写入 1，2，null 和对应的 rep-level , def-level</li><li>回溯到上层，发现成员是 null，写入一个对应的 rep-level , def-level</li><li>发现栈有元素，到下层继续写入</li></ol><h4 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h4><p>这里需要介绍 <code>Iterator</code> 类型，每一层会有一个 <code>Run</code>，拿到对应的范围。有可能：</p><ol><li><code>kDone</code> 做完了，应该向上层走</li><li><code>kNext</code> 应该走进下一层</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// \brief Simple result of a iterating over a column to determine values.</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">IterationResult</span> &#123;</span><br><span class="line">  <span class="comment">/// Processing is done at this node. Move back up the path</span></span><br><span class="line">  <span class="comment">/// to continue processing.</span></span><br><span class="line">  kDone = <span class="number">-1</span>,</span><br><span class="line">  <span class="comment">/// Move down towards the leaf for processing.</span></span><br><span class="line">  kNext = <span class="number">1</span>,</span><br><span class="line">  <span class="comment">/// An error occurred while processing.</span></span><br><span class="line">  kError = <span class="number">2</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>我们以 nullable 为例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">IterationResult <span class="title">Run</span><span class="params">(ElementRange* range, ElementRange* child_range,</span></span></span><br><span class="line"><span class="params"><span class="function">                    PathWriteContext* context)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (new_range_) &#123;</span><br><span class="line">    <span class="comment">// Reset the reader each time we are starting fresh on a range.</span></span><br><span class="line">    <span class="comment">// We can&#x27;t rely on continuity because nulls above can</span></span><br><span class="line">    <span class="comment">// cause discontinuities.</span></span><br><span class="line">    valid_bits_reader_ = <span class="built_in">MakeReader</span>(*range);</span><br><span class="line">  &#125;</span><br><span class="line">  child_range-&gt;start = range-&gt;start;</span><br><span class="line">  ::arrow::internal::BitRun run = valid_bits_reader_.<span class="built_in">NextRun</span>();</span><br><span class="line">  <span class="keyword">if</span> (!run.set) &#123;</span><br><span class="line">    range-&gt;start += run.length;</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(<span class="built_in">FillRepLevels</span>(run.length, rep_level_if_null_, context));</span><br><span class="line">    <span class="built_in">RETURN_IF_ERROR</span>(context-&gt;<span class="built_in">AppendDefLevels</span>(run.length, def_level_if_null_));</span><br><span class="line">    run = valid_bits_reader_.<span class="built_in">NextRun</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (range-&gt;<span class="built_in">Empty</span>()) &#123;</span><br><span class="line">    new_range_ = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">return</span> kDone;</span><br><span class="line">  &#125;</span><br><span class="line">  child_range-&gt;end = child_range-&gt;start = range-&gt;start;</span><br><span class="line">  child_range-&gt;end += run.length;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">DCHECK</span>(!child_range-&gt;<span class="built_in">Empty</span>());</span><br><span class="line">  range-&gt;start += child_range-&gt;<span class="built_in">Size</span>();</span><br><span class="line">  new_range_ = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">return</span> kNext;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里会按情况添加 level，然后返回上一层或者暗示后面还有，走向下一层，这些 node 都是 <strong>有状态的</strong>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Contains logic for writing a single leaf node to parquet.</span></span><br><span class="line"><span class="comment">/// This tracks the path from root to leaf.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// |writer| will be called after all of the definition/repetition</span></span><br><span class="line"><span class="comment">/// values have been calculated for root_range with the calculated</span></span><br><span class="line"><span class="comment">/// values. It is intended to abstract the complexity of writing</span></span><br><span class="line"><span class="comment">/// the levels and values to parquet.</span></span><br><span class="line"><span class="function">Status <span class="title">WritePath</span><span class="params">(ElementRange root_range, PathInfo* path_info,</span></span></span><br><span class="line"><span class="params"><span class="function">                 ArrowWriteContext* arrow_context,</span></span></span><br><span class="line"><span class="params"><span class="function">                 MultipathLevelBuilder::CallbackFunction writer)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 栈表示为 range 栈</span></span><br><span class="line">  <span class="function">std::vector&lt;ElementRange&gt; <span class="title">stack</span><span class="params">(path_info-&gt;path.size())</span></span>;</span><br><span class="line">  MultipathLevelBuilderResult builder_result;</span><br><span class="line">  builder_result.leaf_array = path_info-&gt;primitive_array;</span><br><span class="line">  builder_result.leaf_is_nullable = path_info-&gt;leaf_is_nullable;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 不需要处理递归、特殊场景，嗯写就是了</span></span><br><span class="line">  <span class="keyword">if</span> (path_info-&gt;max_def_level == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// This case only occurs when there are no nullable or repeated</span></span><br><span class="line">    <span class="comment">// columns in the path from the root to leaf.</span></span><br><span class="line">    <span class="type">int64_t</span> leaf_length = builder_result.leaf_array-&gt;<span class="built_in">length</span>();</span><br><span class="line">    builder_result.def_rep_level_count = leaf_length;</span><br><span class="line">    builder_result.post_list_visited_elements.<span class="built_in">push_back</span>(&#123;<span class="number">0</span>, leaf_length&#125;);</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">writer</span>(builder_result);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// root_range 为行的 offset, 是最外层的 range</span></span><br><span class="line">  stack[<span class="number">0</span>] = root_range;</span><br><span class="line">  <span class="built_in">RETURN_NOT_OK</span>(</span><br><span class="line">      arrow_context-&gt;def_levels_buffer-&gt;<span class="built_in">Resize</span>(<span class="comment">/*new_size=*/</span><span class="number">0</span>, <span class="comment">/*shrink_to_fit*/</span> <span class="literal">false</span>));</span><br><span class="line">  <span class="function">PathWriteContext <span class="title">context</span><span class="params">(arrow_context-&gt;memory_pool, arrow_context-&gt;def_levels_buffer)</span></span>;</span><br><span class="line">  <span class="comment">// We should need at least this many entries so reserve the space ahead of time.</span></span><br><span class="line">  <span class="built_in">RETURN_NOT_OK</span>(context.def_levels.<span class="built_in">Reserve</span>(root_range.<span class="built_in">Size</span>()));</span><br><span class="line">  <span class="keyword">if</span> (path_info-&gt;max_rep_level &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="built_in">RETURN_NOT_OK</span>(context.rep_levels.<span class="built_in">Reserve</span>(root_range.<span class="built_in">Size</span>()));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> stack_base = &amp;stack[<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">auto</span> stack_position = stack_base;</span><br><span class="line">  <span class="comment">// This is the main loop for calculated rep/def levels. The nodes</span></span><br><span class="line">  <span class="comment">// in the path implement a chain-of-responsibility like pattern</span></span><br><span class="line">  <span class="comment">// where each node can add some number of repetition/definition</span></span><br><span class="line">  <span class="comment">// levels to PathWriteContext and also delegate to the next node</span></span><br><span class="line">  <span class="comment">// in the path to add values. The values are added through each Run(...)</span></span><br><span class="line">  <span class="comment">// call and the choice to delegate to the next node (or return to the</span></span><br><span class="line">  <span class="comment">// previous node) is communicated by the return value of Run(...).</span></span><br><span class="line">  <span class="comment">// The loop terminates after the first node indicates all values in</span></span><br><span class="line">  <span class="comment">// |root_range| are processed.</span></span><br><span class="line">  <span class="keyword">while</span> (stack_position &gt;= stack_base) &#123;</span><br><span class="line">    PathInfo::Node&amp; node = path_info-&gt;path[stack_position - stack_base];</span><br><span class="line">    <span class="keyword">struct</span> &#123;</span><br><span class="line">      <span class="function">IterationResult <span class="title">operator</span><span class="params">()</span><span class="params">(NullableNode&amp; node)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> node.<span class="built_in">Run</span>(stack_position, stack_position + <span class="number">1</span>, context);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="function">IterationResult <span class="title">operator</span><span class="params">()</span><span class="params">(ListNode&amp; node)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> node.<span class="built_in">Run</span>(stack_position, stack_position + <span class="number">1</span>, context);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="function">IterationResult <span class="title">operator</span><span class="params">()</span><span class="params">(NullableTerminalNode&amp; node)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> node.<span class="built_in">Run</span>(*stack_position, context);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="function">IterationResult <span class="title">operator</span><span class="params">()</span><span class="params">(FixedSizeListNode&amp; node)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> node.<span class="built_in">Run</span>(stack_position, stack_position + <span class="number">1</span>, context);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="function">IterationResult <span class="title">operator</span><span class="params">()</span><span class="params">(AllPresentTerminalNode&amp; node)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> node.<span class="built_in">Run</span>(*stack_position, context);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="function">IterationResult <span class="title">operator</span><span class="params">()</span><span class="params">(AllNullsTerminalNode&amp; node)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> node.<span class="built_in">Run</span>(*stack_position, context);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="function">IterationResult <span class="title">operator</span><span class="params">()</span><span class="params">(LargeListNode&amp; node)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> node.<span class="built_in">Run</span>(stack_position, stack_position + <span class="number">1</span>, context);</span><br><span class="line">      &#125;</span><br><span class="line">      ElementRange* stack_position;</span><br><span class="line">      PathWriteContext* context;</span><br><span class="line">    &#125; visitor = &#123;stack_position, &amp;context&#125;;</span><br><span class="line"></span><br><span class="line">    IterationResult result = std::<span class="built_in">visit</span>(visitor, node);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">ARROW_PREDICT_FALSE</span>(result == kError)) &#123;</span><br><span class="line">      <span class="built_in">DCHECK</span>(!context.last_status.<span class="built_in">ok</span>());</span><br><span class="line">      <span class="keyword">return</span> context.last_status;</span><br><span class="line">    &#125;</span><br><span class="line">    stack_position += <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(result);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">RETURN_NOT_OK</span>(context.last_status);</span><br><span class="line">  builder_result.def_rep_level_count = context.def_levels.<span class="built_in">length</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (context.rep_levels.<span class="built_in">length</span>() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// This case only occurs when there was a repeated element that needs to be</span></span><br><span class="line">    <span class="comment">// processed.</span></span><br><span class="line">    builder_result.rep_levels = context.rep_levels.<span class="built_in">data</span>();</span><br><span class="line">    std::<span class="built_in">swap</span>(builder_result.post_list_visited_elements, context.visited_elements);</span><br><span class="line">    <span class="comment">// If it is possible when processing lists that all lists where empty. In this</span></span><br><span class="line">    <span class="comment">// case no elements would have been added to post_list_visited_elements. By</span></span><br><span class="line">    <span class="comment">// added an empty element we avoid special casing in downstream consumers.</span></span><br><span class="line">    <span class="keyword">if</span> (builder_result.post_list_visited_elements.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">      builder_result.post_list_visited_elements.<span class="built_in">push_back</span>(&#123;<span class="number">0</span>, <span class="number">0</span>&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    builder_result.post_list_visited_elements.<span class="built_in">push_back</span>(</span><br><span class="line">        &#123;<span class="number">0</span>, builder_result.leaf_array-&gt;<span class="built_in">length</span>()&#125;);</span><br><span class="line">    builder_result.rep_levels = <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  builder_result.def_levels = context.def_levels.<span class="built_in">data</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">writer</span>(builder_result);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Samples-for-write"><a href="#Samples-for-write" class="headerlink" title="Samples for write"></a>Samples for write</h2><p>总觉得我写的还是比较抽象的，所以这里尝试举几个例子，来简单介绍一下，因为之前写入的过于抽象了。</p><p>我们回顾一下：</p><ol><li><code>PathBuilder</code> 会根据用户的 Schema 来构建 node，这些 node 有不同的 max-rep-level 和 max-def-level，也有空缺的时候应该写入的 def-level。这里会构成一个栈</li><li>传递数据下来的时候，连续的数据会找到对应的栈，写对应的 def-level 和 rep-level</li></ol><p>我们下面列举的例子都是写入 1024 行数据的，我们会从简单到难来介绍写入 case 的例子</p><h3 id="Case-1-i32"><a href="#Case-1-i32" class="headerlink" title="Case 1: i32"></a>Case 1: i32</h3><p>我们假设有连续的 i32, 它不是 nullable 的，这个时候，arrow 对应的结构是 Fixed 的 int32 数组，没有任何 valid bitmap。</p><p>这个时候，<code>PathBuilder</code>在构建阶段 会构建一个下面的节点：</p><p><img src="https://image.mwish.me/blog-image/parquet-c1.jpg" alt="流程图 (1)"></p><p>在构建阶段，程序会找到这个 node，然后设置迭代的 <code>range = [0, 1024)</code>，然后遍历这个栈…</p><p>不，其实它不会遍历这个栈！还记得之前吗？如果字段是 <code>optional</code>，那么 max-dep + 1，如果是 <code>repeatable</code>, 那么 max-dep + 1, max-rep + 1。也就是说，程序如果检查到 <code>max-dep == 0</code>，那么说明对象都是一对一且无 null 的，这个地方就直接写入所有值了！</p><h3 id="Case-2-optional-i32"><a href="#Case-2-optional-i32" class="headerlink" title="Case 2: optional i32"></a>Case 2: optional i32</h3><p>我们假设有连续的 optional i32，这个时候，arrow 对应的结构是 Fixed 的 int32 数组，没有任何 valid bitmap。</p><p>这个时候，<code>PathBuilder</code>在构建阶段 会构建一个下面的节点：</p><p><img src="https://image.mwish.me/blog-image/parquet-c2.jpg" alt="流程图 (2)"></p><p>在构建阶段，程序会找到这个 node，然后设置迭代的 <code>range = [0, 1024)</code>，然后遍历这个栈，把 <code>[0, 1024)</code> 传给 node，这里访问 validation bitset，如果有元素，就在 def-levels 里面加入 1，否则加入 0。栈只有一层，一次解决 0-1024 所有元素。这里不存在任何 rep-level。</p><p>特殊情况下，如果发现数据全是 Null，会构建一个特殊的节点：</p><p><img src="https://image.mwish.me/blog-image/parquet-c2-1.jpg" alt="parquet-c2-1"></p><p>这里会写入全是 0 的 def-level，然后不写入任何 rep.</p><h3 id="Case-3-array-lt-i32-4-gt"><a href="#Case-3-array-lt-i32-4-gt" class="headerlink" title="Case 3: array&lt;i32, 4&gt;"></a>Case 3: <code>array&lt;i32, 4&gt;</code></h3><p>我们假设 <code>list</code> 不是 nullable 的，这个时候会怎么写入呢？我们假设可以有这样的成员：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]</span><br></pre></td></tr></table></figure><p>这个对应 arrow 中的 <code>FixedSizeListArray</code>，对应内容如下：</p><p><img src="https://image.mwish.me/blog-image/parquet-c3-0.jpg" alt="parquet-c3-0"></p><p>这是一个最简化的模型了，实际上可能会复杂很多，我们先不管。这里输入是 <code>range = [0, 3)</code>，然后数组对应是 <code>Int32Array = [0, 1, 2, 3, 4, 5, ... 11]</code></p><ol><li>第一层栈对应范围是 <code>[0, 3)</code></li><li>第一层栈找到第一个 <strong>非空</strong> 的，是第 0 个，这个时候，如果是第一次访问（开一个新列表），很显然，rep-level 会来自自己的父级。第一个元素写入 <code>prev-rep-level</code>，即 0.<ol><li>因为这个节点是 <code>last_list_node</code>，所以它会向后找到第一个非 empty 的 node，会在 <code>FillForLast</code> 函数找到所有对应的内容，把 rep-level 填充完毕，每遇到非空的内容，都给四个填充 <code>[0, 1, 1, 1]</code> 等。为什么是 <code>[0, 1, 1, 1]</code> 呢？第一个元素需要填充 <code>prev-rep-level</code>，其次要填充 <code>rep-level</code></li></ol></li><li>完毕后，这里要把 <code>[0, 3)</code> 转化为下层需要的范围，<code>FixSizeListNode</code> 对应每个子元素 size 都是 <code>4</code>，所以这里会拿到 <code>[0, 12)</code> ，作为对应的 range</li><li>栈开始处理 <code>AllPresentTerminalNode</code>，丢给下面的范围是 <code>[0, 12)</code>，这里都不是 null 的，就会写入具体的内容，写完具体 12 个值和对应的 def-level，即 12个 1</li></ol><p>我们回过头看下 (2)，这里：</p><ol><li>一旦新开了一个 list，一定写一个自己的 rep-level</li><li>如果 list 是最后一个 list ( 最后可能带来 rep-level 的地方)，它会负责写所有儿子的 rep-level</li></ol><p><strong>还有，非空 和 非 null 是不同的概念，null 会有别的地方来处理，我们之后会介绍。</strong></p><h4 id="Case-3-1-array-lt-optional-i32-4-gt"><a href="#Case-3-1-array-lt-optional-i32-4-gt" class="headerlink" title="Case 3-1: array&lt;optional i32, 4&gt;"></a>Case 3-1: <code>array&lt;optional i32, 4&gt;</code></h4><p>我们假设可以有这样的成员：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[0, null, 2, 3], [4, null, 6, 7], [8, null, 10, 11]]</span><br></pre></td></tr></table></figure><p>这下我们需要改变我们的树了！</p><p><img src="https://image.mwish.me/blog-image/parquet-c3-1.jpg" alt="parquet-c3-1"></p><p>这里 1-3 步和之前一样，4会根据节点写出自己对应的 def-level 是 1 还是 2. 类似 case 2 的场景</p><h3 id="Case-List-lt-int32-gt"><a href="#Case-List-lt-int32-gt" class="headerlink" title="Case: List&lt;int32&gt;"></a>Case: <code>List&lt;int32&gt;</code></h3><p>我们前面介绍了 <code>array&lt;T, 4&gt;</code>，我在画图的时候，把 node 当作 Fixed Sized 的 List，那么实际的 <code>List</code> 或者 <code>repeated</code> 会是什么样的呢？</p><p>这里我们可以看看对应的类型系统：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// List nodes handle populating rep_level for Arrow Lists and def-level for empty lists.</span></span><br><span class="line"><span class="comment">// Nullability (both list and children) is handled by other Nodes. By</span></span><br><span class="line"><span class="comment">// construction all list nodes will be intermediate nodes (they will always be followed by</span></span><br><span class="line"><span class="comment">// at least one other node).</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Type parameters:</span></span><br><span class="line"><span class="comment">//    |RangeSelector| - A strategy for determine the the range of the child node to</span></span><br><span class="line"><span class="comment">//    process.</span></span><br><span class="line"><span class="comment">//       this varies depending on the type of list (int32_t* offsets, int64_t* offsets of</span></span><br><span class="line"><span class="comment">//       fixed.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> RangeSelector&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ListPathNode</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> ListNode = ListPathNode&lt;VarRangeSelector&lt;<span class="type">int32_t</span>&gt;&gt;;</span><br><span class="line"><span class="keyword">using</span> LargeListNode = ListPathNode&lt;VarRangeSelector&lt;<span class="type">int64_t</span>&gt;&gt;;</span><br><span class="line"><span class="keyword">using</span> FixedSizeListNode = ListPathNode&lt;FixedSizedRangeSelector&gt;;</span><br></pre></td></tr></table></figure><p>这部分实现实际上和 Parquet 关系不大，Parquet 只会知道你是 repeated，这部分是 arrow 的逻辑，回顾一下上面的图：</p><ol><li>Fixed Sized 会在元信息里面存放自己的 size</li><li>非 fix sized 会有个 offset 数组，用这个 offset 数组来推断自己的 size</li></ol><p>那么，我们回顾 3 的 case，看看 List 会怎么样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[0, null, 2], [], [8, null, 10, 11]]</span><br></pre></td></tr></table></figure><p>这里会捞到 <code>[0, null, 2]</code>，写入 rep-level <code>[0, 1, 1]</code></p><p>遇到 <code>[]</code> 的时候，它会跳过这个，然后<strong>写入一个 rep-level 和空缺的 def-level</strong></p><p><code>[8, null, 10, 11]</code> 会写入 <code>rep-level</code> <code>[0, 1, 1, 1]</code></p><h3 id="Case-4-optional-array-lt-optional-i32-4-gt"><a href="#Case-4-optional-array-lt-optional-i32-4-gt" class="headerlink" title="Case 4: optional array&lt;optional i32, 4&gt;"></a>Case 4: <code>optional array&lt;optional i32, 4&gt;</code></h3><p>我们假设可以有这样的成员：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[0, null, 2, 3], null, [8, null, 10, 11]]</span><br></pre></td></tr></table></figure><p>这下我们又需要改变我们的树了！</p><p><img src="https://image.mwish.me/blog-image/parquet-c4-0.jpg" alt="parquet-c4-0"></p><p>这里，<code>NullableNode</code> 会读取对应的 validation bitset, 然后返回给下层：</p><ol><li>根节点 range 是 <code>[0, 3)</code></li><li>第一次发现不是 null 的，连续的返回 <code>[0, 1)</code> 范围给下层，下层和之前的逻辑一样处理</li><li>第二次发现 <code>null</code>，这里需要填充 rep-level 和 def-level，分别填充两个 <code>0</code> 上去</li><li>发现为 <code>null</code>，再次令其填充</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>future and promise in libc++/folly</title>
      <link href="/2022/09/18/futures-promise-executors-continuation/"/>
      <url>/2022/09/18/futures-promise-executors-continuation/</url>
      
        <content type="html"><![CDATA[<p>future 表示一个能拿到某个值的预期</p><h2 id="libc-future"><a href="#libc-future" class="headerlink" title="libc++ future"></a>libc++ future</h2><p>逻辑内容：</p><p><img src="https://image.mwish.me/blog-image/libcpp-future.jpg" alt="libcpp-future"></p><p>实现部分在 <code>include/c++/v1/future</code> 和</p><p>future 类型如下:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Rp</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">_LIBCPP_TEMPLATE_VIS</span> _LIBCPP_AVAILABILITY_FUTURE future</span><br><span class="line">&#123;</span><br><span class="line">    __assoc_state&lt;_Rp&gt;* __state_;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">future</span><span class="params">(__assoc_state&lt;_Rp&gt;* __state)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">class</span>&gt; <span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">promise</span>;</span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">class</span>&gt; <span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">shared_future</span>;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// ... </span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>可以看到，future 包装了一层 <code>__assoc_state&lt;_rp&gt;</code>, 我们进 <code>__assoc_state</code> 看看:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Rp</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">_LIBCPP_AVAILABILITY_FUTURE</span> _LIBCPP_HIDDEN __assoc_state</span><br><span class="line">    : <span class="keyword">public</span> __assoc_sub_state</span><br><span class="line">&#123;<span class="comment">//...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>哦，他是 <code>__assoc_sub_state&lt;_Rp&gt;</code> 的子类：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">_LIBCPP_TYPE_VIS</span> _LIBCPP_AVAILABILITY_FUTURE __assoc_sub_state</span><br><span class="line">    : <span class="keyword">public</span> __shared_count</span><br><span class="line">&#123;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里面包了一层 <code>__shared_count</code>，还记得之前的图吗？这个内部就是一个引用计数，实际上 <code>std::shared_ptr</code> 也搬用了这套实现：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">_LIBCPP_TYPE_VIS</span> __shared_count</span><br><span class="line">&#123;</span><br><span class="line">    __shared_count(<span class="type">const</span> __shared_count&amp;);</span><br><span class="line">    __shared_count&amp; <span class="keyword">operator</span>=(<span class="type">const</span> __shared_count&amp;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    <span class="type">long</span> __shared_owners_;</span><br><span class="line">    <span class="keyword">virtual</span> ~__shared_count();</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">virtual</span> <span class="type">void</span> __on_zero_shared() _NOEXCEPT = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">_LIBCPP_INLINE_VISIBILITY</span><br><span class="line">    <span class="type">void</span> __add_shared() _NOEXCEPT;</span><br><span class="line">    _LIBCPP_INLINE_VISIBILITY</span><br><span class="line">    <span class="type">bool</span> __release_shared() _NOEXCEPT;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="function">_LIBCPP_INLINE_VISIBILITY</span></span><br><span class="line"><span class="function">    <span class="type">long</span> <span class="title">use_count</span><span class="params">()</span> <span class="type">const</span> _NOEXCEPT</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里需要解释一下 <code>__on_zero_shared</code>，这里可以看作是用户调用的 rc == 0 的时候清除资源的函数。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">_LIBCPP_TYPE_VIS</span> _LIBCPP_AVAILABILITY_FUTURE __assoc_sub_state</span><br><span class="line">    : <span class="keyword">public</span> __shared_count</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    exception_ptr __exception_;</span><br><span class="line">    <span class="keyword">mutable</span> mutex __mut_;</span><br><span class="line">    <span class="keyword">mutable</span> condition_variable __cv_;</span><br><span class="line">    <span class="type">unsigned</span> __state_;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">virtual</span> <span class="type">void</span> __on_zero_shared() _NOEXCEPT;</span><br><span class="line">    <span class="type">void</span> __sub_wait(unique_lock&lt;mutex&gt;&amp; __lk);</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">enum</span></span><br><span class="line">    &#123;</span><br><span class="line">        __constructed = <span class="number">1</span>,</span><br><span class="line">        __future_attached = <span class="number">2</span>,</span><br><span class="line">        ready = <span class="number">4</span>,</span><br><span class="line">        deferred = <span class="number">8</span></span><br><span class="line">    &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里内容大概是：</p><ol><li><code>__state</code> 标注了对应的状态</li><li><code>__cv_</code> 和 <code>__mut_</code> 表示了对应的并发状态</li><li><code>__exception_</code> 表示存在这里的异常</li></ol><p>这里也有设置状态对应的成员，包括 <code>__set_value</code> 等，基本上是处理并发和设置状态</p><p>回头看外面：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Rp</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">_LIBCPP_AVAILABILITY_FUTURE</span> _LIBCPP_HIDDEN __assoc_state</span><br><span class="line">    : <span class="keyword">public</span> __assoc_sub_state</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">typedef</span> __assoc_sub_state base;</span><br><span class="line">    <span class="keyword">typedef</span> <span class="keyword">typename</span> aligned_storage&lt;<span class="built_in">sizeof</span>(_Rp), alignment_of&lt;_Rp&gt;::value&gt;::type _Up;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    _Up __value_;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">virtual</span> <span class="type">void</span> __on_zero_shared() _NOEXCEPT;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Arg</span>&gt;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">set_value</span><span class="params">(_Arg&amp;&amp; __arg)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Arg</span>&gt;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">set_value_at_thread_exit</span><span class="params">(_Arg&amp;&amp; __arg)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">_Rp <span class="title">move</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="keyword">typename</span> add_lvalue_reference&lt;_Rp&gt;::<span class="function">type <span class="title">copy</span><span class="params">()</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里可以发现 <code>_Up</code> 存储的是对应的值，而 <code>__assoc_sub_state</code> 存储的是状态。之所以是 <code>aligned_storage</code>，是因为这是一块可能没初始化的内存。我们继续看看 <code>wait</code> 之类的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Rp</span>&gt;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Arg</span>&gt;</span><br><span class="line">_LIBCPP_AVAILABILITY_FUTURE</span><br><span class="line"><span class="type">void</span></span><br><span class="line">__assoc_state&lt;_Rp&gt;::<span class="built_in">set_value</span>(_Arg&amp;&amp; __arg)</span><br><span class="line">&#123;</span><br><span class="line">    unique_lock&lt;mutex&gt; __lk(<span class="keyword">this</span>-&gt;__mut_);</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;__has_value())</span><br><span class="line">        __throw_future_error(future_errc::promise_already_satisfied);</span><br><span class="line">    ::<span class="keyword">new</span> ((<span class="type">void</span>*)&amp;__value_) _Rp(_VSTD::forward&lt;_Arg&gt;(__arg));</span><br><span class="line">    <span class="keyword">this</span>-&gt;__state_ |= base::__constructed | base::ready;</span><br><span class="line">    __cv_.<span class="built_in">notify_all</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Rp</span>&gt;</span><br><span class="line">_Rp</span><br><span class="line">__assoc_state&lt;_Rp&gt;::<span class="built_in">move</span>()</span><br><span class="line">&#123;</span><br><span class="line">    unique_lock&lt;mutex&gt; __lk(<span class="keyword">this</span>-&gt;__mut_);</span><br><span class="line">    <span class="keyword">this</span>-&gt;__sub_wait(__lk);</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;__exception_ != <span class="literal">nullptr</span>)</span><br><span class="line">        <span class="built_in">rethrow_exception</span>(<span class="keyword">this</span>-&gt;__exception_);</span><br><span class="line">    <span class="keyword">return</span> _VSTD::<span class="built_in">move</span>(*<span class="built_in">reinterpret_cast</span>&lt;_Rp*&gt;(&amp;__value_));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Rp</span>&gt;</span><br><span class="line"><span class="keyword">typename</span> add_lvalue_reference&lt;_Rp&gt;::type</span><br><span class="line">__assoc_state&lt;_Rp&gt;::<span class="built_in">copy</span>()</span><br><span class="line">&#123;</span><br><span class="line">    unique_lock&lt;mutex&gt; __lk(<span class="keyword">this</span>-&gt;__mut_);</span><br><span class="line">    <span class="keyword">this</span>-&gt;__sub_wait(__lk);</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;__exception_ != <span class="literal">nullptr</span>)</span><br><span class="line">        <span class="built_in">rethrow_exception</span>(<span class="keyword">this</span>-&gt;__exception_);</span><br><span class="line">    <span class="keyword">return</span> *<span class="built_in">reinterpret_cast</span>&lt;_Rp*&gt;(&amp;__value_);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先，<code>__assoc_sub_state</code> 会调用 <code>__sub_wait</code>，这里会等待到 <code>__assoc_sub_state</code> 状态合理：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span></span><br><span class="line">__assoc_sub_state::__sub_wait(unique_lock&lt;mutex&gt;&amp; __lk)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (!__is_ready())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (__state_ &amp; <span class="built_in">static_cast</span>&lt;<span class="type">unsigned</span>&gt;(deferred))</span><br><span class="line">        &#123;</span><br><span class="line">            __state_ &amp;= ~<span class="built_in">static_cast</span>&lt;<span class="type">unsigned</span>&gt;(deferred);</span><br><span class="line">            __lk.<span class="built_in">unlock</span>();</span><br><span class="line">            __execute();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">while</span> (!__is_ready())</span><br><span class="line">                __cv_.<span class="built_in">wait</span>(__lk);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里相当于：</p><ol><li>设置值：拿到 <code>_sub_state</code> 的锁，然后 placement new，再在 <code>_sub_state</code> 上通知</li><li>读取值(wait) ：等待 <code>_sub_state</code> 状态设置完成，然后拿 <code>__value_</code></li></ol><p>最后，我们看看外层的 <code>future</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Rp</span>&gt;</span><br><span class="line">_Rp</span><br><span class="line">future&lt;_Rp&gt;::<span class="built_in">get</span>()</span><br><span class="line">&#123;</span><br><span class="line">    unique_ptr&lt;__shared_count, __release_shared_count&gt; __(__state_);</span><br><span class="line">    __assoc_state&lt;_Rp&gt;* __s = __state_;</span><br><span class="line">    __state_ = <span class="literal">nullptr</span>;</span><br><span class="line">    <span class="keyword">return</span> __s-&gt;<span class="built_in">move</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="promise"><a href="#promise" class="headerlink" title="promise"></a>promise</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// promise&lt;void&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">_LIBCPP_TYPE_VIS</span> _LIBCPP_AVAILABILITY_FUTURE promise&lt;<span class="type">void</span>&gt;</span><br><span class="line">&#123;</span><br><span class="line">    __assoc_sub_state* __state_;</span><br><span class="line"></span><br><span class="line">    <span class="function">_LIBCPP_INLINE_VISIBILITY</span></span><br><span class="line"><span class="function">    <span class="keyword">explicit</span> <span class="title">promise</span><span class="params">(<span class="type">nullptr_t</span>)</span> _NOEXCEPT : __state_(nullptr) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">class</span>&gt; <span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">packaged_task</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里，<code>get_future</code> 会直接返回一个 future:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Rp</span>&gt;</span><br><span class="line">future&lt;_Rp&gt;</span><br><span class="line">promise&lt;_Rp&gt;::<span class="built_in">get_future</span>()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (__state_ == <span class="literal">nullptr</span>)</span><br><span class="line">        __throw_future_error(future_errc::no_state);</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">future</span>&lt;_Rp&gt;(__state_);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们回到 future, 看看它的构造函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Rp</span>&gt;</span><br><span class="line">future&lt;_Rp&gt;::<span class="built_in">future</span>(__assoc_state&lt;_Rp&gt;* __state)</span><br><span class="line">    : __state_(__state)</span><br><span class="line">&#123;</span><br><span class="line">    __state_-&gt;__attach_future();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里依靠 <code>__assoc_sub_state&lt;_Rp&gt;::__attach_future</code> 来避免重复使用</p><h3 id="packaged-task"><a href="#packaged-task" class="headerlink" title="packaged_task"></a>packaged_task</h3><p><code>std::packaged_task</code> 类似 <code>std::function</code>，是一个类型擦除的函数，描述任务，这里还允许 <code>get_future</code> 来访问。</p><h3 id="shared-future"><a href="#shared-future" class="headerlink" title="shared_future"></a>shared_future</h3><p><code>shared_future</code> 可以包装一个 <code>future&lt;T&gt;</code>，然后多次使用，它的内容如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">template &lt;class _Rp&gt;</span><br><span class="line">class _LIBCPP_TEMPLATE_VIS shared_future</span><br><span class="line">&#123;</span><br><span class="line">    __assoc_state&lt;_Rp&gt;* __state_;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">template &lt;class _Rp&gt;</span><br><span class="line">shared_future&lt;_Rp&gt;::~shared_future()</span><br><span class="line">&#123;</span><br><span class="line">    if (__state_)</span><br><span class="line">        __state_-&gt;__release_shared();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>shared_future</code> 有一堆偏特化的版本，因为它的 <code>get</code> 会非常恶心，<code>future</code> 返回一次咋搞都行，<code>shared_future</code> 可能要处理很多语义：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Rp</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">_LIBCPP_TEMPLATE_VIS</span> shared_future&lt;_Rp&amp;&gt;</span><br><span class="line">&#123;</span><br><span class="line">    __assoc_state&lt;_Rp&amp;&gt;* __state_;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// retrieving the value</span></span><br><span class="line">    <span class="function">_LIBCPP_INLINE_VISIBILITY</span></span><br><span class="line"><span class="function">    _Rp&amp; <span class="title">get</span><span class="params">()</span> <span class="type">const</span> </span>&#123;<span class="keyword">return</span> __state_-&gt;<span class="built_in">copy</span>();&#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">_LIBCPP_TYPE_VIS</span> _LIBCPP_AVAILABILITY_FUTURE shared_future&lt;<span class="type">void</span>&gt;</span><br><span class="line">&#123;</span><br><span class="line">    __assoc_sub_state* __state_;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="std-async"><a href="#std-async" class="headerlink" title="std::async"></a>std::async</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">_Fp</span>, <span class="keyword">class</span>... _Args&gt;</span><br><span class="line">_LIBCPP_NODISCARD_AFTER_CXX17</span><br><span class="line">future&lt;<span class="keyword">typename</span> __invoke_of&lt;<span class="keyword">typename</span> decay&lt;_Fp&gt;::type, <span class="keyword">typename</span> decay&lt;_Args&gt;::type...&gt;::type&gt;</span><br><span class="line"><span class="built_in">async</span>(launch __policy, _Fp&amp;&amp; __f, _Args&amp;&amp;... __args)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">typedef</span> __async_func&lt;<span class="keyword">typename</span> decay&lt;_Fp&gt;::type, <span class="keyword">typename</span> decay&lt;_Args&gt;::type...&gt; _BF;</span><br><span class="line">    <span class="keyword">typedef</span> <span class="keyword">typename</span> _BF::_Rp _Rp;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> _LIBCPP_NO_EXCEPTIONS</span></span><br><span class="line">    <span class="keyword">try</span></span><br><span class="line">    &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">        <span class="keyword">if</span> (__does_policy_contain(__policy, launch::async))</span><br><span class="line">        <span class="keyword">return</span> _VSTD::__make_async_assoc_state&lt;_Rp&gt;(_BF(_VSTD::__decay_copy(_VSTD::forward&lt;_Fp&gt;(__f)),</span><br><span class="line">                                                     _VSTD::__decay_copy(_VSTD::forward&lt;_Args&gt;(__args))...));</span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> _LIBCPP_NO_EXCEPTIONS</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">catch</span> ( ... ) &#123; <span class="keyword">if</span> (__policy == launch::async) <span class="keyword">throw</span> ; &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (__does_policy_contain(__policy, launch::deferred))</span><br><span class="line">        <span class="keyword">return</span> _VSTD::__make_deferred_assoc_state&lt;_Rp&gt;(_BF(_VSTD::__decay_copy(_VSTD::forward&lt;_Fp&gt;(__f)),</span><br><span class="line">                                                        _VSTD::__decay_copy(_VSTD::forward&lt;_Args&gt;(__args))...));</span><br><span class="line">    <span class="keyword">return</span> future&lt;_Rp&gt;&#123;&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>里面实现大概是：</p><ol><li>创建 <code>__async_assoc_state</code> 或者 <code>__defered_assoc_state</code></li><li>lazy 或者动态的创建线程</li><li>创建 future</li></ol><h2 id="folly-Future-amp-Executor"><a href="#folly-Future-amp-Executor" class="headerlink" title="folly Future &amp; Executor"></a>folly Future &amp; Executor</h2><p>folly Future 相对于 future，原理并没有太大差异，但是外层和实现丰富了很多：</p><ol><li>使用 <code>folly::Function</code>，函数对象支持了 SBO 等</li><li><code>then</code> 等组合子，方便处理代码</li><li><p><code>via</code> 等，支持绑定 executor，并抽出了 <code>Future</code> 和 <code>SemiFuture</code> 等类型</p><p>folly 对 Future 的支持相当复杂，继承链大概包括：</p></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CoreBase</span><br><span class="line">- Core&lt;T&gt;</span><br><span class="line"></span><br><span class="line">FutureBase&lt;T&gt; (包含 Core&lt;T&gt;)</span><br><span class="line">- Future&lt;T&gt; / SemiFuture&lt;T&gt;</span><br></pre></td></tr></table></figure><p>这里的 Future 允许链式、<code>poll</code> 来查看是否成功等。<code>SemiFuture</code> 则是状态的描述。<code>Future</code> 有对应的 Executor，靠 <code>KeepAlive</code> 来指向 Executor，<code>SemiFuture</code> 则没有，除了 inline 执行（即在本线程就地执行），不会允许对应的逻辑出现。</p><p><code>CoreBase</code> 描述了 <code>Future</code> 基本的对应状态：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">///   +----------------------------------------------------------------+</span></span><br><span class="line"><span class="comment">///   |                       ---&gt; OnlyResult -----                    |</span></span><br><span class="line"><span class="comment">///   |                     /                       \                  |</span></span><br><span class="line"><span class="comment">///   |                  (setResult())             (setCallback())     |</span></span><br><span class="line"><span class="comment">///   |                   /                           \                |</span></span><br><span class="line"><span class="comment">///   |   Start ---------&gt;                              ------&gt; Done   |</span></span><br><span class="line"><span class="comment">///   |     \             \                           /                |</span></span><br><span class="line"><span class="comment">///   |      \           (setCallback())           (setResult())       |</span></span><br><span class="line"><span class="comment">///   |       \             \                       /                  |</span></span><br><span class="line"><span class="comment">///   |        \              ---&gt; OnlyCallback ---                    |</span></span><br><span class="line"><span class="comment">///   |         \           or OnlyCallbackAllowInline                 |</span></span><br><span class="line"><span class="comment">///   |          \                                  \                  |</span></span><br><span class="line"><span class="comment">///   |      (setProxy())                          (setProxy())        |</span></span><br><span class="line"><span class="comment">///   |            \                                  \                |</span></span><br><span class="line"><span class="comment">///   |             \                                   ------&gt; Empty  |</span></span><br><span class="line"><span class="comment">///   |              \                                /                |</span></span><br><span class="line"><span class="comment">///   |               \                            (setCallback())     |</span></span><br><span class="line"><span class="comment">///   |                \                            /                  |</span></span><br><span class="line"><span class="comment">///   |                  --------&gt; Proxy ----------                    |</span></span><br><span class="line"><span class="comment">///   +----------------------------------------------------------------+</span></span><br></pre></td></tr></table></figure><p>因为要描述下一个任务这样的 chain，所以这套逻辑还是比较恶心的。此外，<code>folly::Future</code> 逻辑涉及了对应的 <code>Executor</code>，每个 future 会有 dispatch 给谁的逻辑，这个和链式一样，引入了复杂度。</p><h2 id="Why-are-futures-slow"><a href="#Why-are-futures-slow" class="headerlink" title="Why are futures slow"></a>Why are futures slow</h2><p>future 在 C++ 中出现在 C++11 的标准库，而别的语言也常有类似的东西。它是由库来实现的。类似 <code>std::function</code>，<code>std::future</code> 是堆上的、类型擦除的。这两部分抽象都带来了一定的开销。</p><p>之后会分别介绍 Seastar future、Rust future、C++ executors，来看看它们是怎么抽象的。简单来说：</p><ol><li>C++ executors 会有 sender / receiver，用模版类型来封装他们，然后提供了各种算法来做抽象</li><li>Rust 靠 <code>Future&lt;T&gt;</code> 来抽象，<code>Box&lt;Future&lt;T&gt;&gt;</code> 来表示动态一些的对象。<code>Future&lt;T&gt;</code> 需要可以 <code>poll()</code>，上层的状态机来 polling，做查询</li><li>seastar 靠模型的抽象，来简化了相关的逻辑。</li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><p>libcxx future</p></li><li><p>folly future</p></li><li><p>浅谈The C++ Executors <a href="https://zhuanlan.zhihu.com/p/395250667">https://zhuanlan.zhihu.com/p/395250667</a> (绝世好文)</p></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Parquet Part1: Basic</title>
      <link href="/2022/09/18/Parquet-Part1-Basic/"/>
      <url>/2022/09/18/Parquet-Part1-Basic/</url>
      
        <content type="html"><![CDATA[<p>Parquet 是一个由 Google Dremel 格式启发而来的列存格式，在大数据领域通常作为存储格式，被 iceberg 等湖、各种查询引擎能够合理的使用。Parquet 的格式定义在<a href="https://github.com/apache/parquet-format">https://github.com/apache/parquet-format</a> ，由于大数据事实标准语言是 Java，所以其 Java 实现(  <a href="https://github.com/apache/parquet-mr">https://github.com/apache/parquet-mr</a> ) 较为完善。C++ 实现目前在 arrow 的仓库下：<a href="https://github.com/apache/arrow/tree/master/cpp/src/parquet">https://github.com/apache/arrow/tree/master/cpp/src/parquet</a> 。它的功能实现的不是很完善，具体可以见: <a href="https://arrow.apache.org/docs/cpp/parquet.html">https://arrow.apache.org/docs/cpp/parquet.html</a></p><p>Parquet 在最早被描述为 HDFS 上的格式，所以有 HDFS Block/File 相关的概念。</p><p>此外，有一些地方会专门在自己仓库里实现了一些 parquet 特性，在 2011 年这格式被提出来的时候，相关处理逻辑还是比较复杂的，可能有的人自己实现了一套，又和自己的数据结构很紧密，比如 Impala 实现了一套 parquet 有关的逻辑。这里我将会介绍一下 parquet 和官方的代码，带大家走进黑暗的格式</p><h2 id="Format"><a href="#Format" class="headerlink" title="Format"></a>Format</h2><p><img src="https://image.mwish.me/blog-image/68747470733a2f2f7261772e6769746875622e636f6d2f6170616368652f706172717565742d666f726d61742f6d61737465722f646f632f696d616765732f46696c654c61796f75742e676966.gif" alt="68747470733a2f2f7261772e6769746875622e636f6d2f6170616368652f706172717565742d666f726d61742f6d61737465722f646f632f696d616765732f46696c654c61796f75742e676966"></p><h3 id="Footer-部分"><a href="#Footer-部分" class="headerlink" title="Footer 部分"></a>Footer 部分</h3><p>这图大概如上所示，然后官方介绍的很好：</p><ol><li>读这个，首先要找到 tailer，发现满足对应的 magic number 和 footer length。<em>反过来说，metadata 只在 结尾，允许整个文件只写一次</em>，</li><li><code>Footer</code> 有文件的元信息，用 ThriftCompactProtocol 描述，这里相对 thrift 原本 binary，可能会有一些 varint zigzag 什么的<ol><li>version 应该是 Parquet 内部的信息，在 thrift 里面标明了格式的版本，这里有个<a href="https://github.com/apache/arrow/pull/13665">有趣的 issue</a>，逻辑问题来自于 file 低版本的时候，Page 可能没带版本。</li><li>Schema 代表 RowGroup 的 schema，<strong>所有 RowGroup 都需要是这个 Schema</strong>。schema 感觉其实可能不小，有 name / type (在递归定义中的 path) 等，还有一些子节点相关的信息。这里还有一个很重要的信息 <strong>field id</strong>, 这是上层传下来的，唯一的字段的 id，上层可以用这个字段来做一些 schema evolution 相关的逻辑<ol><li>Schema 类型只是 Parquet 的类型，其中外部的 SQL / 用户类型实际上和 Parquet 内部这些类型不一定能对上，类型需要额外做一层映射 / Hack，可能会借助额外的 Attributes。</li></ol></li><li>Extra key/value pairs 可以塞一些信息，在 arrow 的 compute 模块里，用它来塞了一些和计算有关的逻辑。这块我觉得有点矛盾，因为一个读者必须拿到 writer、收集一些信息或者什么的，才会好放进去，我看一般的库基本没有暴露这个接口出去的，感觉基本上是给一些能改得动 parquet 的人开洞用的。</li></ol></li><li>剩下会给出每个 RowGroup 的元信息，里面包括每个 Column 的元信息。这里的单位是 RowGroup，没有 Page 粒度的信息。它相当于在 parquet.thrift 里面的 <code>RowGroup</code> 里面给了定义。每个 RowGroup 有<strong>所有</strong> Columns 的定义，这里会有<ol><li>指向数据块头的 <code>file_offset</code>，数据页头也是个 thrift 结构，这里可能会 duplicate 一份（结构上有一个 <code>optional ColumnMetaData</code>，在标准上允许你写或者不写，估摸着看实现），这个结构叫做 <code>ColumnMetaData</code>。我们之后介绍数据页的时候，会介绍这里。<ol><li>注意 <code>ColumnMetaData</code> 上有一个 <code>num_values</code>，这里代表的是「包括 nulls，这个 <code>ColumnChunk</code> 对应值的数量」而非「这个 <code>ColumnChunk</code> 对应行的数量」。这个地方我说的可能有一点难理解，比如对于 <code>optional i32</code> 的平坦数据，这里等价于行数，而对于 <code>repeated &lt;optional i32&gt;</code>，这里代表内层的数量。<code>PageHeader</code> 的 <code>num_values</code> 也同理。</li><li>总文件的 <code>FileMetaData</code>、RowGroup 的元数据、DataPageV2 会有 <code>num_rows</code>，表示对应行的数量。<strong>在有嵌套的情况下，这个不等于 <code>num_values</code></strong>.</li></ol></li><li>会有一些 PageIndex 相关的偏移量，这里可能指向 OffsetIndex 和 ColumnIndex. 注意，这里指向的是 <strong>RowGroup 的 Index</strong>。</li><li>会有字典页相关的记录，如果采用了字典编码，ColumnChunk 的第一个页面会是字典页</li><li>记录了总行数，未压缩的大小（未经过压缩，但已经 Encoding），压缩后的大小，RowGroup 对应的位置（即这个 rg 之前的总行数）</li><li>有一个特殊的 <code>SortingColumns</code>，标识这个 RowGroup 按照什么排序。这里类似数据库的 <code>SortingColumn</code>，会有一些 <code>nulls_first</code> 的处理什么的。这里还有一些和类型相关的排序要求 <code>ColumnOrder</code>，会把类型编码到对应的逻辑中。<strong>注意，sorting 是 RowGroup 级别的 sorting，格式应该没有强制整个文件用一样的 sorting</strong> （我觉得这里很鸡贼，schema 用的是同一份，但是 sorting 却并不是…）。</li></ol></li></ol><p>给出一张总图：</p><p><img src="https://image.mwish.me/blog-image/FileFormat.gif" alt="FileFormat"></p><h3 id="数据部分"><a href="#数据部分" class="headerlink" title="数据部分"></a>数据部分</h3><p>元信息中，<code>ColumnChunk</code> 会包含对应的 <code>file_path</code> 和 <code>file_offset</code>，这点 <strong>允许数据分布在别的文件</strong>. 数据文件的分布大概是：</p><ul><li>RowGroup 包含一个或者多个 ColumnChunk</li><li>ColumnChunk 包含一个或者多个 Page，也包含了各种元信息</li></ul><p><strong>注意，ColumnChunk 的元信息（ColumnMetaData）也存放在 ColumnChunk 的尾部</strong>，在 IO 完成后写入。</p><h2 id="类型系统和逻辑类型"><a href="#类型系统和逻辑类型" class="headerlink" title="类型系统和逻辑类型"></a>类型系统和逻辑类型</h2><h3 id="基础类型"><a href="#基础类型" class="headerlink" title="基础类型"></a>基础类型</h3><p>Parquet 只支持一组很小的基础类型，叫做 <code>Type</code>，我们需要把它和后文的 <code>LogicalType</code> 区分开来：</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Types supported by Parquet.  These types are intended to be used in combination</span></span><br><span class="line"><span class="comment"> * with the encodings to control the on disk storage format.</span></span><br><span class="line"><span class="comment"> * For example INT16 is not included as a type since a good encoding of INT32</span></span><br><span class="line"><span class="comment"> * would handle this.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">enum </span><span class="title class_">Type</span> &#123;</span><br><span class="line">  BOOLEAN = <span class="number">0</span>;</span><br><span class="line">  INT32 = <span class="number">1</span>;</span><br><span class="line">  INT64 = <span class="number">2</span>;</span><br><span class="line">  INT96 = <span class="number">3</span>;  <span class="comment">// deprecated, only used by legacy implementations.</span></span><br><span class="line">  FLOAT = <span class="number">4</span>;</span><br><span class="line">  DOUBLE = <span class="number">5</span>;</span><br><span class="line">  BYTE_ARRAY = <span class="number">6</span>;</span><br><span class="line">  FIXED_LEN_BYTE_ARRAY = <span class="number">7</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里物理为啥最低支持 INT32? 因为作者似乎认为 i16 i8 能比较好被压缩。（2023.2.2: 目前似乎在讨论在 spec 里面加入窄浮点数）。</p><p>这个字段配合一个 <code>LogicalType</code>，共同组成了需要的类型：</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * LogicalType annotations to replace ConvertedType.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * To maintain compatibility, implementations using LogicalType for a</span></span><br><span class="line"><span class="comment"> * SchemaElement must also set the corresponding ConvertedType from the</span></span><br><span class="line"><span class="comment"> * following table.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">union LogicalType &#123;</span><br><span class="line">  <span class="number">1</span>:  StringType STRING       <span class="comment">// use ConvertedType UTF8</span></span><br><span class="line">  <span class="number">2</span>:  MapType MAP             <span class="comment">// use ConvertedType MAP</span></span><br><span class="line">  <span class="number">3</span>:  ListType LIST           <span class="comment">// use ConvertedType LIST</span></span><br><span class="line">  <span class="number">4</span>:  EnumType ENUM           <span class="comment">// use ConvertedType ENUM</span></span><br><span class="line">  <span class="number">5</span>:  DecimalType DECIMAL     <span class="comment">// use ConvertedType DECIMAL</span></span><br><span class="line">  <span class="number">6</span>:  DateType DATE           <span class="comment">// use ConvertedType DATE</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// use ConvertedType TIME_MICROS for TIME(isAdjustedToUTC = *, unit = MICROS)</span></span><br><span class="line">  <span class="comment">// use ConvertedType TIME_MILLIS for TIME(isAdjustedToUTC = *, unit = MILLIS)</span></span><br><span class="line">  <span class="number">7</span>:  TimeType TIME</span><br><span class="line"></span><br><span class="line">  <span class="comment">// use ConvertedType TIMESTAMP_MICROS for TIMESTAMP(isAdjustedToUTC = *, unit = MICROS)</span></span><br><span class="line">  <span class="comment">// use ConvertedType TIMESTAMP_MILLIS for TIMESTAMP(isAdjustedToUTC = *, unit = MILLIS)</span></span><br><span class="line">  <span class="number">8</span>:  TimestampType TIMESTAMP</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 9: reserved for INTERVAL</span></span><br><span class="line">  <span class="number">10</span>: IntType INTEGER         <span class="comment">// use ConvertedType INT_* or UINT_*</span></span><br><span class="line">  <span class="number">11</span>: NullType UNKNOWN        <span class="comment">// no compatible ConvertedType</span></span><br><span class="line">  <span class="number">12</span>: JsonType JSON           <span class="comment">// use ConvertedType JSON</span></span><br><span class="line">  <span class="number">13</span>: BsonType BSON           <span class="comment">// use ConvertedType BSON</span></span><br><span class="line">  <span class="number">14</span>: UUIDType UUID</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里它有个 <code>ConvertedType</code>，基本上是兼容旧屎山了，属于旧代码。有一些特殊类型需要注意一下：</p><ol><li>Decimal/Time 可能根据精度/代表的东西不同，物理的表示是不一样的</li><li>对于 struct，外头相当于只会把叶子结点编码，但是还是有一些复杂类型的，比如 LIST 和 MAP:<ol><li>List 相当于 2个元素，<code>LIST&lt;int&gt;</code> 里面，外面的 List 是一组标记，里面 int 又是一组标记</li><li>Map 则相当于三个, <code>Map&lt;K, V&gt;</code> 里面，<code>Map</code> <code>K</code> <code>V</code> 都是标记</li></ol></li></ol><p>有一点需要注意的是，只有 Leaf 节点拥有 <code>Type</code>，它不可能是 Map, List, Struct. 中间的节点可能会是：</p><ol><li>List, Map, Struct 之类的嵌套类型</li><li>别的对应的逻辑类型</li></ol><p>嵌套结构定义其实还挺啰嗦的，这段代码看着还是很恶心的，但是很清晰，可以试看下图：</p><p>List (最外层的 optional 是 List 是否 optional, 里面的是 List member 是否 optional) :</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;list-repetition&gt; <span class="keyword">group</span> &lt;name&gt; (LIST) &#123;</span><br><span class="line">  <span class="keyword">repeated</span> <span class="keyword">group</span> list &#123;</span><br><span class="line">    &lt;element-repetition&gt; &lt;element-type&gt; element;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述是理想场景的 List，下列是读取的时候会遇到的一些奇怪的东西的兼容性：<a href="https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#backward-compatibility-rules">https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#backward-compatibility-rules</a></p><p>Map 的 Key 则需要一个字段，而且必须要 non-null:</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;map-repetition&gt; <span class="keyword">group</span> &lt;name&gt; (MAP) &#123;</span><br><span class="line">  <span class="keyword">repeated</span> <span class="keyword">group</span> key_value &#123;</span><br><span class="line">    <span class="keyword">required</span> &lt;key-type&gt; key;</span><br><span class="line">    &lt;value-repetition&gt; &lt;value-type&gt; value;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>To be honest, 我总觉得存 Map 的话，做不到二分，不过 arrow 的 Map 应该也是这么草台的？</p><p>这里也要考虑兼容性：<a href="https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#backward-compatibility-rules-1">https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#backward-compatibility-rules-1</a></p><h3 id="Sort-Order-amp-Statistics"><a href="#Sort-Order-amp-Statistics" class="headerlink" title="Sort Order &amp; Statistics"></a>Sort Order &amp; Statistics</h3><ul><li>这个地方我不确定自己完全看懂了，因为 Sort Order 在 C++ 实现的时候很 Shit，必须要有 SortOrder 和 Comparable 的信息才能够生成对应的</li><li>至少在今天(2023.2.2)，parquet-format 页面上的描述不是很清晰。但是 parquet.thrift 的定义是十分清晰的</li></ul><p>我直接介绍一下 Parquet-format 的定义，避免说车轱辘话：</p><ol><li>LogicalType Order: 由 LogicalType 定义的 Order，这套东西最好做到标准上，不然应该不太合法<ol><li>目前标准上给每个 LogicalType 都有 Order 相关的定义，如果是用户映射的类型，可能要注意相关的定义</li></ol></li><li>Type：按照 Type 的定义来行为。其中 INT 强制有符号比较，bytes 类的类型强制 byte 比较<ol><li>比较 Trickey 的是浮点数类型，这里 Spec 应该写了如何处理，比较 Trickey: <a href="https://github.com/apache/parquet-format/blob/master/src/main/thrift/parquet.thrift#L888">https://github.com/apache/parquet-format/blob/master/src/main/thrift/parquet.thrift#L888</a></li></ol></li></ol><p>在 C++ 版本代码中，如果不可比较，就不会生成任何 Statistics。这个显然是有问题的。</p><p>Statistics 在 Parquet 中<strong>「永远」</strong> 是 optional 的，下面我把兼容性字段裁剪掉了贴一下 Statistics:</p><figure class="highlight thrift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Statistics per row group and per page</span></span><br><span class="line"><span class="comment"> * All fields are optional.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Statistics</span> </span>&#123;</span><br><span class="line">   <span class="comment">/** count of null value in the column */</span></span><br><span class="line">   <span class="number">3</span>: <span class="keyword">optional</span> <span class="type">i64</span> null_count;</span><br><span class="line">   <span class="comment">/** count of distinct values occurring */</span></span><br><span class="line">   <span class="number">4</span>: <span class="keyword">optional</span> <span class="type">i64</span> distinct_count;</span><br><span class="line">   <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Min and max values for the column, determined by its ColumnOrder.</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * Values are encoded using PLAIN encoding, except that variable-length byte</span></span><br><span class="line"><span class="comment">    * arrays do not include a length prefix.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="number">5</span>: <span class="keyword">optional</span> <span class="type">binary</span> max_value;</span><br><span class="line">   <span class="number">6</span>: <span class="keyword">optional</span> <span class="type">binary</span> min_value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>max_value</code> 和 <code>min_value</code> 都是类型自定义的，按照对应的内容解析。</p><h3 id="SchemaElement"><a href="#SchemaElement" class="headerlink" title="SchemaElement"></a>SchemaElement</h3><p><code>SchemaElement</code> 是 Parquet Schema 的最重要部分之一，没 Statistics 你还能活，没 SchemaElement 就笑嘻了。理解 SchemaElement 也能帮助理解 Nested Type 的处理:</p><figure class="highlight thrift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Represents a element inside a schema definition.</span></span><br><span class="line"><span class="comment"> *  - if it is a group (inner node) then type is undefined and num_children is defined</span></span><br><span class="line"><span class="comment"> *  - if it is a primitive type (leaf) then type is defined and num_children is undefined</span></span><br><span class="line"><span class="comment"> * the nodes are listed in depth first traversal order.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">SchemaElement</span> </span>&#123;</span><br><span class="line">  <span class="comment">/** Data type for this field. Not set if the current element is a non-leaf node */</span></span><br><span class="line">  <span class="number">1</span>: <span class="keyword">optional</span> Type type;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** repetition of the field. The root of the schema does not have a repetition_type.</span></span><br><span class="line"><span class="comment">   * All other nodes must have one */</span></span><br><span class="line">  <span class="number">3</span>: <span class="keyword">optional</span> FieldRepetitionType repetition_type;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Name of the field in the schema */</span></span><br><span class="line">  <span class="number">4</span>: <span class="keyword">required</span> <span class="type">string</span> name;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Nested fields.  Since thrift does not support nested fields,</span></span><br><span class="line"><span class="comment">   * the nesting is flattened to a single list by a depth-first traversal.</span></span><br><span class="line"><span class="comment">   * The children count is used to construct the nested relationship.</span></span><br><span class="line"><span class="comment">   * This field is not set when the element is a primitive type</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">5</span>: <span class="keyword">optional</span> <span class="type">i32</span> num_children;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** When the original schema supports field ids, this will save the</span></span><br><span class="line"><span class="comment">   * original field id in the parquet schema</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">9</span>: <span class="keyword">optional</span> <span class="type">i32</span> field_id;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * The logical type of this SchemaElement</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * LogicalType replaces ConvertedType, but ConvertedType is still required</span></span><br><span class="line"><span class="comment">   * for some logical types to ensure forward-compatibility in format v1.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">10</span>: <span class="keyword">optional</span> LogicalType logicalType</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的结构中我去掉了兼容性有关的字段，和类型 Specific 的字段。可以从 <code>Type</code> 和 <code>LogicalType</code> 的存在性来理解。这个结构会以 depth-first 的形式出现在 FileMetaData 的 Schema 中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Description for file metadata</span><br><span class="line"> */</span><br><span class="line">struct FileMetaData &#123;</span><br><span class="line">  /** Version of this file **/</span><br><span class="line">  1: required i32 version</span><br><span class="line"></span><br><span class="line">  /** Parquet schema for this file.  This schema contains metadata for all the columns.</span><br><span class="line">   * The schema is represented as a tree with a single root.  The nodes of the tree</span><br><span class="line">   * are flattened to a list by doing a depth-first traversal.</span><br><span class="line">   * The column metadata contains the path in the schema for that column which can be</span><br><span class="line">   * used to map columns to nodes in the schema.</span><br><span class="line">   * The first element is the root **/</span><br><span class="line">  2: required list&lt;SchemaElement&gt; schema;</span><br></pre></td></tr></table></figure><p>可以感受一下 Leaf Schema 和 non-leaf 的区别。</p><h2 id="Data-amp-Page"><a href="#Data-amp-Page" class="headerlink" title="Data &amp; Page"></a>Data &amp; Page</h2><p>DataPage 和 Dictionary Page 是系统的重要部分，承载数据。RowGroup 中，每一列会有一个或多个 Page 存在。Page 会有一个 PageHeader，里面可能包含 <code>DataPageHeader</code> 或者 <code>DictionaryPageHeader</code> 或者 <code>DataPageHeaderV2</code>，而 RowGroup 没有 Header，RowGroup 靠偏移量指向每列的第一个 Page。关于 Page 的其他信息，则可以在 <code>PageIndex</code> 中找到，后文再提这些信息。</p><p>PageHeader 会有一些 size 之类的元信息，不过本身 RowGroup 的 Metadata 也有一份这些信息。</p><p>数据可能会有编码之类的，Encoding 和 Compression 都以 Page 为粒度，在 Page 解析的时候会读到对应的标记。为什么呢？因为压缩的时候，这里会有一定的 fallback 策略，row group 不一定有同一个策略。</p><p>里面 repetition level 和 definition level 会紧随在 Page Header 后，这里也会标识他们的长度，这两列会以 RLE 形式被压缩。之后就是 values 的具体编码了。当然，这两个不一定会写入：</p><ol><li>如果没有 nested 定义的话，是不需要 repetition level 的</li><li>如果路径上没有 nullable 的字段的话，是不需要 definition level 的</li></ol><p>具体读取和写入的时候，会按照 ColumnChunk 为单位写入。具体而言，Page 就是某列 Column Chunk 内一批数据而已。</p><p><strong>依照 ColumnChunk 为单位写入</strong>是一个很蛋疼的事情，arrow 的 parquet 实现中，提供了 <code>buffer</code> 和非 buffer 的 io，如果用户是先写完第一个 Column，再写第二个 Column，那么就可以：</p><ol><li>写完第一个 Column 所有内容，写完多个 Page，进行 io，写到文件。当然也可以一个个 Page 写进去。</li><li>第二个 Column 开始同一个步骤…</li></ol><p>所以如果按行或者 vectorized data 写的话，io 其实不太可能完全按照第一个 Column —&gt; 第二个 Column 这样写，所以实际上可能是：</p><ol><li>RowGroup 所有的写都 buffer 在内存里</li><li>监测到要切 row group，然后一起 buffer 写了</li></ol><p>这里还会有 Statistics，包括 Page 包含多少行数据、里面对应 min-max 为何。这部分其实有一部分和 Page Index 功能是重叠的。</p><h3 id="V1-vs-V2"><a href="#V1-vs-V2" class="headerlink" title="V1 vs V2"></a>V1 vs V2</h3><p>DataPage 有两个版本 V1 和 V2，目前，大部分地方没有广泛使用 DataPageV2。</p><p>这两个格式主要区别是 rep-level 和 def-level 的处理，V1 中，两个 level 会和数据一起被压缩；V2 中，两个 level 并未被压缩。此外还有些比较微小的区别，具体可以看 thrift 的定义了。</p><p>在内存中，DataPage 内存存储方式都是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(optional 的 16位数组) rep-levels</span><br><span class="line">(optional 的 16位数组) def-levels</span><br><span class="line">data</span><br></pre></td></tr></table></figure><p>levels 的长度由 Header 来标识。</p><h3 id="切分-Data-amp-Page"><a href="#切分-Data-amp-Page" class="headerlink" title="切分 Data &amp; Page"></a>切分 Data &amp; Page</h3><p>官方可以根据 Row Group Size (推荐 512M - 1GB) 和 Page Size（推荐 8kB）来切分。值得一提的是，感觉这个格式基本没做 Random Access 优化，读取都是 Page 为单位的。</p><h3 id="CRC32"><a href="#CRC32" class="headerlink" title="CRC32"></a>CRC32</h3><p>Page 会对「上面的数据」做 crc，Page 本身不会做 CRC。</p><p>另外，我翻了一下绝大多数实现，截至 2022.10.19，parquet-mr 只有 DataPageV1 和 Dictionary Page 会写 CRC，C++/Rust 版本基本都没写 crc。考虑到之前很多地方落在 S3 / HDFS 上，其实可以理解，但引入了本地 SSD 缓存之后，恐怕没有 CRC 真的就死路一条了，笔者正在给 C++ 标准的 Parquet 实现 crc。</p><h2 id="Encoding"><a href="#Encoding" class="headerlink" title="Encoding"></a>Encoding</h2><p>Parquet 官方规定的 encoding 数量不多，而且实现看上去有点大病。比如字典的实现是：</p><ol><li>先死命往字典里放</li><li>字典空间过大了就 fallback 到 PLAIN<ol><li>这个地方 fallback 到 PLAIN 这个说法比较让人困惑，因为每个 ColumnChunk (RowGroup 内的单个 Column) 是只有一个字典页的，这里编码的时候，会不断往字典里面添加内容，然后之前的页面会缓存下来。如果发现过大，这里会写完之前的字典 + 数据页面</li></ol></li></ol><p>看上去就很傻逼。</p><p>不过，有的地方字典会规定是有序的，Parquet 并没有规定字典本身是有序的，但在字典页面上提供了</p><p>编码的格式见：<a href="https://github.com/apache/parquet-format/blob/master/Encodings.md">https://github.com/apache/parquet-format/blob/master/Encodings.md</a></p><ul><li><p>PLAIN 格式：啥都没有，直接写数据</p><ul><li>关于变长的字段，这里会有 BYTE_ARRAY: 写4B -&gt; 写数据</li></ul></li><li>字典会有 <code>PLAIN_DICTIONARY</code> 和 <code>RLE_DICTIONARY</code>。字典压缩本身会压完一列，然后在<strong>数据页之前</strong>会有字典页，字典页推荐用 PLAIN 格式。<ul><li>同一个 ColumnChunk 共用一个字典，但是可能里面有的页面不用字典编码。</li></ul></li><li>RLE: parquet 推荐的是 RLE + Bit-packing 混合模式，这个地方是「走 RLE 或者走 bit-packing」，这段在 RFC 里面介绍非常鬼畜，建议找代码注释读。</li><li>DELTA: 先走 delta，再走 bit-packing，数据在 bit-packing 层会被压到一堆 miniblocks 里面</li><li>Delta-length byte array: Delta 编码以下所有字符的<strong>长度</strong>，再把内容拼贴</li><li>Delta Strings: 前缀压缩</li></ul><p>关于编码的选择，parquet 没有做任何实现和规定，建议运行的时候 xjb 选吧。Encoding 的格式会标注在 Page 的里面，因为可能同一个 ColumnChunk 的不同 Page 编码方式不一样。</p><h2 id="Page-Index"><a href="#Page-Index" class="headerlink" title="Page Index"></a>Page Index</h2><p><img src="https://image.mwish.me/blog-image/PageIndexLayout.png" alt="PageIndexLayout"></p><p>我们注意到，Metadata 只有 rowgroup 层面的信息，Page 层面的位置和大小，都需要走 PageIndex。这个可以做一些细粒度的裁剪。 Metadata 的 Column 中，会有地方指向这几段。</p><p>PageIndex 希望让点查、Range Scan on sorting columns、Selection 能够以跳过不需要扫描 Page 的方式节省 IO / 计算的资源，<em>同时 full scan 不用扫描这部分数据，让这部分尽量没有开销</em></p><p>PageIndex 描述在 FileMetaData 之前，也就是接近文件尾部的地方。</p><p>PageIndex 是以文件中整个 Column 为粒度的数据，PageIndex 包含两个部分：ColumnIndex 和 OffsetIndex:</p><ol><li>ColumnIndex 会标志某个 RowGroup 的某个 Column  内的各个 Page 的 Range 信息，包括 min-max 。<ol><li>这里有点类似 RocksDB，每列可以存放压缩的值，比如 “ab” “db” 可以存 “a” “d”.</li><li>Statistics 的问题见 <code>Sort Order</code> 一节，其实目前的实现还是有比较大问题的.</li></ol></li><li>OffsetIndex 会标记各个 RowGroup 对应的 Page 的偏移量</li></ol><p>这部分的 Page 类型为 <code>INDEX_PAGE</code>, 对应 thrift 结构如下：</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">struct PageLocation &#123;</span><br><span class="line">  <span class="comment">/** Offset of the page in the file **/</span></span><br><span class="line">  <span class="number">1</span>: <span class="keyword">required</span> i64 offset</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Size of the page, including header. Sum of compressed_page_size and header</span></span><br><span class="line"><span class="comment">   * length</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">2</span>: <span class="keyword">required</span> i32 compressed_page_size</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Index within the RowGroup of the first row of the page; this means pages</span></span><br><span class="line"><span class="comment">   * change on record boundaries (r = 0).</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">3</span>: <span class="keyword">required</span> i64 first_row_index</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct OffsetIndex &#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * PageLocations, ordered by increasing PageLocation.offset. It is required</span></span><br><span class="line"><span class="comment">   * that page_locations[i].first_row_index &lt; page_locations[i+1].first_row_index.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">1</span>: <span class="keyword">required</span> list&lt;PageLocation&gt; page_locations</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Description for ColumnIndex.</span></span><br><span class="line"><span class="comment"> * Each &lt;array-field&gt;[i] refers to the page at OffsetIndex.page_locations[i]</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line">struct ColumnIndex &#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * A list of Boolean values to determine the validity of the corresponding</span></span><br><span class="line"><span class="comment">   * min and max values. If true, a page contains only null values, and writers</span></span><br><span class="line"><span class="comment">   * have to set the corresponding entries in min_values and max_values to</span></span><br><span class="line"><span class="comment">   * byte[0], so that all lists have the same length. If false, the</span></span><br><span class="line"><span class="comment">   * corresponding entries in min_values and max_values must be valid.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">1</span>: <span class="keyword">required</span> list&lt;<span class="type">bool</span>&gt; null_pages</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Two lists containing lower and upper bounds for the values of each page</span></span><br><span class="line"><span class="comment">   * determined by the ColumnOrder of the column. These may be the actual</span></span><br><span class="line"><span class="comment">   * minimum and maximum values found on a page, but can also be (more compact)</span></span><br><span class="line"><span class="comment">   * values that do not exist on a page. For example, instead of storing &quot;&quot;Blart</span></span><br><span class="line"><span class="comment">   * Versenwald III&quot;, a writer may set min_values[i]=&quot;B&quot;, max_values[i]=&quot;C&quot;.</span></span><br><span class="line"><span class="comment">   * Such more compact values must still be valid values within the column&#x27;s</span></span><br><span class="line"><span class="comment">   * logical type. Readers must make sure that list entries are populated before</span></span><br><span class="line"><span class="comment">   * using them by inspecting null_pages.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">2</span>: <span class="keyword">required</span> list&lt;binary&gt; min_values</span><br><span class="line">  <span class="number">3</span>: <span class="keyword">required</span> list&lt;binary&gt; max_values</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Stores whether both min_values and max_values are orderd and if so, in</span></span><br><span class="line"><span class="comment">   * which direction. This allows readers to perform binary searches in both</span></span><br><span class="line"><span class="comment">   * lists. Readers cannot assume that max_values[i] &lt;= min_values[i+1], even</span></span><br><span class="line"><span class="comment">   * if the lists are ordered.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="number">4</span>: <span class="keyword">required</span> BoundaryOrder boundary_order</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** A list containing the number of null values for each page **/</span></span><br><span class="line">  <span class="number">5</span>: <span class="keyword">optional</span> list&lt;i64&gt; null_counts</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>别的字段都比较简单，<code>boundary_order</code> 专门记录了 Page Index 的顺序性。至少是 RowGroup 内的顺序性。</p><h2 id="BloomFilter"><a href="#BloomFilter" class="headerlink" title="BloomFilter"></a>BloomFilter</h2><p><img src="https://image.mwish.me/blog-image/FileLayoutBloomFilter1.png" alt="FileLayoutBloomFilter1"></p><p>BloomFilter 官方实现有两种位置。官方有一个 RowGroup 的 BloomFilter，对需要构建的列构建 BF。值得一提的是，代码实现中，这里需要提前 guess （或者预知）行数，来提前分配 BloomFilter。</p><p>这里的 BloomFilter 算法和 RocksDB 的类似，具体数学可以参考：<a href="https://github.com/facebook/rocksdb/wiki/RocksDB-Bloom-Filter#the-math">https://github.com/facebook/rocksdb/wiki/RocksDB-Bloom-Filter#the-math</a> . 不过看了一下代码后，感觉 RocksDB 做的要细很多。</p><h2 id="Nested-Structure-and-NULL-Serde"><a href="#Nested-Structure-and-NULL-Serde" class="headerlink" title="Nested Structure and NULL: Serde"></a>Nested Structure and NULL: Serde</h2><p>nested 和 null 都是靠 definition level 和 repitition level 来完成的。对于两个 level，这里会用 <code>RLE</code> 进行编码，然后存放在 Page 上，每个 Page 包含的逻辑内容大概是：</p><ol><li>Page Header</li><li>Repitition Levels</li><li>Definition Levels</li><li>具体的值</li></ol><p>给一个 <code>Dremel</code> 论文中的 schema 定义：</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">message </span><span class="title class_">Document</span> &#123;</span><br><span class="line">  <span class="keyword">required</span> <span class="type">int64</span> DocId;</span><br><span class="line">  <span class="keyword">optional</span> <span class="keyword">group</span> Links &#123;</span><br><span class="line">    <span class="keyword">repeated</span> <span class="type">int64</span> Backward;</span><br><span class="line">    <span class="keyword">repeated</span> <span class="type">int64</span> Forward; </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">repeated</span> <span class="keyword">group</span> Name &#123;</span><br><span class="line">    <span class="keyword">repeated</span> <span class="keyword">group</span> Language &#123;</span><br><span class="line">      <span class="keyword">required</span> <span class="type">string</span> Code;</span><br><span class="line">      <span class="keyword">optional</span> <span class="type">string</span> Country; </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">optional</span> <span class="type">string</span> Url; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Repetition-Levels"><a href="#Repetition-Levels" class="headerlink" title="Repetition Levels"></a>Repetition Levels</h3><p>先 repetition levels, 这里只需要保存有值的字段：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DocId</span><br><span class="line">Links.Backward</span><br><span class="line">Links.Forward</span><br><span class="line">Name.Language.Code</span><br><span class="line">Name.Language.Country</span><br><span class="line">Name.Url</span><br></pre></td></tr></table></figure><p>repeatable 的字段是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Links.Backward</span><br><span class="line">Links.Forward</span><br><span class="line">Name</span><br><span class="line">Name.Language</span><br></pre></td></tr></table></figure><p>可以看到，对于一个 <code>Name.Language.Code</code>，它既可能是属于<strong>新的 Name</strong> , 也可能属于 <code>Name</code> 下新的 Language。 那么，对于 <code>repetition</code> 来说，就是「它在哪个级别 repeat 了」。</p><p>那么，如果是某个值「父亲不存在，导致应该存在的值不存在」的话，比如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Document &#123;</span><br><span class="line">  DocId: ...,</span><br><span class="line">  Name: ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个时候，LinkID 是残缺的，这里可以补一个 <code>NULL</code> 的虚拟记录，然后标注一下 r 就可以了</p><h3 id="definition-levels"><a href="#definition-levels" class="headerlink" title="definition levels"></a>definition levels</h3><p>对于某个字段，它的路径上有多少值是「可以不存在」的，可以不存在即 Schema 定义为 nullable 或者 repeated 的字段。这个字段也包括自身（如果自己是 nullable 或者 repeatable 的话）。这个路径也需要理解一下：</p><ol><li>对于非嵌套的字段，如果它是个 optional 的，且为 null，那么自己的 definition levels 就为 0，否则为 1</li><li>嵌套的字段取决于父级对应的字段，<em>parent的一行</em> 数据的某一列至少有一个 d (这话有点模糊，我指的是，如果父亲是 null，这玩意也得带个 d，虽然这行数据不存在)</li></ol><p><img src="https://image.mwish.me/blog-image/C4B586F5-3356-4CCD-AC3B-A9D22E671185.png" alt="C4B586F5-3356-4CCD-AC3B-A9D22E671185"></p><h3 id="编码和解码"><a href="#编码和解码" class="headerlink" title="编码和解码"></a>编码和解码</h3><p>这里可以看到，其实不是所有字段都需要 r/d 的，比如 DocId 就可以都不要；<code>Name.Language</code> 可以不要 <code>d</code>。然后这个编码还是有父子层次的概念的，比如有几条 <code>Name.Language.Country</code> 取决有几条 <code>Name.Language</code>，这个记录可以看看我们前面的定义和 Schema 定义。Parquet 读者在读的时候会创建一个 Struct 对应的 Reader，来递归读取。 </p><p>编码的算法大概如下：</p><ol><li>首先，会根据 Schema 构建出一颗树，来表示对应的结构。这个树的构建方式使用 dfs，大概如下：</li></ol><p><img src="https://image.mwish.me/blog-image/schema.png" alt="schema"></p><ol><li>对构建出来的树扫描的时候，带上 r, d，然后构建</li></ol><p>我们讨论一些特殊情况：</p><ol><li>如果正常的一条路径全部没有 null，那么 <code>d = 路径上(包括自己) nullable 和 repeatable 的数量</code>，<code>r = 路径上(包括自己) repeated 中的某一个</code>。 r 和 d 都是 是「自己级别的 max」</li><li>如果一个路径<strong>自己</strong>是 null，父亲不含 null，那么 <code>d = 路径上(包括自己) nullable 和 repeatable 的数量 - 1</code>，即 <strong>父亲的 d，或者上一个 nullable / repeatable 对象的 d</strong>，r 和 (1) 则一样，<strong>但最大是一样的</strong>，都是「自己级别的 rep-max」</li><li>从 1/2 其实可以看出来，null 可以通过 d 来确定，d 如果小于路径上 nullable/repeatable 值总数，就可以是 Null</li><li>如果某个路径父亲是 null，那么 d 会更小，d 会等于非 null 父级的 d，r 则是父亲级别最大的 r。相当于某个级别开始为空的话，d 会是父级别的 d-max，r 会是自己的 r</li></ol><p>上面这些内容非常重要，因为 arrow 的代码实际上是靠这套规则来实现的。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><p>Google Dremel数据模型详解(上) <a href="http://static.kancloud.cn/digest/in-memory-computing/202157">http://static.kancloud.cn/digest/in-memory-computing/202157</a></p></li><li><p>Google Dremel数据模型详解(下) <a href="http://static.kancloud.cn/digest/in-memory-computing/202158">http://static.kancloud.cn/digest/in-memory-computing/202158</a></p></li><li><p><a href="https://blog.twitter.com/engineering/en_us/a/2013/dremel-made-simple-with-parquet">https://blog.twitter.com/engineering/en_us/a/2013/dremel-made-simple-with-parquet</a></p></li><li><p>专门解释 Parquet / Dremel 格式的文章：<a href="https://github.com/julienledem/redelm/wiki/The-striping-and-assembly-algorithms-from-the-Dremel-paper">https://github.com/julienledem/redelm/wiki/The-striping-and-assembly-algorithms-from-the-Dremel-paper</a></p></li><li><p>Rust 版本的 Parquet 为了解释发了几篇文章，其实介绍的比较好：</p><ol><li>Arrow and Parquet Part 1: Primitive Types and Nullability: <a href="https://arrow.apache.org/blog/2022/10/05/arrow-parquet-encoding-part-1/">https://arrow.apache.org/blog/2022/10/05/arrow-parquet-encoding-part-1/</a></li><li>Arrow and Parquet Part 2: Nested and Hierarchical Data using Structs and Lists: <a href="https://arrow.apache.org/blog/2022/10/08/arrow-parquet-encoding-part-2/">https://arrow.apache.org/blog/2022/10/08/arrow-parquet-encoding-part-2/</a></li></ol></li></ol><p>还有一些二手评论：</p><ol><li><a href="https://zhuanlan.zhihu.com/p/25206176">https://zhuanlan.zhihu.com/p/25206176</a></li><li><a href="https://zhuanlan.zhihu.com/p/25206199">https://zhuanlan.zhihu.com/p/25206199</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>brpc bthread execution-queue</title>
      <link href="/2022/07/26/brpc-execution-queue/"/>
      <url>/2022/07/26/brpc-execution-queue/</url>
      
        <content type="html"><![CDATA[<p>Execution Queue 最早是 brpc 中，多个线程往一个 fd 写数据的时候使用的，这里的需求是：</p><ol><li>每个写应该串行的完成</li><li>会有并发的写.</li></ol><p>Execution Queue 会接受用户投递的任务, 投递完成之后, 用户线程就直接返回了, 然后自己把任务做完, 可能要靠用户的 callback 来通知用户完成. 在内部, 任务会给给投递给它的任务组 batch, 任务 submit 给一个线程异步 batch 处理.</p><p>此外, bthread 的 execution queue 还支持 cancel 任务和调度高优先级的任务.</p><h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p><code>src/bthread/execution_queue.h</code> 描述了如何使用 execution queue, 这些东西也可以在项目<a href="https://github.com/apache/incubator-brpc/blob/master/docs/cn/execution_queue.md">文档</a>里看到.</p><p>这里可以简单介绍一下这个流程，大概要实现一个 Batch 的 <code>demo_execute</code> 函数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// Iterate over the given tasks</span></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">// Examples:</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">user_fn</span><span class="params">(T)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">demo_execute</span><span class="params">(<span class="type">void</span>* meta, TaskIterator&lt;T&gt;&amp; iter)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (iter.<span class="built_in">is_queue_stopped</span>()) &#123;</span><br><span class="line">        <span class="comment">// destroy meta and related resources</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (; iter; ++iter) &#123;</span><br><span class="line">        <span class="comment">// user_fn(*iter)</span></span><br><span class="line">        <span class="comment">// or user_fn(iter-&gt;a_member_of_T)</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里 <code>T</code> 是用户定义的 task 需要处理的对象的类型。这个有点绕，因为你还要定义 <code>demo_execute</code> 来处理一个 batch 的任务，和 <code>TaskIterator</code> 交互。举个例子理解下，比如说，对于用户的 IO 写同一个 fd 的任务，brpc 定义了一个 <code>T = butil::IOBuf*</code> 的例子，来处理 IO 相关的需求. 其实这个就很好理解了吧。</p><h3 id="Execution-Queue-的生命周期"><a href="#Execution-Queue-的生命周期" class="headerlink" title="Execution Queue 的生命周期"></a>Execution Queue 的生命周期</h3><p>Execution Queue 本身会在 bthread 中执行，bthread 本身是有一堆参数的，queue 会有一堆参数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">ExecutionQueueOptions</span> &#123;</span><br><span class="line">    <span class="built_in">ExecutionQueueOptions</span>();</span><br><span class="line">    <span class="comment">// Attribute of the bthread which execute runs on</span></span><br><span class="line">    <span class="comment">// default: BTHREAD_ATTR_NORMAL</span></span><br><span class="line">    <span class="type">bthread_attr_t</span> bthread_attr;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Executor that tasks run on. bthread will be used when executor = NULL.</span></span><br><span class="line">    <span class="comment">// Note that TaskOptions.in_place_if_possible = false will not work, if implementation of</span></span><br><span class="line">    <span class="comment">// Executor is in-place(synchronous).</span></span><br><span class="line">    Executor * executor;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个 <code>Executor</code> 是一个 用户定义的 Executor，用户可以定义在自己的线程池之类的来执行，不过如果用户自己定义了一个 Executor，比如绑了个 folly 的 <code>Executor</code> 然后丢给 folly 执行：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// Start a ExecutionQueue. If |options| is NULL, the queue will be created with</span></span><br><span class="line"><span class="comment">// the default options. </span></span><br><span class="line"><span class="comment">// Returns 0 on success, errno otherwise</span></span><br><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> type |T| can be non-POD but must be copy-constructible</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execution_queue_start</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        ExecutionQueueId&lt;T&gt;* id, </span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> ExecutionQueueOptions* options,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">int</span> (*execute)(<span class="type">void</span>* meta, TaskIterator&lt;T&gt;&amp; iter),</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">void</span>* meta)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execution_queue_stop</span><span class="params">(ExecutionQueueId&lt;T&gt; id)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execution_queue_join</span><span class="params">(ExecutionQueueId&lt;T&gt; id)</span></span>;</span><br></pre></td></tr></table></figure><p>上面任务有 start, stop, 和 join。基本上是一个完整的流程。<code>ExecutionQueueId&lt;T&gt;</code> 是类似 <code>bthread_id</code> 一样的引用，关于这个结构，其实可以参考 brpc 的 memory-management 文档：<a href="https://github.com/apache/incubator-brpc/blob/master/docs/cn/memory_management.md">https://github.com/apache/incubator-brpc/blob/master/docs/cn/memory_management.md</a> 。这里基本上是 4B 地址 + 4B 版本号。</p><h3 id="提交任务"><a href="#提交任务" class="headerlink" title="提交任务"></a>提交任务</h3><p>提交任务有下列的 API:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread-safe and Wait-free.</span></span><br><span class="line"><span class="comment">// Execute a task with options. e.g</span></span><br><span class="line"><span class="comment">// bthread::execution_queue_execute(queue, task, &amp;bthread::TASK_OPTIONS_URGENT)</span></span><br><span class="line"><span class="comment">// If |options| is NULL, we will use default options (normal task)</span></span><br><span class="line"><span class="comment">// If |handle| is not NULL, we will assign it with the handler of this task.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execution_queue_execute</span><span class="params">(ExecutionQueueId&lt;T&gt; id, </span></span></span><br><span class="line"><span class="params"><span class="function">                            <span class="keyword">typename</span> butil::add_const_reference&lt;T&gt;::type task,</span></span></span><br><span class="line"><span class="params"><span class="function">                            <span class="type">const</span> TaskOptions* options)</span></span>;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execution_queue_execute</span><span class="params">(ExecutionQueueId&lt;T&gt; id, </span></span></span><br><span class="line"><span class="params"><span class="function">                            <span class="keyword">typename</span> butil::add_const_reference&lt;T&gt;::type task,</span></span></span><br><span class="line"><span class="params"><span class="function">                            <span class="type">const</span> TaskOptions* options,</span></span></span><br><span class="line"><span class="params"><span class="function">                            TaskHandle* handle)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// [Thread safe and ABA free] Cancel the corresponding task.</span></span><br><span class="line"><span class="comment">// Returns:</span></span><br><span class="line"><span class="comment">//  -1: The task was executed or h is an invalid handle</span></span><br><span class="line"><span class="comment">//  0: Success</span></span><br><span class="line"><span class="comment">//  1: The task is executing </span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execution_queue_cancel</span><span class="params">(<span class="type">const</span> TaskHandle&amp; h)</span></span>;</span><br></pre></td></tr></table></figure><p>这里 <code>execution_queue_execute</code> 可以传入一个参数，带上一个 <code>TaskOptions</code>，也可以拿到一个 <code>TaskHandle</code>，这个 handle 可以用来取消任务。下面在 <code>TaskOptions</code> 还有一些执行相关的参数：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">TaskOptions</span> &#123;</span><br><span class="line">    <span class="built_in">TaskOptions</span>();</span><br><span class="line">    <span class="built_in">TaskOptions</span>(<span class="type">bool</span> high_priority, <span class="type">bool</span> in_place_if_possible);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Executor would execute high-priority tasks in the FIFO order but before </span></span><br><span class="line">    <span class="comment">// all pending normal-priority tasks.</span></span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> We don&#x27;t guarantee any kind of real-time as there might be tasks still</span></span><br><span class="line">    <span class="comment">// in process which are uninterruptible.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Default: false </span></span><br><span class="line">    <span class="type">bool</span> high_priority;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If |in_place_if_possible| is true, execution_queue_execute would call </span></span><br><span class="line">    <span class="comment">// execute immediately instead of starting a bthread if possible</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Note: Running callbacks in place might cause the dead lock issue, you</span></span><br><span class="line">    <span class="comment">// should be very careful turning this flag on.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Default: false</span></span><br><span class="line">    <span class="type">bool</span> in_place_if_possible;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">static</span> TaskOptions TASK_OPTIONS_NORMAL = <span class="built_in">TaskOptions</span>(<span class="literal">false</span>, <span class="literal">false</span>);</span><br><span class="line"><span class="type">const</span> <span class="type">static</span> TaskOptions TASK_OPTIONS_URGENT = <span class="built_in">TaskOptions</span>(<span class="literal">true</span>, <span class="literal">false</span>);</span><br><span class="line"><span class="type">const</span> <span class="type">static</span> TaskOptions TASK_OPTIONS_INPLACE = <span class="built_in">TaskOptions</span>(<span class="literal">false</span>, <span class="literal">true</span>);</span><br></pre></td></tr></table></figure><p>这里我们可以看到对应的优先级和 <code>inplace</code> ，<code>inplace</code> 会在前台执行，<code>high_priority</code> 会投递到高优执行，不过这里还满足串行化的语义。</p><p>这里 <code>cancel</code> 接口有点让人困惑，没有被执行的任务可以被 <code>cancel</code>，这个得对着代码来理解了。</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="从用户提交任务到-lock-free-的添加到任务列表"><a href="#从用户提交任务到-lock-free-的添加到任务列表" class="headerlink" title="从用户提交任务到 lock-free 的添加到任务列表"></a>从用户提交任务到 lock-free 的添加到任务列表</h3><p>这里的实现可以在 <code>execution_queue_inl.h</code> 和 <code>execution_queue.cc</code> 里面，关键类型如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ExecutionQueueId</span> &#123;</span><br><span class="line">    <span class="type">uint64_t</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 任务的状态</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">TaskStatus</span> &#123;</span><br><span class="line">    UNEXECUTED = <span class="number">0</span>,</span><br><span class="line">    EXECUTING = <span class="number">1</span>,</span><br><span class="line">    EXECUTED = <span class="number">2</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">TaskNode</span>;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ExecutionQueueBase</span>;</span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">void</span> <span class="params">(*clear_task_mem)</span><span class="params">(TaskNode*)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">BAIDU_CACHELINE_ALIGNMENT</span> TaskNode;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ExecutionQueue</span> : <span class="keyword">public</span> ExecutionQueueBase;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TaskIteratorBase</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TaskIterator</span> : <span class="keyword">public</span> TaskIteratorBase;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>ExecutionQueue</code> 包了一层 <code>ExecutionQueueBase</code>，<code>ExecutionQueueBase</code> 的结构如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BAIDU_CACHELINE_ALIGNMENT</span> ExecutionQueueBase &#123;</span><br><span class="line"><span class="built_in">DISALLOW_COPY_AND_ASSIGN</span>(ExecutionQueueBase);</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Forbidden</span> &#123;&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Don&#x27;t change the order of _head, _versioned_ref and _stopped unless you </span></span><br><span class="line">    <span class="comment">// see improvement of performance in test</span></span><br><span class="line">    butil::atomic&lt;TaskNode*&gt; BAIDU_CACHELINE_ALIGNMENT _head; <span class="comment">// FIFO 的单队列, 这是队列的尾部, 通过 cas 来 enqueue.</span></span><br><span class="line">    butil::atomic&lt;<span class="type">uint64_t</span>&gt; BAIDU_CACHELINE_ALIGNMENT _versioned_ref; <span class="comment">// 整个对列的 _versioned_ref 计数器, 用来处理 aba 问题.</span></span><br><span class="line">    butil::atomic&lt;<span class="type">bool</span>&gt; BAIDU_CACHELINE_ALIGNMENT _stopped; <span class="comment">// 队列是否被外部停止.</span></span><br><span class="line">    butil::atomic&lt;<span class="type">int64_t</span>&gt; _high_priority_tasks; <span class="comment">// 高优任务计数器, 对列和执行里有任何高优任务都会添加这个计数器.</span></span><br><span class="line">    <span class="type">uint64_t</span> _this_id;</span><br><span class="line">    <span class="type">void</span>* _meta; <span class="comment">// 用户定义的, 绑定到整个 queue 的成员, 作为 execution_func 的参数.</span></span><br><span class="line">    <span class="type">void</span>* _type_specific_function; <span class="comment">// 对应用户的 execution_func</span></span><br><span class="line">    <span class="type">execute_func_t</span> _execute_func; <span class="comment">// 用户提供的执行函数</span></span><br><span class="line">    clear_task_mem _clear_func; <span class="comment">// 清除 Task 上的东西(用户提供) 和 Task 挂的节点的内存.</span></span><br><span class="line">    ExecutionQueueOptions _options;</span><br><span class="line">    butil::atomic&lt;<span class="type">int</span>&gt;* _join_butex;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>ExecutionQueueBase</code> 被实现成一个类似栈的结构，我也说不清是栈还是队列，因为这个地方 enqueue 类似栈，处理类似队列。</p><p>这里的入口是:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">execution_queue_execute</span><span class="params">(ExecutionQueueId&lt;T&gt; id, </span></span></span><br><span class="line"><span class="params"><span class="function">                       <span class="keyword">typename</span> butil::add_const_reference&lt;T&gt;::type task,</span></span></span><br><span class="line"><span class="params"><span class="function">                       <span class="type">const</span> TaskOptions* options,</span></span></span><br><span class="line"><span class="params"><span class="function">                       TaskHandle* handle)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">typename</span> ExecutionQueue&lt;T&gt;::<span class="type">scoped_ptr_t</span> </span><br><span class="line">        ptr = ExecutionQueue&lt;T&gt;::<span class="built_in">address</span>(id);</span><br><span class="line">    <span class="keyword">if</span> (ptr != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> ptr-&gt;<span class="built_in">execute</span>(task, options, handle);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> EINVAL;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以梳理一下执行的链路：</p><ol><li><code>execution_queue_execute</code> : 用户提交任务到某个 execution queue，派发给 <code>ExecutionQueue&lt;T&gt;</code> 调用 <code>execute</code>，来具体执行</li><li>在 <code>ExecutionQueue&lt;T&gt;::execute</code> 中，这里会针对 <code>T</code> 创建对应的 <code>TaskNode</code>，初始化内存和资源，然后投递给 <code>ExecutionQueueBase::start_execute</code></li></ol><p>那么走到最重要的内容 <code>ExecutionQueueBase</code> 了，刚刚我们看到了，它有个 <code>head_</code> 成员，是个 <code>atomic&lt;TaskNode*&gt;</code>，然后还有 <code>_high_priority_tasks</code> 和 <code>_stopped</code> 表示 “是否有高优操作” 和 “是否被停止”。这两个配置和 <code>start_execute</code> 等函数就是这个结构的核心了。我们接着看代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//! 创建好任务后, 会投递到 start_execute 来处理</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ExecutionQueueBase::start_execute</span><span class="params">(TaskNode* node)</span> </span>&#123;</span><br><span class="line">    node-&gt;next = TaskNode::UNCONNECTED;</span><br><span class="line">    node-&gt;status = UNEXECUTED;</span><br><span class="line">    node-&gt;iterated = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// _high_priority_tasks 是表示正在执行的/等待的任务是否有高优先级任务.</span></span><br><span class="line">    <span class="keyword">if</span> (node-&gt;high_priority) &#123;</span><br><span class="line">        <span class="comment">// Add _high_priority_tasks before pushing this task into queue to</span></span><br><span class="line">        <span class="comment">// make sure that _execute_tasks sees the newest number when this </span></span><br><span class="line">        <span class="comment">// task is in the queue. Although there might be some useless for </span></span><br><span class="line">        <span class="comment">// loops in _execute_tasks if this thread is scheduled out at this </span></span><br><span class="line">        <span class="comment">// point, we think it&#x27;s just fine.</span></span><br><span class="line">        _high_priority_tasks.<span class="built_in">fetch_add</span>(<span class="number">1</span>, butil::memory_order_relaxed);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 拿到上一次的 prev_head, 这个时候, 竞选要求只有 prev_head 是 nullptr 的时候,</span></span><br><span class="line">    <span class="comment">// 才能成为 group 的 leader.</span></span><br><span class="line">    <span class="comment">// 这里如果没有成为 group 的 leader, 会在这里堆积.</span></span><br><span class="line"></span><br><span class="line">    TaskNode* <span class="type">const</span> prev_head = _head.<span class="built_in">exchange</span>(node, butil::memory_order_release);</span><br><span class="line">    <span class="keyword">if</span> (prev_head != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        node-&gt;next = prev_head;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Group 的 Leader 有权限执行任务.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Get the right to execute the task, start a bthread to avoid deadlock</span></span><br><span class="line">    <span class="comment">// or stack overflow</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// 因为是 leader, 它的 next 应该是 null.</span></span><br><span class="line">    node-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    node-&gt;q = <span class="keyword">this</span>;</span><br><span class="line"></span><br><span class="line">    ExecutionQueueVars* <span class="type">const</span> vars = <span class="built_in">get_execq_vars</span>();</span><br><span class="line">    vars-&gt;execq_active_count &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (node-&gt;in_place) &#123; <span class="comment">// 如果是 in-place, 那么在本线程(bthread) 执行.</span></span><br><span class="line">        <span class="type">int</span> niterated = <span class="number">0</span>;</span><br><span class="line">        _execute(node, node-&gt;high_priority, &amp;niterated);</span><br><span class="line">        TaskNode* tmp = node;</span><br><span class="line">        <span class="comment">// return if no more</span></span><br><span class="line">        <span class="comment">// 如果是高优任务, 那么处理一下</span></span><br><span class="line">        <span class="keyword">if</span> (node-&gt;high_priority) &#123;</span><br><span class="line">            _high_priority_tasks.<span class="built_in">fetch_sub</span>(niterated, butil::memory_order_relaxed);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果有 more_tasks, 切到别的线程执行这个 group.</span></span><br><span class="line">        <span class="keyword">if</span> (!_more_tasks(tmp, &amp;tmp, !node-&gt;iterated)) &#123;</span><br><span class="line">            vars-&gt;execq_active_count &lt;&lt; <span class="number">-1</span>;</span><br><span class="line">            <span class="built_in">return_task_node</span>(node);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 根据 executor 来执行, 这个时候执行时候的 `node` 是队首.</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">nullptr</span> == _options.executor) &#123;</span><br><span class="line">        <span class="comment">// 在后台线程中, 使用 _execute_tasks 来执行.</span></span><br><span class="line">        <span class="type">bthread_t</span> tid;</span><br><span class="line">        <span class="comment">// We start the execution thread in background instead of foreground as</span></span><br><span class="line">        <span class="comment">// we can&#x27;t determine whether the code after execute() is urgent (like</span></span><br><span class="line">        <span class="comment">// unlock a pthread_mutex_t) in which case implicit context switch may</span></span><br><span class="line">        <span class="comment">// cause undefined behavior (e.g. deadlock)</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">// 在 background 中执行 (<span class="doctag">TODO:</span> 这个地方会丢进队列吗?)</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">bthread_start_background</span>(&amp;tid, &amp;_options.bthread_attr,</span><br><span class="line">                                     _execute_tasks, node) != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">PLOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Fail to start bthread&quot;</span>;</span><br><span class="line">            _execute_tasks(node);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// submit 异步执行.</span></span><br><span class="line">        <span class="keyword">if</span> (_options.executor-&gt;<span class="built_in">submit</span>(_execute_tasks, node) != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="built_in">PLOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Fail to submit task&quot;</span>;</span><br><span class="line">            _execute_tasks(node);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个代码比较长，慢慢来：</p><ol><li>如果是高优任务，添加高优的 counter，执行线程会检测到这个 counter，来做一些特殊处理</li><li>通过 <code>_head.exchange(node, butil::memory_order_release)</code> 来向栈中推进内容，<code>_head</code> 为 0 的时候，设置成功的能够成为这个 group 的 leader，在这个 bthread 或者线程下执行，否则返回程序</li><li>(从这里开始都是 Leader 的行为) 根据 <code>in_place</code> 等参数，决定就地执行还是异步执行，派发给 <code>_execute_tasks</code></li></ol><p>在 <code>_execute_tasks</code> 里面有个大循环，每次会把本个 batch 尽量执行完（为什么是尽量呢，接着看）：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// 调用 execute 来执行对应的任务, 这是一个 static 函数, 需要合理处理高优先级任务.</span></span><br><span class="line"><span class="type">void</span>* ExecutionQueueBase::_execute_tasks(<span class="type">void</span>* arg) &#123;</span><br><span class="line">    ExecutionQueueVars* vars = <span class="built_in">get_execq_vars</span>();</span><br><span class="line">    TaskNode* head = (TaskNode*)arg;</span><br><span class="line">    ExecutionQueueBase* m = (ExecutionQueueBase*)head-&gt;q;</span><br><span class="line">    TaskNode* cur_tail = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="type">bool</span> destroy_queue = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="comment">// 如果队列头已经执行过, 那么切一个队列头(move next), 然后把之前的队列头</span></span><br><span class="line">        <span class="comment">// 处理.</span></span><br><span class="line">        <span class="keyword">if</span> (head-&gt;iterated) &#123;</span><br><span class="line">            <span class="built_in">CHECK</span>(head-&gt;next != <span class="literal">NULL</span>);</span><br><span class="line">            TaskNode* saved_head = head;</span><br><span class="line">            head = head-&gt;next;</span><br><span class="line">            m-&gt;<span class="built_in">return_task_node</span>(saved_head);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">int</span> rc = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 如果有高优先级任务, 调用 _execute 直接处理高优任务, 如果没有高优任务, 调度走等待</span></span><br><span class="line">        <span class="comment">//  投递进来继续组 batch.</span></span><br><span class="line">        <span class="keyword">if</span> (m-&gt;_high_priority_tasks.<span class="built_in">load</span>(butil::memory_order_relaxed) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="type">int</span> nexecuted = <span class="number">0</span>;</span><br><span class="line">            <span class="comment">// Don&#x27;t care the return value (因为不会执行到 stop).</span></span><br><span class="line">            rc = m-&gt;_execute(head, <span class="literal">true</span>, &amp;nexecuted);</span><br><span class="line">            <span class="comment">// 减少对应的高优任务数量</span></span><br><span class="line">            m-&gt;_high_priority_tasks.<span class="built_in">fetch_sub</span>(</span><br><span class="line">                    nexecuted, butil::memory_order_relaxed);</span><br><span class="line">            <span class="comment">// 如果 nexecuted == 0, 调度走, 等待任务被塞到执行队列.</span></span><br><span class="line">            <span class="keyword">if</span> (nexecuted == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">// Some high_priority tasks are not in queue</span></span><br><span class="line">                <span class="built_in">sched_yield</span>();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 没有高优任务, 执行现有的这批.</span></span><br><span class="line">            rc = m-&gt;_execute(head, <span class="literal">false</span>, <span class="literal">NULL</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 是否收到 stop 对象.</span></span><br><span class="line">        <span class="keyword">if</span> (rc == ESTOP) &#123;</span><br><span class="line">            destroy_queue = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Release TaskNode until uniterated task or last task</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">// 释放掉现在所有的执行过的内容, 不过这里只是连续释放, 直到有 uniterated 的对象.</span></span><br><span class="line">        <span class="keyword">while</span> (head-&gt;next != <span class="literal">NULL</span> &amp;&amp; head-&gt;iterated) &#123;</span><br><span class="line">            TaskNode* saved_head = head;</span><br><span class="line">            head = head-&gt;next;</span><br><span class="line">            m-&gt;<span class="built_in">return_task_node</span>(saved_head);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 到这个 batch 的尾部.</span></span><br><span class="line">        <span class="keyword">if</span> (cur_tail == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (cur_tail = head; cur_tail-&gt;next != <span class="literal">NULL</span>; </span><br><span class="line">                    cur_tail = cur_tail-&gt;next) &#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// break when no more tasks and head has been executed</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">// 把加进来的和已有的组成一个新的 Batch, cur_tail 和 &amp;cur_tail 这个有点让人困惑, 因为队列要满足 FIFO 条件,</span></span><br><span class="line">        <span class="comment">// 投递进来的原本是 T3-&gt;T2-&gt;T1. 在第一个 batch 里面, T1 设置到了 head = NULL 到 head = T1, 所以 T1 是</span></span><br><span class="line">        <span class="comment">// leader, 这个时候, cur_tail == T1. old_head == T1, new_tail = &amp;T1(即 head).</span></span><br><span class="line">        <span class="comment">// 再次执行完的时候, 这个队列会变成 T3-&gt;T2, 但是执行顺序是 T2-&gt;T3, 所以, old_head 对应 T2, new_tail 也应该传入</span></span><br><span class="line">        <span class="comment">// T2.</span></span><br><span class="line">        <span class="comment">// 本来这里没有问题, 但是可能 has_uniterated == true, 需要缝合两个队列.</span></span><br><span class="line">        <span class="keyword">if</span> (!m-&gt;_more_tasks(cur_tail, &amp;cur_tail, !head-&gt;iterated)) &#123;</span><br><span class="line">            <span class="built_in">CHECK_EQ</span>(cur_tail, head);</span><br><span class="line">            <span class="built_in">CHECK</span>(head-&gt;iterated);</span><br><span class="line">            m-&gt;<span class="built_in">return_task_node</span>(head);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (destroy_queue) &#123;</span><br><span class="line">        <span class="built_in">CHECK</span>(m-&gt;_head.<span class="built_in">load</span>(butil::memory_order_relaxed) == <span class="literal">NULL</span>);</span><br><span class="line">        <span class="built_in">CHECK</span>(m-&gt;_stopped);</span><br><span class="line">        <span class="comment">// Add _join_butex by 2 to make it equal to the next version of the</span></span><br><span class="line">        <span class="comment">// ExecutionQueue from the same slot so that join with old id would</span></span><br><span class="line">        <span class="comment">// return immediately.</span></span><br><span class="line">        <span class="comment">// </span></span><br><span class="line">        <span class="comment">// 1: release fence to make join sees the newest changes when it sees</span></span><br><span class="line">        <span class="comment">//    the newest _join_butex</span></span><br><span class="line">        m-&gt;_join_butex-&gt;<span class="built_in">fetch_add</span>(<span class="number">2</span>, butil::memory_order_release<span class="comment">/*1*/</span>);</span><br><span class="line">        <span class="built_in">butex_wake_all</span>(m-&gt;_join_butex);</span><br><span class="line">        vars-&gt;execq_count &lt;&lt; <span class="number">-1</span>;</span><br><span class="line">        butil::<span class="built_in">return_resource</span>(<span class="built_in">slot_of_id</span>(m-&gt;_this_id));</span><br><span class="line">    &#125;</span><br><span class="line">    vars-&gt;execq_active_count &lt;&lt; <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这个地方逻辑如下：</p><ol><li>处理已经迭代完的内容, 这里涉及 stop 之类的逻辑</li><li>调用 <code>_execute</code> 函数，来具体执行这个 batch</li><li>看看有没有没执行完的任务和最新的任务，走 <code>_more_tasks</code></li></ol><p>看客这个地方可能会怪我全部贴代码了，不过这个地方流程确实只能硬贴。因为 (2) (3) 都是有巨坑的</p><h3 id="特殊情况：第一次执行"><a href="#特殊情况：第一次执行" class="headerlink" title="特殊情况：第一次执行"></a>特殊情况：第一次执行</h3><p>还记得 <code>_head.exchange</code> 不，这个地方第一次设置成功的 <code>Node</code> 的 <code>next</code> 是 <code>nullptr</code>，第一次执行的时候，整个 batch 只有它一个成员。</p><h3 id="高优先级任务的处理"><a href="#高优先级任务的处理" class="headerlink" title="高优先级任务的处理"></a>高优先级任务的处理</h3><p>我们看到，<code>start_execute</code> 的时候，这里如果是高优任务，就会添加高优的 counter，在 <code>_execute_tasks</code> 的循环里，我们看到这里检查了高优任务:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> rc = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// 如果有高优先级任务, 调用 _execute 直接处理高优任务, 如果没有高优任务, 调度走等待</span></span><br><span class="line"><span class="comment">//  投递进来继续组 batch.</span></span><br><span class="line"><span class="keyword">if</span> (m-&gt;_high_priority_tasks.<span class="built_in">load</span>(butil::memory_order_relaxed) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="type">int</span> nexecuted = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// Don&#x27;t care the return value (因为不会执行到 stop).</span></span><br><span class="line">    rc = m-&gt;_execute(head, <span class="literal">true</span>, &amp;nexecuted);</span><br><span class="line">    <span class="comment">// 减少对应的高优任务数量</span></span><br><span class="line">    m-&gt;_high_priority_tasks.<span class="built_in">fetch_sub</span>(</span><br><span class="line">            nexecuted, butil::memory_order_relaxed);</span><br><span class="line">    <span class="comment">// 如果 nexecuted == 0, 调度走, 等待任务被塞到执行队列.</span></span><br><span class="line">    <span class="keyword">if</span> (nexecuted == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// Some high_priority tasks are not in queue</span></span><br><span class="line">        <span class="built_in">sched_yield</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 没有高优任务, 执行现有的这批.</span></span><br><span class="line">    rc = m-&gt;_execute(head, <span class="literal">false</span>, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以看看 <code>_execute</code> 函数的签名：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> ExecutionQueueBase::_execute(TaskNode* head, <span class="type">bool</span> high_priority, <span class="type">int</span>* niterated);</span><br></pre></td></tr></table></figure><p>这里可以看到，<code>_execute</code> 里面有个 <code>high_priority</code> 的标记，这个是用来干什么的呢？我们这里介绍一下，一个 Batch 只能执行一种优先级的任务，要么高要么低。如果插入了一个高优任务，它要尽量在低优先级任务之前被执行。这里可以想象一下提供给用户的模型：</p><ul><li>有两个队列，一个低优一个高优</li><li>executor 并非是「Batch 执行」，它是串行执行的，从高优看看有没有，有就执行，否则从低优队列取<strong>一个</strong>任务执行</li></ul><p>可以看到，这里是一个非 batch 执行的语义，这个 <code>_execute</code> 靠计数器实现了类似的语义：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 具体执行的逻辑, start_execute -&gt; execute_task -&gt; execute.</span></span><br><span class="line"><span class="type">int</span> ExecutionQueueBase::_execute(TaskNode* head, <span class="type">bool</span> high_priority, <span class="type">int</span>* niterated) &#123;</span><br><span class="line">    <span class="comment">// 如果是一个 stop task, 那么具体执行</span></span><br><span class="line">    <span class="keyword">if</span> (head != <span class="literal">NULL</span> &amp;&amp; head-&gt;stop_task) &#123;</span><br><span class="line">        <span class="built_in">CHECK</span>(head-&gt;next == <span class="literal">NULL</span>);</span><br><span class="line">        head-&gt;iterated = <span class="literal">true</span>; <span class="comment">// 设置自身为 executed.</span></span><br><span class="line">        head-&gt;status = EXECUTED;</span><br><span class="line">        <span class="comment">// 如果是 stop, 那么这里 `high_priority == false`.</span></span><br><span class="line">        <span class="function">TaskIteratorBase <span class="title">iter</span><span class="params">(<span class="literal">NULL</span>, <span class="keyword">this</span>, <span class="literal">true</span>, <span class="literal">false</span>)</span></span>;</span><br><span class="line">        _execute_func(_meta, _type_specific_function, iter);</span><br><span class="line">        <span class="keyword">if</span> (niterated) &#123;</span><br><span class="line">            *niterated = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ESTOP;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function">TaskIteratorBase <span class="title">iter</span><span class="params">(head, <span class="keyword">this</span>, <span class="literal">false</span>, high_priority)</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (iter) &#123;</span><br><span class="line">        _execute_func(_meta, _type_specific_function, iter);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// We must assign |niterated| with num_iterated even if we couldn&#x27;t peek</span></span><br><span class="line">    <span class="comment">// any task to execute at the beginning, in which case all the iterated</span></span><br><span class="line">    <span class="comment">// tasks have been cancelled at this point. And we must return the </span></span><br><span class="line">    <span class="comment">// correct num_iterated() to the caller to update the counter correctly.</span></span><br><span class="line">    <span class="keyword">if</span> (niterated) &#123;</span><br><span class="line">        *niterated = iter.<span class="built_in">num_iterated</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里比较重要的实现在 <code>TaskIteratorBase</code> 里面，这个类型实现了根据优先级来判断是否要迭代的逻辑：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 传递给 execute 函数的迭代器.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TaskIteratorBase</span> &#123;</span><br><span class="line"><span class="built_in">DISALLOW_COPY_AND_ASSIGN</span>(TaskIteratorBase);</span><br><span class="line"><span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">ExecutionQueueBase</span>;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// Returns true when the ExecutionQueue is stopped and there will never be</span></span><br><span class="line">    <span class="comment">// more tasks and you can safely release all the related resources ever </span></span><br><span class="line">    <span class="comment">// after.</span></span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">is_queue_stopped</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> _is_stopped; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">operator</span> <span class="title">bool</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    <span class="built_in">TaskIteratorBase</span>(TaskNode* head, ExecutionQueueBase* queue,</span><br><span class="line">                     <span class="type">bool</span> is_stopped, <span class="type">bool</span> high_priority)</span><br><span class="line">        : _cur_node(head)</span><br><span class="line">        , _head(head)</span><br><span class="line">        , _q(queue)</span><br><span class="line">        , _is_stopped(is_stopped)</span><br><span class="line">        , _high_priority(high_priority)</span><br><span class="line">        , _should_break(<span class="literal">false</span>)</span><br><span class="line">        , _num_iterated(<span class="number">0</span>)</span><br><span class="line">    &#123; <span class="keyword">operator</span>++(); &#125;</span><br><span class="line">    ~<span class="built_in">TaskIteratorBase</span>();</span><br><span class="line">    <span class="type">void</span> <span class="keyword">operator</span>++();</span><br><span class="line">    <span class="function">TaskNode* <span class="title">cur_node</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> _cur_node; &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">num_iterated</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> _num_iterated; &#125;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">should_break_for_high_priority_tasks</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    TaskNode*               _cur_node;</span><br><span class="line">    TaskNode*               _head;</span><br><span class="line">    ExecutionQueueBase*     _q; <span class="comment">// 绑定的整个 queue 的对象.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 注: 如果 _is_stopped == true, _high_pri 必定为 false.</span></span><br><span class="line">    <span class="type">bool</span>                    _is_stopped;</span><br><span class="line">    <span class="type">bool</span>                    _high_priority;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 下面是内部的逻辑.</span></span><br><span class="line">    <span class="type">bool</span>                    _should_break;</span><br><span class="line">    <span class="type">int</span>                     _num_iterated;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个的重点逻辑在 <code>should_break_for_high_priority_tasks</code> 里面：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 有高优任务需要插队.</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">bool</span> <span class="title">TaskIteratorBase::should_break_for_high_priority_tasks</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!_high_priority &amp;&amp; </span><br><span class="line">            _q-&gt;_high_priority_tasks.<span class="built_in">load</span>(butil::memory_order_relaxed) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        _should_break = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> TaskIteratorBase::<span class="keyword">operator</span>++() &#123;</span><br><span class="line">    <span class="keyword">if</span> (!(*<span class="keyword">this</span>)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 已经 iter 的任务不用再处理.</span></span><br><span class="line">    <span class="keyword">if</span> (_cur_node-&gt;iterated) &#123;</span><br><span class="line">        _cur_node = _cur_node-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 有高优任务需要插队的时候, 需要暂时 break 掉, 等待高优先级任务执行.</span></span><br><span class="line">    <span class="comment">// 如果迭代中发现有高优先级任务, 那么这里不再会执行任一个 task.</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">should_break_for_high_priority_tasks</span>()) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;  <span class="comment">// else the next high_priority_task would be delayed for at most one task</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 没有高优先级任务, 然后不是 stop.</span></span><br><span class="line">    <span class="keyword">while</span> (_cur_node &amp;&amp; !_cur_node-&gt;stop_task) &#123;</span><br><span class="line">        <span class="comment">// 如果优先级等同, 那么执行: 如果有高优先级的, 低优先级的不会被执行</span></span><br><span class="line">        <span class="keyword">if</span> (_high_priority == _cur_node-&gt;high_priority) &#123;</span><br><span class="line">            <span class="comment">// 如果没有 iterated, 那么捞出来设置一下状态, 然后返回.</span></span><br><span class="line">            <span class="keyword">if</span> (!_cur_node-&gt;iterated &amp;&amp; _cur_node-&gt;<span class="built_in">peek_to_execute</span>()) &#123;</span><br><span class="line">                ++_num_iterated;</span><br><span class="line">                _cur_node-&gt;iterated = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            _num_iterated += !_cur_node-&gt;iterated;</span><br><span class="line">            _cur_node-&gt;iterated = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 取下一个可执行的任务。</span></span><br><span class="line">        _cur_node = _cur_node-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="组下一个-batch-的逻辑"><a href="#组下一个-batch-的逻辑" class="headerlink" title="组下一个 batch 的逻辑"></a>组下一个 batch 的逻辑</h3><p>组下一个 batch 的逻辑在 <code>_more_tasks</code> 中，但我们必须联动上一节，假设某个 Batch:</p><ol><li>执行低优任务，有五个任务，执行了三个发现有高优任务插队了</li><li>执行高优任务，有10个任务，但是只有一个高优任务</li></ol><p>这个时候，组 batch 的时候，可能自己手头上的 batch 还没执行完，用户又提交了，这就涉及到两个 batch 缝合，我们先看调用 <code>_more_tasks</code> 的地方：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// Release TaskNode until uniterated task or last task</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 释放掉现在所有的执行过的内容, 不过这里只是连续释放, 直到有 uniterated 的对象.</span></span><br><span class="line"><span class="keyword">while</span> (head-&gt;next != <span class="literal">NULL</span> &amp;&amp; head-&gt;iterated) &#123;</span><br><span class="line">    TaskNode* saved_head = head;</span><br><span class="line">    head = head-&gt;next;</span><br><span class="line">    m-&gt;<span class="built_in">return_task_node</span>(saved_head);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 到这个 batch 的尾部.</span></span><br><span class="line"><span class="keyword">if</span> (cur_tail == <span class="literal">NULL</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> (cur_tail = head; cur_tail-&gt;next != <span class="literal">NULL</span>; </span><br><span class="line">            cur_tail = cur_tail-&gt;next) &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// break when no more tasks and head has been executed</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 把加进来的和已有的组成一个新的 Batch, cur_tail 和 &amp;cur_tail 这个有点让人困惑, 因为队列要满足 FIFO 条件,</span></span><br><span class="line"><span class="comment">// 投递进来的原本是 T3-&gt;T2-&gt;T1. 在第一个 batch 里面, T1 设置到了 head = NULL 到 head = T1, 所以 T1 是</span></span><br><span class="line"><span class="comment">// leader, 这个时候, cur_tail == T1. old_head == T1, new_tail = &amp;T1(即 head).</span></span><br><span class="line"><span class="comment">// 再次执行完的时候, 这个队列会变成 T3-&gt;T2, 但是执行顺序是 T2-&gt;T3, 所以, old_head 对应 T2, new_tail 也应该传入</span></span><br><span class="line"><span class="comment">// T2.</span></span><br><span class="line"><span class="comment">// 本来这里没有问题, 但是可能 has_uniterated == true, 需要缝合两个队列.</span></span><br><span class="line"><span class="keyword">if</span> (!m-&gt;_more_tasks(cur_tail, &amp;cur_tail, !head-&gt;iterated)) &#123;</span><br><span class="line">    <span class="built_in">CHECK_EQ</span>(cur_tail, head);</span><br><span class="line">    <span class="built_in">CHECK</span>(head-&gt;iterated);</span><br><span class="line">    m-&gt;<span class="built_in">return_task_node</span>(head);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里根据任务有没有执行完，设置了不同的 <code>cur_tail</code> 来处理。然后我们看 <code>_more_tasks</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">inline</span> <span class="type">bool</span> ExecutionQueueBase::_more_tasks(</span><br><span class="line">        TaskNode* old_head, TaskNode** new_tail, </span><br><span class="line">        <span class="type">bool</span> has_uniterated) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(old_head-&gt;next == <span class="literal">NULL</span>);</span><br><span class="line">    <span class="comment">// Try to set _head to NULL to mark that the execution is done.</span></span><br><span class="line">    TaskNode* new_head = old_head;</span><br><span class="line">    TaskNode* desired = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="type">bool</span> return_when_no_more = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (has_uniterated) &#123; <span class="comment">// desired 设置到 old_head, 方便组 batch.</span></span><br><span class="line">        desired = old_head;</span><br><span class="line">        return_when_no_more = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// _head 和 old_head 如果相等, 就把 desired 设置给 _head. 只有没有新任务来的时候, 会相等.</span></span><br><span class="line">    <span class="comment">// desired 在迭代完全的时候, 会是 NULL, 这个时候队列也设置为空; 否则设置为这次迭代的尾部, 允许别人再 append.</span></span><br><span class="line">    <span class="comment">// 失败的时候, 新的 _head 会被加载到 `new_head` 中.</span></span><br><span class="line">    <span class="keyword">if</span> (_head.<span class="built_in">compare_exchange_strong</span>(</span><br><span class="line">                new_head, desired, butil::memory_order_acquire)) &#123;</span><br><span class="line">        <span class="comment">// No one added new tasks.</span></span><br><span class="line">        <span class="comment">// 没有新任务, 这里返回本队列是否迭代完成.</span></span><br><span class="line">        <span class="keyword">return</span> return_when_no_more;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">CHECK_NE</span>(new_head, old_head);</span><br><span class="line">    <span class="comment">// Above acquire fence pairs release fence of exchange in Write() to make</span></span><br><span class="line">    <span class="comment">// sure that we see all fields of requests set.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Someone added new requests.</span></span><br><span class="line">    <span class="comment">// Reverse the list until old_head.</span></span><br><span class="line">    TaskNode* tail = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">if</span> (new_tail) &#123;</span><br><span class="line">        *new_tail = new_head;</span><br><span class="line">    &#125;</span><br><span class="line">    TaskNode* p = new_head;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="comment">// TODO(mwish): 这个地方和 enqueue 有并发, 没有问题吗.</span></span><br><span class="line">        <span class="keyword">while</span> (p-&gt;next == TaskNode::UNCONNECTED) &#123;</span><br><span class="line">            <span class="comment">// TODO(gejun): elaborate this</span></span><br><span class="line">            <span class="built_in">sched_yield</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        TaskNode* <span class="type">const</span> saved_next = p-&gt;next;</span><br><span class="line">        p-&gt;next = tail;</span><br><span class="line">        tail = p;</span><br><span class="line">        p = saved_next;</span><br><span class="line">        <span class="built_in">CHECK</span>(p != <span class="literal">NULL</span>);</span><br><span class="line">    &#125; <span class="keyword">while</span> (p != old_head);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Link old list with new list.</span></span><br><span class="line">    old_head-&gt;next = tail;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里会把两个 queue 拼成一个，大概逻辑如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">正在执行的 Queue: T1(done)-&gt;T2(done)-&gt;T3(undone, head)</span><br><span class="line">head_ 有关的结构: (head)T6-&gt;T5-&gt;T4-&gt;T3-&gt;T2-&gt;T1</span><br><span class="line"></span><br><span class="line">回收空间，正在执行的 Queue: T3(undone, head)</span><br><span class="line">head_ 有关的结构: (head)T6-&gt;T5-&gt;T4-&gt;T3-&gt;T2-&gt;T1</span><br><span class="line"></span><br><span class="line">拼接后, queue 有关的结构: T3-&gt;T4-&gt;T5-&gt;T6</span><br><span class="line">head_ 有关的结构: (head)T6-&gt;T5-&gt;T4-&gt;T3</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这里的执行流程如下</p><ol><li>对已经执行的 Task 的资源回收，调用 <code>ExecutionQueueBase::return_task_node</code>，在 <code>_more_tasks</code> 之前回首掉</li><li>会组好 Batch，然后等待下一次执行。这里会如上图一样拼接</li><li>如果没有更多的任务，可能会回收 <code>head</code>s</li></ol><h3 id="Graceful-shutdown"><a href="#Graceful-shutdown" class="headerlink" title="Graceful shutdown"></a>Graceful shutdown</h3><p>对于一个关闭的 queue，首先，投递的任务会失败：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// (在 class ExecutionQueue&lt;T&gt; 里面)</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execute</span><span class="params">(<span class="keyword">typename</span> butil::add_const_reference&lt;T&gt;::type task,</span></span></span><br><span class="line"><span class="params"><span class="function">                <span class="type">const</span> TaskOptions* options, TaskHandle* handle)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">stopped</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> EINVAL;</span><br><span class="line">        &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其次，这里有一套引用计数机制，来保证持有的地方不会失效：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function">ExecutionQueueBase::<span class="type">scoped_ptr_t</span> <span class="title">ExecutionQueueBase::address</span><span class="params">(<span class="type">uint64_t</span> id)</span></span>;</span><br></pre></td></tr></table></figure><p>当引用计数差不多得了的时候，这里会投递一些关闭的 flag，调用 <code>_on_recycle</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="type">void</span> ExecutionQueueBase::_on_recycle() &#123;</span><br><span class="line">    <span class="comment">// Push a closed tasks</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        TaskNode* node = butil::<span class="built_in">get_object</span>&lt;TaskNode&gt;();</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">BAIDU_LIKELY</span>(node != <span class="literal">NULL</span>)) &#123;</span><br><span class="line">            <span class="built_in">get_execq_vars</span>()-&gt;running_task_count &lt;&lt; <span class="number">1</span>;</span><br><span class="line">            node-&gt;stop_task = <span class="literal">true</span>;</span><br><span class="line">            node-&gt;high_priority = <span class="literal">false</span>;</span><br><span class="line">            node-&gt;in_place = <span class="literal">false</span>;</span><br><span class="line">            <span class="built_in">start_execute</span>(node);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="literal">false</span>) &lt;&lt; <span class="string">&quot;Fail to create task_node_t, &quot;</span> &lt;&lt; <span class="built_in">berror</span>();</span><br><span class="line">        ::<span class="built_in">bthread_usleep</span>(<span class="number">1000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Notes on Btree Implements: PostgreSQL</title>
      <link href="/2022/07/09/Notes-on-Btree-Implements-PostgreSQL/"/>
      <url>/2022/07/09/Notes-on-Btree-Implements-PostgreSQL/</url>
      
        <content type="html"><![CDATA[<p>PostgreSQL 也有索引和 BTree 索引，但是它和 InnoDB 是有区别的，InnoDB 有 “Cluster Index”，索引指向 Cluster Index，Cluster Index 上数据有是完整的，它也有 <code>roll_pointer</code> 字段指向 Undo。PostgreSQL 没有 Cluster Index。它的主数据存储在一个叫 Heap Table 的”堆表”上，需要更新的时候，堆表上会插入对应的 Tuple，如果是字段更新，那么会在之前的 Tuple 记录一条指向现有 Tuple 的指针。这里对应的逻辑视图如下：</p><p><img src="https://image.mwish.me/blog-image/190D2463-5889-453A-8310-C1C1058911D5.png" alt="190D2463-5889-453A-8310-C1C1058911D5"></p><p>也就是说，对比 InnoDB，PostgreSQL 相当于 <strong>只有 secondary index</strong>。</p><h2 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h2><h3 id="Tuple"><a href="#Tuple" class="headerlink" title="Tuple"></a>Tuple</h3><p>PostgreSQL 的 Tuple 分为 <code>HeapTuple</code> 和 <code>IndexTuple</code>，<code>HeapTuple</code> 是主表上的数据，<code>IndexTuple</code> 是索引上存储的指向 HeapTuple 的数据，它们大致逻辑内容如下：</p><p><img src="https://image.mwish.me/blog-image/fig-5-02.png" alt="fig-5-02"></p><p><img src="https://image.mwish.me/blog-image/fig-5-03.png" alt="fig-5-03"></p><p>HeapTuple 定义在 pg 的 <code>src/include/access/htup.h</code>, 除了用户定义的值，它包含几个隐藏字段：</p><ol><li><code>t_xmin</code>, <code>t_xmax</code>: <code>t_xmin</code> 表示创建这个 Tuple 的事务的事务 id，即这个事务 commit 之后，事务 id 比 <code>t_xmin</code> 大的就可以看见 <code>tuple</code> ；<code>t_xmax</code> 表示更新或者删除这条记录的事务的 id（它也可以表示事务正在对这个 tuple 上锁）</li><li>实际上，读一个 tuple 的时候，PG 可能要判断一下这个事务 id 的状态是什么样子的，Tuple 的隐藏字段有一些 info bits，如果查完可以把相关状态在 info bits 上做标记，优化查表的开销</li><li><code>t_cid</code> 是更新这个 tuple 的 command id</li><li><code>t_ctid</code> 是一个指针，指向 <em>Tuple 自己的位置</em> 或者 <em>被更新之后，Tuple新的位置</em></li></ol><p>我们以上图为例：</p><ol><li>Page 的 tuple1 被 txn_id 为 99 的事务插入，它的 <code>t_xmin</code> 为 99，<code>t_ctid</code> 指向自己的位置 <code>(0, 1)</code></li><li>Page 的 tuple1 被 txn_id 为 100 的事务更新，它的 <code>t_xmax</code> 为 100, 创建了一条新的记录 Tuple2，<code>t_xmin</code> 为 100，<code>t_xmax</code> 为 0。Tuple1 的 <code>t_ctid</code> 指向 tuple2</li></ol><p>对于 IndexTuple，假设主表属性是 <code>(a, b, c)</code>, 而对 <code>(b)</code> 建了索引，那么索引 Tuple 可以被视作 <code>&lt;(b), 主表上 Tuple 的位置&gt;</code>, 同时，索引的 IndexTuple 可能只有叶子结点上才有主表 Tuple 的位置。 它被定义在 <code>src/include/access/itup.h</code></p><p><img src="https://image.mwish.me/blog-image/fig-5-06.png" alt="fig-5-06"></p><h3 id="Page"><a href="#Page" class="headerlink" title="Page"></a>Page</h3><p>PostgreSQL 的 Page 格式比较统一，而且非常典型，典型到很多数据库教材上都有。相比 InnoDB 的 稀疏索引 + 单向链表 + 垃圾链表 + 统计信息，PostgreSQL （以降低更新性能为代价）使用了一个非常简单的格式：</p><p><img src="https://image.mwish.me/blog-image/4C345186-B4D8-435E-9C5B-DDD4D18671A5.png" alt="4C345186-B4D8-435E-9C5B-DDD4D18671A5"></p><p>对于 Heap Table，不考虑 GC 数据（即 Vacuum）的情况下，数据几乎是只会往后添加、不会变更位置的。</p><h3 id="Index"><a href="#Index" class="headerlink" title="Index"></a>Index</h3><p>终于讲到我们今天的主题了…其实还没有。我们刚才说过，不考虑 Vacuum 的情况下，数据几乎只会往后添加、不会变更位置。Index 需要指向最初的那个 Tuple，如图所示：</p><p>PostgreSQL 把 Index 接口和 Index 管理器暴露给了用户，用户可以创建 HashIndex, Btree Index 等索引。</p><p><img src="https://image.mwish.me/blog-image/fig-5-14.png" alt="fig-5-14"></p><p>我们刚才谈到了，更新一个值可能会更改它的 <code>t_ctid</code>，指向新的位置。这个时候 <strong>索引的值不能改变，同时旧值不能被回收</strong>，除非索引相关的值被改变。如果 Tuple 为 <code>(a, b, c)</code>, 对 <code>(b)</code> 构建了索引，然后一个请求修改了 <code>b</code>，这个时候需要在索引插入一个新的值，但旧值也不能删除。需要等待 vacuum 阶段删除。</p><h3 id="Vacuum"><a href="#Vacuum" class="headerlink" title="Vacuum"></a>Vacuum</h3><p>对于 PG 来说，它做的是一个比较复杂的多阶段的删除，用的 Tuple-level GC + VAC，具体可见 Vacuum 相关的材料（Lazy Vacuum, Full Vacuum）</p><ul><li>对于事务的记录，PostgreSQL 维护在 clog 里面，这可以当作一个事务表。它根据事务 id 的顺序存在各个 Page 上，缓存在内存的 slru 中。当事务推进的时候，可以 Truncate 前面的事务记录来回收空间，推进系统事务</li><li>PostgreSQL 的 <code>xmax</code> 如果被标记且 tuple 没有被上锁，那么这个 tuple 是被删除的，如果 <code>xmax</code> 小于 <code>min-txn</code>，那这个 tuple 在逻辑上不会被任何事务看见，虽然物理上它还存在</li><li>GC 过程中，PostgreSQL 会扫描所有 dead 的 tuple，然后清除它们，这里首先有一个 visibilitymap, 对应代码在 <code>backend/access/heap/visibilitymap</code>。如果某个 Page 被改了，有 Tuple 可能需要 GC，就会给 vm 记一下，然后这样的 Page 才需要被清理，这段过程中，索引的数据会被清除，如下面的图。</li><li>索引数据清除之后，Heap Tuple 的数据会被标记删除，但是 slot 上的位置还是会留着。</li><li>更新对应的 VM，移除 clog 等事务表信息。</li></ul><p><img src="https://image.mwish.me/blog-image/fig-6-01.png" alt="fig-6-01"></p><h3 id="事务状态-CLOG"><a href="#事务状态-CLOG" class="headerlink" title="事务状态: CLOG"></a>事务状态: CLOG</h3><p><img src="https://image.mwish.me/blog-image/fig-5-07.png" alt="fig-5-07"></p><p><img src="https://image.mwish.me/blog-image/fig-5-08.png" alt="fig-5-08"></p><h3 id="WAL-XLog"><a href="#WAL-XLog" class="headerlink" title="WAL: XLog"></a>WAL: XLog</h3><p>PostgreSQL 的日志写在 XLog 中。PostgreSQL 模型中，没有 InnoDB 的 Undo data，但它认为它在 Heap Table 中维护了多版本，所以只写了 Redo Log。</p><h2 id="NBTree"><a href="#NBTree" class="headerlink" title="NBTree"></a>NBTree</h2><p>PostgreSQL 的索引管理器定义在了 <code>src/backend/access/index</code>，而 Btree 的定义在 <code>src/backend/access/nbtree</code>。BTree 对外提供了 cursor, 插入，删除等接口，同时也定义了并行访问的接口。</p><p>PostgreSQL 实现了 B-link Tree，B-link Tree 来自论文 Efficient Locking for Concurrent Operations on  B-Trees 逻辑定义如下：</p><p><img src="https://image.mwish.me/blog-image/68DC4BF6-FEDB-47B0-A10E-A981B22BECC3.png" alt="68DC4BF6-FEDB-47B0-A10E-A981B22BECC3"></p><p><img src="https://image.mwish.me/blog-image/AD6DE068-6D32-4756-8ED3-E841A8969781.png" alt="AD6DE068-6D32-4756-8ED3-E841A8969781"></p><ul><li>所有页面可能包含一个 <code>highkey</code>，表示本页面存储的 key 的最大值。同时可能包含一个分裂到一半需要的 <code>rightlink</code>，指向自己节点的右边。比 <code>highkey</code> 高的值可以去右边查询，走到右边的行为叫 <code>moveright</code></li><li>b-link tree 的分裂是分为多阶段的<ul><li>分裂的时候，<strong>永远只会向右分裂</strong>，首先节点会创建一个右节点，修改 high-key，链接 <code>rightlink</code>，完成操作的第一步</li><li>之后发现这里有未完成的分裂后，会在父节点上插入右节点，完成分裂。如果父节点分裂，那么回到上一步，递归完成分裂。</li></ul></li></ul><p>对于一个下降的查询 <code>key</code>，它移动下来的时候，会先比较 <code>key</code> 和 这个 Page 上的 <code>highkey</code>，如果自己小于 Page 的 highkey，那么就在本页面查询，否则会需要 <code>moveright</code>，移动到右节点查询。</p><p>PostgreSQL 的 Index 对外暴露了一组管理 api，包括：</p><ol><li>Search</li><li>插入节点</li><li>更新一些节点的元信息</li><li>Scan</li><li>Batch 的在 vacuum 阶段做删除节点</li><li>…</li></ol><p>在 <code>Datum bthandler(PG_FUNCTION_ARGS)</code> 这个函数有着将函数 bind 到 <code>IndexAm</code> 上的逻辑。这里其实基本上相当于虚函数什么的了。</p><h3 id="BTree-的结构和各种Page"><a href="#BTree-的结构和各种Page" class="headerlink" title="BTree 的结构和各种Page"></a>BTree 的结构和各种Page</h3><p>我们在刚刚介绍 InnoDB Btree 的时候提到过，InnoDB 有整个索引的锁，同时它的 RootPage 是不会改变的。</p><p>InnoDB 的 RootPage 是会改变的，它有一个 MetaPage 指向它。Meta 永远是整个树的第一个 Page，而 Root 和 Internal Page 其实没有什么区别。如下图：</p><p><img src="https://image.mwish.me/blog-image/IMG_1042.jpg" alt="IMG_1042"></p><p>还可以注意到，Leaf Page 是有左指针 <code>leftlink</code> 的，这是因为反向 Scan 的时候，它希望不获取上层 Page 直接 Scan 下来。</p><p>BTree 相关的内容定义在 <code>src/include/access/nbtree.h</code>，我们可以从 Meta 看起：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * The Meta page is always the first page in the btree index.</span></span><br><span class="line"><span class="comment"> * Its primary purpose is to point to the location of the btree root page.</span></span><br><span class="line"><span class="comment"> * We also point to the &quot;fast&quot; root, which is the current effective root;</span></span><br><span class="line"><span class="comment"> * see README for discussion.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * MetaPageData 指向</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">BTMetaPageData</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="comment">// 一些标志位</span></span><br><span class="line">uint32btm_magic;<span class="comment">/* should contain BTREE_MAGIC */</span></span><br><span class="line">uint32btm_version;<span class="comment">/* nbtree version (always &lt;= BTREE_VERSION) */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 真实的 root</span></span><br><span class="line">BlockNumber btm_root;<span class="comment">/* current root location */</span></span><br><span class="line">uint32btm_level;<span class="comment">/* tree level of the root page */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Fastroot 相关的内容</span></span><br><span class="line">BlockNumber btm_fastroot;<span class="comment">/* current &quot;fast&quot; root location */</span></span><br><span class="line">uint32btm_fastlevel;<span class="comment">/* tree level of the &quot;fast&quot; root page */</span></span><br><span class="line"><span class="comment">/* remaining fields only valid when btm_version &gt;= BTREE_NOVAC_VERSION */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 一些 vacuum 有关的标记.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* number of deleted, non-recyclable pages during last cleanup */</span></span><br><span class="line">uint32btm_last_cleanup_num_delpages;</span><br><span class="line"><span class="comment">/* number of heap tuples during last cleanup (deprecated) */</span></span><br><span class="line">float8btm_last_cleanup_num_heap_tuples;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span>btm_allequalimage;<span class="comment">/* are all columns &quot;equalimage&quot;? */</span></span><br><span class="line">&#125; BTMetaPageData;</span><br></pre></td></tr></table></figure><p>上面是整个 Page 的信息。</p><p>对于 Internal Page 和 Leaf Page，PostgreSQL 并没有引入额外的结构，它和我们之前聊的 Page 结构是一样的，只是 Tuple 是 <code>IndexTuple</code>，尾部内容如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *  在 Page 的尾部, 存储 Page 的 left 和 right 的兄弟节点和 btree 的 level,</span></span><br><span class="line"><span class="comment"> *   page 的 type. Vacuum 本身也会占有锁.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *BTPageOpaqueData -- At the end of every page, we store a pointer</span></span><br><span class="line"><span class="comment"> *to both siblings in the tree.  This is used to do forward/backward</span></span><br><span class="line"><span class="comment"> *index scans.  The next-page link is also critical for recovery when</span></span><br><span class="line"><span class="comment"> *a search has navigated to the wrong page due to concurrent page splits</span></span><br><span class="line"><span class="comment"> *or deletions; see src/backend/access/nbtree/README for more info.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *In addition, we store the page&#x27;s btree level (counting upwards from</span></span><br><span class="line"><span class="comment"> *zero at a leaf page) as well as some flag bits indicating the page type</span></span><br><span class="line"><span class="comment"> *and status.  If the page is deleted, a BTDeletedPageData struct is stored</span></span><br><span class="line"><span class="comment"> *in the page&#x27;s tuple area, while a standard BTPageOpaqueData struct is</span></span><br><span class="line"><span class="comment"> *stored in the page special area.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *We also store a &quot;vacuum cycle ID&quot;.  When a page is split while VACUUM is</span></span><br><span class="line"><span class="comment"> *processing the index, a nonzero value associated with the VACUUM run is</span></span><br><span class="line"><span class="comment"> *stored into both halves of the split page.  (If VACUUM is not running,</span></span><br><span class="line"><span class="comment"> *both pages receive zero cycleids.)This allows VACUUM to detect whether</span></span><br><span class="line"><span class="comment"> *a page was split since it started, with a small probability of false match</span></span><br><span class="line"><span class="comment"> *if the page was last split some exact multiple of MAX_BT_CYCLE_ID VACUUMs</span></span><br><span class="line"><span class="comment"> *ago.  Also, during a split, the BTP_SPLIT_END flag is cleared in the left</span></span><br><span class="line"><span class="comment"> *(original) page, and set in the right page, but only if the next page</span></span><br><span class="line"><span class="comment"> *to its right has a different cycleid.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *<span class="doctag">NOTE:</span> the BTP_LEAF flag bit is redundant since level==0 could be tested</span></span><br><span class="line"><span class="comment"> *instead.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *<span class="doctag">NOTE:</span> the btpo_level field used to be a union type in order to allow</span></span><br><span class="line"><span class="comment"> *deleted pages to store a 32-bit safexid in the same field.  We now store</span></span><br><span class="line"><span class="comment"> *64-bit/full safexid values using BTDeletedPageData instead.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">BTPageOpaqueData</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="comment">/** 两个兄弟 **/</span></span><br><span class="line"></span><br><span class="line">BlockNumber btpo_prev;<span class="comment">/* left sibling, or P_NONE if leftmost */</span></span><br><span class="line">BlockNumber btpo_next;<span class="comment">/* right sibling, or P_NONE if rightmost */</span></span><br><span class="line"><span class="comment">// 本 tree 的深度</span></span><br><span class="line">uint32btpo_level;<span class="comment">/* tree level --- zero for leaf pages */</span></span><br><span class="line"><span class="comment">// 下面几行就介绍这些 flags 了</span></span><br><span class="line">uint16btpo_flags;<span class="comment">/* flag bits, see below */</span></span><br><span class="line">BTCycleIdbtpo_cycleid;<span class="comment">/* vacuum cycle ID of latest split */</span></span><br><span class="line">&#125; BTPageOpaqueData;</span><br></pre></td></tr></table></figure><p>这里我们关注 <code>btpo_next</code>，是对应的下一页。这是一个定长的字段。那么 highkey 存在哪里呢？答案是：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *Lehman and Yao&#x27;s algorithm requires a ``high key&#x27;&#x27; on every non-rightmost</span></span><br><span class="line"><span class="comment"> *page.  The high key is not a tuple that is used to visit the heap.  It is</span></span><br><span class="line"><span class="comment"> *a pivot tuple (see &quot;Notes on B-Tree tuple format&quot; below for definition).</span></span><br><span class="line"><span class="comment"> *The high key on a page is required to be greater than or equal to any</span></span><br><span class="line"><span class="comment"> *other key that appears on the page.  If we find ourselves trying to</span></span><br><span class="line"><span class="comment"> *insert a key that is strictly &gt; high key, we know we need to move right</span></span><br><span class="line"><span class="comment"> *(this should only happen if the page was split since we examined the</span></span><br><span class="line"><span class="comment"> *parent page).</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *Our insertion algorithm guarantees that we can use the initial least key</span></span><br><span class="line"><span class="comment"> *on our right sibling as the high key.  Once a page is created, its high</span></span><br><span class="line"><span class="comment"> *key changes only if the page is split.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *On a non-rightmost page, the high key lives in item 1 and data items</span></span><br><span class="line"><span class="comment"> *start in item 2.  Rightmost pages have no high key, so we store data</span></span><br><span class="line"><span class="comment"> *items beginning in item 1.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> P_HIKEY((OffsetNumber) 1)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> P_FIRSTKEY((OffsetNumber) 2)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> P_FIRSTDATAKEY(opaque)(P_RIGHTMOST(opaque) ? P_HIKEY : P_FIRSTKEY)</span></span><br></pre></td></tr></table></figure><p>我们可以给 Page 画一个草图，如下：</p><p><img src="https://image.mwish.me/blog-image/E586E76B8C150D42A8D7A4AA738ACB98.jpg" alt="E586E76B8C150D42A8D7A4AA738ACB98"></p><p>此外，需要注意，对于 Internal Page 用户的第一个 key 相当于 <code>-inf</code>，它小于任何一个值。具体可以参考 <code>_bt_compare</code> 的注释。</p><p>在叶子结点上，IndexTuple 包含有指向的 HeapTuple 的位置。</p><h4 id="Fastroot"><a href="#Fastroot" class="headerlink" title="Fastroot"></a>Fastroot</h4><p>我们可以看到, <code>MetaPage</code> 有一个 <code>fastroot</code>，这个地方表示的是实际逻辑上的 Root，如下图：</p><p><img src="https://image.mwish.me/blog-image/C0C2426A8807D6CA2DB200A68939625B.jpg" alt="C0C2426A8807D6CA2DB200A68939625B"></p><p>这里 Root 到很下层都只有一个 link（可能是由于分裂和删除导致的，为什么会形成这种结构之后会讲），所以真实的 root 不等于访问上最快捷的 root，Meta 会有个 <code>fastroot</code> 来指向开始分叉的结点，来优化读</p><h3 id="Btree-的查找和移动"><a href="#Btree-的查找和移动" class="headerlink" title="Btree 的查找和移动"></a>Btree 的查找和移动</h3><h4 id="下降"><a href="#下降" class="headerlink" title="下降"></a>下降</h4><p>Btree 下降的主要逻辑在下列两个函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> BTStack _bt_search(Relation rel, BTScanInsert key, Buffer *bufP,</span><br><span class="line">  <span class="type">int</span> access, Snapshot snapshot);</span><br><span class="line"><span class="keyword">extern</span> Buffer _bt_moveright(Relation rel, BTScanInsert key, Buffer buf,</span><br><span class="line"><span class="type">bool</span> forupdate, BTStack <span class="built_in">stack</span>, <span class="type">int</span> access, Snapshot snapshot);</span><br></pre></td></tr></table></figure><p>一个下降，无论是插入还是查找，都会走到 <code>_bt_search</code>，不过这两种情况的 <code>access</code> 标识是不一样的。读取的时候，<code>access</code> 是 <code>BT_READ</code>, 写入的时候是<code>BT_WRITE</code> 。<code>Relation</code> 是整个关系（可以理解成表，有 HeapTable 和 Index 的信息），<code>BTScanInsert</code> 是需要查找的或者插入有关的 key，他可能会指定是否是 <code>next_key</code>, 查询的方向等。最后会搜到叶子结点，返回 <code>BTStack</code>，即 Btree 遍历的时候的栈。</p><p>我们首先介绍读的下降，下面逻辑对应的逻辑都在 <code>_bt_search</code> 中，假设第一次到第 k 层</p><ol><li>拿到本 Page 的读锁，对本 Page 进行 Pin。比较本 key 和 Page 的 <code>highkey</code>。如果小于等于 <code>highkey</code>，那么可以继续下降，否则，需要 <code>_bt_moveright</code> 向右移动</li><li>向右移动的时候，<strong>先拿到右 Page 指针，然后再释放锁和pin，再 acquire 右边的 Page 和锁</strong>，然后回到 (1) 的逻辑<ol><li>正确性：释放锁后，本 Page 和右边的 Page 可能都会分裂，因为 <code>highkey</code> 的限定，本 Page 分裂后，所有值仍然小于 highkey。而右边 Page 如果分裂，也只会向右分裂。Page 可能会删除 Page，这个时候删除 Page 的并发逻辑会保证删除的正确性</li></ol></li><li>如果移动到了 <code>key &lt;= highkey</code> 的场景，那么我们就找到了，如果是叶子结点，那就访问叶子，否则下降。这里首先把这个节点放到 <code>BTStack</code> 这个遍历的栈中，然后查找到走哪个 key 下降（调用 <code>_bt_binsrch</code> 做二分查找），然后<strong>释放自己的锁和 pin，再下降</strong>，这里仍然是靠 <code>highkey</code> 保证了下降的正确性。</li></ol><p><img src="https://image.mwish.me/blog-image/60C70C6E4770D882C1A15954F931DADF.jpg" alt="60C70C6E4770D882C1A15954F931DADF"></p><p>这里就可以正确的到达了。然后上面是讲第 <code>k</code> 层下降的。那根结点是怎么拿到的呢？这里会拿到 <code>fastroot</code>，直接下来就行了。用户没有插入任何值的时候，root 可能不存在。PG 如果发现 root 不存在，那就会直接返回 “啥都没查到”。</p><p>对于插入而言，如果没有 RootPage，会创建一个 RootPage。插入的逻辑从 <code>_bt_doinsert</code> 开始，Btree 会在 <code>Relation</code> 上记录最右 Page，如果 Page 是一个最右插入（即大于所有的插入值），那么它会直接走到最右侧的 page, 把它当作 <code>root</code> (记得吗，root 只是一个正常的 internal 或者 leaf page), 否则，它会返回树的 root。如果是插入的话，PG 发现 root 不存在，会直接创建一个 Root。</p><p>接下来，它会走 <code>_bt_search</code>，这里大概逻辑和 1-3 是一样的。不过读的时候拿的从根到叶子都是读锁，但 <strong>写在叶子结点的时候会切成写锁</strong>。</p><p>还有一些地方有区别，在写链路上，这里如果遇到了未完成的分裂，会驱动父节点把 <code>rightlink</code> 完成分裂，插入父节点。这部分代码在 <code>_bt_moveright</code> 和 <code>_bt_finish_split</code> 中。</p><h3 id="Scan"><a href="#Scan" class="headerlink" title="Scan"></a>Scan</h3><p>PostgreSQL 的 Scan 会首先下降到叶子节点，然后向右或者向左进行迭代。Scan 相关的一组函数如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">bool</span> _bt_first(IndexScanDesc scan, ScanDirection dir); <span class="comment">// 找到第一个对应位置, 然后把结构存在 `scan` 里面</span></span><br><span class="line"><span class="type">bool</span> _bt_next(IndexScanDesc scan, ScanDirection dir);  <span class="comment">// 对 scan 捞到下一个值</span></span><br><span class="line"><span class="type">bool</span> _bt_endpoint(IndexScanDesc scan, ScanDirection dir);</span><br></pre></td></tr></table></figure><p>Scan 首先要争取处理方向，然后 <code>IndexScanDesc</code> 描述了 Index 和 <code>ScanKey</code> 的关系：可能是 <code>&gt;=</code>, <code>&lt;=</code>, <code>&gt;</code> , <code>&lt;</code> 等。这里才实际执行的时候会变成：</p><ol><li><code>goback</code>: 是否要回退一个。如果 <code>goback == true</code>，就要回退一项</li><li><code>nextkey</code>: 是否要拿到大于搜索项的 key。这个有点怪，<code>nextkey</code> 设置的时候，会拿到 <code>item &gt; scan key</code>的，否则直接 <code>item &gt;= scan key</code> 就可以了</li></ol><p>有点绕，我们可以看看具体分析，这里有：</p><ol><li>如果是 <code>&lt;</code>, 那么会当 <code>&gt;=</code> 处理，然后需要 <code>goback</code></li><li>如果是 <code>&lt;=</code>，那么会当成 <code>&gt;=</code> 处理，需要 <code>goback</code> + <code>nextkey</code></li><li>…</li></ol><p>这里会构造一个搜索的 key 对象，来进行 <code>_bt_search</code>，再走 <code>_bt_binsrch</code> 在页面上定位到对应的位置。</p><p>下面会有一些比较 hack 的地方，在定位到位置后，这里会用 <code>_bt_readpage</code>来读出本页面剩下来所有内容，然后<strong>释放锁</strong>。这个地方感觉有点 RC 的意思了，新插入的数据感觉 PostgreSQL 是读不到的。猜测它这就没在意这个。释放锁是个很奇怪的地方，我们后面会论证它的正确性。</p><p><code>_bt_next</code> 移动到下一个要读的目标。这里有缓存的话，会先读取自己的缓存，没有的话，会走到下一个页面，调用函数: <code>_bt_steppage(IndexScanDesc scan, ScanDirection dir)</code>。</p><p>如果要向右移动，这里 PostgreSQL 会在搜到页面然后放锁之前，拿到 Page 的 right link，然后在需要跳转到下一个页面的时候拿到，这里逻辑如下图：</p><p><img src="https://image.mwish.me/blog-image/IMG_1046.jpg" alt="IMG_1046"></p><ol><li>如果自己这个 Page 没有分裂，即 <code>(1)</code>，那么移动到正确的页面</li><li>如果自己这个 Page 分裂了，然后这里可以直接移动过去。</li></ol><p>读左边的页面比较复杂，需要验证比较多东西。这个时候会：</p><ol><li>先锁住本页面，<strong>拿到 left-link</strong>，注意，向右移动的时候拿的是刚下来的时候拿到的 right-link, 反之 left-link 则是在需要左移的时候再拿的</li><li>放锁，走 left-link，拿到 left 的页面的锁</li><li>查看右边的 Page 是不是原来的 Page，如果是的话，就成功了，否则要向右再移动</li></ol><p><img src="https://image.mwish.me/blog-image/IMG_1047.jpg" alt="IMG_1047"></p><p>这里相对右移会复杂很多。这里再额外讨论一个 Page 被删除的情况。这个情况会根据 high key 来判断移动的范围。</p><h3 id="插入和分裂"><a href="#插入和分裂" class="headerlink" title="插入和分裂"></a>插入和分裂</h3><p>B-link tree 的分裂也是 Btree 的分裂，和 InnoDB 一样，PostgreSQL 也支持按照 bytes 50%-50% 分裂，也能支持向右分裂。我们这里可以先看看插入的时候用的栈：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">btinsert -- hook 在上层插入的函数</span><br><span class="line">- _bt_doinsert -- 转换了一下 key, 具体的去做 insert</span><br><span class="line">  用我们上面介绍的逻辑, 走 _bt_search_insert, 里面会走我们上面的逻辑, 需要注意的是, **这里检测到未完全分裂的 Page, 会做 _bt_finish_split, 完成分裂**</span><br><span class="line">  做一些 checkUnique 和事务有关的东西(比如上锁), 可能会走到 HeapTable 上验证, 或者靠 LP_DEAD 等辅助位判断</span><br><span class="line">  - _bt_insertonpg, 具体插入</span><br><span class="line">  如果 PageGetFreeSpace(page) &lt; itemsz, 调用分裂, 走 _bt_split 和 _bt_insert_parent</span><br><span class="line">  否则, 直接插入页面, 写一条 xlog, 然后标识 LSN.</span><br></pre></td></tr></table></figure><p>这里在搜索的时候，会有一些特殊的逻辑，搜索路径上碰到分裂会做 <code>_finish_split</code></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * If this page was incompletely split, finish the split now.  We do</span></span><br><span class="line"><span class="comment"> * this while holding a lock on the left sibling, which is not good</span></span><br><span class="line"><span class="comment"> * because finishing the split could be a fairly lengthy operation.</span></span><br><span class="line"><span class="comment"> * But this should happen very seldom.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">if</span> (P_INCOMPLETE_SPLIT(opaque))</span><br><span class="line">&#123;</span><br><span class="line">_bt_finish_split(rel, rbuf, <span class="built_in">stack</span>);</span><br><span class="line">rbuf = InvalidBuffer;</span><br><span class="line"><span class="keyword">continue</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (!P_IGNORE(opaque))</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">if</span> (P_RIGHTMOST(opaque))</span><br><span class="line">elog(ERROR, <span class="string">&quot;fell off the end of index \&quot;%s\&quot;&quot;</span>,</span><br><span class="line"> RelationGetRelationName(rel));</span><br></pre></td></tr></table></figure><h4 id="第一阶段-页面分裂"><a href="#第一阶段-页面分裂" class="headerlink" title="第一阶段: 页面分裂"></a>第一阶段: 页面分裂</h4><p>页面分裂会带上锁，然后把页面分裂成两份，然后标记页面为 unfinished split. 代码逻辑在 <code>_bt_split</code>:</p><ol><li><code>_bt_findsplitloc</code> 找到分裂点。这里准备临时的 leftpage 和 rightpage 作为目标，rightpage 需要持久化到存储中，leftpage 会写回原来的 page1</li><li>产生新 Page, 在内存申请 page， 设置写入的 LSN，寻找分裂到左边的 highkey 等</li><li>用  <code>_pg_addtup</code> 插入元素。</li><li>写 xlog，把两边的更新写入 log buffer, 然后重新设置 LSN.</li><li>放锁</li></ol><h4 id="第二阶段-插入父节点"><a href="#第二阶段-插入父节点" class="headerlink" title="第二阶段: 插入父节点"></a>第二阶段: 插入父节点</h4><p><code>_bt_finish_split</code> 在扫描阶段会检测到分裂到一半的节点，他会判断自己是不是 root，对自己和右节点上写锁（下降的时候，需要释放读锁，然后切成写锁），然后走 <code>_bt_insert_parent</code>，而分裂在代码上也会走 <code>_bt_insert_parent</code>。这里会有叶子和兄弟阶段的写锁。</p><p><code>_bt_insert_parent</code> 中，之前 <code>BTStack</code> 上的锁都释放了，这里父节点不能被删除（因为删除比较特殊），但<strong>可能分裂了</strong>，所以要查到真的父节点在哪，然后再插入。插入很简单，但是查找父节点比较 hack，这部分代码在: <code>_bt_getstackbuf</code>:</p><ol><li>找到 stack 的父节点，get 起来然后捞到死锁</li><li>(递归的) 调用 <code>_bt_finish_split</code>, 完成 incomplete split.</li><li>扫描 page，看看子节点有没有对应的待完成分裂的那个，如果有的话，搜索成功</li><li>否则，尝试 moveright</li></ol><h4 id="Root-的分裂"><a href="#Root-的分裂" class="headerlink" title="Root 的分裂"></a>Root 的分裂</h4><p>根节点的分裂和正常节点没有什么区别，这里根分裂会产生一个新的根节点，然后让 meta 指向它。</p><p><img src="https://image.mwish.me/blog-image/IMG_1048.jpg" alt="IMG_1048"></p><p>这里走的逻辑是 <code>_bt_newroot</code>，需要修改 <code>MetaPage</code> 上的标记</p><h3 id="对-Key-的删除"><a href="#对-Key-的删除" class="headerlink" title="对 Key 的删除"></a>对 Key 的删除</h3><p>在原来的 B-link 树论文中，Delete 几乎是串行的。其实 B-link tree 也差不多，删除会占据 super lock：删的时候，页面要没有 Pin (防止 Scan 出问题) 也要没有 Lock。</p><p>PG 不会对 key 简单删除，只会在 vacuum 的时候进行删除。PG 还有一个 simple delete，这里会把 touch 不到的多余的版本标记为 <code>LP_DEAD</code>，等待回收。</p><p>PG 只有叶子节点删空了才会被回收，回收也是多阶段的，需要调整兄弟节点的指针，所以非常非常麻烦，这里会先调整指针，然后再把整个子结构摘除。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Notes on Btree Implements: InnoDB</title>
      <link href="/2022/07/04/Notes-on-Btree-Implements-InnoDB/"/>
      <url>/2022/07/04/Notes-on-Btree-Implements-InnoDB/</url>
      
        <content type="html"><![CDATA[<p>BTree 的实现一直是有范本但工程上很难做的事情，Btree 自上世纪 70 年代被提出后(1972)，已经是一个久经考验的结构了（远比 LSM-Tree 古老），但是 B-Tree 的并发一直是介绍材料不多、工程实现难啃的部分。相对于 2021 年常见的 LSM-Tree 而言，[1] B-Tree 实现大部分不是 immutable 的 。[2] B-Tree 大部分和存储引擎、Recover System、事务、Catalog 结合得很紧密，大部分时候不是一个简单的 KV 接口。导致这个常见的数据库结构带上了很多神秘的面纱。</p><p>我们希望介绍 MySQL 的 InnoDB 引擎、PostgreSQL 的 BTree 引擎和 WiredTiger 的 COW BTree 结构。来介绍一下常见数据库真实使用的 BTree 范本。</p><h2 id="MySQL-InnoDB"><a href="#MySQL-InnoDB" class="headerlink" title="MySQL InnoDB"></a>MySQL InnoDB</h2><p>MySQL InnoDB 基于 Jim Gray 的 Transaction Processing 一书实现。这里实现了一个 MVCC 的 BTree，MVCC 数据采用 N2O 的形式链接，主表数据存储在 BTree 上，称为 <strong>Cluster Index</strong>；索引数据；旧版本的数据会放到一个 Delta Space 里面。删除和 MVCC 的形式结合起来，做标记删除。</p><p>一刻 BTree 的 Page 会尽量存放在一起，具体可以参考 InnoDB 的表空间。同一个索引中，non-leaf page 会存储在一个 Segment 中；leaf page 会存储在一个 Segment 中。Segment 会按照 Extent (大小为 1MB，默认为 64 个 Page ) 为单位，向系统申请存储空间。</p><h3 id="Page"><a href="#Page" class="headerlink" title="Page"></a>Page</h3><blockquote><p>数据页包括七个部分，数据页文件头，数据页头，最大最小记录，用户记录，空闲空间，数据目录，数据页尾部。 简单的来说，数据页分两部分，一部分存储数据记录，按照记录的大小通过记录的指针连接起来。另外一部分存储数据页的目录，用来加速查找。</p></blockquote><p>以索引页为例：</p><p><img src="https://image.mwish.me/blog-image/mysql_10.png" alt="mysql_10"></p><p>File Header 部分会标志这里是什么页，而 File Trailer 则有 crc 和页面的 lsn。这一组内容由 <code>fil</code> 有关的文件组提供，代码在：<a href="https://github.com/CatKang/InnoDB/blob/master/innobase/include/fil0fil.h#L789">https://github.com/CatKang/InnoDB/blob/master/innobase/include/fil0fil.h#L789</a></p><p><code>page</code> 有关的文件基本上是为索引页设计的，<code>page</code> 开头基本上是存储的页面元信息，Page Header 之类的，它的元信息在 <code>page0page</code>  维护，操作主要在：<a href="https://github.com/CatKang/InnoDB/blob/master/innobase/include/page0cur.h">https://github.com/CatKang/InnoDB/blob/master/innobase/include/page0cur.h</a></p><h3 id="Tuple"><a href="#Tuple" class="headerlink" title="Tuple"></a>Tuple</h3><p><img src="https://image.mwish.me/blog-image/66E4B75E-076C-4F97-A65A-C9AB3427F6AD.png" alt="66E4B75E-076C-4F97-A65A-C9AB3427F6AD"></p><p>这些 Tuple 之间会根据 <code>next_record</code> 构成一个单向链表，指向下一个字段的 header 之后，真实信息之前，<code>transaction_id</code> 是一个顺序增长的 id，用来表示创建这条记录的事务 id，<code>roll_pointer</code> 指向 undo 上的记录。</p><h3 id="Leaf-Page-Non-Leaf-Page"><a href="#Leaf-Page-Non-Leaf-Page" class="headerlink" title="Leaf Page / Non Leaf Page"></a>Leaf Page / Non Leaf Page</h3><p>下面的代码实现在 <code>page0page</code> 相关的系统中。</p><p>InnoDB 的 Page 内容采取双向链表 + 稀疏索引的形式实现，头部还有一些统计信息，下图比较清晰：</p><p><img src="https://image.mwish.me/blog-image/215370F3-E7ED-4D14-B00C-23DDDAACED2E.png" alt="215370F3-E7ED-4D14-B00C-23DDDAACED2E"></p><p>此外，Page 内还有页面的垃圾链表，存放垃圾记录：</p><p><img src="https://image.mwish.me/blog-image/D58CA7AD-5362-42E3-9700-4454036DF6C6.png" alt="D58CA7AD-5362-42E3-9700-4454036DF6C6"></p><p>对 Page 的操作可以看：<a href="http://mysql.taobao.org/monthly/2018/04/03/">http://mysql.taobao.org/monthly/2018/04/03/</a></p><p>对 Page 的操作会被封装在 <code>mtr</code> 里面，这里日志类似物理逻辑日志。写 Undo Page 也会落 mtr。</p><p>同一高度的 Page 会组织成双向链表，称为 Page List。</p><h4 id="对页面的操作"><a href="#对页面的操作" class="headerlink" title="对页面的操作"></a>对页面的操作</h4><p>结合之前说到过的 Page 内部组织，page 的查找和插入、更新操作都在 <code>page0cur</code> 相关的文件中。需要注意的是，对 Page 的操作不是单个操作，而是一组操作，具体而言，比如说对 Page 的插入，这里会拿到一个对应的 cursor，指向插入的<em>前一条记录</em>，详见代码 <code>page_cur_insert_rec_low</code>:</p><ol><li>找到 Page 的原本的信息，包括一些统计信息</li><li>在 Page 里找到空闲的空间插入记录</li><li>修改统计信息，和上一条记录的 next （还记得它们是单向链表吗）</li></ol><p>所以这里插入实际上不是单条操作，而是一组合起来的操作。</p><p>删除的话，可能直接标记 <code>delete_mark</code>，然后更新一些统计信息即可。</p><h3 id="Undo"><a href="#Undo" class="headerlink" title="Undo"></a>Undo</h3><p>InnoDB 的 MVCC 实现是 Main-Delta。逻辑如下所示：</p><p><img src="https://image.mwish.me/blog-image/64C7B2DB-DD5C-40EF-AAE3-AF420AB6A390.png" alt="64C7B2DB-DD5C-40EF-AAE3-AF420AB6A390"></p><p>具体而言，对于 InnoDB，如果有表 <code>(a: PrimaryKey, b)</code>, 然后 b 被两个事务更新两次，可能会有：</p><ol><li>Cluster Index: <code>(a: a, b: b2), update by txn2, roll_pointer-&gt;u2</code></li><li>Undo:<ol><li><code>u2: &lt;Undo Update, txn1, (a: a, b: b1), roll_pointer-&gt;u1&gt;</code></li><li><code>u1: &lt;Undo Update, txn1, (a: a, b: b0), roll_pointer-&gt;NULL&gt;</code></li></ol></li></ol><p>在逻辑上如下图表示：</p><p><img src="https://image.mwish.me/blog-image/undo_logical.png" alt="undo_logical"></p><p>Undo 实际上承担的功能类似：</p><ol><li>回滚数据库未完成的事务（教科书上的 undo，不过这样其实是<strong>最多只需要一个版本</strong>的），对应接口在 <strong>row_undo</strong>，<strong>trx_roll_pop_top_rec_of_trx</strong> 这条链路</li><li>MVCC 回溯版本链，作为 Undo 的数据，对应接口在在函数<strong>row_search_mvcc</strong>中，关注<strong>trx_undo_prev_version_build</strong> 和 <strong>row_upd_rec_in_place</strong></li></ol><p>物理空间上，Undo 也是由 Page 组织的。一个事务主要记录会保留在一个 Undo Page 上（多余一个的会存在一个 Page 上，但是不讨论），事务的记录会被一个双向链表 history list 串起来，然后按照全局的最低活跃事务和这个 history list 来做多版本数据的 GC。</p><p><img src="https://image.mwish.me/blog-image/undo_log_disk_structure.png" alt="undo_log_disk_structure"></p><p>此外，虽然 btr 我们后面才会介绍，但是 InnoDB Undo 不会涉及 secondary indexes，这点在官方文档也有提及：<a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html">https://dev.mysql.com/doc/refman/8.0/en/innodb-multi-versioning.html</a></p><h3 id="Redo"><a href="#Redo" class="headerlink" title="Redo"></a>Redo</h3><p>InnoDB 的 Redo 感觉就和教科书的 Redo 很接近了。这里有一些分类：</p><ol><li>Page 内操作的物理逻辑日志，比如 <code>MLOG_REC_INSERT</code>, <code>MLOG_REC_UPDATE_IN_PLACE</code>, <code>MLOG_REC_DELETE</code>，它们会有一些操作标注修改的页面。</li><li><code>MLOG_FILE_CREATE</code> 等空间状态的日志</li><li><code>MLOG_MULTI_REC_END</code> 等表示一组操作的日志。比如页面分裂的时候，会有一组表示拷贝记录的日志，需要用这样的日志结尾。</li></ol><h3 id="Transaction-和-MTR"><a href="#Transaction-和-MTR" class="headerlink" title="Transaction 和 MTR"></a>Transaction 和 MTR</h3><p>最后介绍一下事务子系统，希望能把上面的 Btree 和 Undo 内容连起来：</p><p>mtr 完成的是 atomic, durable 的多页面操作，它会封装对<strong>单个</strong>索引（包括 Cluster Index）和 Undo 。mtr recover 的时候，只有 redo，没有 rollback。rollback 都是上层事务的 rollback。</p><p><img src="https://image.mwish.me/blog-image/90D7A363-9443-4B7E-A032-EFF999FFECBD.png" alt="90D7A363-9443-4B7E-A032-EFF999FFECBD"></p><p>对事务的操作都会丢到 mtr 的 buffer 里面，提交完后原子提交到 redo 中。同时，读取可能也有 mtr。</p><p>事务层会有 多个 mtr: 包括索引的 mtr, undo 的 mtr，事务是 mtr 上层的概念。它从 Btree 读取 mtr 中读到数据，然后在这一层上锁。</p><h2 id="InnoDB-Btree-的操作"><a href="#InnoDB-Btree-的操作" class="headerlink" title="InnoDB Btree 的操作"></a>InnoDB Btree 的操作</h2><h3 id="下降和-Latch"><a href="#下降和-Latch" class="headerlink" title="下降和 Latch"></a>下降和 Latch</h3><p>BTree 访问遵照 Latching Protocol。具体代码在 <code>btr0btr</code> 和 <code>btr0cur</code> 中. <code>btr_cur_t</code> 是 btr 的 cursor，从 <code>btr_cu r_search_to_nth_level</code> 中拿到对应的 cursor。然后这里 <code>btr_cur_t</code> 插入和删除。同时，我们还可以和 <code>page0cur</code> 中的 <code>page_cur_t</code> 结合起来。btree 访问有几种 flag:</p><blockquote><p>在B+ tree上共有三种操作：</p><ul><li>读（<strong>BTR_SEARCH_LEAF</strong> / <strong>BTR_SEARCH_LEAF</strong>）：分为点查询和范围查询</li><li>乐观写（<strong>BTR_MODIFY_LEAF</strong>）：仅影响到一个索引页的增删改</li><li>悲观写（<strong>BTR_MODIFY_TREE</strong>）：影响到超过一个索引页的增删改（e.g. DELETE SQL导致了页合并）</li></ul></blockquote><p>同时， BTree 有 Latch 的概念，btree 操作很多都有参数 <code>dict_index_t::lock</code>，表示 btree 的锁。Page 的 latch 在 <code>buf</code> 层实现，外部可以在调用传入 <code>buf_page_get_gen</code> 传入参数。叶子结点访问有 <code>btr_cur_latch_leaves</code></p><p><code>btr_cur_search_to_nth_level</code> 有一千多行代码，逻辑比较复杂，在 8.0 版本中，读取实现逻辑如下：</p><ol><li>获取 index 的 S 锁: <code>mtr_s_lock(..)</code></li><li>然后沿着搜索 btree 路径, 遇到的 non-leaf node page 都加 S LOCK</li><li>然后直到找到 leaf node 以后, 对 leaf node page 也是 S LOCK ( <code>btr_cur_latch_leaves</code> )</li><li>然后把index-&gt; lock 放开, 释放掉别的 latch ( <code>mtr_release_s_latch_at_savepoint</code> )</li></ol><p><img src="https://image.mwish.me/blog-image/AGN3ghS.png" alt="AGN3ghS"></p><p>对于修改请求，这里有 <strong>乐观</strong> 和 <strong>悲观</strong> 两种：</p><ol><li>乐观：<code>btr_cur_optimistic_insert</code>：假设没有 SMO，进行插入</li><li>悲观：<code>btr_cur_pessimistic_insert</code>：乐观插入发现叶子会分裂，进行插入</li></ol><p>上面内容不会出现在 <code>btr_cur_search_to_nth_level</code>，不过会影响 <code>btr_cur_search_to_nth_level</code> 的参数 <code>btr_latch_mode</code>. 他们插入内容如下图：</p><ul><li>乐观插入类似查找，也是 S 拿到 index 锁，拿到叶子结点的 X 锁（为了与 S 锁互斥）</li><li>悲观插入假设自己会引发 SMO ，首先，它会拿到 SX 锁。SX 锁能够与 SX 锁互斥（即与悲观的插入/删除互斥），但不阻塞读和无关的写。然后，下降的时候，因为已经给btree 加上 SX 锁, 那么搜索路径上的btree 的page 都不需要加锁, 但是需要把搜索过程中的page 保存下来, 最后阶段给搜索路径上有可能发生结构变化的page 加x lock。此外，这里叶子需要 X锁，且需要<strong>左右兄弟的锁</strong>。</li></ul><p><img src="https://image.mwish.me/blog-image/ye4VVpc.png" alt="ye4VVpc"></p><h3 id="Cursor-amp-Persistent-Cursor"><a href="#Cursor-amp-Persistent-Cursor" class="headerlink" title="Cursor &amp; Persistent Cursor"></a>Cursor &amp; Persistent Cursor</h3><p>对于下降函数，这里可能会下降很多次，最终到达叶子结点，但对于一个 Scan，肯定不能每次下降一次。这里要根据 page 上的 cursor 来做一些操作，包括 scan 的 next 什么的，这里有一些优化：</p><ol><li><strong>record buffer</strong>：对于连续的记录扫描，在满足比较严格的条件时采用 record buffer，预读几条数据</li><li><strong>persistent cursor</strong>（持久化游标，简称 pcur）：当进入 InnoDB 层获得记录后，返回 SQL 层前，当前在 B-tree 上的 cursor 会被暂时存储到 <code>row_prebuilt_t::pcur</code> 中，当再次从 InnoDB 层拿数据时，如果对应的 buf_block_t 没有发生任何修改，则可以继续沿用之前存储的 cursor（optimistic restore cursor）。否则需要重新定位（pessimistic restore cursor）。如果没有 persistent cursor 则每次都需要重新定位</li></ol><p>persistent cursor 代码在 <code>btr_pcur_t</code>，文件在 <code>btr0pcur</code>。<code>btr_pcur_move_to_next_page</code> 描述了它读下一个页面的流程（本页面都扫描完了），这里会获取下一页面，再释放本页面的锁。<code>restore_position</code> 描述了 <code>pcur</code> 回到本页面的逻辑。</p><p>上面都比较简单，因为移动到下一页相对比较轻，但是比较复杂的情况是逆序扫描，这里代码在 <code>move_backward_from_page</code>，这里如果搜索了前一个 Page 的话，那么会有问题：先锁右 - 再锁左边会违背 latching protocol，这里会：</p><ol><li>释放之前的 latch</li><li>在树上从新搜索之前的值的前一个值, <code>btr_search_to_nth_level</code> + <code>BTR_SEARCH_PREV</code></li></ol><h3 id="分裂"><a href="#分裂" class="headerlink" title="分裂"></a>分裂</h3><p>我们之前介绍了 下降 + 插入的情况。分裂/合并都是 SMO 操作，他们是由悲观的插入来提供的。</p><p>Btree 分裂在 <code>btr_page_split_and_insert</code>, 在插入 Page 的时候，会有一些元信息来表示顺序插入的次数，如果插入都是顺序插入或者满足一定条件，那么 Page 会向右分裂；否则会按照 bytes 空间的 50% 来进行分裂。</p><p><img src="https://image.mwish.me/blog-image/btr_page_split_and_insert.png" alt="btr_page_split_and_insert"></p><h4 id="根结点的分裂"><a href="#根结点的分裂" class="headerlink" title="根结点的分裂"></a>根结点的分裂</h4><p>在 InnoDB 中，BTree 的 Root Page 是不会更改的。如果是 RootPage 从叶子结点分裂到根结点，具体逻辑如下：</p><ol><li>产生一个叶子结点</li><li>把根结点数据拷贝上去，根结点指向它</li><li>这个叶子结点执行分裂</li></ol><p><img src="https://image.mwish.me/blog-image/btr_root_raise_and_insert.png" alt="btr_root_raise_and_insert"></p><h3 id="Insert-Buffer"><a href="#Insert-Buffer" class="headerlink" title="Insert Buffer"></a>Insert Buffer</h3><p>insert buffer 对于 non-unique 的  secondary index 才有用，在写索引的时候，无法加载到内存中的时候，插入 insert buffer 作为缓存。</p><p>这块代码其实比较 hack 而且散在各处，比如读取的时候还要查一下有没有 insert buffer 里面的写，然后把数据倒腾进去。</p><h3 id="上层的-ICP-和-Lock"><a href="#上层的-ICP-和-Lock" class="headerlink" title="上层的 ICP 和 Lock"></a>上层的 ICP 和 Lock</h3><p>对 Btree 的访问本身是没有锁的，锁是在上层拿到的。对于一个查询 + 更新而言，大概逻辑如下：</p><ol><li>从 btr 查询需要的行</li><li>给记录加锁</li><li>申请 undo, 写 undo</li><li>更新对应的行，这个和 undo 其实是不同的 mtr</li><li>commit</li></ol><p>ICP 是查询的时候带有对应的谓词，大概逻辑如下：<br><img src="https://image.mwish.me/blog-image/v2-d99e782c382bb6bab211faf1d8f432ac_r.jpeg" alt="v2-d99e782c382bb6bab211faf1d8f432ac_r"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://catkang.github.io/2020/02/27/mysql-redo.html">https://catkang.github.io/2020/02/27/mysql-redo.html</a></li><li><a href="https://catkang.github.io/2020/02/27/mysql-redo.html">https://catkang.github.io/2020/02/27/mysql-redo.html</a></li><li>InnoDB：B-tree index（1） - Skywalker的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/164705538">https://zhuanlan.zhihu.com/p/164705538</a></li><li>InnoDB：B-tree index（2） - Skywalker的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/164728032">https://zhuanlan.zhihu.com/p/164728032</a></li><li>InnoDB——Btree与MTR的牵扯: <a href="http://liuyangming.tech/05-2019/InnoDB-Mtr.html">http://liuyangming.tech/05-2019/InnoDB-Mtr.html</a></li><li>MySQL · 源码分析 · btr_cur_search_to_nth_level 函数分析: <a href="http://mysql.taobao.org/monthly/2021/07/02/">http://mysql.taobao.org/monthly/2021/07/02/</a></li><li>MySQL · 内核特性 · InnoDB btree latch 优化历程: <a href="http://mysql.taobao.org/monthly/2020/06/02/">http://mysql.taobao.org/monthly/2020/06/02/</a></li><li><a href="https://mariadb.org/wp-content/uploads/2018/02/Deep-Dive_-InnoDB-Transactions-and-Write-Paths.pdf">https://mariadb.org/wp-content/uploads/2018/02/Deep-Dive_-InnoDB-Transactions-and-Write-Paths.pdf</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>毕业两年记</title>
      <link href="/2022/07/03/%E6%AF%95%E4%B8%9A%E4%B8%A4%E5%B9%B4%E8%AE%B0/"/>
      <url>/2022/07/03/%E6%AF%95%E4%B8%9A%E4%B8%A4%E5%B9%B4%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>不知不觉毕业两年了。在同济的快乐时光好像还在昨天一样——毕业前去动物园、去博物馆。我并不是一个很有集体荣誉感的人，毕业那几天的时候班级说拍毕业照，我觉得太无聊了就看了一晚上动画然后睡到11点没去，反正大部分人我上学的时候都不熟悉，下午打着瞌睡去参加毕业典礼找人拍照，毕业典礼的时候也不咋激动。不过感觉那会儿毕业典礼大家感情还算很真挚，校领导说要把论文写在祖国大地上，贵校搞了这么多土建，感觉倒是挺真实，反正贵校 se 一届 200人，cs 100 人，比起土木一个院 500 人，感觉他们确实把自己贡献过去了。大家确实很了不起，当然，也没有得到什么应得的待遇。说远了，比较真挚的是学生代表，也是土木的，成绩不算好那种，跟我们讲自己找不到工作的事情。感觉傻逼同济没啥人文气息，不过还是有点真挚的。当然，这是好的回忆了，我不知道这傻逼学校一年后搞出了嘉定食物中毒，两年后搞出了生猪肉和赶博士生。妈的，我又想起嘉定那边搞会然后把上学路封起来的傻逼事情了，还有不处理学校野狗什么的，越想越气了。</p><p>言归正传。我没在大学学到什么专业知识，很多东西都是 breezewish 学长带我进 PingCAP 实习之后，我从零开始自学的。按照疾世愤俗或者比较上进的人的思路，我应该开始诅咒国内学校的十八代了——或许我真的应该那么做，啊哈哈，不过我总是想起一些好的回忆（可能是毕业了，记忆自动美化了很多）。想起我在大学对不起的信任我的人，想起我那三个和我一样爱摸鱼的舍友、想起楼下201宿舍天天跑去图书馆的大手子们，想起 SXKDZ 学长和嘤嘤学长、灿学长、洞叔、王这些人，像塞林格说的，“你千万别跟我提起来，你一旦提起来，我就能想起他们所有人”，哦不对，想起我大二的时候 SXKDZ 学长说的“这是最后一个上课的老师都知道自己在上什么课的学期了”。我想说的是，16-20 年，这个学校没给我什么压力，也没有约束我什么，我用这段时间好好玩了一下，虽然没学到什么，但我很开心，这就是虚度光阴的快乐吧。反正咱这傻逼地方毕业的，工作也都是自学，没啥不一样的。</p><p>工作之后和上学还是挺不一样的，工作是一个很奇怪的事情，我大概五月份才找到一份正式的上岸工作，当时我给很多地方投简历都没啥满意结果，然后给一个知乎的网友发了私信问能不能帮我推一推简历，这才在毕业之前终于上了岸。我抱着忐忑的心进了知名的奶头乐批发商 ByteDance，老实说，感谢我的同事们，他们对我还算好，让我觉得自己是能够当一个社会人的。工作用很单一的领域来不断挑战你、用日常性麻痹你、用不同的人干同样的事来给你一个即多元又单调的世界。相比在学校可能做一些混合的项目，在工作中，你需要一天超过10小时的做一件事，这些东西既忙碌又琐碎，而且绩效比成绩更奇怪，它依靠你本身的水平，但更依赖你有什么事情做。我有幸赶上了有代码写的时候，给团队做了一些简单贡献，也很不幸常常被抓着凌晨 oncall、电话被打爆、被业务骚扰到疲于奔命。坦白说，在字节工作所有人都是琐碎的 sre，同时你的见识严格被限定于同事们。虽然大公司里面有非常多的学习资源，但是很多东西我确实也没认真看，算是虚度了不少光阴。感谢任老师在这段时间教了我非常多的知识，给我很多帮助；也感谢 cc 和 zz 这两位同事帮我挡住和解决了很多困难，也没有在工作上给我太大压力，给了我一个还算愉快的工作环境并作为我的学习榜样。刚参加工作的时候心态经常出问题，也靠着群里的朋友们能舒缓情绪，看着大家轮流发病，来在 99 个未接来电之中舒缓情绪。自己也慢慢能够翻着一些 ppt，把计算机和数据库的基础慢慢补上。坦白说我很笨，悟性很差，很多东西看了一遍也草草看过，其实并没有看懂，我也不擅长和人交流、找到合适的地方问这些问题，甚至不擅长写代码，不太能找到一个专一的目标然后继续干完。但毕竟自己一直在慢慢看书、在组里参与写代码，掌握知识比别人慢就慢呗，毕竟我要看动画打游戏的，上班凑合凑合着过熬资历呗，不过满满的这样感觉终于能够跟上一些行业知识的背影了，也能够在公司组里小小的立足了。这段时间也算入门了一些社会科学，从啥都不懂的到对涂尔干、韦伯、马克思他们有浮光掠影的了解。</p><p>但是毕业以后最开心的时光还是回家或者去上海找老同学。北京是一个奇怪的地方，它给每个区固定了用处，区分了市内和郊外，城市被严格的切成碎块，它有丰富的文化遗产和悠久的历史，但像列斐伏尔描述的那样，这多少有点像「设计专家」设计的居住城市，你在这里感受不到生活。虽然海淀区学校扎堆，但很难看到所谓的富有生活气息的人——或许有，但朝10晚10的程序员可能看不到吧。它还会用户口和价格等方式拒绝你。在这里，我感受到一股浓浓的「异乡」感——“没有故乡的人有难了！”今年的疫情加重了这一现象，在封闭、乱象、网络上的民粹和 long lockdown 中，人难免不感受到这个世界的焦虑。当然，我们可以借着这个聊福柯、聊经济、聊这个 covid 大流行和别的可怜事情也多的世界。但我只想聊聊这种抛弃感和焦虑: 「如果一直待在这种地方，是没有办法塑造美好的回忆的」。恍惚之间想起快乐的时候，在家边上骑车、在家里和同学看电影、给爸妈下片子、到大学同学家借宿和打扫卫生。人的日常生活有多美好的潜力，但是日常是不会自己改变日常的，日常要靠超越性的或者破坏性的内外力量来改变。所以今年我也希望自己能有一些变化吧。</p><p>眨眼就毕业两年了，本来想写写同学、写写工作、写写感谢的同事、期盼一下自己未来能稍微不那么菜一点，不过感觉这成了老年人发牢骚了。总而言之，希望学校的回忆能一直是我美好的记忆，我能靠着这份美好的回忆，创造一些新的美好记忆。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>[VLDB&#39;17] An Empirical Evaluation of In-Memory Multi-Version Concurrency Control</title>
      <link href="/2022/07/03/An-Empirical-Evaluation-of-In-Memory-Multi-Version-Concurrency-Control/"/>
      <url>/2022/07/03/An-Empirical-Evaluation-of-In-Memory-Multi-Version-Concurrency-Control/</url>
      
        <content type="html"><![CDATA[<p>本文是一篇关于 MVCC 的综述，将 MVCC 分为了 protocol, version storage, index-management, gc 四个部分, 在 Peleton 上实现了各种 protocol, 进行试验，然后 benchmark。benchmark 结果是：protocol 上看争用，读多写少争用多的话，2PL/OCC 反而不太行；N2O 几乎总是比 O2N 好，不过 O2N 可以GC；Delta 占用的空间小一些（Delta 类似 MySQL Undo log buffer）；Txn Level GC 好一些，但实现难度高一些。</p><p>当初第一次看的时候大概懂了大意，不过当时对 MVCC 没看过什么代码，也没有什么基本理解，最近看 WiredTiger/PostgreSQL/InnoDB 的时候感觉理解了一些 context，回头写一点总结，也混杂一些我对 WT/PG/InnoDB 的理解。</p><p>关于 MVCC，有的地方实际怀疑它是否牺牲了空间以换取了不知道有没有的性能，关于这些争论，我个人想法类似 Hekaton 论文里面的理解：MVCC 可能在冲突低的情况下降低了性能和局部性，但是增强了系统对抗一些混合负载的能力。同时，MVCC 方便支持一些 Time-Traver 查询（类似 MySQL / PG 的 PITR 系统）。</p><p>之所以有这篇论文，是因为 MVCC 虽然历史悠久，但是几乎所有新系统都自己嗯造了一套，所以需要衡量一下对应的 design choice 和 trade-off</p><h3 id="DBMS-Meta-Data"><a href="#DBMS-Meta-Data" class="headerlink" title="DBMS Meta-Data"></a>DBMS Meta-Data</h3><p>论文讲数据分为下列数据，感觉是作者在 Peloton 实现的数据：</p><p><img src="https://image.mwish.me/blog-image/97119CA8-7614-4F6F-841C-386E9B579756.png" alt="97119CA8-7614-4F6F-841C-386E9B579756"></p><p>事务需要一个独立的，单调递增的标记来识别，文中记作 $T_{id}$ .</p><p>同时，物理的版本包括了 <code>txn-id</code>, 两个时间戳和版本指针，事务 id 类似 Hekaton 的，最高位表示是否有 write-lock，然后论文用 CAS 做修改，我们可以对比一下 PostgreSQL 和 InnoDB 的记录：</p><ul><li>PostgreSQL 的 xmax(类似 end-ts ) 充当了 txn-id 作用，表示对对象上锁。论文里可能有多个 in-flight 的事务在同一条记录上，所以感觉引入一个 txn-id 也没啥问题。此外，PostgreSQL 的行还引入了 info bits，避免查事务表来确定 <code>txn</code> 的状态，所以相当于上面 txn-id 和 end-ts 做到了一起，PG 有一个 <code>c_tid</code>，相当于上面的 pointer，指向自己或者更新的版本。</li></ul><p><img src="https://image.mwish.me/blog-image/fig-5-03.png" alt="fig-5-03"></p><ul><li>PostgreSQL 的 txn-id 和时间是 32-bit 的，所以最大也就4亿，占有空间小，但是需要 FREEZE （冻结版本）和 Vacuum（回收）来处理。InnoDB 可能需要用户提供的 gtid 什么的。它只有一个类似 ts 的字段，因为比它小的就会走 undo chain。<strong>PG 需要 x-min, x-max; 但 InnoDB 用 txn-id + roll_pointer</strong> 做了逻辑上一样的事情。那删除会怎么样呢？InnoDB 记录刚被删除会挂上一个 delete-mark，然后指向 undo 上的 delete 记录。</li><li>InnoDB 只有一个 txn-id，大于就读它，否则就走上文 pointer 的字段，如下图。这些字段被称为 hidden columns。此外，InnoDB Undo 实际上存放的是<strong>逻辑日志</strong></li></ul><p><img src="https://image.mwish.me/blog-image/undo_logical.png" alt="undo_logical"></p><p><img src="https://image.mwish.me/blog-image/31C650E4-80D1-4C76-8A9A-91F8EDD7E522.png" alt="31C650E4-80D1-4C76-8A9A-91F8EDD7E522"></p><p>总的来说，感觉这篇论文还是偏内存数据库一些，然后考虑了并发更新什么的。</p><h2 id="Concurrency-Control-Protocol"><a href="#Concurrency-Control-Protocol" class="headerlink" title="Concurrency Control Protocol"></a>Concurrency Control Protocol</h2><p>在论文中，cc 相当于定义了：</p><ol><li>是否允许 txn 访问或者更新一个 tuple</li><li>允许 txn 来 commit 自身的提交</li></ol><p>经典的 Concurrency control 包括我们熟悉的内容：</p><ol><li><p>Transaction, OCC and Modern Hardware: <a href="https://blog.mwish.me/2022/01/28/Transaction-OCC-and-modern-hardware/">https://blog.mwish.me/2022/01/28/Transaction-OCC-and-modern-hardware/</a></p></li><li><p>事务: 并发控制协议: 2PL &amp;&amp; TS: <a href="https://blog.mwish.me/2020/11/15/transaction-concurrency-control/">https://blog.mwish.me/2020/11/15/transaction-concurrency-control/</a></p></li></ol><p>可能是出于实现粒度和学术追求，论文只考虑 Tuple Level MVCC + Serializable。实践中，感觉这些级别还是比较高，有比较多的场景还是 SI / RR + SELECT for update 这种。同时，论文也放弃了中心化的 Lock Manager，这样的东西很容易成为一个性能上的瓶颈。</p><h3 id="MVTO"><a href="#MVTO" class="headerlink" title="MVTO"></a>MVTO</h3><p>类似 TS 协议: <a href="https://blog.mwish.me/2020/11/15/transaction-concurrency-control/#TS">https://blog.mwish.me/2020/11/15/transaction-concurrency-control/#TS</a> </p><p><img src="https://image.mwish.me/blog-image/15916E36-99FF-406A-BB36-49819AC7A8B9.png" alt="15916E36-99FF-406A-BB36-49819AC7A8B9"></p><p>论文 figure 2.a 做了一个图示，读会更新对应的 <code>ReadTS</code>, 这是一个额外需要的字段，读会增加这个字段的内容，然后写的时候写入的版本不仅需要自己是唯一的写，要比最大的读取版本高，否则就视作读了不合法的数据。</p><p>实际上，这里感觉只有读最新的版本会对事务更新产生影响，然后这个并发感觉需要控制的比较好。</p><h3 id="MVOCC"><a href="#MVOCC" class="headerlink" title="MVOCC"></a>MVOCC</h3><p>我写过一段比较长的文章来介绍 OCC，参考：<a href="https://blog.mwish.me/2022/01/28/Transaction-OCC-and-modern-hardware/#MVOCC">https://blog.mwish.me/2022/01/28/Transaction-OCC-and-modern-hardware/#MVOCC</a></p><p>MVOCC 有一点好，就是 OCC 是 read - verification - write 三个阶段。对于 MVOCC 而言，可以给每个数据带上一个 begin-ts 和 end-ts，这里就不用拷贝事务的 private space 了，取而代之的是 GC 问题。</p><p>论文描述了它的 MVOCC 算法，原先的实现中，靠拷贝读写集 + 验证来解决，而现在可以当作读的 ts 和提交 ts 之间做验证，看这段时间有没有被别人改过。相对 OCC，MVOCC 很多时候甚至直观一些。</p><ol><li>Read phase: 拿到一个读取用的 txn-id 和 ts，用来读取数据，写入的时候只能写入没有写入冲突的数据。读取记录到 read-set 中</li><li>Validation phase: 拿到 commit ts, 看 read-set 有没有被别人更新（因为 ts 是递增的，进 validation 说明，只有发现 commit-ts 在 read-ts 和自己的 commit-ts 之间的记录，才需要改掉）</li><li>提交，把 MVCC 记录提交</li></ol><p><img src="https://image.mwish.me/blog-image/FA5699F5-1384-4BA3-AC77-C8D32D8CD423.png" alt="FA5699F5-1384-4BA3-AC77-C8D32D8CD423"></p><p>显然，上述算法…可能饿死 long runing read-only txn…</p><h3 id="MV2PL"><a href="#MV2PL" class="headerlink" title="MV2PL"></a>MV2PL</h3><p>作者的实现中，它使用了 no-wait 来实现 2PL 的冲突处理，在读的时候加读锁，写的时候加写锁。这些都在 tuple 上用计数器实现，本质上有点点小类似 ts 协议，只不过 ts 是读的时候 inc counter，2PL 是写上写锁 + 写锁和读的计数器互斥。发现有别人在写就直接 abort 自己，满粗暴的。</p><p><img src="https://image.mwish.me/blog-image/F713048B-C6A6-4F32-A7B9-243DDADFF4BA.png" alt="F713048B-C6A6-4F32-A7B9-243DDADFF4BA"></p><h3 id="Serialization-Certiﬁer"><a href="#Serialization-Certiﬁer" class="headerlink" title="Serialization Certiﬁer"></a>Serialization Certiﬁer</h3><p>类似 SSI，识别 dangerous structure，来做处理。 </p><h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><ul><li>MV2PL / MVTS 的读要改 counter / lock，有一些负载，同时会导致一些伪阳性的 abort。</li><li>MVOCC 的算法可能导致长读事务饿死</li></ul><p>相关的，有一些优化的提案：</p><ol><li>speculatively read uncommitted versions. Hekaton 用了这个. 如果事务冲突少, 这是良药, 否则就是毒药。为了做 cascading abort, 这里还要做一些 dependency graph 之类的，这难免会是个有些中心化的结构。</li><li>eagerly update, Hekaton 也做了这个优化，缺点同 (1)</li></ol><h2 id="Version-Storage"><a href="#Version-Storage" class="headerlink" title="Version Storage"></a>Version Storage</h2><p>这里的内容包含：</p><ol><li>数据库怎么存储不同的物理版本</li><li>每个版本包含的信息</li></ol><p>DBMS 可以包含一个 latch-free 的同一个 tuple 的版本单链表（latch-free 的双链表是很难的），版本链的头可以是 newest 或者 oldest 的事务。</p><h3 id="Append-only-Storage"><a href="#Append-only-Storage" class="headerlink" title="Append-only Storage"></a>Append-only Storage</h3><p>在 PostgreSQL, Hekaton, MemSQL 采用的是这种策略：</p><p><img src="https://image.mwish.me/blog-image/8B61A2DA-C237-4696-9295-C4EE2572D9C3.png" alt="8B61A2DA-C237-4696-9295-C4EE2572D9C3"></p><p>O2N 和 N2O 分别是旧到新 — 新到旧。</p><p>O2N 的好处是，没有更新索引字段的话，索引是不用修改的，但是这个时候 DBMS 可能要走很长的版本链来查找记录，然后走 chain 查找还是比较慢的，所以这里依赖比较频繁的 GC 来保证性能。</p><p>N2O 需要在索引值没变更的时候也更新索引，造成了一定的开销。</p><p>另一个问题是对 non-inline attributes 的处理，比如 MySQL 的 BLOB 或者 PG 的 TOAST，不同的版本可能可以共享同一个 BLOB，DB 维护它的 RC，来避免 BLOB 上的开销。</p><p><img src="https://image.mwish.me/blog-image/2807BAAE-7689-48B9-8508-8BA2D8906FA0.png" alt="2807BAAE-7689-48B9-8508-8BA2D8906FA0"></p><p>PostgreSQL 的 TOAST 有类似的技术：</p><blockquote><p>The TOAST management code is triggered only when a row value to be stored in a table is wider than <code>TOAST_TUPLE_THRESHOLD</code> bytes (normally 2 kB). The TOAST code will compress and/or move field values out-of-line until the row value is shorter than <code>TOAST_TUPLE_TARGET</code> bytes (also normally 2 kB, adjustable) or no more gains can be had. During an UPDATE operation, values of unchanged fields are normally preserved as-is; so an UPDATE of a row with out-of-line values incurs no TOAST costs if none of the out-of-line values change.</p></blockquote><h3 id="Time-Travel-Storage"><a href="#Time-Travel-Storage" class="headerlink" title="Time-Travel Storage"></a>Time-Travel Storage</h3><p><img src="https://image.mwish.me/blog-image/67ADE0DE-EE4C-4A1A-A354-EDFE8E4039AB.png" alt="67ADE0DE-EE4C-4A1A-A354-EDFE8E4039AB"></p><p>类似 Append-Only Storage，但版本分成了主表和别的存储，存一个主表，Time-Travel Table 存放不同的版本。需要更新的时候，这里需要在 time-travel table 中申请空间，然后把数据拷贝过去，然后改主表。没改 index key 的话，index 是不需要更新的。</p><h3 id="Delta-Main-Storage"><a href="#Delta-Main-Storage" class="headerlink" title="Delta-Main Storage"></a>Delta-Main Storage</h3><p><img src="https://image.mwish.me/blog-image/64C7B2DB-DD5C-40EF-AAE3-AF420AB6A390.png" alt="64C7B2DB-DD5C-40EF-AAE3-AF420AB6A390"></p><p>HyPer, MySQL 和 Oracle 使用了这种方法，相对 Time-travel Storage，这里存储的是 Delta 的内容，而非全部内容。对 Update 密集的负载，这种逻辑相对来说性能很好，但是对读来说，这会有一定的问题。</p><p>笔者认为，这里可以考虑类似 logging 那种 physical / logical 类似的区别，不用和 time-travel 分太开？</p><h3 id="讨论-1"><a href="#讨论-1" class="headerlink" title="讨论"></a>讨论</h3><p>这里具体的 pros &amp; cons 只能做一个 case by case 的分析，对于 TP workload, append-only 在没啥 overwrite 的情况下工作的不错，因为有着不错的局部性，有版本链就炸给你看。这种方式同时也加重了 index 管理的难度。</p><p>PostgreSQL 是现实 Append-Only Storage + N2O，写入的数据会更新 <code>xmax</code> 和 <code>ctid</code>，指向最新的数据，索引不会更改。当索引引用的 Tuple 最新版本被删，然后所有事务都读不到它的时候，所以会标记 <code>LP_DEAD</code> 来实现懒惰删除，等待 vacuum 进程 GC。</p><p>InnoDB 使用了 Delta-Main 的方式，主表是一个索引，Undo 段负责回滚。Undo 写的是逻辑更新，其实就是 delta 存储。</p><p>WiredTiger 会</p><p>TBD</p><h2 id="Garbage-Collection"><a href="#Garbage-Collection" class="headerlink" title="Garbage Collection"></a>Garbage Collection</h2><p>GC 是 MVCC 比较重要又比较 hack 的一块，也有 Purge/Vacuum 这些关键词来描述他们。大部分面向用户的介绍材料很少提及 GC 是怎么工作的。</p><p>总的来说，GC 大概分为三步：</p><ol><li>识别不再需要的版本</li><li>把他们从 version chain 摘除，然后处理索引对应的情况</li><li>回收空间</li></ol><p>可能系统会有一个活跃事务 txn-id 下界，会根据这个回收，也有系统会有一些细粒度的回收，比如 HyPer / SAP HANA 的回收，或者 crdb 的 protect ts。当然，txn-id 作为中心化 allocator 本身会比较费。有一些粗粒度的方式，比如用 epoch 来批量做事务的回收。</p><p>本论文讲 GC 分为：</p><ul><li>Tuple Level GC</li><li>Transaction-level GC</li></ul><p><img src="https://image.mwish.me/blog-image/D55A6BAD-A2D6-47C8-BC96-8C547903ACB2.png" alt="D55A6BAD-A2D6-47C8-BC96-8C547903ACB2"></p><h3 id="Tuple-level-Garbage-Collection"><a href="#Tuple-level-Garbage-Collection" class="headerlink" title="Tuple-level Garbage Collection"></a>Tuple-level Garbage Collection</h3><p>这里细分为 Background Vacuuming (VAC) 和 Cooperative Cleaning (COOP)。</p><p>VAC 会有后台的 GC 进程来清除。有一种草台的方式是这个进程检测有哪些版本进行删除，然后清除，这种方式对于比较大的库来说性能肯定拉了。文中提出了两种优化方式：</p><ol><li>把对应的失败版本注册到某个 lock-free 的地方，然后清除进程直接清除这些版本</li><li>标注哪些数据块需要清除，然后跳过不需要 GC的那些块（PostgreSQL 的实现逻辑类似这样）</li></ol><p>Cooperative Cleaning (COOP) 会在 N2O 系统中，遍厉的时候回收。PG 感觉因为 Tuple 位置是固定的，所以虽然 N2O，但是没办法这么做。还有个问题，就是这种回收如果没 touch 到对应的版本，就不回收了。Hekaton 碰到过这个问题，解决方式是加上了个 VAC。</p><p>最后，这节源论文介绍很少，但我个人意见是，这里 pattern 还是挺多的。比如 Compaction 的时候回收、标注回收的 Page、把回收的版本挂起来等等。</p><h3 id="Transaction-level-Garbage-Collection"><a href="#Transaction-level-Garbage-Collection" class="headerlink" title="Transaction-level Garbage Collection"></a>Transaction-level Garbage Collection</h3><p>事务 track 对应的读写集，然后在单个事务或者一堆事务的 epoch 结束的时候做 GC。缺点是 track 空间，优点则是及时的回收。</p><h3 id="讨论-2"><a href="#讨论-2" class="headerlink" title="讨论"></a>讨论</h3><p>Tuple-level Garbage Collection + VAC 应该是最常见的实现方法。增加 GC 的线程一般都能提升 GC 系统的性能，而 long-running txn 可能会影响 GC，这需要一些细粒度的 GC 实现。</p><p>PostgreSQL 和 MySQL InnoDB 都维护了事务的列表、最低和最高的事务水位，我们用 txn-table, active-txn-list, min-txn 和 max-txn 表示。</p><h4 id="PostgreSQL-的-Vacuum"><a href="#PostgreSQL-的-Vacuum" class="headerlink" title="PostgreSQL 的 Vacuum"></a>PostgreSQL 的 Vacuum</h4><p>对于 PG 来说，它做的是一个比较复杂的多阶段的删除，用的 Tuple-level GC + VAC，具体可见 Vacuum 相关的材料（Lazy Vacuum, Full Vacuum）</p><ul><li>对于事务的记录，PostgreSQL 维护在 clog 里面，这可以当作一个事务表。它根据事务 id 的顺序存在各个 Page 上，缓存在内存的 slru 中。当事务推进的时候，可以 Truncate 前面的事务记录来回收空间，推进系统事务</li><li>PostgreSQL 的 <code>xmax</code> 如果被标记且 tuple 没有被上锁，那么这个 tuple 是被删除的，如果 <code>xmax</code> 小于 <code>min-txn</code>，那这个 tuple 在逻辑上不会被任何事务看见，虽然物理上它还存在</li><li>GC 过程中，PostgreSQL 会扫描所有 dead 的 tuple，然后清除它们，这里首先有一个 visibilitymap, 对应代码在 <code>backend/access/heap/visibilitymap</code>。如果某个 Page 被改了，有 Tuple 可能需要 GC，就会给 vm 记一下，然后这样的 Page 才需要被清理，这段过程中，索引的数据会被清除，如下面的图。</li><li>索引数据清除之后，Heap Tuple 的数据会被标记删除，但是 slot 上的位置还是会留着。</li><li>更新对应的 VM，移除 clog 等事务表信息。</li></ul><p><img src="https://image.mwish.me/blog-image/fig-6-01.png" alt="fig-6-01"></p><h4 id="InnoDB-的-Purge"><a href="#InnoDB-的-Purge" class="headerlink" title="InnoDB 的 Purge"></a>InnoDB 的 Purge</h4><p>对于 MySQL InnoDB 来说，它的 GC 在 Purge Undo 里，Index Page 的回收我不是很熟悉，就不献丑了，前面已经说过了</p><p><img src="https://image.mwish.me/blog-image/undo_log_disk_structure.png" alt="undo_log_disk_structure"></p><p>InnoDB 的 Undo 存在 Page 上，对这个 Page 的操作是需要写 <code>mtr</code> 和 redo 的。事务可以申请需要写 undo log，然后系统会给它分配对应的 undo page。同时，没有清除的事务会挂在 history list 上。通过扫描 history list，来回收这些版本。</p><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>WiredTiger 的 GC 比较简单，在 Reconcile 的时候，每个 tuple 会把「所有事务都可见」的数据当作 base，把不可见的版本 GC 掉</p><p><img src="https://image.mwish.me/blog-image/wt-mem-low.png" alt="wt-mem-low"></p><h2 id="Index-Management"><a href="#Index-Management" class="headerlink" title="Index Management"></a>Index Management</h2><p><img src="https://image.mwish.me/blog-image/992D5709-7238-47B6-8015-E218C786A055.png" alt="992D5709-7238-47B6-8015-E218C786A055"></p><p>DBMS 的索引更新和实现有关，比如 MySQL InnoDB 有 Cluster Index 和 Secondary Index，然后可能还有 Covering Index。PostgreSQL 则是 index + heap table。</p><p>「更新」也是个很奇怪的事情，我们可以区分一下：</p><ul><li>更新的字段跟索引没关系</li><li>更新了索引的字段</li></ul><p>实际上，在 MVCC 系统中，很多索引字段被更新了，基本上要插入一条新的记录，同时旧的记录也要保留，这给 <code>checkUnique</code> 带来了不小麻烦。PostgreSQL 做了一个 <code>LP_DEAD</code>，来给这种被更新的索引做优化，andy 的 slide 也提到了这个问题：</p><p><img src="https://image.mwish.me/blog-image/9E78FAF1-5133-435A-82C0-C1AF21FCACAE.png" alt="9E78FAF1-5133-435A-82C0-C1AF21FCACAE"></p><p>论文引入了 indirection 和 direction 的方式:</p><ul><li>indirection 引入了一个间接层，这个间接层可以是 TupleID 或者 Primary Key. 相对来说，PrimaryKey 空间开销大一些，TupleID 维护则复杂一些。这个怎么理解呢？<ul><li>索引存的是 <code>&lt;IndexKeys, PrimaryKey&gt;</code>，那么，根据 PK 可以找到唯一的主键。当然，如果 pk 很大，这里空间放大会有，如果 pk 是 int 之类的，感觉也没啥开销啊（</li></ul></li><li>direction 则是 PG 的方案，直接指向物理空间</li></ul><h3 id="讨论-3"><a href="#讨论-3" class="headerlink" title="讨论"></a>讨论</h3><p>作者评价如下：</p><blockquote><p>The logical pointer approach is better for write-intensive workloads, as the DBMS updates the secondary indexes only when a transaction modiﬁes the indexes attributes. Reads are potentially slower, however, because the DBMS traverses version chains and perform additional key comparisons. Likewise, using physical pointers is better for read-intensive workloads because an index entry points to the exact version. But it is slower for update operations because this scheme requires the DBMS to insert an entry into every secondary index for each new version, which makes update operations slower.</p></blockquote><p>这里还有个 Index Only Scan 的问题，你看，对于数据 <code>(a, b, c)</code> 有索引 <code>(b)</code>, 然后用户只 get <code>b</code>，本来是个很简单的问题，但你的索引上如果不维护 MVCC 信息的话，可能就寄了。</p><p>这里可以参考 PostgreSQL 的 Index Only Scan，借助了我们上一节说的 vm 系统:</p><p><img src="https://image.mwish.me/blog-image/index-only-scan.png" alt="index-only-scan"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>PostgreSQL 部分：</p><ul><li><p><a href="https://www.interdb.jp/pg">https://www.interdb.jp/pg</a></p></li><li><p><a href="https://blog.yasking.org/a/postgresql-vacuum.html">PosrgreSQL 学习计划——Vacuum 清理机制</a> <a href="https://blog.yasking.org/a/postgresql-vacuum.html">https://blog.yasking.org/a/postgresql-vacuum.html</a></p></li></ul><p>InnoDB 部分：</p><ul><li><p>MySQL · 源码分析 · InnoDB的read view，回滚段和purge过程简介 <a href="http://mysql.taobao.org/monthly/2018/03/01/">http://mysql.taobao.org/monthly/2018/03/01/</a></p></li><li><p>MySQL · 引擎特性· InnoDB之UNDO LOG介绍 <a href="http://mysql.taobao.org/monthly/2021/12/02/">http://mysql.taobao.org/monthly/2021/12/02/</a></p></li></ul><p>感谢原论文：An Empirical Evaluation of In-Memory Multi-Version Concurrency Control</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Notes: folly::ThreadLocalPtr</title>
      <link href="/2022/06/12/Notes-folly-ThreadLocalPtr/"/>
      <url>/2022/06/12/Notes-folly-ThreadLocalPtr/</url>
      
        <content type="html"><![CDATA[<p>材料：</p><ol><li><a href="https://github.com/facebook/folly/blob/main/folly/docs/ThreadLocal.md">https://github.com/facebook/folly/blob/main/folly/docs/ThreadLocal.md</a></li><li>无锁编程实践：RocksDB ThreadLocalPtr剖析 - 杨凿让的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/398409455">https://zhuanlan.zhihu.com/p/398409455</a></li><li><a href="https://github.com/halty/writing/blob/master/Folly_Source_Insight_Series-ThreadLocalPtr.md">https://github.com/halty/writing/blob/master/Folly_Source_Insight_Series-ThreadLocalPtr.md</a></li></ol><p>Thread Local 是很常见的东西，<code>errno</code> 就是著名的 thread local 变量。它们通常用作一些优化。关于 thread local，一般认为有下面接口：</p><ol><li>Gcc 等相关的 <code>__thread</code> : <a href="https://gcc.gnu.org/onlinedocs/gcc/Thread-Local.html">https://gcc.gnu.org/onlinedocs/gcc/Thread-Local.html</a></li><li><code>pthread_key</code> 相关的 POSIX 接口，和其他平台提供的接口.</li><li><code>thread_local</code> 等语言关键字，它的初始化类似 <code>static</code></li></ol><p>关于 TLS 是怎么做的，下面这篇博客给了一个很好的介绍：<a href="https://chao-tic.github.io/blog/2018/12/25/tls">https://chao-tic.github.io/blog/2018/12/25/tls</a> </p><p>如果对编译、链接、ELF相关的东西感兴趣，还可以看看：<a href="https://maskray.me/blog/2021-02-14-all-about-thread-local-storage">https://maskray.me/blog/2021-02-14-all-about-thread-local-storage</a></p><p><code>folly::ThreadLocal</code> 实现了和 <code>pthread_key</code> 相关 api 一样性能的 TLS，并且提供了 <code>accessAllThreads</code> 的能力（实际上介绍 perfbook 的时候，你会发现大部分东西都需要类似的语义）</p><hr><p>Folly 的 <code>ThreadLocalPtr</code> 接口如：<code>ThreadLocalPtr&lt;T, Tag, AccessMethod&gt;</code>，每个 Tag 会有一组每个线程都有的 <code>StaticMeta&lt;Tag&gt;</code> 对象，<code>StaticMeta&lt;Tag&gt;</code> 对象持有一个 <code>ThreadEntry</code> 的双向链表（<code>ThreadEntryList</code>），为了维护这个双向链表，它持有了双向链表的 Header (<code>head_</code>) ，同时，双向链表是很难并发的，所以它持有了一个 mutex，来保证这个链表访问和插入的安全性。</p><p>每个线程，如果需要，会有一个 <code>ThreadEntry</code> 对象。他们被 <code>StaticMeta&lt;Tag&gt;</code> 管理，里面有一个 <code>vector</code>(没有实现成 vector, 但其实可以理解成 vector，没啥问题)。<strong>每个 TLS 对象有一个固定的 id, 表示自己在 vector 里面是第几位, 一个 Tag 在每个线程中可能声明了多个 TLS 对象，所以用一个 Vector</strong>。TLS 读的时候，会找到本线程的 <code>ThreadEntry</code> 对象，看看自己在 <code>vector</code> 第几个，然后获取 vector 中的对象。对象由 <code>ElementWrapper</code> 包装，这个 Wrapper 包装了一下用户的析构函数。</p><p><code>StaticMeta::getThreadEntrySlow</code> 用来创建线程的 TLS 对象（<code>ThreadEntry</code>），把 <code>ThreadEntry</code> 对象注册在 <code>pthread_getspecific</code> 中。这个和 OS 有什么区别呢？答案在于原本是多个 Key，现在每个 tag 只需要一个 key。</p><p>使用 TLS 的时候，会拿到 <code>StaticMeta&lt;Tag&gt;</code> 的单例对象，然后在调用获取本线程对象的时候，调用 <code>StaticMeta::get(EntryID*)</code>，来获取本线程的 TLS 对象。每个 <code>ThreadLocalPtr</code> 持有一个 <code>id_</code> ，这个 <code>id_</code> 实现是一个 <code>EntryID</code>, 保存了一个 <code>atomic&lt;uint32_t&gt;</code>。这个 id 也是由 <code>StaticMeta&lt;Tag&gt;</code> 分配的。需要注意的是，一些紧张情况下，<code>ThreadEntry</code> 的 <code>ElementWrapper</code> 数组会需要扩容，这个时候要占用全局的锁，然后一个个扩容，会很费。</p><p><code>accessAll</code> 的时候，也要占据 <code>StaticMeta&lt;Tag&gt;</code> 的锁，此外，还有个 <code>accessALlThreadsLock_</code>，不过我没看出来这个玩意有什么特别大的意义。他们会根据 TLS 对象的 id 遍历每个数组，然后访问对应 index 上的对象。</p><p><img src="https://image.mwish.me/blog-image/ThreadLocalPtr.jpeg" alt="ThreadLocalPtr"></p><p>上图来自博客：<a href="https://github.com/halty/writing/blob/master/Folly_Source_Insight_Series-ThreadLocalPtr.md">https://github.com/halty/writing/blob/master/Folly_Source_Insight_Series-ThreadLocalPtr.md</a> </p><p>感谢允许灌水</p><hr><p>在使用上，folly 的 <code>HazardPointer</code>、<code>CachedIntCounter</code> 等容器都使用了 TLS ptr，而 RocksDB 自己写了一套 <code>ThreadLocalPtr</code>，但是实现的机制差不多，少了 Tag 之类的，多维护了一个更新的语义，详见：<a href="https://zhuanlan.zhihu.com/p/398409455">https://zhuanlan.zhihu.com/p/398409455</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Parallel and Distributed Query Processing</title>
      <link href="/2022/06/05/Parallel-and-Distributed-Query-Processing/"/>
      <url>/2022/06/05/Parallel-and-Distributed-Query-Processing/</url>
      
        <content type="html"><![CDATA[<p>这一节对应的是 Database System Concept 的分布式查询执行部分。这一部分可能本身描述的内容是分布式执行（也可以联系到一个现在很流行的词：MPP），但同时可能涉及一些非分布式执行的内容，包括：</p><ol><li>在单机系统上，也能用 exchange 等算子做一些并行化。特别是，如果你按照 NUMA / Core 切分负载，就可以发现这些部分的事情也是一种分布式执行，当然 bus 可能比网络通信靠谱很多</li><li>生成 Plan 方面，本身 Plan 就很难生成了，然后又搞这么一套，就更难了</li></ol><p>教科书上这节写的相当相当细，甚至包括一些 fdw 和数据湖的内容。虽然我本人不是很懂分布式查询处理，但是这块内容确实讲的很好。</p><h2 id="分布式数据库的架构"><a href="#分布式数据库的架构" class="headerlink" title="分布式数据库的架构"></a>分布式数据库的架构</h2><p>其实网络还是个挺复杂的东西的，但是目前大家都很能抽象，实际上目前很多地方部署的网络都类似下面的 <code>(e)</code>:</p><p><img src="https://image.mwish.me/blog-image/51EA3B2A-6300-474A-808E-457F875D5167.png" alt="51EA3B2A-6300-474A-808E-457F875D5167"></p><p>当然，随着硬件发展，实际上大家也会有一些其他方案，比如构建 RDMA 网络。</p><p>对于单机而言，博客（<a href="https://blog.mwish.me/2022/05/04/perfbook-notes-hardware/）提到了其中的访问效率，总之访问临近内存">https://blog.mwish.me/2022/05/04/perfbook-notes-hardware/）提到了其中的访问效率，总之访问临近内存</a> bandwidth 是访问远端的数倍，速度也快了很多：</p><p><img src="https://image.mwish.me/blog-image/C055FAB3-9FB7-4133-B8C3-65B37789DDAB.png" alt="C055FAB3-9FB7-4133-B8C3-65B37789DDAB"></p><p>最后是一些共享 XX 的架构，这图既可以是单机房的，也可以是集群概念上的（比如我们经常说 ClickHouse/TiDB 是 Shared Nothing，而 snowflake/Aurora 是 Shared Storage）：</p><p><img src="https://image.mwish.me/blog-image/01958C33-98F6-47D8-A1A3-3FC18B61C1E2.png" alt="01958C33-98F6-47D8-A1A3-3FC18B61C1E2"></p><p>关于并行执行查询，经典的例子是 interquery parallelism 和 intraquery parallelism。这两种操作是互补的。前者比如对 Sort、Join 等操作做并行化，后者例如 Pipeline Execution 的时候，并行处理不同的 Pipeline。并行查询通常和架构相关，这里以 shared nothing 架构为例子做讨论</p><h2 id="Sort-Join-等操作的并行执行"><a href="#Sort-Join-等操作的并行执行" class="headerlink" title="Sort/Join 等操作的并行执行"></a>Sort/Join 等操作的并行执行</h2><h3 id="并行排序"><a href="#并行排序" class="headerlink" title="并行排序"></a>并行排序</h3><p><img src="https://image.mwish.me/blog-image/A35B426B-C144-4DB9-A30A-87513D29A332.png" alt="A35B426B-C144-4DB9-A30A-87513D29A332"></p><p>方案 (1) 是 先做 range partition, 然后再 Local Sort；方案 2 是先 Local Sort，然后再在各个节点串行 Merge。</p><p>对于方案 1，这里我们显然会联想到数据的 Skew 上，对于 <code>(a)</code>，可以用虚拟节点等方式，把数据切碎，当然这个可能引入别的网络通信流程。对于方案 2，实际上，本地排序完后，在走 (2) 可能会变得很奇怪，这里可能会有 execution skew，即在每个节点接收完后，才能处理到下一个节点。这里也有改善成并行处理的方式：这里可能需要提前对数据范围分区，然后按照数据应该被分区到哪 并行 + Chunk 发送。</p><p>观察到，如果数据在每个地方已经排序好，或者是范围分片的话，相当于很多东西已经执行好了，这还是挺爽的。</p><h3 id="并行-Join"><a href="#并行-Join" class="headerlink" title="并行 Join"></a>并行 Join</h3><p>我们可以先回顾一下单机 Join 的执行方式：<a href="https://blog.mwish.me/2021/02/08/Notes-on-Query-Execution/#Join">https://blog.mwish.me/2021/02/08/Notes-on-Query-Execution/#Join</a></p><p>JOIN 有很多形式，一些简单的形式中，比如内连接 + 等值连接，可以使用类似单机 Hash Join 的方式。当然，这里分片可以按照 Range/Hash 任意一种方式分片。Hash Join 的很多优化这里也能用上，比如部分缓存在内存中。</p><p><img src="https://image.mwish.me/blog-image/1526690F-EE20-43B5-B6AE-7688D7F76048.png" alt="1526690F-EE20-43B5-B6AE-7688D7F76048"></p><p>对于一些连接条件非等值的，可以采用 broadcast-join 的方式：将某个关系分区，并且将另一个关系（尽量要小）复制到所有的节点上，这种方式被称为 Asymmetric fragment and replicate。还有更狠的方式，就是两边全部拆了，然后全部拷贝：关系 s, r 都被拆成 m, n 份，分配到 $m * n$ 个节点上，产生 Join。 Fragment and replicate 方式更普适一些。而对于 skew，可以用类似虚拟节点 + work steal 的方式处理或者拆分。</p><p><img src="https://image.mwish.me/blog-image/F31EE37E-F4D4-4105-A093-2A92002DA520.png" alt="F31EE37E-F4D4-4105-A093-2A92002DA520"></p><p>对于其他操作来说，执行方式如下：</p><ol><li>Selection 中，如果有对查询的属性有分区，那么给固定的分区发送查询。如果没有分区，那么需要所有的节点并行走查询</li><li>duplicate elimination 中，可以借助排序 + 去重执行</li><li>对于 Projection，可以按照是否 dedup 来分类，如果去重，那么可能走 2；否则可以直接推下去</li><li>Aggregation: 这里比如说 sum/count/avg 可以分区，然后单机返回对应的 sum/count/(sum, count)，然后对每个机器返回的综合处理</li></ol><p>实际上，这里还可以考虑到 Map-Reduce 的模型：</p><p><img src="https://image.mwish.me/blog-image/750E9CBC-0DBB-4911-A353-C7B4F03764F8.png" alt="750E9CBC-0DBB-4911-A353-C7B4F03764F8"></p><ul><li>Map 可以视为某种类型的 Projection 算子</li><li>Reduce 可以视为一种用户定义的 Agg 算子</li><li>Combine 类似一个 pre-aggregate，相当于部分 agg 的操作</li><li>Shuffle 定义打到 Reduce 上的分片规则</li><li>根据工作进展动态调度</li><li>BSP 模型，执行完 Map 才能执行 Reduce</li></ul><p>实际上，Map-Reduce 还有 Map-side join 和 Reduce-side join:</p><ol><li>Map-side join 会在 map 阶段产生不同的 join-key，这样能够在 Reduce 之前就划分到一起</li><li>Broadcast join 也是一种 map-side join，小关系会被 Map 阶段 broadcast 到所有地方</li><li>Reduce-side join: Each mapper tags each row of two relations to identify which relation the row come from. After that, rows of which keys have the same key value are copied to the same reducer during shuﬄing.</li></ol><p>关于 Map-Reduce，一篇比较好的材料是 KAIST 的 <em>Parallel Data Processing with MapReduce: A Survey</em></p><h2 id="Operator-的并行执行"><a href="#Operator-的并行执行" class="headerlink" title="Operator 的并行执行"></a>Operator 的并行执行</h2><p>首先，Pipeline + Push 的模型，相对 Pull 的模型，实际上是很好并行的。各个阶段都是能并行的，一个很明显的地方是，一些非 blocking operator，可以运行生产者和消费者并行。</p><p>此外，不关联的 Operator 是可以并行完成的。</p><p>最后我们可以引入著名的 Exchange 算子。这个算子最早来源于 Volcano 模型，它对数据进行某种程度的分区，然后按照这种分区来执行：</p><p><img src="https://image.mwish.me/blog-image/1E1CD9BE-B5B7-4DF4-9469-F3B6358AE707.png" alt="1E1CD9BE-B5B7-4DF4-9469-F3B6358AE707"></p><p><img src="https://image.mwish.me/blog-image/76F108B0-F7FA-42B6-BEB4-C121C613108D.png" alt="76F108B0-F7FA-42B6-BEB4-C121C613108D"></p><p>Exchange 算子相当于手动的分区 + 归并，来做数据上的并行。下图为一个分布式执行的 sample:</p><p><img src="https://image.mwish.me/blog-image/6706C982-3FA1-4495-898B-9FB669D243AF.png" alt="6706C982-3FA1-4495-898B-9FB669D243AF"></p><p>上面的内容表示了单部分的 Pipeline 和 Pipeline 之间的依赖关系。</p><p>分布式查询执行还得考虑一些别的东西，比如故障，这里有两种可以参考的方案：</p><ol><li>Map-Reduce 那种 BSP 的方案</li><li>Spark 的 RDD 方案</li></ol><h3 id="共享内存系统的查询处理"><a href="#共享内存系统的查询处理" class="headerlink" title="共享内存系统的查询处理"></a>共享内存系统的查询处理</h3><p>这个类似在单机的 NUMA 系统上并行处理查询。之前的内容也是能用上的，但是有一些比较微妙的不同：</p><ol><li>对于 broadcast join，小表数据可能可以放在共享内存中，用更巧妙的方式共享（不过估摸着也得考虑 cache 什么的，感觉实际区别不大）</li><li>Work-steal 会变得简单很多，尽管多核系统访问别的地方数据也有惩罚，但是会比 shard nothing 系统小很多很多。可以用这种方式避免 skew</li><li>Hash Join 既可以用 shared nothing 的方式处理、也可以让关系 Hash Join 索引表小一些，然后并行 Build -&gt; 并行 Probe （类似 Morsel 调度论文提到的）</li></ol><p>最合适的算法一般都是 NUMA-Aware 的，具体可以参考 Morsel 或者一些查询执行相关的论文。</p><h2 id="查询优化和代价"><a href="#查询优化和代价" class="headerlink" title="查询优化和代价"></a>查询优化和代价</h2><p>这里相对于之前我们介绍的单机 Planner，要考虑的东西更多了：</p><ol><li>怎么对 Operator 进行并行化：包括使用什么算法、怎么分区、怎么插入 Exchange 算子</li><li>如何对计划进行调度，包括：<ol><li>Operator 使用多少节点</li><li>将什么计算 Pipeline 化</li><li>分辨串行/并行的执行</li></ol></li></ol><p>书上举了个有点像 Interesting order 的例子，来说明分布式 Plan 的复杂性:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r JOIN s ON r.A = s.A AND r.B = s.B</span><br></pre></td></tr></table></figure><p>对于上述内容而言，把 <code>r</code> 和 <code>s</code> 按照 <code>A</code> , <code>B</code>, <code>(A, B)</code> 分区中，<code>(A, B)</code> 显然是最合适的，但是如果查询如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT SUM(s.C) from (r JOIN s ON r.A = s.A AND r.B = s.B) GROUP BY s.A;</span><br></pre></td></tr></table></figure><p>那么，如果按照 <code>(A, B)</code> 分区，这里可能又要按照 A 来做一次聚合，可能按照 <code>A</code> 分区代价又是最小的。</p><p>在并行模型中，还有一些关于代价的问题，在 RDBMS 中，我们以之前博客举的例子为例：<a href="https://blog.mwish.me/2021/11/05/An-Overview-of-Query-Optimization-in-Relational-Systems/#Statistics-And-Cost-Estimation">https://blog.mwish.me/2021/11/05/An-Overview-of-Query-Optimization-in-Relational-Systems/#Statistics-And-Cost-Estimation</a></p><p>这里的 Cost 就是资源消耗的 cost，即 IO Cost + CPU cost + memory + bandwidth…</p><p>你可能觉得很自然，但是实际上分布式系统里，两个 Plan 「资源消耗」相同，但是由于并行能力，可能执行时间不一样，这里还要考虑「response-time cost model」：假设 p1, p2 部分能并行，这部分代价可能就是 $max(p1, p2)$ ，它要考虑在多个节点进行运算的启动成本（start-up cost）和 skew。</p><p>最后，对于相关的 Plan 生成，因为这里 Card 又大了不少，所以会非常麻烦。优化器可能会用启发式的方法：生成最佳的单机执行计划，然后分布式化。这里可以参考 CockroachDB 的文档：<a href="https://github.com/cockroachdb/cockroach/blob/master/docs/RFCS/20160421_distributed_sql.md">https://github.com/cockroachdb/cockroach/blob/master/docs/RFCS/20160421_distributed_sql.md</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>crossbeam-epoch</title>
      <link href="/2022/06/04/crossbeam-epoch/"/>
      <url>/2022/06/04/crossbeam-epoch/</url>
      
        <content type="html"><![CDATA[<p><code>crossbeam-epoch</code> 是 crossbeam 用来管理内存的子包，它实现了 epoch-based reclaim。并发编程的时候会有内存回收问题和 ABA 问题，但本质上，解决了内存问题，就解决了 ABA 问题，因为后者本质是内存 reuse 导致的。</p><p>Epoch Based Reclaim 有点类似某种程度上的 RC，但是它的 RC 的粒度要粗很多：针对 Epoch，而非针对 Object，这让维护和使用它的代价变小了很多，它引入的语义如下：</p><blockquote><p>There are a few non-GC-based ways of managing memory for lock-free code, but they all come down to the same core observations:</p><ol><li>There are two sources of reachability at play – the data structure, and the snapshots in threads accessing it. Before we delete a node, we need to know that it cannot be reached in either of these ways.</li><li>Once a node has been unlinked from the data structure, no <em>new</em> snapshots reaching it will be created.</li></ol></blockquote><p>综上，一个对象只能被删除一次，随着最后一个可能可能读到它的线程结束，它就是「可清除」的了，它会随着 epoch 的推高而清除。</p><p><code>crossbeam-epoch</code> 实现了上述的语义，并引入了一套子系统，来表示对应的内存指针和引用。</p><p>Epoch 提供了：</p><ol><li>Global Epoch Counter (取值 0/1/2, 三个 epoch 迭代)</li><li>每个 Epoch 挂的 Garbage</li><li>每个 Thread 是否是 “Active” 的</li><li>每个 Thread 的 Epoch</li></ol><p>每个线程启动的时候，会把自己的 Epoch 设置成全局的 Epoch，unlink 一个对象的时候，会放到 Global Garbage 列表中，「当前 Epoch」对应的地方。线程完成操作的时候，会清除 Active 标记。这里有3个 epoch，没有任何读者的 Epoch 理论上是 <code>current - 2</code>, 它上面的对象可以被 GC。</p><p>性能相关可见：<em>Performance of memory reclamation for lockless synchronization</em></p><h2 id="API-of-crossbeam-epoch"><a href="#API-of-crossbeam-epoch" class="headerlink" title="API of crossbeam-epoch"></a>API of crossbeam-epoch</h2><p><code>pin()</code> 产生一个本线程的 <code>Guard</code> ，<code>Guard</code> 没退出表示这个线程还在活跃，实际上就是 某个线程/版本的 RAII。</p><p>然后有下面的智能指针：</p><blockquote><p>To put the <code>Guard</code> to use, Crossbeam provides a set of three pointer types meant to work together:</p><ul><li><code>Owned&lt;T&gt;</code>, akin to <code>Box&lt;T&gt;</code>, which points to uniquely-owned data that has not yet been published in a concurrent data structure.</li><li><code>Shared&lt;&#39;a, T&gt;</code>, akin to <code>&amp;&#39;a T</code>, which points to shared data that may or may not be reachable from a data structure, but it guaranteed not to be freed during lifetime <code>&#39;a</code>.</li><li><code>Atomic&lt;T&gt;</code>, akin to <code>std::sync::atomic::AtomicPtr</code>, which provides atomic updates to a pointer using the <code>Owned</code> and <code>Shared</code> types, and connects them to a <code>Guard</code>.</li></ul></blockquote><p>上面的类型足以表述了，具体见：<a href="https://aturon.github.io/blog/2015/08/27/epoch/">https://aturon.github.io/blog/2015/08/27/epoch/</a></p><p>一些要点是（在上文的 Managing garbage 段）：</p><ol><li>unlink 的时候可以运行 destructor, 而 ebr 只具体回收内存（安全性：操作都会走 cas）</li><li>线程有一些 TLS 的垃圾列表，可能会在有一定阈值的时候 emit 到全局的列表中</li><li><code>epoch::pin</code> 的时候，可能会 emit 垃圾甚至触发垃圾清理</li></ol><h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><h3 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">➜  src git:(master) tree</span><br><span class="line">.</span><br><span class="line">├── atomic.rs</span><br><span class="line">├── collector.rs</span><br><span class="line">├── default.rs</span><br><span class="line">├── deferred.rs</span><br><span class="line">├── epoch.rs</span><br><span class="line">├── guard.rs</span><br><span class="line">├── internal.rs</span><br><span class="line">├── lib.rs</span><br><span class="line">└── sync</span><br><span class="line">    ├── list.rs</span><br><span class="line">    ├── mod.rs</span><br><span class="line">    └── queue.rs</span><br></pre></td></tr></table></figure><p>首先，我们关注一下周边工具，例子是 <code>sync</code> 目录，这个目录有点循环引用的味道，用 <code>crossbeam-epoch</code> 实现了两个组件：</p><ol><li>并发的 linked-list queue：按照 <a href="http://dl.acm.org/citation.cfm?id=248106">http://dl.acm.org/citation.cfm?id=248106</a> 和 <a href="https://doi.org/10.1007/978-3-540-30232-2_7">https://doi.org/10.1007/978-3-540-30232-2_7</a> 实现</li><li>并发的侵入式链表：<a href="http://www.cs.tau.ac.il/~afek/p73-Lock-Free-HashTbls-michael.pdf">http://www.cs.tau.ac.il/~afek/p73-Lock-Free-HashTbls-michael.pdf</a></li></ol><p>上面两个 case 可以当作实现的例子，然后 crossbeam-epoch 也用到了它俩。</p><p>Queue 的接口比较简单：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;T&gt; Queue&lt;T&gt; &#123;</span><br><span class="line">    <span class="comment">/// Create a new, empty queue.</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">new</span>() <span class="punctuation">-&gt;</span> Queue&lt;T&gt;;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/// Adds `t` to the back of the queue, possibly waking up threads blocked on `pop`.</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">push</span>(&amp;<span class="keyword">self</span>, t: T, guard: &amp;Guard);</span><br><span class="line">    </span><br><span class="line">        <span class="comment">/// Attempts to dequeue from the front.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// Returns `None` if the queue is observed to be empty.</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">try_pop</span>(&amp;<span class="keyword">self</span>, guard: &amp;Guard) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;T&gt;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Attempts to dequeue from the front, if the item satisfies the given condition.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// Returns `None` if the queue is observed to be empty, or the head does not satisfy the given</span></span><br><span class="line">    <span class="comment">/// condition.</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">try_pop_if</span>&lt;F&gt;(&amp;<span class="keyword">self</span>, condition: F, guard: &amp;Guard) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;T&gt;</span><br><span class="line">    <span class="keyword">where</span></span><br><span class="line">        T: <span class="built_in">Sync</span>,</span><br><span class="line">        F: <span class="title function_ invoke__">Fn</span>(&amp;T) <span class="punctuation">-&gt;</span> <span class="type">bool</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而 List 是一个侵入式结构，大概需要实现一个 <code>IsElement</code>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// An entry in a linked list.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// An Entry is accessed from multiple threads, so it would be beneficial to put it in a different</span></span><br><span class="line"><span class="comment">/// cache-line than thread-local data in terms of performance.</span></span><br><span class="line"><span class="meta">#[derive(Debug)]</span></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">struct</span> <span class="title class_">Entry</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Implementing this trait asserts that the type `T` can be used as an element in the intrusive</span></span><br><span class="line"><span class="comment">/// linked list defined in this module. `T` has to contain (or otherwise be linked to) an instance</span></span><br><span class="line"><span class="comment">/// of `Entry`.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// # Example</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// ```ignore</span></span><br><span class="line"><span class="comment">/// struct A &#123;</span></span><br><span class="line"><span class="comment">///     entry: Entry,</span></span><br><span class="line"><span class="comment">///     data: usize,</span></span><br><span class="line"><span class="comment">/// &#125;</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// impl IsElement&lt;A&gt; for A &#123;</span></span><br><span class="line"><span class="comment">///     fn entry_of(a: &amp;A) -&gt; &amp;Entry &#123;</span></span><br><span class="line"><span class="comment">///         let entry_ptr = ((a as usize) + offset_of!(A, entry)) as *const Entry;</span></span><br><span class="line"><span class="comment">///         unsafe &#123; &amp;*entry_ptr &#125;</span></span><br><span class="line"><span class="comment">///     &#125;</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">///     unsafe fn element_of(entry: &amp;Entry) -&gt; &amp;T &#123;</span></span><br><span class="line"><span class="comment">///         let elem_ptr = ((entry as usize) - offset_of!(A, entry)) as *const T;</span></span><br><span class="line"><span class="comment">///         &amp;*elem_ptr</span></span><br><span class="line"><span class="comment">///     &#125;</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">///     unsafe fn finalize(entry: &amp;Entry, guard: &amp;Guard) &#123;</span></span><br><span class="line"><span class="comment">///         guard.defer_destroy(Shared::from(Self::element_of(entry) as *const _));</span></span><br><span class="line"><span class="comment">///     &#125;</span></span><br><span class="line"><span class="comment">/// &#125;</span></span><br><span class="line"><span class="comment">/// ```</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// This trait is implemented on a type separate from `T` (although it can be just `T`), because</span></span><br><span class="line"><span class="comment">/// one type might be placeable into multiple lists, in which case it would require multiple</span></span><br><span class="line"><span class="comment">/// implementations of `IsElement`. In such cases, each struct implementing `IsElement&lt;T&gt;`</span></span><br><span class="line"><span class="comment">/// represents a distinct `Entry` in `T`.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// For example, we can insert the following struct into two lists using `entry1` for one</span></span><br><span class="line"><span class="comment">/// and `entry2` for the other:</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// ```ignore</span></span><br><span class="line"><span class="comment">/// struct B &#123;</span></span><br><span class="line"><span class="comment">///     entry1: Entry,</span></span><br><span class="line"><span class="comment">///     entry2: Entry,</span></span><br><span class="line"><span class="comment">///     data: usize,</span></span><br><span class="line"><span class="comment">/// &#125;</span></span><br><span class="line"><span class="comment">/// ```</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">trait</span> <span class="title class_">IsElement</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="comment">/// Returns a reference to this element&#x27;s `Entry`.</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">entry_of</span>(_: &amp;T) <span class="punctuation">-&gt;</span> &amp;Entry;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Given a reference to an element&#x27;s entry, returns that element.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// ```ignore</span></span><br><span class="line">    <span class="comment">/// let elem = ListElement::new();</span></span><br><span class="line">    <span class="comment">/// assert_eq!(elem.entry_of(),</span></span><br><span class="line">    <span class="comment">///            unsafe &#123; ListElement::element_of(elem.entry_of()) &#125; );</span></span><br><span class="line">    <span class="comment">/// ```</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// # Safety</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// The caller has to guarantee that the `Entry` is called with was retrieved from an instance</span></span><br><span class="line">    <span class="comment">/// of the element type (`T`).</span></span><br><span class="line">    <span class="keyword">unsafe</span> <span class="keyword">fn</span> <span class="title function_">element_of</span>(_: &amp;Entry) <span class="punctuation">-&gt;</span> &amp;T;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// The function that is called when an entry is unlinked from list.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// # Safety</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// The caller has to guarantee that the `Entry` is called with was retrieved from an instance</span></span><br><span class="line">    <span class="comment">/// of the element type (`T`).</span></span><br><span class="line">    <span class="keyword">unsafe</span> <span class="keyword">fn</span> <span class="title function_">finalize</span>(_: &amp;Entry, _: &amp;Guard);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// A lock-free, intrusive linked list of type `T`.</span></span><br><span class="line"><span class="meta">#[derive(Debug)]</span></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">struct</span> <span class="title class_">List</span>&lt;T, C: IsElement&lt;T&gt; = T&gt;;</span><br></pre></td></tr></table></figure><p>这个结构就，非常侵入式，牛逼的。</p><h4 id="Epoch"><a href="#Epoch" class="headerlink" title="Epoch"></a>Epoch</h4><p>然后是 epoch 有关的类型，下面这部分在 <code>epoch.rs</code>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//! The global epoch</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! The last bit in this number is unused and is always zero. Every so often the global epoch is</span></span><br><span class="line"><span class="comment">//! incremented, i.e. we say it &quot;advances&quot;. A pinned participant may advance the global epoch only</span></span><br><span class="line"><span class="comment">//! if all currently pinned participants have been pinned in the current epoch.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! If an object became garbage in some epoch, then we can be sure that after two advancements no</span></span><br><span class="line"><span class="comment">//! participant will hold a reference to it. That is the crux of safe memory reclamation.</span></span><br></pre></td></tr></table></figure><p>看上面的表示，Epoch 最后一位表示是否 pin，这个在全局 Epoch 里面是没有意义的，但是局部数据对象可能依赖这个数据，而前面的数据代表具体版本：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// An epoch that can be marked as pinned or unpinned.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Internally, the epoch is represented as an integer that wraps around at some unspecified point</span></span><br><span class="line"><span class="comment">/// and a flag that represents whether it is pinned or unpinned.</span></span><br><span class="line"><span class="meta">#[derive(Copy, Clone, Default, Debug, Eq, PartialEq)]</span></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">struct</span> <span class="title class_">Epoch</span> &#123;</span><br><span class="line">    <span class="comment">/// The least significant bit is set if pinned. The rest of the bits hold the epoch.</span></span><br><span class="line">    data: <span class="type">usize</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里还包了一层 <code>AtomicEpoch</code>, <code>AtomicEpoch</code> 提供了对 <code>Epoch</code> 的 <code>load</code>, <code>store</code> 和 <code>cas</code> 操作：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// An atomic value that holds an `Epoch`.</span></span><br><span class="line"><span class="meta">#[derive(Default, Debug)]</span></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">struct</span> <span class="title class_">AtomicEpoch</span> &#123;</span><br><span class="line">    <span class="comment">/// Since `Epoch` is just a wrapper around `usize`, an `AtomicEpoch` is similarly represented</span></span><br><span class="line">    <span class="comment">/// using an `AtomicUsize`.</span></span><br><span class="line">    data: AtomicUsize,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Deferred"><a href="#Deferred" class="headerlink" title="Deferred"></a>Deferred</h4><p><code>Deferred</code> 是一个 defer 的 <code>data</code> + <code>destructor</code>, 我感觉可以 <code>Box&lt;Fn(...)&gt;</code>，不过它这感觉泛用很多。它靠谱的功能如下：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Number of words a piece of `Data` can hold.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Three words should be enough for the majority of cases. For example, you can fit inside it the</span></span><br><span class="line"><span class="comment">/// function pointer together with a fat pointer representing an object that needs to be destroyed.</span></span><br><span class="line"><span class="keyword">const</span> DATA_WORDS: <span class="type">usize</span> = <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// Some space to keep a `FnOnce()` object on the stack.</span></span><br><span class="line"><span class="keyword">type</span> <span class="title class_">Data</span> = [<span class="type">usize</span>; DATA_WORDS];</span><br><span class="line"></span><br><span class="line"><span class="comment">/// A `FnOnce()` that is stored inline if small, or otherwise boxed on the heap.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// This is a handy way of keeping an unsized `FnOnce()` within a sized structure.</span></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">struct</span> <span class="title class_">Deferred</span> &#123;</span><br><span class="line">    call: <span class="keyword">unsafe</span> <span class="title function_ invoke__">fn</span>(*<span class="keyword">mut</span> <span class="type">u8</span>),</span><br><span class="line">    data: MaybeUninit&lt;Data&gt;,</span><br><span class="line">    _marker: PhantomData&lt;*<span class="title function_ invoke__">mut</span> ()&gt;, <span class="comment">// !Send + !Sync</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Deferred</span> &#123;</span><br><span class="line">    <span class="comment">/// Constructs a new `Deferred` from a `FnOnce()`.</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">new</span>&lt;F: <span class="title function_ invoke__">FnOnce</span>()&gt;(f: F) <span class="punctuation">-&gt;</span> <span class="keyword">Self</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Calls the function.</span></span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">call</span>(<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">call</span> = <span class="keyword">self</span>.call;</span><br><span class="line">        <span class="keyword">unsafe</span> &#123; <span class="title function_ invoke__">call</span>(<span class="keyword">self</span>.data.<span class="title function_ invoke__">as_mut_ptr</span>() <span class="keyword">as</span> *<span class="keyword">mut</span> <span class="type">u8</span>) &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实很明显了，感觉还是挺简单的。</p><h4 id="Bag"><a href="#Bag" class="headerlink" title="Bag"></a>Bag</h4><p>在 <code>internal.rs</code> 里面，实现了 <code>Bag</code> 和 <code>SealedBag</code>. <code>Bag</code> 是一组 <code>Deferred</code>, 而 <code>SealedBag</code> 则是定了某个版本的 <code>SealedBag</code>, 他们内容如下：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//! # Thread-local bag</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! Objects that get unlinked from concurrent data structures must be stashed away until the global</span></span><br><span class="line"><span class="comment">//! epoch sufficiently advances so that they become safe for destruction. Pointers to such objects</span></span><br><span class="line"><span class="comment">//! are pushed into a thread-local bag, and when it becomes full, the bag is marked with the current</span></span><br><span class="line"><span class="comment">//! global epoch and pushed into the global queue of bags. We store objects in thread-local storages</span></span><br><span class="line"><span class="comment">//! for amortizing the synchronization cost of pushing the garbages to a global queue.</span></span><br></pre></td></tr></table></figure><p>代码：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Maximum number of objects a bag can contain.</span></span><br><span class="line"><span class="meta">#[cfg(not(crossbeam_sanitize))]</span></span><br><span class="line"><span class="keyword">const</span> MAX_OBJECTS: <span class="type">usize</span> = <span class="number">62</span>;</span><br><span class="line"><span class="meta">#[cfg(crossbeam_sanitize)]</span></span><br><span class="line"><span class="keyword">const</span> MAX_OBJECTS: <span class="type">usize</span> = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// A bag of deferred functions.</span></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">struct</span> <span class="title class_">Bag</span> &#123;</span><br><span class="line">    <span class="comment">/// Stashed objects.</span></span><br><span class="line">    deferreds: [Deferred; MAX_OBJECTS],</span><br><span class="line">    len: <span class="type">usize</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Bag</span> &#123;</span><br><span class="line">    <span class="comment">/// Returns a new, empty bag.</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">new</span>() <span class="punctuation">-&gt;</span> <span class="keyword">Self</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Returns `true` if the bag is empty.</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">is_empty</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">bool</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Attempts to insert a deferred function into the bag.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// Returns `Ok(())` if successful, and `Err(deferred)` for the given `deferred` if the bag is</span></span><br><span class="line">    <span class="comment">/// full.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// # Safety</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// It should be safe for another thread to execute the given function.</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">unsafe</span> <span class="keyword">fn</span> <span class="title function_">try_push</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, deferred: Deferred) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;(), Deferred&gt;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Seals the bag with the given epoch.</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">seal</span>(<span class="keyword">self</span>, epoch: Epoch) <span class="punctuation">-&gt;</span> SealedBag;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// A pair of an epoch and a bag.</span></span><br><span class="line"><span class="meta">#[derive(Default, Debug)]</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SealedBag</span> &#123;</span><br><span class="line">    epoch: Epoch,</span><br><span class="line">    _bag: Bag,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// It is safe to share `SealedBag` because `is_expired` only inspects the epoch.</span></span><br><span class="line"><span class="keyword">unsafe</span> <span class="keyword">impl</span> <span class="title class_">Sync</span> <span class="keyword">for</span> <span class="title class_">SealedBag</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">SealedBag</span> &#123;</span><br><span class="line">    <span class="comment">/// Checks if it is safe to drop the bag w.r.t. the given global epoch.</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">is_expired</span>(&amp;<span class="keyword">self</span>, global_epoch: Epoch) <span class="punctuation">-&gt;</span> <span class="type">bool</span> &#123;</span><br><span class="line">        <span class="comment">// A pinned participant can witness at most one epoch advancement. Therefore, any bag that</span></span><br><span class="line">        <span class="comment">// is within one epoch of the current one cannot be destroyed yet.</span></span><br><span class="line">        global_epoch.<span class="title function_ invoke__">wrapping_sub</span>(<span class="keyword">self</span>.epoch) &gt;= <span class="number">2</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="外部接口"><a href="#外部接口" class="headerlink" title="外部接口"></a>外部接口</h3><p>外部很多接口是现在 <code>default.rs</code> 里面。很多读者可能会很困惑，刚刚不是还在讲工具类吗，现在怎么外部接口了，答案是剩下内容都是紧密缝合的，适合自顶向下讲了。工具先看完，然后自顶向下推进，还挺好的。</p><p><a href="https://github.com/crossbeam-rs/crossbeam/blob/master/crossbeam-epoch/src/default.rs">https://github.com/crossbeam-rs/crossbeam/blob/master/crossbeam-epoch/src/default.rs</a></p><p>这里有：</p><ol><li>全局 lazy_static 的 <code>Collector</code></li><li>单个线程一个的 <code>LocalHandle</code>, 由 <code>COLLECTOR.register()</code> 生成</li></ol><p>然后外部的 <code>pin</code> 接口会拿到 tls 的 <code>LocalHandle</code>, 用它来 <code>pin</code>.</p><p>而 <code>Collector</code> 和 <code>LocalHandle</code> 则是 内部的 <code>Global</code> 和 <code>Local</code> 的包装器：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// An epoch-based garbage collector.</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Collector</span> &#123;</span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) global: Arc&lt;Global&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Collector</span> &#123;</span><br><span class="line">    <span class="comment">/// Creates a new collector.</span></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">new</span>() <span class="punctuation">-&gt;</span> <span class="keyword">Self</span> &#123;</span><br><span class="line">        <span class="keyword">Self</span>::<span class="title function_ invoke__">default</span>()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Registers a new handle for the collector.</span></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">register</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> LocalHandle &#123;</span><br><span class="line">        Local::<span class="title function_ invoke__">register</span>(<span class="keyword">self</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/// A handle to a garbage collector.</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">LocalHandle</span> &#123;</span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) local: *<span class="keyword">const</span> Local,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">LocalHandle</span> &#123;</span><br><span class="line">    <span class="comment">/// Pins the handle.</span></span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">pin</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> Guard &#123;</span><br><span class="line">        <span class="keyword">unsafe</span> &#123; (*<span class="keyword">self</span>.local).<span class="title function_ invoke__">pin</span>() &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Returns `true` if the handle is pinned.</span></span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">is_pinned</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">bool</span> &#123;</span><br><span class="line">        <span class="keyword">unsafe</span> &#123; (*<span class="keyword">self</span>.local).<span class="title function_ invoke__">is_pinned</span>() &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Returns the `Collector` associated with this handle.</span></span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">collector</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> &amp;Collector &#123;</span><br><span class="line">        <span class="keyword">unsafe</span> &#123; (*<span class="keyword">self</span>.local).<span class="title function_ invoke__">collector</span>() &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Drop</span> <span class="keyword">for</span> <span class="title class_">LocalHandle</span> &#123;</span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">unsafe</span> &#123;</span><br><span class="line">            Local::<span class="title function_ invoke__">release_handle</span>(&amp;*<span class="keyword">self</span>.local);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这俩哥们基本属于套娃包装，所以我们最后当然必须再来看看 <code>internal.rs</code>，这里面东西主要有 Global 和 Local:</p><p>Global 是全局状态池子，由 Collector 包装（等下会讲），内容大概如下：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// The global data for a garbage collector.</span></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">struct</span> <span class="title class_">Global</span> &#123;</span><br><span class="line">    <span class="comment">/// The intrusive linked list of `Local`s.</span></span><br><span class="line">    locals: List&lt;Local&gt;,</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// The global queue of bags of deferred functions.</span></span><br><span class="line">    queue: Queue&lt;SealedBag&gt;,</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// The global epoch.</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) epoch: CachePadded&lt;AtomicEpoch&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Global 会挂着：</p><ol><li><code>SealedBag</code> 的队列，作为延迟调用的函数</li><li><code>List&lt;Local&gt;</code>，作为活跃的线程的侵入式链表</li><li><code>epoch</code>, 全局的 atomic epoch，最后一位是无用的</li></ol><p>Global 的方法得全贴出来：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span> <span class="title class_">Global</span> &#123;</span><br><span class="line">    <span class="comment">/// Number of bags to destroy.</span></span><br><span class="line">    <span class="keyword">const</span> COLLECT_STEPS: <span class="type">usize</span> = <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Creates a new global data for garbage collection.</span></span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">new</span>() <span class="punctuation">-&gt;</span> <span class="keyword">Self</span> &#123;</span><br><span class="line">        <span class="keyword">Self</span> &#123;</span><br><span class="line">            locals: List::<span class="title function_ invoke__">new</span>(),</span><br><span class="line">            queue: Queue::<span class="title function_ invoke__">new</span>(),</span><br><span class="line">            epoch: CachePadded::<span class="title function_ invoke__">new</span>(AtomicEpoch::<span class="title function_ invoke__">new</span>(Epoch::<span class="title function_ invoke__">starting</span>())),</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Pushes the bag into the global queue and replaces the bag with a new empty bag.</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">push_bag</span>(&amp;<span class="keyword">self</span>, bag: &amp;<span class="keyword">mut</span> Bag, guard: &amp;Guard) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">bag</span> = mem::<span class="title function_ invoke__">replace</span>(bag, Bag::<span class="title function_ invoke__">new</span>());</span><br><span class="line"></span><br><span class="line">        atomic::<span class="title function_ invoke__">fence</span>(Ordering::SeqCst);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">epoch</span> = <span class="keyword">self</span>.epoch.<span class="title function_ invoke__">load</span>(Ordering::Relaxed);</span><br><span class="line">        <span class="keyword">self</span>.queue.<span class="title function_ invoke__">push</span>(bag.<span class="title function_ invoke__">seal</span>(epoch), guard);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Collects several bags from the global queue and executes deferred functions in them.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// Note: This may itself produce garbage and in turn allocate new bags.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// `pin()` rarely calls `collect()`, so we want the compiler to place that call on a cold</span></span><br><span class="line">    <span class="comment">/// path. In other words, we want the compiler to optimize branching for the case when</span></span><br><span class="line">    <span class="comment">/// `collect()` is not called.</span></span><br><span class="line">    <span class="meta">#[cold]</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">collect</span>(&amp;<span class="keyword">self</span>, guard: &amp;Guard) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">global_epoch</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">try_advance</span>(guard);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">steps</span> = <span class="keyword">if</span> <span class="built_in">cfg!</span>(crossbeam_sanitize) &#123;</span><br><span class="line">            usize::<span class="title function_ invoke__">max_value</span>()</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">Self</span>::COLLECT_STEPS</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> <span class="variable">_</span> <span class="keyword">in</span> <span class="number">0</span>..steps &#123;</span><br><span class="line">            <span class="keyword">match</span> <span class="keyword">self</span>.queue.<span class="title function_ invoke__">try_pop_if</span>(</span><br><span class="line">                &amp;|sealed_bag: &amp;SealedBag| sealed_bag.<span class="title function_ invoke__">is_expired</span>(global_epoch),</span><br><span class="line">                guard,</span><br><span class="line">            ) &#123;</span><br><span class="line">                <span class="literal">None</span> =&gt; <span class="keyword">break</span>,</span><br><span class="line">                <span class="title function_ invoke__">Some</span>(sealed_bag) =&gt; <span class="title function_ invoke__">drop</span>(sealed_bag),</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Attempts to advance the global epoch.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// The global epoch can advance only if all currently pinned participants have been pinned in</span></span><br><span class="line">    <span class="comment">/// the current epoch.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// Returns the current global epoch.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// `try_advance()` is annotated `#[cold]` because it is rarely called.</span></span><br><span class="line">    <span class="meta">#[cold]</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">fn</span> <span class="title function_">try_advance</span>(&amp;<span class="keyword">self</span>, guard: &amp;Guard) <span class="punctuation">-&gt;</span> Epoch &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">global_epoch</span> = <span class="keyword">self</span>.epoch.<span class="title function_ invoke__">load</span>(Ordering::Relaxed);</span><br><span class="line">        atomic::<span class="title function_ invoke__">fence</span>(Ordering::SeqCst);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// TODO(stjepang): `Local`s are stored in a linked list because linked lists are fairly</span></span><br><span class="line">        <span class="comment">// easy to implement in a lock-free manner. However, traversal can be slow due to cache</span></span><br><span class="line">        <span class="comment">// misses and data dependencies. We should experiment with other data structures as well.</span></span><br><span class="line">        <span class="keyword">for</span> <span class="variable">local</span> <span class="keyword">in</span> <span class="keyword">self</span>.locals.<span class="title function_ invoke__">iter</span>(guard) &#123;</span><br><span class="line">            <span class="keyword">match</span> local &#123;</span><br><span class="line">                <span class="title function_ invoke__">Err</span>(IterError::Stalled) =&gt; &#123;</span><br><span class="line">                    <span class="comment">// A concurrent thread stalled this iteration. That thread might also try to</span></span><br><span class="line">                    <span class="comment">// advance the epoch, in which case we leave the job to it. Otherwise, the</span></span><br><span class="line">                    <span class="comment">// epoch will not be advanced.</span></span><br><span class="line">                    <span class="keyword">return</span> global_epoch;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="title function_ invoke__">Ok</span>(local) =&gt; &#123;</span><br><span class="line">                    <span class="keyword">let</span> <span class="variable">local_epoch</span> = local.epoch.<span class="title function_ invoke__">load</span>(Ordering::Relaxed);</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// If the participant was pinned in a different epoch, we cannot advance the</span></span><br><span class="line">                    <span class="comment">// global epoch just yet.</span></span><br><span class="line">                    <span class="keyword">if</span> local_epoch.<span class="title function_ invoke__">is_pinned</span>() &amp;&amp; local_epoch.<span class="title function_ invoke__">unpinned</span>() != global_epoch &#123;</span><br><span class="line">                        <span class="keyword">return</span> global_epoch;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        atomic::<span class="title function_ invoke__">fence</span>(Ordering::Acquire);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// All pinned participants were pinned in the current global epoch.</span></span><br><span class="line">        <span class="comment">// Now let&#x27;s advance the global epoch...</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">// Note that if another thread already advanced it before us, this store will simply</span></span><br><span class="line">        <span class="comment">// overwrite the global epoch with the same value. This is true because `try_advance` was</span></span><br><span class="line">        <span class="comment">// called from a thread that was pinned in `global_epoch`, and the global epoch cannot be</span></span><br><span class="line">        <span class="comment">// advanced two steps ahead of it.</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">new_epoch</span> = global_epoch.<span class="title function_ invoke__">successor</span>();</span><br><span class="line">        <span class="keyword">self</span>.epoch.<span class="title function_ invoke__">store</span>(new_epoch, Ordering::Release);</span><br><span class="line">        new_epoch</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里，其他函数含义都非常清晰，难一点的是 <code>try_advance</code> ，如果它发现现在所有活跃线程都是 <code>pinned</code> 的，且等于自身周期，那么它会推进。这个地方有点难懂，我们可以回顾一下，可以推进是因为只有这个版本的 reader 了，再之前的数据对象可以 gc 掉，这里和 <code>pin</code> 的流程是有关的。总之，每个 <code>Local</code> 都是本周期且 pin 了，就可以推进 + 回收了。回收流程见 <code>collect</code></p><p>至于 Local，其实挺…听不 RAII 的，它会在 <code>register</code> 的时候 创建，<code>pin</code> 的时候初始化，<code>release_handle</code> 的时候销毁。它本身会被 TLS 的使用，和线程绑定：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Participant for garbage collection.</span></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">struct</span> <span class="title class_">Local</span> &#123;</span><br><span class="line">    <span class="comment">/// A node in the intrusive linked list of `Local`s.</span></span><br><span class="line">    entry: Entry,</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// The local epoch.</span></span><br><span class="line">    epoch: AtomicEpoch,</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// A reference to the global data.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// When all guards and handles get dropped, this reference is destroyed.</span></span><br><span class="line">    collector: UnsafeCell&lt;ManuallyDrop&lt;Collector&gt;&gt;,</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// The local bag of deferred functions.</span></span><br><span class="line">    <span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) bag: UnsafeCell&lt;Bag&gt;,</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// The number of guards keeping this participant pinned.</span></span><br><span class="line">    guard_count: Cell&lt;<span class="type">usize</span>&gt;,</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// The number of active handles.</span></span><br><span class="line">    handle_count: Cell&lt;<span class="type">usize</span>&gt;,</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// Total number of pinnings performed.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// This is just an auxiliary counter that sometimes kicks off collection.</span></span><br><span class="line">    pin_count: Cell&lt;Wrapping&lt;<span class="type">usize</span>&gt;&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你会发现它也有个 <code>epoch</code>, 没错，这玩意只有 <code>pin</code> 的时候会初始化。我看还有 <code>repin</code> 什么的，估计是为了优化准备的吧。</p><p>最后有个 <code>Guard</code>，本身就是很简单的绑定 <code>Local</code> 的组件了。需要注意的是，<code>Local</code> 和 <code>Guard</code> 大部分接口都是串行的，只有读 epoch 的时候，会并行，它也只靠 epoch 和 <code>collector</code> 与 Global 互相通信</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://aturon.github.io/blog/2015/08/27/epoch/">https://aturon.github.io/blog/2015/08/27/epoch/</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Scheduling Blog Overview</title>
      <link href="/2022/05/29/Scheduling-Blog-Overview/"/>
      <url>/2022/05/29/Scheduling-Blog-Overview/</url>
      
        <content type="html"><![CDATA[<p>今天本来打算看 <em>Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework for the Many-Core Age</em> 这玩意，看了一点之后感觉自己理性上知道这篇文章是把 Task 切碎了，然后调度的时候根据数据亲和性来做处理，然后做了协同调度。但是看到这些词汇的时候，好像一点都想不起来咋做的，感觉我对调度系统理解是一片空白。知道它在讲啥也不能清晰的理解内容。</p><p>刚看了看陈海波的 os 书第六章，突然理解了很多名词，不过感觉记 notes 也不如原书这一章好，所以干脆做一个索引。来描述我对调度系统名词理解。</p><p>这篇文章是瞎几把写的，很多东西我也就先占坑，所以没啥必要看，主要是以后理清楚了可以在这里回过头来写写「原来是这样」</p><h2 id="基本概念-OS"><a href="#基本概念-OS" class="headerlink" title="基本概念: OS"></a>基本概念: OS</h2><p>这里最好参考陈海波的 <em>&lt;现代操作系统：原理与实现&gt;</em> 来理解。</p><p>这里有一个任务（Task）的概念，Linux 里面线程/进程都是 <code>task_struct</code> 里面都是 Task。这里还会涉及别的东西，包括：</p><ol><li>优先级（Priority）</li><li>时间片（Timeslice）</li><li>Deadline</li><li>…</li></ol><p>关于调度目标，</p><p>性能相关指标有：吞吐量（单位时间内处理的任务数量）、周转时间（任务发起到结束的时间）、响应时间</p><p>非性能相关：公平性、资源利用率</p><p>任务可能有不同类型，比如<strong>批处理</strong>类型更希望有更大的吞吐量、更小的周转时间；<strong>交互式任务</strong>会希望有更小的响应时间；实时任务会希望有更好的实时性；移动设备可能希望开销小一点，它还大小核什么的。</p><p>同时，任务数量会很多，而且现代系统本身也向多核发展（详见：<a href="https://blog.mwish.me/2022/05/04/perfbook-notes-hardware/">https://blog.mwish.me/2022/05/04/perfbook-notes-hardware/</a> 和 <a href="https://blog.mwish.me/2022/05/02/Arch-Blog-Overviews/">https://blog.mwish.me/2022/05/02/Arch-Blog-Overviews/</a> ）。所以也会希望能用上所有的 CPU、调度开销小。</p><p>然后不同任务指标是不一样的（当时看这里不太理解，但是看 AP/TP/HSAP 等工业界需求，就会明白很多了），这里也有各种 trade-off：</p><ol><li>调度开销 vs 调度效果</li><li>优先级 vs 公平性</li><li>性能 vs 能耗</li></ol><p>关于上面的，还有一些 os 的博客指出它们的 trade-off ，比如 SOCC’14 的 Tales of the Tail: Hardware, OS, and Application-level Sources of Tail Latency</p><h3 id="调度机制"><a href="#调度机制" class="headerlink" title="调度机制"></a>调度机制</h3><p>长期、短期、中期调度，长期控制是否 spawn task，短期处理任务状态，中期根据 IO 等状况调整</p><p><img src="https://image.mwish.me/blog-image/DE0BC35E-653F-4B34-98CB-B2A5E35462CA.png" alt="DE0BC35E-653F-4B34-98CB-B2A5E35462CA"></p><p><img src="https://image.mwish.me/blog-image/E2C862EC-D7E8-4B59-91D0-D4A2E6444DD0.png" alt="E2C862EC-D7E8-4B59-91D0-D4A2E6444DD0"></p><h3 id="单核调度"><a href="#单核调度" class="headerlink" title="单核调度"></a>单核调度</h3><p>FCFS/SJF/MLFQ/RR ，抢占/非抢占，是否有优先级（多级反馈队列），是否有份额（比如各个用户付了不同的钱，那么调度会根据 stride 或者彩票来调度）</p><p>上面其实不是谁比谁更优，而要考虑各种 功能需求 / trade-off</p><h3 id="实时调度"><a href="#实时调度" class="headerlink" title="实时调度"></a>实时调度</h3><p>TBD</p><h3 id="多核调度"><a href="#多核调度" class="headerlink" title="多核调度"></a>多核调度</h3><p><img src="https://image.mwish.me/blog-image/89918942-3B8F-493A-AF3E-9AE58BB381F6.png" alt="89918942-3B8F-493A-AF3E-9AE58BB381F6"></p><p>首先考虑协同调度/群组调度，上层知道任务的分组/协同情况，就更能利用多核的性能。例如 BSP 模型（常用于类似 MR/图计算）。</p><p>这里还要考虑两级调度，这样能保证调度的开销是小的（考虑 NUMA 等情况）：</p><p><img src="https://image.mwish.me/blog-image/60BBDBE5-2C89-4B54-B9B0-E2EA96080CD8.png" alt="60BBDBE5-2C89-4B54-B9B0-E2EA96080CD8"></p><p>调度要考虑调度的开销，Linux 有一个 Per-Entity Load Tracing 机制来考虑。</p><p>然后调度到不同 core 开销也不同，所以有：</p><p><img src="https://image.mwish.me/blog-image/AE849A38-8937-40C4-B68A-A24A3EDD15F9.png" alt="AE849A38-8937-40C4-B68A-A24A3EDD15F9"></p><h3 id="Linux-调度"><a href="#Linux-调度" class="headerlink" title="Linux 调度"></a>Linux 调度</h3><p>CFS 等：</p><p><img src="https://image.mwish.me/blog-image/5F54B43F-6BA8-4576-9FE1-776FB791ADB1.png" alt="5F54B43F-6BA8-4576-9FE1-776FB791ADB1"></p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul><li>Tokio 调度，在 coroutine 上引入了一些 ts 等：<a href="https://tokio.rs/blog/2019-10-scheduler">https://tokio.rs/blog/2019-10-scheduler</a> 和 <a href="https://tokio.rs/blog/2020-04-preemption">https://tokio.rs/blog/2020-04-preemption</a></li></ul><h2 id="分布式调度系统"><a href="#分布式调度系统" class="headerlink" title="分布式调度系统"></a>分布式调度系统</h2><p>《大数据日知录》第四章。</p><p>静态划分是很好的方法，但是资源利用率不高，更期望把资源当作整体管理：</p><p><img src="https://image.mwish.me/blog-image/F762A867-E008-4306-B743-BC2F4392614A.png" alt="F762A867-E008-4306-B743-BC2F4392614A"></p><p>这里要考虑：workload 的资源的性质（CPU/Disk/GPU，有无状态）；数据局部性（Node -&gt; Rack -&gt; Cluster）；调度的是否抢占（能否暂停/干死正在跑的任务，还是只能从 spare 中分配资源）</p><p>也要考虑单机各种资源隔离的方法，是否饿死任务等。</p><p>调度器也有不同的类型：</p><p><img src="https://image.mwish.me/blog-image/B606A247-F83F-4F87-BDFD-D76908EA3036.png" alt="B606A247-F83F-4F87-BDFD-D76908EA3036"></p><p>还有不同的调度算法：</p><p><img src="https://image.mwish.me/blog-image/31432F80-4DEE-4105-B7CC-3A736E84463D.png" alt="31432F80-4DEE-4105-B7CC-3A736E84463D"></p><h2 id="DB-的调度系统"><a href="#DB-的调度系统" class="headerlink" title="DB 的调度系统"></a>DB 的调度系统</h2><p>相对我们之前提的 OS 调度来说，DB 调度系统可能可以：</p><ol><li>根据 Plan 和 Catalog 预估各种开销</li><li>更好的并行，协同调度，比如 Exchange 算子</li><li>单机还好，分布式的话，开销会引入网络开销，还算未知</li></ol><p>材料有：</p><ol><li><a href="https://15721.courses.cs.cmu.edu/spring2020/papers/12-scheduling/p743-leis.pdf">Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework for the Many-Core Age</a></li><li><a href="https://15721.courses.cs.cmu.edu/spring2020/papers/12-scheduling/p1442-psaroudakis.pdf">Scaling Up Concurrent Main-Memory Column-Store Scans: Towards Adaptive NUMA-aware Data and Task Placement</a></li><li>SQL 查询的分布式执行与调度 <a href="https://zhuanlan.zhihu.com/p/100949808">https://zhuanlan.zhihu.com/p/100949808</a></li><li>PolarDB 并行计算框架 <a href="https://zhuanlan.zhihu.com/p/346320114">https://zhuanlan.zhihu.com/p/346320114</a></li></ol><p>Spark, Presto, StarRocks 等</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Constant Time Recovery in Azure SQL Database</title>
      <link href="/2022/05/28/Constant-Time-Recovery-in-Azure-SQL-Database/"/>
      <url>/2022/05/28/Constant-Time-Recovery-in-Azure-SQL-Database/</url>
      
        <content type="html"><![CDATA[<p>传统的 ARIES 算法一直是「数据库的成人礼」，Azure SQL 之前用的是 ARIES 算法实现恢复。但是在有长事务的时候，恢复会比较恶心，特别是在 Undo 阶段。要拿到长事务修改过的每个地方给他嗯 Undo 回来，直到这个长事务 Log 开头，然后这些 Log 也不能 GC 掉，这个显然就很 waste of time。</p><p>Azure SQL 曾经遇到过一个大事务，改了一堆元素，恢复的时候花了 12个小时。后来 Azure SQL 在原先 ARIES 的基础上实现了并行恢复，让这个时间变快不少。不过这个可以看出，混合负载下恢复确实是成问题的。</p><p>此外，公司内部的数据库可以跑在一些核心硬件上，利用各种规模效应，来降低成本；核心服务甚至自己有一套硬件设备，但是，作为云上的 TP 数据库，可能需要考虑：</p><ol><li>数据规模变大，可能会导致单机数据规模变大，恢复时间变长</li><li>云上硬件不一定好，增加了各种出现问题的概率</li><li>可能会有各种云上软件升级、调度之类的事情，导致出问题频率变高</li></ol><p>论文在 SQL Server 中设计了 Constant Time Recovery(CTR) 的恢复机制，将 MVCC 和 Undo 结合，实现了常数时间恢复的恢复算法。然后进行了不少工程优化，包括小事务优化等，因为没有大事务的情况下恢复本身很快，所以它尽量只让大事务走这套机制。有了这个恢复算法后，带长事务的系统恢复时间大大减少了。</p><h2 id="之前的设计模型"><a href="#之前的设计模型" class="headerlink" title="之前的设计模型"></a>之前的设计模型</h2><p>SQL Server 之前使用的是修改过的 ARIES，具体而言，它的数据模型是数据 + Log，数据和 Log 是分开存储的，Log 遵循 ARIES 的语义，如下图：</p><p><img src="https://image.mwish.me/blog-image/1EE46719-2743-4D24-9B39-819CDC57EEDB.png" alt="1EE46719-2743-4D24-9B39-819CDC57EEDB"></p><p>它的数据在内存中逻辑上是 MVCC 的，模型是 N2O + Main/Delta。这里它的 Delta 是一个 volatile 的结构，因为 crash 之后它认为不需要之前那些数据了，详见 Figure3:</p><p><img src="https://image.mwish.me/blog-image/F8277752-FDF1-4D22-8604-77A2D0A235F5.png" alt="F8277752-FDF1-4D22-8604-77A2D0A235F5"></p><p>在系统中，它会走一个 Recover 的流程，类似 ARIES，但是有一些小小的区别，如 Figure2:</p><p><img src="https://image.mwish.me/blog-image/76002207-4750-4DDD-9410-0C08E189746A.png" alt="76002207-4750-4DDD-9410-0C08E189746A"></p><p>我们都很熟悉 ARIES 的流程，所以会看到 Phase 2a: <code>Redo Lock Acquisition</code> 这玩意比较奇怪，怎么会是呢？因为在 SQL Server 中，它在 Redo 完了就可以 Serve 外部系统了。那没 Undo 完的怎么办呢？Redo 的时候会占上该获得的锁，这个时候请求的事务会被这些锁 block 住，直到 Undo 完成。这相当于用 Phase 2a 的恢复时间换来了没有锁的各个 Tuple 的恢复时间。</p><h2 id="Constant-Time-Recovery"><a href="#Constant-Time-Recovery" class="headerlink" title="Constant Time Recovery"></a>Constant Time Recovery</h2><p>这个算法目标如下：</p><blockquote><ul><li>Database recovery in constant time, regardless of the user workload and transaction sizes.</li><li>Transaction rollback in constant time regardless of the transaction size.</li><li>Continuous transaction log truncation, even in the presence of long running transactions.</li></ul></blockquote><p>具体而言，这个算法把对数据库的操作分为了下面的类型：</p><ol><li>Data Modifications</li><li>System Operations</li><li>Logical and Other Non-versioned operations</li></ol><h4 id="Data-Modifications"><a href="#Data-Modifications" class="headerlink" title="Data Modifications"></a>Data Modifications</h4><p>对于 Data Modifications，就是 Row/Tuple 的修改，由外部事务驱动。这里改动如下：</p><ol><li>由一个 volatile 的内容存储版本，改成和 InnoDB 那样的持久化存储。这个估计实现就类似 InnoDB Undo 那套</li><li>版本链可以装 aborted 的版本，无论在 main 还是 delta 中。abort 的版本可以被忽略</li><li>每个 Row 上会有一个 TxnID，可以识别出它是否被 abort，来判断是否可读取</li></ol><p>那么实际上，恢复的时候，<strong>只需要知道哪些事务 abort 了，并不需要手动 undo 这些。而多余的版本由 GC( Cleanup ) 来回收</strong>。</p><h4 id="System-Operations"><a href="#System-Operations" class="headerlink" title="System Operations"></a>System Operations</h4><p>这里通常是空间(Page) 的 alloc 或者 dealloc，SMO 操作。这些操作本身不那么带版本。它们其实不一定会被事务完成之后 undone，一般会有一些后台线程来回收这些数据。</p><h4 id="Logical-and-Other-Non-versioned-Operations"><a href="#Logical-and-Other-Non-versioned-Operations" class="headerlink" title="Logical and Other Non-versioned Operations"></a>Logical and Other Non-versioned Operations</h4><p>这里操作包括 Logical 的操作，比如 Lock acquisition；或者是一些需要在 Recover 之前就 aware 的行为，比如修改 Catalog 的操作。这些操作是非版本化的，但仍然是可回滚的。CTR 使用了一个独立的 SLog 系统来承载这些操作。</p><h3 id="Persistent-Version-Storage"><a href="#Persistent-Version-Storage" class="headerlink" title="Persistent Version Storage"></a>Persistent Version Storage</h3><p>这个我看了下，和 MySQL 的 Undo Space 没啥区别。这里通过 <code>&lt;PageID, SlotID&gt;</code> 定位具体的 Row，有点类似 PG HeapTuple 那套。然后修改操作反正也和 MySQL mtr 差不多。一些优化如下：</p><blockquote><p>The off-row PVS leverages the table infrastructure to simplify storing and accessing versions but is highly optimized for concurrent inserts. The accessors required to read or write to this table are cached and partitioned per core, while inserts are logged in a non-transactional manner (logged as redo-only operations) to avoid instantiating additional transactions. Threads running in parallel can insert rows into different sets of pages to eliminate contention. Finally, space is pre-allocated to avoid having to perform allocations as part of generating a version.</p></blockquote><p>还有一个优化点是 in-row version store:</p><p><img src="https://image.mwish.me/blog-image/9A30DEDC-1EC1-44B3-8500-20D3160224CD.png" alt="9A30DEDC-1EC1-44B3-8500-20D3160224CD"></p><p>这里是一个 trade-off，将 row 空间放大和修改做到本地做权衡，这种方式能很好的优化 Deleted 的结构，在 main 标记删除即可。</p><p><img src="https://image.mwish.me/blog-image/665C7137-EB70-4AC3-8734-270C38E5A003.png" alt="665C7137-EB70-4AC3-8734-270C38E5A003"></p><p>当然，这里有个问题，就是这些空间放大会不会有影响。SQL Server 似乎会判断 <em>Delta 会不会很大</em> 和 <em>这样标记会不会影响分裂</em> 来决定是否做成 inline 的</p><h3 id="Logical-Revert"><a href="#Logical-Revert" class="headerlink" title="Logical Revert"></a>Logical Revert</h3><p>这里其实就是，对于 Data Modification，某种意义上说 Redo 完就行了，然后查的时候，MainTable 扫一扫，如果某个版本 abort 了就不要读它，就行了。如果最新的版本是个 aborted 的，那么可能有下图的优化：</p><p><img src="https://image.mwish.me/blog-image/2786AFA9-67ED-4B8F-AE4B-9A29506ECB4A.png" alt="2786AFA9-67ED-4B8F-AE4B-9A29506ECB4A"></p><ol><li>Logical Revert，把 Version Store 的内容提到主表中，缩短链长。这由一个 System Transaction 完成，而且是只修改单个 Row 的操作，所以会非常非常短</li><li>Overwrite: 新事务直接覆盖掉主表的 aborted version</li></ol><h4 id="Transaction-State-Management"><a href="#Transaction-State-Management" class="headerlink" title="Transaction State Management"></a>Transaction State Management</h4><p>一般事务内部会 keep 内存的事务表集合，之所以只要在内存中，因为这些可以根据 Log 全量构建。MySQL 的模型和 SQL Server 修改后差不多，但是它有 Undo 流程，所以不需要引入额外的结构。</p><p>SQL Server 因为会在 Main/Delta 中直接有 aborted 的结构，所以必须引入一个 aborted 事务表，来进行操作。这个 aborted 事务表的增/删也要落 Log。当某个事务 aborted，它会被加入表中，当它修改的所有 rows 不可见了（由 Cleanup 操作完成），这个东西会在事务表中被回收掉。</p><p>CTR 引入了一个 Aborted Transaction Map，来存储这些信息，ATM 还会随着 ckpt 存储下去，加速恢复：</p><blockquote><p>CTR stores the aborted transaction information in the “Aborted Transaction Map” (ATM), a hash table that allows fast access based on the Transaction Id. When a transaction aborts, before releasing any locks, it will add its Transaction Id to the ATM and generate an “ABORT” log record indicating that it was aborted.</p><p>As part of the Undo phase, any uncommitted transactions will also be marked as aborted, generating the corresponding ABORT log records, and added to the ATM.</p><p>Once all versions generated by an aborted transaction have been reverted, the transaction is no longer interesting for recovery and can be removed from the ATM. Removing a transaction is also a logged operation, using a “FORGET” log record, to guarantee that the content of the ATM is recovered correctly.</p></blockquote><p>读者肯定会有一个疑问，ATM 会不会疯狂膨胀，下一小节就是讲这个的。</p><h4 id="Short-Transaction-Optimization"><a href="#Short-Transaction-Optimization" class="headerlink" title="Short Transaction Optimization"></a>Short Transaction Optimization</h4><p>ATM 会带来两种问题：</p><ol><li>任何一个小事务，如果 abort 了，要记 log；如果清理完了，还要记 log。相对原本 ARIES 来说，空间和延迟都会放大</li><li>ATM 本身可能膨胀</li></ol><p>总之，引入 ATM 让系统能够常数时间恢复，但是这会对性能造成不小的负面影响。这里引入了一个动态抉择方案：<strong>「只有大事务会走 CTR，小事务就走原来的，因为不影响」</strong>：</p><blockquote><p>To optimize for both scenarios, CTR dynamically decides, based on the transaction size, whether a transaction should be marked as aborted, using the CTR mechanisms, or undone using the transaction log.</p></blockquote><p>其实我觉得很合理，这么修改以后，整个算法不是「常数时间」了，但是解决了根本问题。</p><h3 id="Non-versioned-Operations"><a href="#Non-versioned-Operations" class="headerlink" title="Non-versioned Operations"></a>Non-versioned Operations</h3><p>上面介绍了正常的 data-modification 版本化语义的操作，这里再来介绍一下 non-version 的操作，这里有下面对应的流：</p><blockquote><ul><li>逻辑上的锁和 SMO 操作，对 Page 的申请/释放等</li><li>对 Catalog、Schema 之类的系统的修改</li><li>对系统启动/关闭之类的 metapage 的修改</li></ul></blockquote><p>这些东西是非版本化的，SQL Server 抽了一条额外的流来优化。</p><h4 id="SLog-A-Secondary-Log-Stream"><a href="#SLog-A-Secondary-Log-Stream" class="headerlink" title="SLog: A Secondary Log Stream"></a>SLog: A Secondary Log Stream</h4><blockquote><p>SLog is a secondary log stream designed to only track nonversioned operations that must be redone or undone using information from the corresponding log records.</p></blockquote><p>本质上又是一个 Log 流存储系统，如下图：</p><p><img src="https://image.mwish.me/blog-image/5B8EE8B5-479B-4F4E-B322-26F2701F2B18.png" alt="5B8EE8B5-479B-4F4E-B322-26F2701F2B18"></p><p>它们会存储到内存中，然后 Batch Flush 下去：</p><blockquote><p>When a checkpoint occurs, all in-memory records with LSN ≤ the Checkpoint Begin LSN get serialized and written into the transaction log.</p></blockquote><p>这个时候可以再度引入变更了的系统：</p><p><img src="https://image.mwish.me/blog-image/8F2FC8D4-E2D1-494C-814E-7DC971EE6C7F.png" alt="8F2FC8D4-E2D1-494C-814E-7DC971EE6C7F"></p><h4 id="Leveraging-System-Transactions"><a href="#Leveraging-System-Transactions" class="headerlink" title="Leveraging System Transactions"></a>Leveraging System Transactions</h4><p>这里还是同样的问题，全丢 SLog 本身太占内存了。这里把 Page 分配/释放丢给了原来的 ARIES 系统来做处理。</p><h3 id="Redo-Locking-Optimization"><a href="#Redo-Locking-Optimization" class="headerlink" title="Redo Locking Optimization"></a>Redo Locking Optimization</h3><p>原先的 SQL Server 为啥要 Lock 呢？因为它希望只对 要 Undo 的地方 Lock。那新的 CTR 协议里， RW 节点的恢复中，我这 SLog 处理完就没事了，那为啥还要 Lock 呢？这里做的非常工程化：如果是分布式的 RO节点，Replay Log，那它也不知道这个事务后来咋样了，所以还是要的。还有一些分布式事务的场景，也是需要 Lock 的。</p><p>这里引入了一些细粒度的锁，让这种场景下事务完成—通知变得高效，同时让这个锁是 Multi-Version 的，不影响一些不阻塞的读。</p><h3 id="Aggressive-Log-Truncation"><a href="#Aggressive-Log-Truncation" class="headerlink" title="Aggressive Log Truncation"></a>Aggressive Log Truncation</h3><p>TBD</p><h3 id="Background-Cleanup"><a href="#Background-Cleanup" class="headerlink" title="Background Cleanup"></a>Background Cleanup</h3><p>TBD</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>perfbook notes: defered processing</title>
      <link href="/2022/05/24/perfbook-notes-defered-processing/"/>
      <url>/2022/05/24/perfbook-notes-defered-processing/</url>
      
        <content type="html"><![CDATA[<h2 id="Data-ownership"><a href="#Data-ownership" class="headerlink" title="Data ownership"></a>Data ownership</h2><p>一种避免 Locking 开销的方式是，让数据属于某个 CPU/Thread，回到并行设计的策略，你会发现这个是完美贴合的：</p><blockquote><p>Interestingly enough, data ownership covers each of the “big three” parallel design techniques: It partitions over threads (or CPUs, as the case may be), it <strong>batches</strong> all local operations, and its elimination of synchronization operations is weakening carried to its logical extreme.</p></blockquote><p>这里有几种方式来做这些操作：</p><ol><li>data 全是线程自身的，不需要同步方案</li><li>Data 来自一个共享区域，但是每个线程 manage 其中的一部分（想象一个固定 slot 的 bucket）</li><li>function shipping，用一些方式来访问别的地方 own 的数据</li><li>Designated Thread，特定的线程访问这些数据</li></ol><p>关于 (1) 我们可以回顾 Counter 的方案，counter 数据是线程/CPU 自身的。只能自己单线程添加，但别的线程可以去 read。在 Linux Kernel 中，也有这种情况：某个 CPU A 在 <strong>interrupt disabled</strong> 的情况下，可以读取一些自己的变量；别的 CPU B 在拿到了这个 CPU A 的 per-CPU 锁的时候，才能读 CPU A 的这些变量；而 CPU A 在更新的情况下，需要 <strong>interrupt disabled</strong> + CPU A 的 Per-CPU lock。Per-CPU 的 memory allocator 也是一个很好的例子。</p><p>function shipping 类似 counter 那节的信号 counter。通过一些通信的方式，来获取（拿走）别的线程的数据，这通常可以引入一些 concurrent queue 或者 message queue 一类的东西。这里还会涉及到一个「哪些线程管自己的数据」这种问题。其实这个可以参考线程池之类的，走 queue 分配，tokio 应该有不错的博客描述它们的方案。</p><p>还有一种方式是 Designated Thread，即一个/多个特定的线程访问特定的数据。这个可以参考 <code>eventually</code>，最终一致性的 counter，即有一个 <code>eventual</code> 线程扫所有线程的 counter，把他们移动到 <code>global</code>。这个就用一个特定的线程来并发。这个思路在非 counter 也很常见，比如 <code>rpc</code> 可能会有特定的线程来扫数据，处理回调。</p><p>有一种提升并发的方式，就是将共享的并发同步点，变成私有的数据。</p><blockquote><p>Data ownership is perhaps the most underappreciated synchronization mechanism in existence. When used properly, it delivers unrivaled simplicity, performance, and scalability. Perhaps its simplicity costs it the respect that it deserves. Hopefully a greater appreciation for the subtlety and power of data ownership will lead to greater level of respect, to say nothing of leading to greater performance and scalability coupled with reduced complexity.</p></blockquote><h2 id="Deferred-Processing"><a href="#Deferred-Processing" class="headerlink" title="Deferred Processing"></a>Deferred Processing</h2><p>对于并行系统来说，deferred processing 能减弱对同步原语的需求，并大大提升性能。这里会介绍：</p><ol><li>Reference counting</li><li>hazard pointers</li><li>sequence locking</li><li>RCU</li></ol><p>这里举了一个 Practical 的例子：</p><p><img src="https://image.mwish.me/blog-image/04885DC0-FF37-4AD8-9792-56E7FBFF6494.png" alt="04885DC0-FF37-4AD8-9792-56E7FBFF6494"></p><p>这里提供的是一个链表，链表有 lookup, add, del 的需求，单线程代码如下：<a href="https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/defer/route_seq.c">https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/defer/route_seq.c</a></p><p>显然，网络栈相关的代码是不太会单线程的，所以需要并行方式来处理。</p><h3 id="Reference-Counting"><a href="#Reference-Counting" class="headerlink" title="Reference Counting"></a>Reference Counting</h3><p>rc 作为一个常见方案是很常用的。<code>Arc</code> 和 <code>shared_ptr</code> 都是一种并发的 RC，关于它们的语义，boost 有很精彩的介绍：<a href="https://www.boost.org/doc/libs/1_63_0/doc/html/atomic.html">https://www.boost.org/doc/libs/1_63_0/doc/html/atomic.html</a> . 据传，RC 可以追溯到上世纪四五十年代里面计算机硬件管理的流程上，要用的地方贴个条，没条了才能关。</p><p>perfbook 给了一个不是很完善的实现：<a href="https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/defer/route_refcnt.c">https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/defer/route_refcnt.c</a> </p><p>RC 会需要对一个 atomic 的计数器，通过 faa 来增加/减少 counter。我们之前讲到 faa 的限制，实际上可以参考下图：</p><p><img src="https://image.mwish.me/blog-image/77841631-8B37-407F-8529-CF2704D4D054.png" alt="77841631-8B37-407F-8529-CF2704D4D054"></p><p>这里 ref-cnt 随着 CPU/Thread 增多，不太是 scalable 的。</p><p>Ref-cnt 还有个问题，就是说，我们假设有一块 RC 的内存，那这个 <code>count</code> 本身和 <code>data</code> 放在一起的话，可能是不合适的，所以一般实现上，控制块和数据块可能是分开的。这点也启发了后续的一些内容。</p><h3 id="Hazard-Pointer"><a href="#Hazard-Pointer" class="headerlink" title="Hazard Pointer"></a>Hazard Pointer</h3><p>hzdptr 思路和 ref-cnt 有点类似，不过：</p><blockquote><p>Rather than incrementing an integer stored in the data element, instead store a pointer to that data element in per-CPU (or per-thread) lists. Each element of these lists is called a hazard pointer [Mic04].</p></blockquote><p>这里 hazard pointer 遵守规则：</p><ol><li>如果被 free 了，后续再也不会增加这个被 free 的线程的读者</li><li>不维护计数，而是每个线程维护一个 hazptr 列表（实际上就类似计数）。某个元素的引用计数 等于 所有线程的列表中，指向这块内存地址中 hazptr 的总量。</li><li>Batch 访问，来减轻计算 (2) 中引用计数的开销。</li></ol><p>下面是使用的时候：</p><ol><li>Hazptr 在访问的时候，都要记录到本线程的 hazptr 列表中，这里会调用 API <code>hp_record</code> 或者 <code>hp_try_record</code> 来注册。它会注册到本线程的列表中。在访问的时候，这里抽出了一个 grace 值，<code>HAZPTR_POISON</code> ，实现为 <code>0x8</code>，这个值用来表示 hazptr 的特殊值。当写入或者删除的时候，需要靠这个值表示「被删掉了」或者「状态未决」。</li><li>在摘除的时候，不会直接 free 内存，而会走 <code>hazptr_free_later</code>，注册到一个 free 列表中。<code>hazptr_free_later</code> 同时有一个计数器，如果里面元素过多的话，会触发 <code>hazptr_scan</code>，做真正的删除（这里体现了 Batch 操作）</li><li><code>hazptr_scan</code> 会把全局的引用列表扫出来，然后和本线程的 free 列表对比，看看有没有被引用的，没有被 hazptr 引用就可以 gc 掉了。注意：free 列表中的对象在被 free 之后就不再会被引用，而且至多被 free 一次。</li></ol><p>上述就是风险指针的流程，具体的实现会复杂很多，主要是有很多并发的小 corner case 要处理。</p><p>hazptr 代码可以参考：</p><ol><li>Folly: <a href="https://github.com/facebook/folly/blob/main/folly/synchronization/Hazptr.h">https://github.com/facebook/folly/blob/main/folly/synchronization/Hazptr.h</a></li><li>perfbook: <a href="https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/defer/hazptr.h">https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/defer/hazptr.h</a> 和 <a href="https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/defer/hazptr.c">https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/defer/hazptr.c</a></li></ol><p>对上述这些 api 的使用，可以参考 perfbook 的例子：<a href="https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/defer/route_hazptr.c">https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/defer/route_hazptr.c</a> 。这里注意到，由于 <code>hazptr</code> 列表可能被修改，一旦遇上了 <code>HAZPTR_POISON</code>，这里就会重试。不过这也不是必须的，这里提到：</p><blockquote><p>In certain cases, restart can be avoided by using link counting as exempliﬁed by the UnboundedQueue and  ConcurrentHashMap data structures implemented in Folly open-source library.</p></blockquote><p>下面是性能相关：</p><p><img src="https://image.mwish.me/blog-image/3BCAF617-31BD-4713-A98F-D44F3F23915C.png" alt="3BCAF617-31BD-4713-A98F-D44F3F23915C"></p><p>可以看到，由于利用了 Batching，hazptr 相对来说性能提升不少。</p><h3 id="Sequence-Locks"><a href="#Sequence-Locks" class="headerlink" title="Sequence Locks"></a>Sequence Locks</h3><blockquote><p>Sequence locks are used in the Linux kernel for readmostly data that must be seen in a consistent state by readers. However, unlike reader-writer locking, readers do not exclude writers. Instead, like hazard pointers, sequence locks force readers to retry an operation if they detect activity from a concurrent writer.</p></blockquote><p>这个方式可以理解为有点类似在数据库 OCC Validation 中做的那样。它需要在数据上有一个对应的 seq，这里会允许多读者、单写者，并且读者如果是需要重试的，这个其实也可以对比 OCC。结论就是，和 OCC 类似，没有更新的时候，性能会非常好。</p><p>perfbook 上的 seqlock 有点邪门，它不关心「有没有读到一个一致的快照」，它在开始更新的时候会把 <code>seq</code> 设置为奇数，然后更新完成会设置为偶数。</p><p>对于读写，这里接口有：</p><ol><li><code>read_seqbegin</code> 和 <code>read_seqretry</code></li><li><code>write_seqlock</code> 和 <code>write_sequnlock</code></li></ol><p><img src="https://image.mwish.me/blog-image/C0251FC1-7B61-440C-B9D8-F10E8A8B3DD2.png" alt="C0251FC1-7B61-440C-B9D8-F10E8A8B3DD2"></p><p>这个实现是非常简单的：<a href="https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/defer/seqlock.h">https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/defer/seqlock.h</a> 。它提供了一种不阻塞，而是重试读的「乐观读写锁」。</p><p>当然，用我们之前 Lock 的视角分析，这个方案需要更精细的设计，因为这里读可能会被不停的写入饿死，正如系统描述的：</p><blockquote><p>Both the read-side and write-side critical sections of a sequence lock can be thought of as transactions, and sequence locking therefore can be thought of as a limited form of transactional memory, which will be discussed in Section 17.2. The limitations of sequence locking are: (1) Sequence locking restricts updates and (2) sequence locking does not permit traversal of pointers to objects that might be freed by updaters. These limitations are of course overcome by transactional memory, but can also be overcome by combining other synchronization primitives with sequence locking.</p></blockquote><p>不过，它的好处是，没有写入者的时候，系统是 scalable 的。</p><p><img src="https://image.mwish.me/blog-image/B8059A1F-F9F4-4BAD-B5CA-8BB637F88D5F.png" alt="B8059A1F-F9F4-4BAD-B5CA-8BB637F88D5F"></p><h3 id="RCU"><a href="#RCU" class="headerlink" title="RCU"></a>RCU</h3><p>Perfbook 的作者是 RCU 的提出者，所以他花了比上面内容合起来嗨唱的篇幅来介绍 RCU 技术。当然，这也是值得的。RCU 实际上是有很多变体的，包括 Double Buffer 这种。</p><p>对于 RC，它把 faa 的巨大开销丢给了读者，让读者不 scalable；hazptr 减小了同步开销，但是线程需要记录相关的 ptr，读内存需要有 <code>WRITE_ONCE</code> 之类的接口来写入，这也可能有一定开销；seqlock 避免了读相关的 contention，但是写非常拉胯。需要注意的是，它们可以视为「在同一块内存空间上的并发」。这些接口在读的时候，也需要引入 <code>memory barrier</code>，来做同步。</p><p>RCU(read-copy update) 提供了 API，允许通过增大更新代价，来让读可扩展。书后面介绍了经典的 RCU、基本的 RCU 概念、内核 Linux API、RCU 的用处。</p><h4 id="从一个指针开始的-RCU-Introduction"><a href="#从一个指针开始的-RCU-Introduction" class="headerlink" title="从一个指针开始的 RCU Introduction"></a>从一个指针开始的 RCU Introduction</h4><p><img src="https://image.mwish.me/blog-image/963AF616-C2C7-4FB2-A67F-85CC643E5DBE.png" alt="963AF616-C2C7-4FB2-A67F-85CC643E5DBE"></p><p>这里的模型是一个指向结构体的指针，然后实现 Insert 和 Delete。</p><p>Insert 相对于用 <code>atomic</code> 接口读写指针没啥区别，Figure 9.6 则是正常的 <code>std::atomic</code> 指针那套（这里用的是内核的各种接口，不过意思懂就行）。</p><p>Delete 就有区别了！区别在于，<code>gptr</code> 设置是很方便的，但之前可能有读者在读，所以这里涉及一个 GC 的过程。这里要「等待之前读者（pre-existing readers）完成，然后再 <code>free</code>」</p><p><img src="https://image.mwish.me/blog-image/BB98CABE-1A28-4403-BFAD-196E131C327B.png" alt="BB98CABE-1A28-4403-BFAD-196E131C327B"></p><p>这里有个问题：如何「等待之前读者完成」？</p><ol><li>首先想到的是 RC，不过我们之前介绍过了 RC 的缺点，hazptr 也有一定开销</li><li>memory synchronization 比较昂贵，通常会引入 mb，所以用 register，比如查看别的线程的 PC。这种方法就太 hacking 了</li><li>等待固定长度的时间，等到理论上没有 reader 了。这个在实时系统可能有用，但是太 hacking 了</li><li>不释放了，leaking memory! 给我摆！这可以由 GC 来各种处理。</li><li>停止程序，直到 pre-existing readers 完成…这不是回来了吗？答案是，这里相对 RC 那种读者 GC，这里需要 变更值 + 同步 + 写者 GC。当所有线程完成时，RCU 完成了 <em>grace period</em>，可以 GC 了。</li></ol><p>方案 (5) 和内核正好有一些地方匹配，还记得 <code>spin_lock</code> 可能会关中断吗：</p><blockquote><p>The spinning threads will not relinquish their CPUs until they acquire the lock, but the thread holding the lock cannot possibly release it until one of the spinning threads relinquishes a CPU. This is a classic deadlock situation, and this deadlock is avoided by forbidding blocking while holding a spinlock.</p></blockquote><p>这样系统就会类似一个非抢占的系统，那么，主线程要做什么呢？答案是 <code>context swtich</code> 到每个线程上，这样就能保证它们完成了，如图：</p><p><img src="https://image.mwish.me/blog-image/6566C47B-B026-4AD8-823F-CA68D6695468.png" alt="6566C47B-B026-4AD8-823F-CA68D6695468"></p><blockquote><p>This approach is termed quiescent state based reclamation (QSBR) [HMB06].</p></blockquote><p>所以，最简单的实现是，进 RCU 读区域关中断，删除的时候，需要 <code>synchronize_rcu()</code>，来 context switch 到每个 CPU 上，保证度过临界区。</p><p>那么，在这里，RCU 特点是，读可扩展，不用鸟写者。接口类似：</p><ol><li><code>rcu_read_lock</code> 和 <code>rcd_read_unlock</code>，在我们上面例子是开关中断</li><li><code>synchronize_rcu</code>, 保证所有读者完成，在我们上面例子是调度</li><li><code>rcu_ assign_pointer()</code> and <code>rcu_dereference()</code>, 发布指针。</li></ol><h4 id="RCU-Fundamentals"><a href="#RCU-Fundamentals" class="headerlink" title="RCU Fundamentals"></a>RCU Fundamentals</h4><p>这里是 RCU 需要依赖的基础：</p><ol><li>插入：publish-subscribe mechanism</li><li>删除和内存回收：waiting for pre-existing RCU readers enabled deletion</li><li>并发更新：maintaining multiple versions of recently updated objects</li></ol><h5 id="Publish-Subscribe-Mechanism"><a href="#Publish-Subscribe-Mechanism" class="headerlink" title="Publish-Subscribe Mechanism"></a>Publish-Subscribe Mechanism</h5><p>我们之前靠 atomic 更新指针来发布，实际上 RCU 需要这种机制，来保证「旧的版本不再被读到」。</p><p><img src="https://image.mwish.me/blog-image/41DE6CA6-1269-4D58-A3A3-A8F59D013650.png" alt="41DE6CA6-1269-4D58-A3A3-A8F59D013650"></p><p>这里需要保证：</p><ol><li>pointer 的 pusblish，即 <code>rcu_assign_pointer</code> 是原子的</li><li>pointer 的 deref ，即 subscribe 是原子的，表现为<code>rcu_dereference</code></li></ol><p>这里可以视作是一组发布-订阅的 api。</p><h5 id="Wait-For-Pre-Existing-RCU-Readers"><a href="#Wait-For-Pre-Existing-RCU-Readers" class="headerlink" title="Wait For Pre-Existing RCU Readers"></a>Wait For Pre-Existing RCU Readers</h5><p>RCU 读区域被称为 RCU read-side critical section，由 <code>rcu_read_lock</code> 和 <code>rcu_read_unlock</code>:</p><p><img src="https://image.mwish.me/blog-image/48ABD729-5EBE-4CD4-A71C-AEF661EF9CF5.png" alt="48ABD729-5EBE-4CD4-A71C-AEF661EF9CF5"></p><p><code>synchronize_rcu</code> 会在发布之后，等待之前的读者完成。这里我们聊到了 context switch。而 <code>DoublyBuffer</code> 可能会用 lock 和 cv 来做，语义上是差不多的。</p><h5 id="Maintain-Multiple-Versions-of-Recently-Updated-Objects"><a href="#Maintain-Multiple-Versions-of-Recently-Updated-Objects" class="headerlink" title="Maintain Multiple Versions of Recently Updated Objects"></a>Maintain Multiple Versions of Recently Updated Objects</h5><p>这里之前举的例子都是单个值的例子，实际上，并发的写也是可行的，只要能维护多个版本。</p><p>当然，这里可能要和别的方法结合，如图 9.15，这里 RCU 不会保证「读到一致性快照」：</p><p><img src="https://image.mwish.me/blog-image/C2794F61-0FD2-4975-953C-152CEEDD10F3.png" alt="C2794F61-0FD2-4975-953C-152CEEDD10F3"></p><p>当然，很多 RCU 使用的情况是 point get，在 point get 下，这种情况通常是可以容忍的，如文章所述：</p><blockquote><p>In summary, maintaining multiple versions is exactly what enables the extremely low overheads of RCU readers, and as noted earlier, many algorithms are unfazed by multiple versions. However, there are algorithms that absolutely cannot handle multiple versions. There are techniques for adapting such algorithms to RCU [McK04], but these are beyond the scope of this section.</p></blockquote><h4 id="Kernel-的-RCU-API"><a href="#Kernel-的-RCU-API" class="headerlink" title="Kernel 的 RCU API"></a>Kernel 的 RCU API</h4><p>Linux 并不是有一个 RCU API，而是有一组…Paul 在 LWN 写过：<a href="https://lwn.net/Articles/777036/">https://lwn.net/Articles/777036/</a></p><p>这里还提供了 callback 和 barrier 相关的内容，如：</p><blockquote><p>The asynchronous update-side primitive, call_rcu(), invokes a speciﬁed function with a speciﬁed argument after a subsequent grace period. For example, call_rcu(p,f); will result in the “RCU callback” f(p) being invoked after a subsequent grace period. There are situations, such as when unloading a Linux-kernel module that uses call_rcu(), when it is necessary to wait for all outstanding RCU callbacks to complete [McK07e]. The rcu_barrier() primitive does this job.</p></blockquote><p>除了经典的我们刚才介绍的一些 API，这里还有 <code>srcu</code>, <code>s</code> 即 sleepable，它使用类似 blocking api 来实现 rcu 机制。</p><p>此外，RCU 还有各种 list 有关的 API。</p><h4 id="RCU-Usage"><a href="#RCU-Usage" class="headerlink" title="RCU Usage"></a>RCU Usage</h4><p><a href="https://lwn.net/Articles/263130/">https://lwn.net/Articles/263130/</a> 这里小标题特别好：</p><ol><li><a href="https://lwn.net/Articles/263130/#RCU is a Reader-Writer Lock Replacement">RCU is a Reader-Writer Lock Replacement</a></li><li><a href="https://lwn.net/Articles/263130/#RCU is a Restricted Reference-Counting Mechanism">RCU is a Restricted Reference-Counting Mechanism</a></li><li><a href="https://lwn.net/Articles/263130/#RCU is a Bulk Reference-Counting Mechanism">RCU is a Bulk Reference-Counting Mechanism</a></li><li><a href="https://lwn.net/Articles/263130/#RCU is a Poor Man&#39;s Garbage Collector">RCU is a Poor Man’s Garbage Collector</a></li><li><a href="https://lwn.net/Articles/263130/#RCU is a Way of Providing Existence Guarantees">RCU is a Way of Providing Existence Guarantees</a></li><li><a href="https://lwn.net/Articles/263130/#RCU is a Way of Waiting for Things to Finish">RCU is a Way of Waiting for Things to Finish</a></li></ol><p>还有各种 performance 图，直接看就是了。</p><h3 id="Which-to-Choose"><a href="#Which-to-Choose" class="headerlink" title="Which to Choose?"></a>Which to Choose?</h3><p><img src="https://image.mwish.me/blog-image/6567DA82-6B70-40C4-AF96-3ED5E95BBC77.png" alt="6567DA82-6B70-40C4-AF96-3ED5E95BBC77"></p><p>在 folly 的 hazptr 也写了一下这些具体的区别：<a href="https://github.com/facebook/folly/blob/main/folly/synchronization/Hazptr.h">https://github.com/facebook/folly/blob/main/folly/synchronization/Hazptr.h</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>perfbook notes: parallel, mutex, fastpath</title>
      <link href="/2022/05/04/perfbook-notes-parallel-mutex-fastpath/"/>
      <url>/2022/05/04/perfbook-notes-parallel-mutex-fastpath/</url>
      
        <content type="html"><![CDATA[<p>在介绍完硬件后，perfbook 用 scalable-counter 为例子，介绍了并发数据结构的设计。这里面有一些大概的要点：</p><ol><li>Partition<ol><li>根据 Core 或者线程来 Partition。比如 counter、allocator。<code>malloc()</code> 和 <code>inc()</code> 可能不指定具体的 key，因此这个资源可以池化，绑定在 CPU、Thread 之类的对象上</li><li>根据 key 来 partition。<code>get(key)</code> 本身可以做一些 Partition，来保证粒度</li></ol></li><li>Fastpath、Slowpath 和开销<ol><li>理想情况下，所有操作开销都很低，但是不可能，所以要有个 trade-off</li><li>「开销」可以根据操作的粒度来权衡，不能说「锁操作很重」「atomic 很轻」就行，而要对比临界区、执行 Path 的内容和执行时间，来考量这个开销是不是过大。</li><li>可以区分 Fastpath 和 Slowpath，很少情况执行</li></ol></li><li>Batching<ol><li>将操作批量处理</li></ol></li></ol><p>这里先用 <code>counting</code> 做了一个入门介绍，然后引入了 Paritition/Synchronize Design，最后介绍了一些 Locking 和 Locking 相关的设计。</p><h2 id="Counting"><a href="#Counting" class="headerlink" title="Counting"></a>Counting</h2><p>Scalable Counting 是一个比较开放的问题，这里列举了下面的需求：</p><ol><li>Statistics</li><li>Approximate limit / Exact limit</li><li>Ref-count</li></ol><p>最朴素的思路当然是 <code>std::atomic&lt;uint64_t&gt;</code> 一把梭。但是它不是 scalable 的，回顾一下我们上一节描述的，可能它要保证操作的时候，数据由你的 Cacheline 保护：</p><p><img src="https://image.mwish.me/blog-image/28AFE9DD-5AFE-4E26-B965-00AEEE83CF9E.png" alt="28AFE9DD-5AFE-4E26-B965-00AEEE83CF9E"></p><p><img src="https://image.mwish.me/blog-image/1D331DF5-8280-4232-A5B6-EAF9995CCB4F.png" alt="1D331DF5-8280-4232-A5B6-EAF9995CCB4F"></p><p>这里就有个严肃的同步问题。而且可能是跨 socket 的。当然可以保证这里的统计信息是准的。这里下面有几种 counter :</p><ol><li>statistical counter: 统计，计算总和，很可能不准，但非常高效</li><li>Approximate Limit Counters: 少许超过 limit 限制也可以</li><li>Exact Limit Counters: 不允许超过限制</li></ol><p>这里程序用了 Per-CPU，这个在内核其实不难做，在用户态的话，可以参考 <code>TCMalloc</code> 用的 <code>rseq(2)</code>：</p><ol><li><a href="https://www.efficios.com/blog/2019/02/08/linux-restartable-sequences/">https://www.efficios.com/blog/2019/02/08/linux-restartable-sequences/</a></li><li><a href="https://google.github.io/tcmalloc/rseq.html">https://google.github.io/tcmalloc/rseq.html</a></li></ol><p>相对于 Per-CPU，一些地方会使用 Per-Thread 的程序。perfbook 介绍了为什么没有提供 Per-Thread 设施：</p><blockquote><p>A key limitation that the Linux kernel imposes is a compile-time maximum bound on the number of CPUs, namely, <code>CONFIG_NR_CPUS</code>, along with a typically tighter boot-time bound of <code>nr_cpu_ids</code>. In contrast, in user space, there is not necessarily a hard-coded upper limit on the number of threads.</p></blockquote><p>一般的用户程序可能会用 Doubly List 来挂一些统计信息。</p><h3 id="statistical-counter"><a href="#statistical-counter" class="headerlink" title="statistical counter"></a>statistical counter</h3><p>一种方式是，用 Per-CPU 或者<strong>固定</strong>大小的 Array，然后每个线程/CPU 用 <code>WRITE_ONCE</code> 写本地 counter，读的时候读起来所有的 counter。这个地方统计不一定完全准确，因为统计的时候可能 counter 还会增加。这种方法几乎是 Linear scalable 的，但是受限于 <strong>固定大小</strong>。</p><p>Counter 可能可以根据 TLS 来实现。<code>inc</code> 对应的操作应用在 <code>TLS</code> 上，线程销毁的时候，会获取 <code>lock</code>, 然后把操作挂靠在 <code>global_count</code> 上。读取的时候，需要读取 每个线程的 count + <code>global_count</code>。这里具体代码如下：<a href="https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/count/count_tstat.c">https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/count/count_tstat.c</a></p><p>这里有一个小瓶颈在于，读取 <code>global_count</code> 可能需要锁。线程销毁也需要锁，这个是<strong>准确的，但是不 scalable</strong>。这里可以考虑 <strong>Eventual consistency</strong>，达到最终一致性即可：<a href="https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/count/count_stat_eventual.c">https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/count/count_stat_eventual.c</a></p><p>这里引入了一个<strong>额外的线程</strong>来处理数据，读的时候只需要读取 <code>global_count</code>，写也只要直接写，额外的线程会定期把值合并到 <code>global_count</code>.</p><p>这些实现能够牺牲准确性，但是提供近线形的可扩展性。</p><h3 id="Approximate-Limit-Counters"><a href="#Approximate-Limit-Counters" class="headerlink" title="Approximate Limit Counters"></a>Approximate Limit Counters</h3><blockquote><p>Suppose further that these structures are short-lived, that this limit is rarely exceeded, and that this limit is approximate in that it is OK to exceed it sometimes by some bounded amount.</p></blockquote><p>这里会有频繁的 <code>inc(size)</code> 和 <code>dec(size)</code> 操作，希望不要越界过于离谱。</p><p>一个简单的想法是，比如计数是 10000，有 100 个线程，就每个 100 个。但是这对任何有 skew 的 workload 都太垃圾了。这里有一个方法，是上面一个方法的修改版：</p><ol><li>正常分配的时候，每个线程会有一部分剩余的 <code>counter</code> 分配器，它有 <code>countermax</code> 和 <code>counter</code>。正常情况（fast path) 会 <code>++counter</code>，然后保证 <code>counter &lt; countermax</code></li><li>(Slow path): 如果 <code>counter == countermax</code>，那么这里会把 <code>counter</code> 中的一半移动给 <code>globalcount</code>，再回到 (1). 这里还涉及到一个限制，我们会有 <code>globalcountmax</code>, 如果 <code>globalcount</code> 超过了 max，那么计数器就溢出了。</li><li>(slow path): 如果 <code>counter == 0</code>, 且还需要减少，类似 (2)，从 <code>globalcount</code> 来 Steal.</li></ol><p><img src="https://image.mwish.me/blog-image/AE328AD5-DBF0-4D0A-B31A-9FDA957675F4.png" alt="AE328AD5-DBF0-4D0A-B31A-9FDA957675F4"></p><p>具体代码：<a href="https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/count/count_lim_app.c">https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/count/count_lim_app.c</a></p><p>这里在 add, sub 的时候可能会有超限制的情况。导致无法推进。为什么呢？这里可能会有能分配，但是实际上分配不出的情况：</p><p><img src="https://image.mwish.me/blog-image/C3AA88D1-78AC-46A8-BF6C-060C7549F7FC.png" alt="C3AA88D1-78AC-46A8-BF6C-060C7549F7FC"></p><p>这里，<code>0</code> 需要增加，但是可能别的 <code>countermax</code> 还有剩余，但是它申请不出来了。</p><h3 id="Exact-Limit-Counters"><a href="#Exact-Limit-Counters" class="headerlink" title="Exact Limit Counters"></a>Exact Limit Counters</h3><p>如果要能准确分配，这必定涉及 slowpath 下向别的 counter 索要内容。这个就涉及跨线程交互了，这里提供了两种方案。方案1是全部走原子指令：</p><ul><li><a href="https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/count/count_lim_atomic.c">https://github.com/paulmckrcu/perfbook/blob/master/CodeSamples/count/count_lim_atomic.c</a></li></ul><p>这个的 <code>read_count</code> 不一定完全准，但是上线和下界都是准确的，缺点是所有写操作基本都是个 CAS。</p><p>这里还用信号和状态机做了个比较复杂的系统，大概思路是：</p><ol><li>本线程的添加是 <code>WRITE_ONCE</code> 原子即可（类比于 <code>relaxed</code> ）</li><li>Slowpath 需要走 <code>pthread_kill</code>，别的线程收到信号后，会自己提交信息</li><li>因为信号是可重入的，所以需要写一个很复杂的状态机，如下图：</li></ol><p><img src="https://image.mwish.me/blog-image/7C9EAE64-1FBE-4A4C-AEBD-768E34E0E202.png" alt="7C9EAE64-1FBE-4A4C-AEBD-768E34E0E202"></p><h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><p><img src="https://image.mwish.me/blog-image/34EEB050-4CC0-4255-A116-376142A6C045.png" alt="34EEB050-4CC0-4255-A116-376142A6C045"></p><ol><li>Partitioning promotes performance and scalability.</li><li>Partial partitioning, that is, partitioning applied only to common code paths, works almost as well.</li><li>Batch Updates</li><li>Read-only code paths should remain read-only: Spurious synchronization writes to shared memory kill performance and scalability, as seen in the count_end.c row of Table 5.1. （记得我们的 eventual 吗？）</li><li>Parallel performance and scalability is usually a balancing act: Beyond a certain point, optimizing some code paths will degrade others.</li><li>Diﬀerent levels of performance and scalability will aﬀect algorithm and data-structure design, as do a large number of other factors. Figure 5.1 illustrates this point: Atomic increment might be completely acceptable for a two-CPU system, but be completely inadequate for an eight-CPU system.</li></ol><p>后面又总结了三点：</p><p>(1) partitioning over CPUs or threads, (2) batching so that more work can be done by each expensive synchronization operations, and (3) weakening synchronization operations where feasible.</p><h2 id="Partition-and-Synchronization-Design"><a href="#Partition-and-Synchronization-Design" class="headerlink" title="Partition and Synchronization Design"></a>Partition and Synchronization Design</h2><p>这里介绍的是 Partition 相关的设计。介绍了哲学家用餐问题和双端队列。这里有几个要考量的点：</p><ol><li>performance</li><li>scalability</li><li>response time</li></ol><p>对于哲学家进餐问题，很多地方会考虑 Dijkstra 的编号算法。这里有一个问题是这个算法可能有活锁，可能真的没人在推进。一种可靠的方式是固定谁拿什么叉子，直接 scalable 了。</p><p>另一个问题是双端队列。对于 Compound Double-Ended Queue，这里类似 Btree 的 iterator，会规定一个获取锁的方向：</p><p><img src="https://image.mwish.me/blog-image/12F8C1A4-EEE5-44F3-8CE6-993E5F0DA147.png" alt="12F8C1A4-EEE5-44F3-8CE6-993E5F0DA147"></p><p>获取锁的方向都是 左-&gt;右，如果右向左前进，需要先释放自己的锁，拿到左边，再 grab 回来（感觉这还涉及 data-ownership 的问题，哎…）。</p><p>关于这种队列，还有一个最先插入一些元素的问题，也就是队列是空的、只有一个元素的时候应该怎么操作。参考：<a href="https://github.com/paulmckrcu/perfbook/blob/46ff2e75ea1b645dabc7405884ddf666f94b4b07/CodeSamples/SMPdesign/locktdeq.c">https://github.com/paulmckrcu/perfbook/blob/46ff2e75ea1b645dabc7405884ddf666f94b4b07/CodeSamples/SMPdesign/locktdeq.c</a></p><p>这里做的还是比较 hack 的。有一个讨论是关于这个 queue 的语义（如果你写 Rust，其实会见到什么 mpmc 之类的，或者一些 Linearizable 之类的）：</p><blockquote><p>In fact, as noted by Dice et al. [DLM + 10], an unsynchronized single-threaded double-ended queue signiﬁcantly outperforms any of the parallel implementations they studied.</p><p>Furthermore, these strict FIFO queues are strictly FIFO only with respect to linearization points [HW90]  that are not visible to the caller, in fact, in these examples, the linearization points are buried in the lock-based critical sections.</p><p>All that said, if you are pushing all the data used by your concurrent program through a single queue, you really need to rethink your overall design.</p></blockquote><h3 id="Design-Criteria"><a href="#Design-Criteria" class="headerlink" title="Design Criteria"></a>Design Criteria</h3><p>这里考虑的是一些并发的设计原则，其实还是比较重要的。包括临界区大小，对什么上锁之类的。以前我确实只会觉得「xx并发好」「xx有瓶颈」，但是没有比较细的思考这些问题。</p><p>第一个是什么让你竟然需要并发，可能是：</p><ol><li>Speedup (这里考虑阿姆达尔定律)</li><li>Contention: CPU 数量上来之后，会不会有 Lock/Memory 等资源的竞争</li><li>Work-to-Synchronization Ratio: 并发可能有 message latency, locking primitives, atomic instructions, memory barrier 的开销。如果临界区之类的里面的东西比同步开销操作重，那就可以（ for example: <a href="https://github.com/apache/incubator-brpc/issues/363）">https://github.com/apache/incubator-brpc/issues/363）</a></li><li>Read-to-Write Ratio: A data structure that is rarely updated may often be replicated rather than partitioned</li><li>Complexity: 可能并行的程序会复杂很多，其实一个工业界很贴近的例子就是 Redis，可以考虑一下给 Redis 增加并行之后会有什么问题</li></ol><p><img src="https://image.mwish.me/blog-image/824F4B98-460F-4941-8B38-CA14CAA45F52.png" alt="824F4B98-460F-4941-8B38-CA14CAA45F52"></p><h3 id="Synchronization-Granularity"><a href="#Synchronization-Granularity" class="headerlink" title="Synchronization Granularity"></a>Synchronization Granularity</h3><p>如果程序全是串行的，那么卵粒度都没有，不过：</p><p><img src="https://image.mwish.me/blog-image/0A3C39FC-F2C3-40CD-A690-36F9A0F9913E.png" alt="0A3C39FC-F2C3-40CD-A690-36F9A0F9913E"></p><p>（我觉得很反我作为一个 16 年才学计算机的人的直觉就是，不改代码程序竟然会越跑越快…可能这就是摩尔定律吧）</p><p>最常见的方式被这里称为 <strong>Code Locking</strong>，就是我们最常见的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">C::func</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">l</span><span class="params">(mu_)</span></span>;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对整个代码段上锁。</p><p>另一种被称为 <strong>data locking</strong>:</p><blockquote><p>You should use data locking when contention must be reduced, and where synchronization overhead is not limiting speedups.</p></blockquote><p>这里 lock 可能会被绑定在某个 <code>bucket</code> 或者结构上，类似分桶 hashing，或者 Linux 的 <code>dcache</code>，可以当作这里比 code locking 提供了更细的粒度，给某个 <code>key</code> 对应的 <code>bucket</code> 或者更细的粒度提供锁定。</p><p>这里还有个 data ownership 的问题，比方说给某个线程/CPU 划分一些数据。这个的问题是，回忆到 counting，这里要处理 skew、hotspot 和一些必要的跨线程通信的问题。</p><h3 id="Parallel-Fastpath"><a href="#Parallel-Fastpath" class="headerlink" title="Parallel Fastpath"></a>Parallel Fastpath</h3><p>对于并发来说，设计细粒度的并发策略实际上是很难的。一个粗粒度的并发结构会让人想到「一把大锁」，而细粒度的结构则可能从各种 corner case、原语甚至到一些内存回收策略。</p><p>fastpath 思路其实在之前的 counter 系统中就基本提到了，就是在常规路径下开销很小，只有必要的时候引入一些重的开销。下面提到了一些使用 fastpath 的场景：</p><p><img src="https://image.mwish.me/blog-image/E39EA9B2-16C2-4AB7-818F-191C8D87BB12.png" alt="E39EA9B2-16C2-4AB7-818F-191C8D87BB12"></p><ul><li>Read-Write Locking: 当<strong>同步开销很小</strong> （例如同步相对于临界区非常小，这点很重要）的时候，可以引入 reader-write locking。当然，这里没有暗示任何实现（RW Lock 可能会有各种各样的实现）</li><li>Hierarchical Locking: 有一个 粗粒度锁 — 细粒度锁的层次。这里引入了多余的锁，但是减小了一定情况下的冲突。当在细粒度锁上操作其实还比较重的时候，这种方式并行化了它的访问。</li><li>Resource Allocator Caches: 这个 pattern 通常是那种不具名的资源，有一些 per-CPU 的资源，和一些全局的资源。具体可以参考 <code>TCMalloc</code> 、<code>JeMalloc</code> 、<code>MiMalloc</code>甚至 <code>PtMalloc</code>.</li></ul><p>我就不一一举例了，这里还有个 pool:</p><p><img src="https://image.mwish.me/blog-image/1E3AAC09-C5B8-42E7-9BBE-8888FB3DE74E.png" alt="1E3AAC09-C5B8-42E7-9BBE-8888FB3DE74E"></p><p>当然，现实中的池子可能会有各种的 size-class，能够把内存返回给系统（<code>munmap</code> 或者 <code>sbrk</code> 缩小），这里也举了一些实际上并发的例子，他们通常是混合的：</p><p><img src="https://image.mwish.me/blog-image/71BAD532-A9D2-4D47-84B9-A9074CA1C090.png" alt="71BAD532-A9D2-4D47-84B9-A9074CA1C090"></p><h2 id="Locking"><a href="#Locking" class="headerlink" title="Locking"></a>Locking</h2><p>Locking 是最通用的并发同步手段，尽管可能会有下面的问题：</p><blockquote><p>Locking stands accused of inciting deadlocks, convoying, starvation, unfairness, data races, and all manner of other concurrency sins. </p></blockquote><p>这里有一些 pattern:</p><ol><li>使用 lock hierarchy 来做死锁避免</li><li>用工具来检测死锁</li><li>用一些对 locking 的模式很友好的数据结构</li><li>使用一些上面介绍的 partition 来减少 lock contention</li><li>和别的工具协调，只在 slowpath 等地方使用 lock 甚至避免 lock</li><li>好好地 bench lock 是不是真有问题，会不会影响你（有一些测 contention 的工具什么的）</li></ol><h3 id="死锁避免和-Lock-Hierarchy"><a href="#死锁避免和-Lock-Hierarchy" class="headerlink" title="死锁避免和 Lock Hierarchy"></a>死锁避免和 Lock Hierarchy</h3><p>死锁和活锁一直是比较让人头疼的问题，尤其是，如果你跑在一个 stackless coroutine 上，那你 debug 都会要靠一些 user-space 的 locking，把人整吐。</p><p>Locking Hierarchies 描述的是锁的层级、获取锁的顺序。比如先拿大锁 -&gt; 拿细锁 -&gt; 放大锁，如果细锁要 grab 大锁估计要涉及一些协议，比如先把自己放了，然后获取下来再查查自己有没有被改。</p><p>这里作者引入了一些问题（在 7.1.1），即，library function 和 lock 应该怎么适配，比如你编写了一个并行算法代码，然后把它们中的内容丢到了库里，然后库没有按照你的 hierachy 锁，而是 xjb 乱锁，这就造成了死锁问题（不过笔者认为，现实场景应该很少会这样把带锁内容丢进库？作者也认为应该在这种函数之前释放锁）。作者为了讨论这个引入了 <strong>Local Locking Hierarchies</strong> 和 <strong>Layered Locking Hierarchies</strong>：</p><p><img src="https://image.mwish.me/blog-image/9B314C2B-1C22-4762-B899-E8B620EDC014.png" alt="9B314C2B-1C22-4762-B899-E8B620EDC014"></p><p>对于 Local Locking Hierarchy, 要获得下一个锁之前，都释放掉未知的锁，那么我们就不会有这种问题了。当然，这表示最多持有 1把锁，可能和层次目标比起来怪怪的。</p><p>Layered Locking Hierarchy 在库这里也引入了获取锁的层次，来达成目标：</p><p><img src="https://image.mwish.me/blog-image/291A6825-116C-48B6-8507-E0D42EC990DD.png" alt="291A6825-116C-48B6-8507-E0D42EC990DD"></p><p>以上描述的都是在层次逻辑上「可以避免死锁」的方案，就是程序本来不应该有冲突，可以让他们没有。但是有的时候，程序就正经就该有冲突，比如：</p><ol><li>并发 BTree 有一个左向右的迭代器，有一个右向左的迭代器</li><li>不同层次的系统（比如网络协议栈）里面有一个下降的，有一个上升的</li></ol><p>这里可以引入 <strong>conditional locking</strong>，来让某个方向的 locking 做试探性的上锁，正如：</p><blockquote><p>One way to avoid deadlocks in this case is to impose a locking hierarchy, but when it is necessary to acquire a lock out of order, acquire it conditionally</p></blockquote><p>相对于上面的锁定方案，还有一种粗暴但有效的方案：Acquire Needed Locks First。这就在处理前都悲观的都嗯锁上，类似 2PL，或者 TiDB 的悲观锁模型。这种方式可能会带来活锁的问题，这些系统需要很强的能力来处理 Transaction abort，能够 abort/回滚掉事务。</p><p>最后一种方案比较 hacking，就是类似 local locking hierarchy，一个时间同一个地方只持有一把锁。感觉这个需要把并发设计的非常细心。</p><p>最后，这里讨论了一下 <code>lock</code>/<code>unlock</code> 和 <code>signal</code> 配合的语义，这可能会让系统变得非常复杂（信号可重入感觉是个非常蛋疼的问题）。</p><p>此外，还有 livelock 相关的问题，也会导致 starvation：长时间内米有一个 worker 在正常工作。这可能可以引入一个发现这些问题的 <strong>contention manger</strong>，然后引入一些 <code>backoff</code> 策略，比如指数退避。有一种大力出奇迹的方案，就是设置一个退避次数，乐观这样重试，不行就上个全局锁，悲观执行。</p><p>还有一些奇怪的 unfairness 问题，比如某个 core 或者什么会不会比别的 core 更容易拿到锁；同时，锁也会有比较重的 cache miss，我们可以看看之前的 <code>Hardware</code> 那节的情况。最简单的 <code>spinlock</code> 都每次会走一个 <code>acq</code> 的 CAS，这个也看同步和执行之间的开销对比来决定了。</p><h3 id="Types-of-Locks"><a href="#Types-of-Locks" class="headerlink" title="Types of Locks"></a>Types of Locks</h3><p>锁定通常通过 <code>atomic</code> (用户态不推荐 spinlock )、<code>futex</code> 加上一些用户态的 flag 实现。这里可能不会直接用 pthread 的工具，比如数据库的 Page。</p><p>用户态实现一般基于 <code>futex</code>，有的地方会引入一些花活，比如 <code>MCS Lock</code> ，或者 <code>WTF::ParkingLot</code> 这种并发设施。但不管基于什么，这里有一些共性的问题需要讨论。包括锁的互斥、读写和它们的语义。</p><h4 id="Exclusive-Lock"><a href="#Exclusive-Lock" class="headerlink" title="Exclusive Lock"></a>Exclusive Lock</h4><p>经典的锁，这里语义可能有：</p><ol><li>Strict FIFO</li><li>Approximate FIFO</li><li>FIFO within priority level</li><li>Random</li><li>Unfair</li></ol><p>不同的锁可以有不同的策略，越上面的，保证越强、代价越高。</p><h4 id="Reader-Writer-Lock"><a href="#Reader-Writer-Lock" class="headerlink" title="Reader-Writer Lock"></a>Reader-Writer Lock</h4><p>我们经常被介绍说读写锁会引入巨大开销，这是因为读写锁实现的时候可能要引入额外的逻辑甚至额外的锁，这些信息甚至锁的维护开销是比较大的。</p><blockquote><p>The classic reader-writer lock implementation involves a set of counters and ﬂags that are manipulated atomically. This type of implementation suﬀers from the same problem as does exclusive locking for short critical sections: The overhead of acquiring and releasing the lock is about two orders of magnitude greater than the overhead of a simple instruction.</p><p>Of course, if the critical section is long enough, the overhead of acquiring and releasing the lock becomes negligible. However, because only one thread at a time can be manipulating the lock, the required critical-section size increases with the number of CPUs.</p><p>The canonical use case for readerwriter locking involves very long read-side critical sections, preferably measured in hundreds of microseconds or even milliseconds.</p></blockquote><p>Brpc 也是因为这个原因，不太在库里写 bthread 的 rwlock。</p><p>Rw lock 可能有不同的语义和不同的实现，然后通用实现几乎都不那么令人满意，所以需要根据自己的需求来定制：</p><ol><li>读者优先的实现，可能会永久饿死某个 writer</li><li>Batch-fair 的实现，读者和写者都会互相 Batch 的来访问</li><li>写者优先的实现</li></ol><h4 id="更细的锁语义"><a href="#更细的锁语义" class="headerlink" title="更细的锁语义"></a>更细的锁语义</h4><p><img src="https://image.mwish.me/blog-image/465B1D27890482CA56D68CE6529B4E3D.png" alt="465B1D27890482CA56D68CE6529B4E3D"></p><p>作者这里举例了 VAX/VMS DLM。笔者作为 DB RD，觉得这里其实可以参考 Btree 各种 Latch 协议，比如 SX Latch 什么的。笔者认为，这里关键点是：</p><ol><li>知道什么可以和什么并发，画出并发的图</li><li>弄清楚这样开销是否合适，类似 RW-Latch 那个问题，它的开销比通常的互斥锁高了几倍。这是值得的吗？</li></ol><h3 id="锁的实现"><a href="#锁的实现" class="headerlink" title="锁的实现"></a>锁的实现</h3><p>这部分可以看看我爹 rsygg（征婚中）写的： <a href="https://github.com/rsy56640/triviality/tree/master/content/%E8%B0%88%E8%B0%88%E5%B9%B6%E5%8F%91#mutex">https://github.com/rsy56640/triviality/tree/master/content/%E8%B0%88%E8%B0%88%E5%B9%B6%E5%8F%91#mutex</a> 或者 futex is trickey</p><p>不过这部分其实更多介绍的是用户层次的锁实现，偏向策略而非机制。</p><p>Atomic + CAS 自然可以实现锁，在 low contention 的时候甚至可以工作的很好、也有很小的 meory footprint，但是在高占用的情况下可能就炸了。</p><p>ticket lock 实现了 strict FIFO 的语义，它的活跃度可能值得商榷。而解锁中，为了不一次通知所有的等待者，则需要引入一些 queue （想象 futex 的语义），这样它只需要通知该唤醒的线程。不过这些策略会导致在 low-contention 的情况下，增大锁相关的开销。</p><p>此外，这里还有优先级反转的问题，占锁的线程如果是个低优先级的线程的话，这里就会有奇怪的问题，比如它被调度走整个系统就没人工作了。这里有两种方案：占锁了就不能被调度走；使用优先级反转。</p><p>这里作者还提到了不用原子指令实现 lock 的方案，我只能说真的牛逼。</p><p>最后：</p><blockquote><p>The Linux kernel now uses queued spinlocks [Cor14b], but because of the complexity of implementations that provide good performance across the range of contention levels, the path has not always been smooth [Mar18, Dea18].</p><p>Nevertheless, you should carefully consider this important safety tip: Use the standard synchronization primitives whenever humanly possible. The big advantage of the standard synchronization primitives over roll-your-own eﬀorts is that the standard primitives are typically much less bug-prone.8</p></blockquote><h3 id="Lock-Based-Existence-Guarantees"><a href="#Lock-Based-Existence-Guarantees" class="headerlink" title="Lock-Based Existence Guarantees"></a>Lock-Based Existence Guarantees</h3><p>Existence 比较奇怪，不过这里讨论的内容挺正经的：</p><ol><li>Global/Static local variable 的 existance</li><li>Global/Static local variable 的加载</li><li>Heap 上变量的存在性，比方说给数据库 <code>LockManager</code> 的一个请求，会被放到队列里，等待通知。这个被通知完之后，可能被回收</li></ol><p>这里可以：</p><ul><li>把 Lock 或者一个标志和对象抽开，然后用这个对象来识别</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>perfbook notes: Hardware</title>
      <link href="/2022/05/04/perfbook-notes-hardware/"/>
      <url>/2022/05/04/perfbook-notes-hardware/</url>
      
        <content type="html"><![CDATA[<p>Perfbook 全称是 <em>Is Parallel Programming Hard, And, If So, What Can You Do About It?</em> 作者是 Paul E. McKenney，也是 RCU 的发明者。这本书相对来说语法有点点难，我个人看的有那么点小吃力，但是作者能够非常形象的描述并发数据结构是怎么设计的，并且从 scalable-counter、partition、lock、data-ownership 介绍到 RCU。书具体内容很好，也值得我做一些笔记以便未来回顾。</p><p>书的编写会包括一些 Quiz，有的还是比较有难度的，帮助自己理解问题。我的笔记只供自己做一个回顾和一些工业界实现的参考，所以不会完全参考原书的布局。</p><p>Chap2-4 描述了一些 smp 的原语和性能</p><h2 id="并行编程的需求、基本性能与原语"><a href="#并行编程的需求、基本性能与原语" class="headerlink" title="并行编程的需求、基本性能与原语"></a>并行编程的需求、基本性能与原语</h2><p>并行编程在上世纪是个非常小众的领域，只有专业人士会写。但是随着 CPU 撞上功耗墙，这一小众领域现在已经成了大众卷 b 之地。现在有 <code>tbb</code>、<code>folly</code> 等库，也有 <code>thread</code> <code>atomic</code> 等编程工具/原语。此外，还有一些用户态线程、协程也在近年重新受到关注，它们可以减少线程调度和切栈或者申请栈的开销、和 <code>async</code> 等语法结合，用于优化代码和改善性能。</p><p><img src="https://image.mwish.me/blog-image/7BF7E021-3D1F-4F27-9BAB-EC772C386339.png" alt="7BF7E021-3D1F-4F27-9BAB-EC772C386339"></p><p>并行化的优势在于：</p><ol><li><p>Performance: 包括 scalability( performance per CPU) 和 efficiency (performance per watt), 这两个东西都重要，一起才能拼出个不错的最终结果。同时如果你的程序够快、没有性能问题，那串行就串行吧。</p></li><li><p>Productivity:  通过你的东西，实现内容的生产力</p></li><li><p>Generality: 方法的通用性。事实上我们之前讨论的 RCU 什么的 api 相对来说性能好，但是通用性确实差不少。</p></li></ol><p>这里考察了 C++ POSIX Thread API(Performance、Generality)，Java （相较 C++ 牺牲了一点性能）、SQL (不太泛用、领域专一，但有着好的性能和 Productivity)。</p><p>然后作者整了张图，再讲了下 OS/硬件 层面是如何对上述内容取舍和抽象的。因为 OS 本身是一个很「通用」的东西，所以它的 Performance/Generality 的要求是很高的，而越上层的应用可能对 Productivity 要求越高。</p><p><img src="https://image.mwish.me/blog-image/77B09222-65ED-4732-B215-09355B46E7A6.png" alt="77B09222-65ED-4732-B215-09355B46E7A6"></p><h3 id="Alternatives-to-Parallel-Programming"><a href="#Alternatives-to-Parallel-Programming" class="headerlink" title="Alternatives to Parallel Programming"></a>Alternatives to Parallel Programming</h3><p>这一节的内容非常的工程师智慧，介绍了如何「不编写一个并行的系统，又用上硬件这些功能」：</p><ol><li>运行多个串行系统的 instance，并能够对 workload partition</li><li>用已有的并行系统</li><li>串行上进行优化，优化到不用并行也运行的挺好</li></ol><h3 id="What-Makes-Parallel-Programming-Hard"><a href="#What-Makes-Parallel-Programming-Hard" class="headerlink" title="What Makes Parallel Programming Hard?"></a>What Makes Parallel Programming Hard?</h3><p><img src="https://image.mwish.me/blog-image/CE768DAC-77B4-4D12-8878-B0BF058C4302.png" alt="CE768DAC-77B4-4D12-8878-B0BF058C4302"></p><p>因为这个地方要成功的切分任务，然后既然有切分，那运行之类的还有通信的事情要考虑，同时还要考虑资源管理、回收 etc… 本身这些任务都有相对的复杂性。</p><p>这一节相当于介绍了「并发编程为什么这么难」。其实可以看到，跟我个人的想象不同，这个领域是</p><h2 id="Hardware-and-its-Habits"><a href="#Hardware-and-its-Habits" class="headerlink" title="Hardware and its Habits"></a>Hardware and its Habits</h2><p>一个现代的 CPU 大概在执行的时候会有：</p><ol><li>pipelines</li><li>Superscalar</li><li>Speculative execution</li><li>…</li></ol><p>具体我感觉 15-418 给的材料比较好。</p><p><img src="https://image.mwish.me/blog-image/4C310521-6C51-4748-8D82-672D94AC3D52.png" alt="4C310521-6C51-4748-8D82-672D94AC3D52"></p><p>关于现代 CPU，本身性能下降的原因，perfbook 列了：</p><ol><li>Pipeline 相关，比如 branch mispredict/structural hazard: <a href="https://blog.mwish.me/2020/10/21/SDS-Intro-RISC-V-Datapath-4-Pipeline/">https://blog.mwish.me/2020/10/21/SDS-Intro-RISC-V-Datapath-4-Pipeline/</a></li><li>Memory Reference: 这里不光是访问内存的开销，更多的是，给出一个地址，然后访问其内存的开销。</li><li>Atomic Operations: 这个地方不涉及 memory barrier, 应该指的就是对某段内存的 atomic 操作。原子操作有的地方是违背 CPU 假设的。atomic op 的操作经常要：<ol><li>保证数据是这个 cacheline 所有的</li><li>操作完后数据还归属于这个 cacheline</li><li>pipeline must be delayed or even ﬂushed in order to perform the setup operations that permit a given atomic operation to complete correctly.</li></ol></li><li>Memory Barriers: memory barriers 在语言层面上经常和 atomic op 放在一起讨论，但是这个可能需要对 Writer Buffer 之类的东西做特殊处理，可能会影响应能</li><li>Cache Miss: 懂得都懂。</li><li>I/O Operations: 懂得都懂。可惜我不懂 io_uring，令人唏嘘。</li></ol><p>按照我偷来的图：</p><p><img src="https://image.mwish.me/blog-image/F373D15D-0CE9-4427-80BE-B4545FAA35BE.png" alt="F373D15D-0CE9-4427-80BE-B4545FAA35BE"></p><h3 id="硬件及其假设"><a href="#硬件及其假设" class="headerlink" title="硬件及其假设"></a>硬件及其假设</h3><p><img src="https://image.mwish.me/blog-image/734E9D9B-1488-432F-B534-2817C6FD327A.png" alt="734E9D9B-1488-432F-B534-2817C6FD327A"></p><p>上面是 perfbook 的图，我从 15-418 偷了几张图：</p><p><img src="https://image.mwish.me/blog-image/3DB734F8-B806-4A45-91AA-97DBA2E3B272.png" alt="3DB734F8-B806-4A45-91AA-97DBA2E3B272"></p><p><img src="https://image.mwish.me/blog-image/0D78679C-E152-4396-AE71-8A643D8F7770.png" alt="0D78679C-E152-4396-AE71-8A643D8F7770"></p><p>这几张图应该概述了 NUMA、SIMD 之类的。</p><p>perfbook 举了个例子，在某个架构中，如果 CPU (CPU0) 想要写一个跨 Socket 的 mem 地址，可能会：</p><ol><li>check local cache(L1, L2)</li><li>走目录协议，给 CPU0 或者别的 CPU 发送指令，然后让这个 Cacheline 搞到自己上头</li><li>cacheline 到自己上，真正可写</li><li>具体写</li></ol><p>下面一张图介绍了各种操作的开销：</p><p><img src="https://image.mwish.me/blog-image/FG9cf5AaIAAxxUI.png" alt="FG9cf5AaIAAxxUI"></p><p><img src="https://image.mwish.me/blog-image/FGkZD2DVgAAW6Ij.png" alt="FGkZD2DVgAAW6Ij"></p><ol><li>同一个 CPU 的 CAS 可以几 ns 内完成，流程基本上相当于在 cacheline 做标记。这里 cas 是 x86 的 <code>lock;cmpxchg</code></li><li>In-core 表示在同一个核心上，共享同一个 cache hierarchy；blind cas 表示「不读旧值，直接 CAS」，而 CAS 是「读旧值 + CAS」。后者可能访存两次</li></ol><p><img src="https://image.mwish.me/blog-image/2D9BD427-C39E-43B2-AA69-C37BF71341B6.png" alt="2D9BD427-C39E-43B2-AA69-C37BF71341B6"></p><p>这里还有些 dark side 优化：</p><ol><li>large cacheline</li><li>cache prefetching</li><li>store buffer</li><li>speculative execution</li><li>large caches</li><li>read-mostly replication（想下 MESI）</li></ol><p>上面这些策略其实软件也是很常用的。</p><h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h2><p>本节内容比较难，但我不太打算写。这里用的工具不太是 user-level 的 C++11 atomic 之类的，本节介绍了 Linux 常用的 <code>WRITE_ONCE</code> <code>READ_ONCE</code>，和 <code>volatile</code> 的语义。然后介绍了一下各种并发。</p><p>在这之前，chap4 介绍了一些不用上面方式的工具，比如 bash 脚本这一著名、经典的并发程序。详细内容我觉得可以参考 6.null。</p><p><code>POSIX</code> 提供了 <code>fork</code> <code>wait</code> 等进程接口，但这些接口的使用通常和 shm、signal 结合。在 <code>nptl</code> 没实现的时候，PostgreSQL 这些只能依赖这套东西做。</p><p>下面介绍了一下 POSIX mutex、GNU 的 atomic 和<code>__sync_</code>。然后着重介绍了 <code>volatile</code> 的语义。我觉得别的地方介绍都没这里好。但是我感觉这段不如直接 atomic，所以感兴趣的自己回头看吧。</p><p>这里基本还可以参考一些 futex are trickey 什么的，看看对应接口的实现。<code>webkit</code> 实现了一套并发库：<a href="https://webkit.org/blog/6161/locking-in-webkit/">https://webkit.org/blog/6161/locking-in-webkit/</a> ，可以作为参考（不完全是 futex，相当于在用户态包装了一层 futex）</p><p>或者也可以看我 rsy 爹的 blog: <a href="https://github.com/rsy56640/triviality/tree/master/content/%E8%B0%88%E8%B0%88%E5%B9%B6%E5%8F%91">https://github.com/rsy56640/triviality/tree/master/content/%E8%B0%88%E8%B0%88%E5%B9%B6%E5%8F%91</a></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://www.quora.com/What-is-robust-mutex-in-Linux-What-are-some-use-cases-of-robust-mutex">https://www.quora.com/What-is-robust-mutex-in-Linux-What-are-some-use-cases-of-robust-mutex</a></li><li>CMU 15-418</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Arch Blog Overviews</title>
      <link href="/2022/05/02/Arch-Blog-Overviews/"/>
      <url>/2022/05/02/Arch-Blog-Overviews/</url>
      
        <content type="html"><![CDATA[<p>这篇博客干脆做一个汇总好了，在毕业那年算是做了一些 Arch 的入门. 现在回头翻也比较好，然后最近也可能添加一些新内容（因为在看 perfbook）。</p><h2 id="mwish’s-blogs"><a href="#mwish’s-blogs" class="headerlink" title="mwish’s blogs"></a>mwish’s blogs</h2><p>首先是我自己写的一些：</p><h3 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h3><ol><li>Cache Consistency in CPU and Distributed System: <a href="https://blog.mwish.me/2020/12/12/Cache-Consistency-in-CPU-and-Distributed-System/">https://blog.mwish.me/2020/12/12/Cache-Consistency-in-CPU-and-Distributed-System/</a> （介绍了一些 MOSI 之类的东西，包括 Snooping 协议和 Directory 协议）</li><li>Cache 的结构，和组相联缓存：<a href="https://blog.mwish.me/2020/10/29/Cache-and-Related-Part1/">https://blog.mwish.me/2020/10/29/Cache-and-Related-Part1/</a></li><li>用户使用 Cache 的优化：<a href="https://blog.mwish.me/2020/10/31/Cache-and-Related-Part2/">https://blog.mwish.me/2020/10/31/Cache-and-Related-Part2/</a></li><li>Cache Coherent 和 Memory Order: <a href="https://blog.mwish.me/2020/11/01/Cache-and-Related-Part3-Coherent/">https://blog.mwish.me/2020/11/01/Cache-and-Related-Part3-Coherent/</a></li></ol><p>此外因为是 RV，所以我收集了一些内存模型相关的材料：</p><ol><li><a href="https://www.cs.utexas.edu/~bornholt/post/memory-models.html">https://www.cs.utexas.edu/~bornholt/post/memory-models.html</a></li><li>A Tutorial Introduction to the ARM and POWER Relaxed Memory Models</li><li><a href="https://www.kernel.org/doc/Documentation/memory-barriers.txt">https://www.kernel.org/doc/Documentation/memory-barriers.txt</a> (和 2 可以一起看，对照就懂很多了)</li><li><a href="https://riscv.org/wp-content/uploads/2018/05/14.25-15.00-RISCVMemoryModelTutorial.pdf">https://riscv.org/wp-content/uploads/2018/05/14.25-15.00-RISCVMemoryModelTutorial.pdf</a></li><li>A Primer on Memory Consistency and Cache Coherence, Second Edition</li></ol><p>按照顺序读下去基本上不会被网友扯犊子骗了。</p><h3 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h3><ol><li>flip-flop 到执行电路：<a href="https://blog.mwish.me/2020/10/14/SDS-Intro-RISC-V-Datapath/">https://blog.mwish.me/2020/10/14/SDS-Intro-RISC-V-Datapath/</a></li><li>基本的 datapath: <a href="https://blog.mwish.me/2020/10/15/SDS-Intro-RISC-V-Datapath-2-Datapath/">https://blog.mwish.me/2020/10/15/SDS-Intro-RISC-V-Datapath-2-Datapath/</a></li><li>控制逻辑、Pipeline：<a href="https://blog.mwish.me/2020/10/18/SDS-Intro-RISC-V-Datapath-3-Control-logic-and-metric/">https://blog.mwish.me/2020/10/18/SDS-Intro-RISC-V-Datapath-3-Control-logic-and-metric/</a></li><li>Hazard、Pipeline、OoO: <a href="https://blog.mwish.me/2020/10/21/SDS-Intro-RISC-V-Datapath-4-Pipeline/">https://blog.mwish.me/2020/10/21/SDS-Intro-RISC-V-Datapath-4-Pipeline/</a></li></ol><p>看 perfbook 的时候追加了一些图片: <a href="https://blog.mwish.me/2022/05/04/perfbook-notes-hardware/">https://blog.mwish.me/2022/05/04/perfbook-notes-hardware/</a></p><h3 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h3><ol><li>虚拟内存： <a href="https://blog.mwish.me/2020/11/08/%E8%BD%AF-%E7%A1%AC%E7%9A%84%E5%88%86%E7%95%8C-%E8%99%9A%E6%8B%9F/">https://blog.mwish.me/2020/11/08/%E8%BD%AF-%E7%A1%AC%E7%9A%84%E5%88%86%E7%95%8C-%E8%99%9A%E6%8B%9F/</a></li></ol><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ol><li>RISC-V 基本指令：<a href="https://blog.mwish.me/2020/03/28/RISC-V-GetStart/">https://blog.mwish.me/2020/03/28/RISC-V-GetStart/</a></li><li>RISC-V 指令格式：<a href="https://blog.mwish.me/2020/10/04/RISC-V-%E6%8C%87%E4%BB%A4%E6%A0%BC%E5%BC%8F/">https://blog.mwish.me/2020/10/04/RISC-V-%E6%8C%87%E4%BB%A4%E6%A0%BC%E5%BC%8F/</a></li><li>libc 和 标准库：<a href="https://blog.mwish.me/2020/04/04/CALL-libc-%E5%92%8C-C-%E6%A0%87%E5%87%86%E5%BA%93/">https://blog.mwish.me/2020/04/04/CALL-libc-%E5%92%8C-C-%E6%A0%87%E5%87%86%E5%BA%93/</a></li><li>二进制补码、整数、浮点数、大小端：<a href="https://blog.mwish.me/2020/09/19/Integer-Endian/">https://blog.mwish.me/2020/09/19/Integer-Endian/</a></li></ol><h2 id="Courses"><a href="#Courses" class="headerlink" title="Courses"></a>Courses</h2><p>然后是一些课程：</p><ol><li>UCB cs61c: 比较入门的课程，算是体系结构版 CSAPP. 我上面很多基础概念基本都是这里 Build 的</li><li>UCB cs152: cs61c 的后续，正经系统结构</li><li>CMU 15-418: CMU 的 HPC，很多图和分析思路非常好</li><li>ETHz dphpc 2019: 包括了一些 Lock-free 之类的东西，很 pratical</li></ol><h2 id="Books-and-websites"><a href="#Books-and-websites" class="headerlink" title="Books and websites"></a>Books and websites</h2><p>最后是一些外部资源：</p><ol><li>Computer Organization and Design RISC-V Edition : The Hardware Software Interface</li><li><a href="https://www.agner.org/">https://www.agner.org/</a></li><li>Computer Architecture: A Quantitative Approach, 6th</li><li>深入浅出SSD : 固态存储核心技术、原理与实战</li><li>What Every Programmer Should Know About Memory</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Delta Lake &amp; Lakehouse</title>
      <link href="/2022/05/01/Delta-Lake-Lakehouse/"/>
      <url>/2022/05/01/Delta-Lake-Lakehouse/</url>
      
        <content type="html"><![CDATA[<p>我的友人 xzt 老师曾经对我说过一个笑话，大概长这样：</p><blockquote><p>高情商：”我们有基于数据湖的数据管理系统”<br>低情商：”你要在 HDFS 上手写 MapReduce 任务”</p></blockquote><p>我一直觉得这是个没毛病的说法，所以对最近创业的各种东西感觉比较困惑。尤其是之前上网搜了一波数据湖是什么，感觉他们讲的都是一些哲学概念而不是技术。今天看了看 Databricks 的 Delta Lake 和 Lakehouse，想了想，终于知道数据湖这个批词指的是什么东西了。</p><p>Delta Lake 提供了一个类似表格的服务，在 S3 上提供了 ACID 语义。它存储类似 Parquet 这样支持 nested 的格式，并且给每列数据一些描述元信息。同时，它本身的 Schema 应该是柔性的，对比到行存类似 Protobuf、Avro 这种软的格式。对前台写入而言，Delta Lake 的上述内容提供了 ACID 的写入，这点对用户还是比较重要的，这里可以对比 Hive，用户瞎几把改了一堆数据然后任务挂了，你这堆东西你看你留不留？Delta Lake 很好的解决了这个问题。Delta Lake 提供了在 OSS 上实现 ACID 语义的逻辑，并支持了 Streaming 等接口（但不太是给 Streaming 原生设计的，感觉写入性能还是受限的）。</p><p>对数据分析师或者各种用户而言，比较重要的是 <code>Optimize</code> 操作。这个有点类似 LSM 的 Compaction，会把零散的 Parquet 文件组织成便于分析的 Parquet 文件，这个过程似乎被称作 Clustering : 把你写的那些乱七八糟的 Schema 组织成一些比较结构化的、便于 AP 查询执行的 Schema，然后这些文件对于每列会有一些 <code>min-max</code> 描索引信息，帮助上层查询跳过。这部分在 Delta Lake 论文有简短描述。</p><p>对于上层系统而言，Lakehouse 对 Delta Lake 提供了元数据层、缓存和一些端到端的 API，做到了嗯舔用户。</p><p><img src="https://image.mwish.me/blog-image/C7203105-EDF4-4E9C-92D3-21C031F4E77B.png" alt="C7203105-EDF4-4E9C-92D3-21C031F4E77B"></p><p>回过头来说，如果说 snowflake 是发现了云上 “不跑的机器可以不收费” + “AP Workload 没有那么延时敏感” + “算不来的东西多调机器就行了”，那么 Delta Lake + Lakehouse 则是 “云上低性能 Batch ACID” + “Compaction 阶段调整格式”。关于 Cache 其实和 Snowflake 差不多。</p><p>本来想写点什么的，但是感觉知道它在做什么就索然无味了…所以就发个这么短的了。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li>深度对比delta、iceberg和hudi三大开源数据湖方案: <a href="https://zhuanlan.zhihu.com/p/110748218">https://zhuanlan.zhihu.com/p/110748218</a></li><li>通过数据组织加速大规模数据分析: <a href="https://zhuanlan.zhihu.com/p/354334895">https://zhuanlan.zhihu.com/p/354334895</a></li><li>【论文分享】从Lakehouse看Databricks对下一代数据湖架构的理解 - ShallowMind的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/462094560">https://zhuanlan.zhihu.com/p/462094560</a></li><li>数据湖竟然能和数据仓库打通？如何评价阿里云推出的湖仓一体解决方案？ - 贾扬清的回答 - 知乎 <a href="https://www.zhihu.com/question/421711474/answer/1480957849">https://www.zhihu.com/question/421711474/answer/1480957849</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ARIES/IM</title>
      <link href="/2022/04/30/ARIES-IM/"/>
      <url>/2022/04/30/ARIES-IM/</url>
      
        <content type="html"><![CDATA[<p><code>&lt;ARIES/IM: An Efficient Management Method and High Concurrency index Using Write-Ahead Logging&gt;</code> 描述了 ARIES 是如何维护索引相关的 Latch 和 Lock 的。在 B+Tree 上可能会涉及 IO 、SMO 等情况，在这种情况下，对一个树的查询要保证高性能、并发安全。</p><p>ARIES/IM 在索引和 Lock 上的想法是：</p><ol><li>Data Lock, 只在 Data 上上锁，Index 上不上锁</li><li>为了并发，尽量少的获取要等待到 Commit 阶段的 Locking</li><li>允许查找/删除/插入和 SMO 一起执行</li></ol><p>ARIES/IM 本身使用 ARIES 做恢复，会对 Page 进行 Redo 和 Undo，ARIES/IM 保证这些都是 Page 级别上执行的。</p><p>2/3 都比较常见，(1) 需要额外解释一下，我们从 hedengcheng 的 slide 里面引一张 InnoDB 锁的图：</p><p><img src="https://image.mwish.me/blog-image/3243D20E-840B-42F1-9221-1963EAA12616.png" alt="3243D20E-840B-42F1-9221-1963EAA12616"></p><p>这里的锁是 Index + Data(Primary Key), 然后查询使用的 Index 也需要上锁。ARIES/IM 这里只需要给 Primary Key 或者 Heap Tuple 上锁。</p><p>ARIES/IM 论文应该使用的是 Heap Tuple 模型。在论文中，索引的叶子结点包含 <code>&lt;key-value, recordID&gt;</code>, 模型中，叶子结点被双向链接，非叶子结点有指向下层的指针和对应的 <code>high key</code>。非叶子结点的 High Key 一定比下层的 High Key 大。</p><p>ARIES/IM 提供了下列的索引原语：</p><ol><li><code>Fetch(Key or Partial-key, starting-condition)</code>, <code>starting-condition</code> 包含 <code>Eq</code> 、<code>GT</code> 和 <code>GTE</code>，然后拿到整个 Key</li><li><code>FetchNext(stopping-condition)</code>: 对 <code>Fetch</code> 的结果，然拿到下一个 key</li><li><code>Insert(key-value, RID)</code>: 插入 <code>(key-value, RID)</code> 对. 对于 <code>unique</code> 的索引来说，这里需要查找到这个 <code>key</code> 是否重复，儿对于 <code>nonunique index</code>, <code>(key-value, RID)</code> 对需要查找是否重复</li><li><code>Delete(key)</code> 删 <code>key</code> (这个接口我觉得怪怪的，是不是还得加个 <code>RID</code>?)</li></ol><p>那么，这套东西考虑并发和 Recover，可能有下列的问题：</p><ol><li>对 Index 需要记录什么样的日志，来保证完整（不丢数据）、高性能恢复</li><li>SMO 在发生的时候崩溃了，恢复的时候保证没有问题</li><li>如何提升 Page 上访问的并发度</li><li><strong>假如事务在 Rollback 的时候，已经完成了某个 SMO，它可以不用 UNDO 这个 SMO</strong></li><li>如 Figure1，如何保证 SMO 发生的时候，Page 被移动到了别的地方，这个时候，如果要 rollback T1，这种基于 Page 的 Undo 可能会啥都删不掉，需要从上层来做一个 Logical Undo。需要能够阻止或者检测出这种结果</li><li>(5) 讲述的是插入 - SMO - abort 的情况，同样这里还有 删除 - SMO - abort 的情况，也要能够正确恢复</li><li>怎么防止 Rollback 的时候，事务出现 Deadlock</li><li>怎么设计不同级别的锁</li><li>RR 的隔离级别下，怎么做谓词锁</li><li>怎么保证一个 Unique Index 中，A 删掉了一个 Key，B 需要插入同一个 Key，而 A 可能 Abort 的情况</li><li>SMO 发生的同时，Tree Traversal 也能正确执行</li></ol><p><img src="https://image.mwish.me/blog-image/0C7F9D1B-691F-4186-ACA5-5D537870631F.png" alt="0C7F9D1B-691F-4186-ACA5-5D537870631F"></p><p>关于 ARIES Recover 可以参考我之前的 Blog: <a href="https://blog.mwish.me/2021/08/07/Database-Recover-System/">https://blog.mwish.me/2021/08/07/Database-Recover-System/</a></p><h2 id="Concurrency-Control"><a href="#Concurrency-Control" class="headerlink" title="Concurrency Control"></a>Concurrency Control</h2><p>这部分的 Concurrency Control 不涉及 Recover. 有一部分 <code>Del_Bit</code> 和 Recover 有关，可以不用理解。</p><p>这里贴一下 Data-Only Lock 相关的上锁规则：</p><p><img src="https://image.mwish.me/blog-image/AFE6B33F-70C6-472E-8F22-49A49FAFC5F0.png" alt="AFE6B33F-70C6-472E-8F22-49A49FAFC5F0"></p><p>细心的你可能发现了，这里还有个 index-specific locking，ARIES/IM 认为 index-specific locking 可能可以提升并发能力，但是会增加实现的复杂性和维护锁的代价。</p><p>在支持 RR / 维护 Unique Index 的时候，在删除或者插入一个 key 的时候，需要对下一个 key 上锁，这种策略被称为 <code>next-key locking</code>. 在 <code>Fetch</code> 和 <code>Fetch Next</code> 的时候，若 Key 不存在，也要考虑这个问题。</p><p>Latching: Latching 维护了 Page 和 B+Tree 物理结构上的一致性。在 Index 访问的时候，不会 Grab 数据页的 Latch。获得 Latch 的顺序是下降获取的，这个流程要遵循 <strong>Latch Coupling</strong>:</p><ol><li>先锁定根节点，从根节点下降</li><li>按照锁叶子结点 — 切换 — 下降 — 释放父节点锁的过程进行下降。中间全都是 S Latch，到根节点的时候，根据操作类型来决定是 S 还是 X</li></ol><p>这里还有 SMO 对应的处理，当一个 Txn 执行 Split 的时候，别的事务要保证正确处理。ARIES/IM 会要求「向右分裂」，即把 higher key 移动到下一个节点。然后 Bottom-Up 的分裂，Bottom-Up 这个顺序和查找的时候下降的顺序是相反的，为了避免 Latch 的死锁，ARIES/IM 引入了 <code>SM_Bit</code>，然后在 SMO 的时候会做 <code>SM_Bit</code> 标记，随之释放锁 - 上升。而下降的时候会注意到 <code>SM_Bit</code>, 进行一些别的操作，等待 SMO 完成。</p><p>那「别的操作」 是什么呢？ARIES/IM 引入了一个 B+Tree 级别的 <code>RWLatch</code>: <code>TreeLatch</code>，供 SMO 同步使用，SMO 会 <code>Grab X Latch on TreeLatch</code>，然后下降的时候，如果注意到了 <code>SM_Bit</code>，这里需要放锁 -&gt; <code>Grab S Latch on TreeLatch</code>，等待 SMO 完成. 然后如果某个节点拿到了 <code>S Latch</code>，这里它就可以清掉 <code>SM_Bit</code> 了，因为 SMO 已经完成了。这个 <code>TreeLatch</code> 同时也保证了写入的串行性。</p><p>上面的部分是算法的大意，下面这里要讲一讲具体怎么实现，值得一提的是，下面的部分有一个 <code>Del_Bit</code>，这个和 Recover 有关，先不用管，然后论文估摸着是假设 Page 全在内存中，没有考虑不在内存中的情况。</p><h3 id="Fetch"><a href="#Fetch" class="headerlink" title="Fetch"></a>Fetch</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">/* for simplicity, root = leaf case not specified here */</span><br><span class="line">S latch root and note root&#x27;s page_LSN</span><br><span class="line">Child := Root</span><br><span class="line">Parent := NIL</span><br><span class="line"></span><br><span class="line">// 下降</span><br><span class="line">Descend:</span><br><span class="line">  IF child is a leaf AND Op is (insert OR delete) THEN</span><br><span class="line">  X latch child</span><br><span class="line">  ELSE S latch child</span><br><span class="line">  Node child&#x27;s page_LSN</span><br><span class="line">  IF child is a nonleaf page:</span><br><span class="line">  IF nonempty child &amp; ((input key &lt;= highest key in child) OR (input key &gt; highest key in child &amp; SM_Bit == 0)):</span><br><span class="line">  // 操作是安全的, 可以进行</span><br><span class="line">  IF Parent != NIL:</span><br><span class="line">  unlatch parent</span><br><span class="line">  Parent := Child</span><br><span class="line">  Child := Page_Search(Child)</span><br><span class="line">  goto Descent</span><br><span class="line">  ELSE:</span><br><span class="line">  // input key 比 highest key 大, 且 SM_Bit 被标记了, 说明有 SMO</span><br><span class="line">  Unlatch parent &amp; child</span><br><span class="line">  S latch TreeLatch for instant duration // 主动锁 TreeLatch, 等待 SMO 结束</span><br><span class="line">  Unwind recursion based on noted page_LSNs, and Descend // 根据 page_LSNs 回滚</span><br><span class="line">  ELSE:</span><br><span class="line">  Case Op:</span><br><span class="line">  Fetch: // 上 S latch 什么的</span><br><span class="line">  Insert: // 上 X latch 什么的</span><br><span class="line">  Delete: // ...</span><br><span class="line">   END</span><br></pre></td></tr></table></figure><p>上面表现了一个 <code>Descend</code> 的流程，具体还有一个 Fetch 的流程：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Find requested or next higher key(maybe on NextPage)</span><br><span class="line">Unlatch parent</span><br><span class="line">Request conditional S lock on found key</span><br><span class="line">IF lock granted:</span><br><span class="line">Unlatch child &amp; return found key</span><br><span class="line">ELSE:</span><br><span class="line">Note LSN and key position and unlatch child // 有别的占锁了</span><br><span class="line">Request unconditional lock on key</span><br><span class="line">Once lock granted backup &amp; search if needed</span><br></pre></td></tr></table></figure><p>这里 Lock 需要拿到了 Latch 再上, 保证正确性。而为了保证 next-key locking，甚至可能要捞右侧的 Page。在获取下一个页面的 Page 的时候，上一个页面的 Latch 不能被释放。</p><p>这里还有个特点就是捞 Page 的时候会记 <code>Page_LSN</code>，没被更新的话就该咋样咋样，Page 被更新了就要重来，检查一下发生什么事了。</p><p><code>conditional</code> 应该是「没获取到就失败」，而「unconditional」是一直等待获取到。这里的 Lock 是 Commit Duration 的。如果拿到了最后都没有，应该要对一个最高 Key 的特殊 Maximum 记录上锁。</p><h3 id="Fetch-next"><a href="#Fetch-next" class="headerlink" title="Fetch next"></a>Fetch next</h3><p>Fetch next流程首先定位一个key，然后记下 <code>Page_LSN</code> 和位置，然后不断顺序遍历符合范围查找要求的key，每次返回一个符合要求的key时都需要记录相应的page_lsn。下一次查找时需要比较page_lsn，若page_lsn变更，说明页被修改，此时需要再次走一次 Fetch，来重新定位。</p><h3 id="Insert"><a href="#Insert" class="headerlink" title="Insert"></a>Insert</h3><p>如果 Leaf Page 有足够空间，这里会定位到相同或者比自己大的 key 上，然后 Grab X Lock，进行插入的 key 的 locking。上锁后，再进行 unique check。这个锁是 Commit Duration 的。</p><p>这里还要对 next-key 进行 X lock，来保证锁定。这个可能还会需要锁定下一页。这个 lock 是 instant 的，它只用来避免 RR 上出现 Phantom Data。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">IF SM_BIT | Del_Bit THEN:</span><br><span class="line">Instant S latch tree, set Bits to &#x27;0&#x27;</span><br><span class="line">Unlatch parent</span><br><span class="line">Find key &gt; insert key &amp; X lock it for instant duration</span><br><span class="line"></span><br><span class="line">Insert key, log and update page_LSN</span><br><span class="line">Release child latch</span><br></pre></td></tr></table></figure><p>如果需要分裂，为了维护 B+Tree 结构，这个需要把邻居节点捞上来（维护双向链表），然后把涉及的 Page 全部弄到内存中，再 Grab X Lock，进行 SMO。这里我们只需要了解 SMO 会创建一个 sibling page，然后处理结构，标记 <code>SM_Bit</code>，层层向上。</p><h3 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a>Delete</h3><p>Delete 会对 Next-Key 上 Commit Duration X Lock，用来防止之前问题 (10) 等场景。此外还有一些用于恢复的逻辑，比如删除边界值的时候，需要给整个 Tree 上锁；同时需要引入 <code>Del_Bit</code>。之后会在 Recovery 里面讨论这些个细节</p><p>这里实现的不一定是标准的 B+Tree，只有删空一个 Page 的时候，才会执行 DeletePage 的 SMO。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">IF SM_Bit == 1:</span><br><span class="line">Instant S latch TreeNode and set SM_Bit to 0</span><br><span class="line">Set Delete_Bit to 1</span><br><span class="line">Unlatch parent</span><br><span class="line">Find key &gt; delete key &amp; X lock it for commit duration</span><br><span class="line">IF delete key is smallest/largest on page:</span><br><span class="line">S latch tree and set Delete_Bit to 0</span><br><span class="line">Delete key, log and update page_LSN</span><br><span class="line">Release child latch and tree latch, if held.</span><br></pre></td></tr></table></figure><h3 id="SMO"><a href="#SMO" class="headerlink" title="SMO"></a>SMO</h3><p><img src="https://image.mwish.me/blog-image/DCEB073D-03B6-482E-8207-E1ADFF2A70F0.png" alt="DCEB073D-03B6-482E-8207-E1ADFF2A70F0"></p><p>SMO 重点是和 Insert/Delete 一起考虑并发。还有一些 Del_Bit 的 hacking。</p><h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><p>为什么 Delete 要 Commit Duration；Insert 只要 Instant Duration 呢？实际上，没有提交的 Insert 对外部是一条可见记录，而 Delete 则是看不到了（记录直接没了）。所以插入的时候放个 <code>&lt;key, value, RID&gt;</code>记录在这，看看后面是不是有记录，然后嗯插就行，反正自己上面有把锁。删除的时候清掉 <code>&lt;Key, value, RID&gt;</code>，自己 <code>RID</code> 别人也锁不了了，就只能嗯锁下一个。</p><h2 id="Recovery-in-ARIES-IM"><a href="#Recovery-in-ARIES-IM" class="headerlink" title="Recovery in ARIES/IM"></a>Recovery in ARIES/IM</h2><p>论文之前的问题也提到了 Recovery，SMO 由 Delete/Insert 触发。如果 SMO 做完了，而事务 Abort 了，SMO 会照常推进下去，如图：</p><p><img src="https://image.mwish.me/blog-image/2A164111-9675-4BB3-B8E8-8A14C35A62DF.png" alt="2A164111-9675-4BB3-B8E8-8A14C35A62DF"></p><p><img src="https://image.mwish.me/blog-image/C8A02D69-79C9-45EA-8109-998CB32759D4.png" alt="C8A02D69-79C9-45EA-8109-998CB32759D4"></p><p>在 Rollback 的时候，Delete/Insert 可以被撤销，对于 Delete，Redo 的时候反正先 Delete 了，SMO，然后再对整个树插入；Insert 的时候，插入的记录再被滚掉。如果 SMO 没有写 <code>Dummy CLR</code>，那么 SMO 会被回滚。在 <code>SMO</code> 期间，操作需要对 <code>TreeLatch</code> 同步，所以对 Page 回滚是安全的。</p><p>当然，你会注意到，<strong>不是所有操作都能在这个流程中做到对 Page 回滚的</strong>。如 Figure 10，当这个事务失败但 SMO 成功的时候，Page 都没了，怎么回滚呢？这个时候，ARIES/IM 策略是 <strong>尽量对 Page 物理回滚，不行的话整个树下来做逻辑删除</strong>，具体而言，假设事务在 $t_1$ 时刻进行，$t_2$ 时刻 Undo，需要执行 Logical Undo 的规则是：</p><ol><li>Undo Delete 的时候，Page 没有足够空间进行插入，说明 t1-t2 期间，有一个事务占有了删除的空间</li><li>Undo 的时候，key 不属于原来的 Page，说明 t1-t2 期间，有一个别的 SMO</li><li>不知道 Key 是否属于原来的 Page：在 Undo 的时候，可能插入了一堆相同的记录，导致不确定具体啥情况</li><li>Undo Insert 可能导致原来的 Page 变空。这显然不科学，说明 <strong>t1-t2 之间有一个对边界 key 的删除</strong>。</li></ol><p>在 Undo 阶段可能也有 SMO。一般的 Undo 的 CLR 是只有最终镜像的，但是 SMO 可能失败，所以 SMO 的 Undo 也需要完整的日志。</p><p>在执行阶段，Undo 的时候如果要 SMO 也需要 <code>X TreeLatch</code>，来串行处理。</p><p>对于一个 SMO，当持久化 <code>Dummy CLR</code> 日志的时候，才能释放 <code>X TreeLatch</code> (表示这次 SMO 已经完成，可以恢复）。</p><p>这里 ARIES/IM 还需要保证 Undo 是能够进行的，这个点有点奇怪，为什么 Undo 会不能进行呢？可以参考下图：</p><p><img src="https://image.mwish.me/blog-image/9658AEDC-3E91-4745-82C4-6ECFDB454404.png" alt="9658AEDC-3E91-4745-82C4-6ECFDB454404"></p><p>一个 SMO 可能导致 Delete 的 Undo 是不可进行的！这个未完成的 SMO 会导致对 Delete 的恢复无法从根节点找到。这个时候你可以发现 <code>Del_Bit</code> 和串行化 SMO 的妙处了。</p><p>我们回到需要执行 Logical Undo 的规则 和 <code>Delete</code> <code>Insert</code> 的代码，可以看到，<code>TreeLatch</code> 这里承担了一个很重要的同步点，来保证并发的安全性。当你需要删除、删边界 key、SMO 的时候，都要主动拿一下 Latch 来强制同步。</p><h2 id="优化和其他协议"><a href="#优化和其他协议" class="headerlink" title="优化和其他协议"></a>优化和其他协议</h2><p>可以看到，上述一个复杂点是，删除的时候如果物理删除了，可能回滚的时候有额外的功夫。Graefe Goetz 提出过一个逻辑删除。即删除不实际从 Page 上抹除这条记录，而是一个标记删除，来解决问题。不过我不是很清楚这样删了之后，需要用什么条件来 GC 这些数据。</p><p>标记删除需要和 Purge 的流程联动起来，这里可能还会需要一些 mtr，比方说标记删除后，确定某个事务的 Garbage 记录可以被回收，那可以写个 mtr 把 Page 上的这个垃圾记录回收掉。感觉这个稍微有点类似 MVCC？</p><p>论文里没有提到根节点分裂的情况，但实际上这是一个比较复杂的 case，可能也需要 grab 一把锁来解决。</p><p>InnoDB 的 Btree 感觉相对没这么细，不过也可以看的出来为啥。感觉在那上面改并发类似一个不可能完成的任务了…</p><p>关于这些，可以看 alibaba 的数据库月报：</p><ol><li><a href="http://mysql.taobao.org/monthly/2020/06/02/">http://mysql.taobao.org/monthly/2020/06/02/</a></li><li><a href="http://mysql.taobao.org/monthly/2020/05/02/">http://mysql.taobao.org/monthly/2020/05/02/</a></li><li><a href="http://mysql.taobao.org/monthly/2020/11/02/">http://mysql.taobao.org/monthly/2020/11/02/</a></li><li><a href="http://mysql.taobao.org/monthly/2021/12/04/">http://mysql.taobao.org/monthly/2021/12/04/</a></li></ol><p>可以看到，MySQL 5.6 的 InnoDB 这里会有一个 Btree Latch，然后在下降的时候可能要 S Latch 它，然后下降，下降之后，根据有没有 SMO，来判定剩下来的操作是否要 Latch 整个树。同时，这里只有叶子结点上有 Latch，non-leaf page 是不会上锁的。</p><p>InnoDB 在 MySQL 8.0 引入了 SX Lock（类似 rwlatch？），也引入了 non-leaf page lock，不过仍然是比较粗粒度的锁。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li>ARIES/IM: An Efficient Management Method and High Concurrency index Using Write-Ahead Logging</li><li>二手文章 ARIES/IM: <a href="http://mysql.taobao.org/monthly/2020/05/03/">http://mysql.taobao.org/monthly/2020/05/03/</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LLAMA: A Cache/Storage Subsystem for Modern Hardware</title>
      <link href="/2022/04/20/Notes-LLAMA/"/>
      <url>/2022/04/20/Notes-LLAMA/</url>
      
        <content type="html"><![CDATA[<p>Bw-Tree, 即 “Buzz Word Tree”，由微软在 2013 年提出，基本是给 SQL Server 做内存引擎的。Bw-Tree 及其底座 LLAMA 的一作 Justin Levandoski 最早在 MS，后来去了 Aurora，现在在 Google BigQuery。</p><p>Bw-Tree 主要内容是 SSD 友好的数据结构，它希望对 Bw-Tree 的操作都是 Lock-free 的，它的数据基于 Page (Inner node + Leaf node) + Log （Delta node），用 Mapping Table 和 64-bit uuid 来映射到对应的 node （Page 或者 Delta node），它用 Epoch-based Reclaim 来回收空间，回收的时候，Bw-Tree 并没有做到 interval-GC（或者是它论文没说），相对的，在 Consolidation （Log + Page 产生新的 Page）之后，会把旧的 Node 给放到可 GC 的区域中。</p><p>它的分裂合并操作和 Blink-Tree 有一点相似，Split 和 Merge 都分裂成多个阶段，并引入了 Split / Merge 节点。SMO 本身是个多步的操作，当发现系统中有 SMO 的时候，别的操作会先帮助推进 SMO（有点像是在说这个 SMO 是 wait-free 的？）。</p><p>Bw-Tree 论文在国内已经有不少二手文章了，除了 Bw-Tree 文章外，CMU 在 SIGMOD’18 发表了一篇文章，描述了一些 In-memory 的 Bw-Tree 的行为和工程优化，测试(diss)了一下它的性能。笔者认为，B-Tree 族的算法比较复杂，而且和实现高度相关，移步这些专业人士写的二手文章相对来说更靠谱。不过，关于 LLAMA，介绍的二手文章比较少。</p><p><img src="https://image.mwish.me/blog-image/84102576-8957-4691-92DB-772A07FB6F53.png" alt="84102576-8957-4691-92DB-772A07FB6F53"></p><p>LLAMA 提供了一个所谓  Log Structured “Page” Store 的引擎，对上层提供 Page 的接口和 更新/覆盖(替换) Page，但又提供以 Delta Log 和整个 Page 的形式写入具体的存储层的接口。下层类似 LFS。同时，LLAMA 提供 lock-free 的操作族，它的 flush 等操作都可以是异步的。</p><h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>LLAMA 提供了 Cache / Storage 两层的管理，以 Page 和 Page-Delta 的形式提供服务。它不需要理解 Page 的内容。它分为两层：CL 和 SL，即缓存层和存储层。可以简单把 LLAMA 当成一个 BufferPool：</p><ol><li>Storage + Cache</li><li>Mapping Table + Page + Delta</li><li>lock-free</li></ol><p>逻辑上的结构可以见下图（不考虑更新和 Delta Log）：</p><p><img src="https://image.mwish.me/blog-image/33FB84CE-4078-45D9-AC16-DCF1BB31A7A6.png" alt="33FB84CE-4078-45D9-AC16-DCF1BB31A7A6"></p><p>LLAMA 并不会知道 Page 的内容，相关的 WAL/LSN/Checkpoint 需要外部维护，它只提供 Page 的 Allocate/Update/Overwrite/Flush/Remove。虽然表面上存储的是 Page，但是其实类似 LFS，这些数据会以 Log 的形式写到存储系统上，这个和 Delta Log 系统一起，降低了系统的写入开销。LLAMA 还提供了系统事务，用来支持类似 Bw-Tree SMO 等对多个 Page 的原子操作。</p><h2 id="LLAMA-Interface"><a href="#LLAMA-Interface" class="headerlink" title="LLAMA Interface"></a>LLAMA Interface</h2><p>这批论文一张图都没有。</p><h3 id="Page-Data-Operations"><a href="#Page-Data-Operations" class="headerlink" title="Page Data Operations"></a>Page Data Operations</h3><p>LLAMA 提供了 Page Data Operations 操作数据，包括：</p><ol><li><code>Update-D(PID, in-ptr, out-ptr, data)</code>. <code>D</code> 是 delta 的意思，<code>data</code> 通常包含 <code>&lt;lsn, key, data&gt;</code> 这样的逻辑数据。<code>in-ptr</code> <code>out-ptr</code> 其实是塞给 mapping table 或者存储那一套，会把更新后的句柄丢出来</li><li><code>Update-R(PID, in-ptr, out-ptr, data)</code>: <code>R</code> 是 replace 的意思，这里相当于整个页面的状态一把更新</li><li><code>Read(PID, out-ptr)</code>: 返回 <code>out-ptr</code> 指向的内存地址，如果 <code>Page</code> 在盘上，也要把这个捞起来。</li></ol><h3 id="Page-Management-Operations"><a href="#Page-Management-Operations" class="headerlink" title="Page Management Operations"></a>Page Management Operations</h3><p>LLAMA 还提供了一组数据管理接口，支持 flush 等接口：</p><ol><li><code>Flush(PID, in-ptr, out-ptr, annotation)</code>: 把 Page 的状态拷贝到 log structured store(下文称 <strong>LSS</strong> ) 的 IO-Buffer，并且添加一个 <code>Flush</code> 的 Delta 记录，如后文的图。<code>Flush</code> 其实是个 async 接口，并不代表成功写到盘上了。这里还有个要注意的是，这里刷的时候可能大小不固定，然后 annotation 可能是 LSN 这些业务语义，也会带下去。</li><li><code>Mk-Stable(LSS address)</code>:  保证在 <code>LLS address</code> 之前的 IO-Buffer 上的记录都已经写到持久存储上了。</li><li><code>Hi-Stable(out-LSS address)</code>: 返回刷到持久存储的最高位点</li><li><code>Allocate(out-PID)</code> 懂得都懂，申请一个 Page 返回 pid 然后在 mapping table 注册一下. 同时这样的 Page 也要持久化</li><li><code>Free(PID)</code>: 准备会收掉对应的 PageID / Page</li></ol><p>我吐槽下，这论文也没说什么模型，<code>data</code> 是啥，我感觉只能猜测是一些 Delta Log 和什么别的了。LSS 数据估计是一个无线长的数据段或者环状 buffer。至于别的基本上都是 BufferPool 该有的，只是存储变成 Delta 了。</p><h3 id="System-Transaction-Operations"><a href="#System-Transaction-Operations" class="headerlink" title="System Transaction Operations"></a>System Transaction Operations</h3><p>这里会产生系统内部事务，读写会 buffer 在内存中，在 commit 的时候提交。commit 阶段的时候，所有的 Page 会原子性添加到 LSS 的 IO-Buffer 中，然后被刷下去。LLAMA 这里好像并没有描述任何的并发控制和策略，估摸着是上层控制了，BwTree 的事物靠上层的 <strong>Deuteronomy</strong> 来控制。</p><p>这里提供了大概如下的接口：</p><ol><li><code>TBegin(out-TID)</code>: 拿到一个 TID，这需要维护一个 active transaction table (下称 ATT)</li><li><code>Commit(TID)</code>: 从 ATT 中取出来，原子性的写到哪步</li><li><code>TAbort(TID)</code>: 从 ATT 出来 abort</li></ol><p>这里不应该 <code>Update-R</code>，似乎是觉得 Replace 会导致这个内部事务过于复杂，所以没支持。总之会被刷进去。</p><h3 id="Bw-Tree-如何利用-LLAMA"><a href="#Bw-Tree-如何利用-LLAMA" class="headerlink" title="Bw-Tree 如何利用 LLAMA"></a>Bw-Tree 如何利用 LLAMA</h3><p>Bw-Tree 提供 Key-Value 接口，自己维护 LSN，根据事务接口并发控制和管理 Ckpt。通过 <code>Update-D</code>  和 <code>Update-R</code> 来更新/Consolidate。通过 <code>Allocate</code> 和 <code>Free</code> 来申请/收缩。</p><h2 id="Cache-Layer"><a href="#Cache-Layer" class="headerlink" title="Cache Layer"></a>Cache Layer</h2><p>可以视作，Cache Layer 对外提供了 Mapping Table 等抽象，并能够换出对应的内容。如我们在 Bw-Tree 所描述的一样，这里依靠 <code>Write Log</code>-&gt; <code>CAS mapping table</code> 一对操作来进行原子的写入。这里 Mapping 的内容会无论如何存储一个指向 LSS 中位置的指针，来作为 CAS 的主体，用户的指针也会携带一个对应的 LSS。</p><p>这节的内容其实比较 hacking，我估摸着得翻翻实现才能好理解。上面这段话说的比较绕，实际逻辑可以看下面，大概就是无论如何会放一个 <code>LogOffset</code>.</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[allow(clippy::module_name_repetitions)]</span></span><br><span class="line"><span class="meta">#[derive(Clone, Copy, PartialOrd, Ord, Eq, PartialEq, Hash)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">HeapId</span> &#123;</span><br><span class="line">    <span class="keyword">pub</span> location: <span class="type">u64</span>,</span><br><span class="line">    <span class="keyword">pub</span> original_lsn: Lsn,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// A pointer to a location on disk or an off-log heap item.</span></span><br><span class="line"><span class="comment">/// </span></span><br><span class="line"><span class="comment">/// (log_offxet, heap_id)</span></span><br><span class="line"><span class="meta">#[derive(Debug, Clone, Copy, PartialEq)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">enum</span> <span class="title class_">DiskPtr</span> &#123;</span><br><span class="line">    <span class="comment">/// Points to a value stored in the single-file log.</span></span><br><span class="line">    <span class="title function_ invoke__">Inline</span>(LogOffset),</span><br><span class="line">    <span class="comment">/// Points to a value stored off-log in the heap.</span></span><br><span class="line">    <span class="title function_ invoke__">Heap</span>(<span class="type">Option</span>&lt;NonZeroU64&gt;, HeapId),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>LLAMA 会存储成 Delta / Page, 大概是 <code>PID -&gt; Delta LSS -&gt; Delta LSS -&gt; Page</code>, 需要靠上层 <code>Update-R</code> 之类的来 consolidate.</p><p><img src="https://image.mwish.me/blog-image/450839E1-75FD-48DC-81E9-BC8E10FE04EE.png" alt="450839E1-75FD-48DC-81E9-BC8E10FE04EE"></p><h3 id="Flush-的原子性"><a href="#Flush-的原子性" class="headerlink" title="Flush 的原子性"></a>Flush 的原子性</h3><p>Flush 包括：</p><ol><li>拷贝到 LSS 的内容中</li><li>CAS 发布</li></ol><p>如果同时有更新，可能需要保证正在 copy 的内容不要和 flush 的流混了。这里它的策略如下：</p><ol><li>在 LSS Buffer 给 Allocate 一段 IO Buffer</li><li>创建一个 Flush Delta, 尝试 CAS 这个 LSS</li><li>(2) 成功了，就拷贝到 Buffer 中；否则在 Buffer 写一个 <code>FAILED_FLUSH</code> 记录，防止恢复的时候数据错误</li></ol><h3 id="Page-换出"><a href="#Page-换出" class="headerlink" title="Page 换出"></a>Page 换出</h3><p>这里允许记录或者 Page 换出，为了防止内容空悬，可以用一个 <code>PARTIAL SWAP</code> 记录表示内存中的结构 Swap 出去了：</p><p><img src="https://image.mwish.me/blog-image/8B64DF88-DD1E-4107-862A-A276B5313E76.png" alt="8B64DF88-DD1E-4107-862A-A276B5313E76"></p><p>这里还使用使用 Epoch Base Reclaim 来回收内存，不再赘述。</p><p><img src="https://image.mwish.me/blog-image/3E209D4B-B2B4-45F4-A240-C3643AA78B54.png" alt="3E209D4B-B2B4-45F4-A240-C3643AA78B54"></p><h2 id="Storage-Layer"><a href="#Storage-Layer" class="headerlink" title="Storage Layer"></a>Storage Layer</h2><p>这节说是 Storage Layer，其实就是介绍了它的 Log 写入层和一些 lock-free 的 WAL，和 LFS/MySQL 8.0 WAL 很像。LLAMA 这里没说怎么 GC，不过我感觉因为 Consolidation，早点的记录基本都能被清除掉。</p><p><img src="https://image.mwish.me/blog-image/7F968374-1EDD-41E9-BB82-683D2F88BECC.png" alt="7F968374-1EDD-41E9-BB82-683D2F88BECC"></p><p>比较关键的是 Flushing 部分，它希望 Flushing 是 lock-free 的，每个 Buffer 有一个固定大小。这里有几个控制字段：</p><ol><li>Sealed bit</li><li>Active writers</li><li>Offset</li></ol><p><img src="https://image.mwish.me/blog-image/78BF2138-B283-4EF7-BC9A-FF97521E1749.png" alt="78BF2138-B283-4EF7-BC9A-FF97521E1749"></p><p>那么实现的逻辑如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">WriteOnBuf(buf, data):</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">  (sealed, active_writers, offset) = buf.ctl.load()</span><br><span class="line">    <span class="keyword">if</span> (sealed):</span><br><span class="line">      去写另外的 Buf</span><br><span class="line">    offset += data.size()</span><br><span class="line">    <span class="keyword">if</span> offset 超过限制:</span><br><span class="line">      设置 sealed = <span class="literal">True</span></span><br><span class="line">    设置 writer += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> buf.ctl.cas():</span><br><span class="line">      <span class="keyword">break</span></span><br><span class="line">  拷贝 data 到给定的字段</span><br><span class="line">  cas 减少 writer, 如果 active writer = <span class="number">0</span> 且 Sealed, 推进拷贝到存储空间</span><br></pre></td></tr></table></figure><p>这里其实和 MySQL 那个 Lock-free WAL 协议很像。</p><h3 id="LSS-Clean-GC"><a href="#LSS-Clean-GC" class="headerlink" title="LSS Clean (GC)"></a>LSS Clean (GC)</h3><p>这里内容类似 LFS 或者 WiscKey。LSS 可以视作无限增长的，然后内容写在一个环状缓冲区上。</p><p>InnoDB 会两个 log 文件换着写，我觉得基本也就这个样子。</p><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>作为一个缝合怪，这里性能描述如下:</p><blockquote><p>First, there is no empty space in pages that are flushed. They are written as packed variable length strings. On average, traditional B-tree pages are only 69% utilized. Second, because we will frequently flush only deltas since the prior flush, much less space will be consumed per page flush. Finally</p></blockquote><p>我觉得没啥意思…</p><h2 id="System-Transaction"><a href="#System-Transaction" class="headerlink" title="System Transaction"></a>System Transaction</h2><p>这里不提供通用的事务，多个 Page 的更新可能会被 Partial 的读到。但是这里靠框架上的更新来处理这一点。</p><p>我上面说的话我自己读了一遍都没太懂，所以我贴个 Cow-Btree:</p><p><img src="https://image.mwish.me/blog-image/updated-btree.png" alt="updated-btree"></p><p>这里不是说 Bw-Tree 是 Cow-Btree, 不过其实差不多，这里 Split/Merge 本身是能够做到原子被看见的：</p><p><img src="https://image.mwish.me/blog-image/F06B0563-9E77-407A-85D8-086EF2A10580.png" alt="F06B0563-9E77-407A-85D8-086EF2A10580"></p><h2 id="Recovery"><a href="#Recovery" class="headerlink" title="Recovery"></a>Recovery</h2><p> 这里 Recover 其实挺类似 WiscKey Recover 的，麻烦在于恢复 Mapping Table。这里会定期写快照，然后 Replay log 来恢复。</p><p><img src="https://image.mwish.me/blog-image/EF1946C6-A748-4289-98A7-8EF5720F92C7.png" alt="EF1946C6-A748-4289-98A7-8EF5720F92C7"></p><h2 id="sled"><a href="#sled" class="headerlink" title="sled"></a>sled</h2><p>sled 是一个 LLAMA 的实现。它上层并没有用 Bw-Tree，用了一个 Epoch GC 的实现。这里有几个关键内容：</p><ol><li><code>IoBuf</code> 和 <code>IoBufs</code> 对应论文里面的无锁 Buffer，由 <code>Log</code> 包装。基本上实现了论文描述的内容。</li><li><code>PageTable</code> 是对应的 Mapping Table 的实现</li><li><code>Node</code> 代表 Page 或者 Delta, 用 link 添加新操作。这里由更新的次数来决定是否 consolidation</li><li><code>transaction.rs</code> 有事务相关的内容。</li><li>GC 使用 crossbeam 的 <code>crossbeam-epoch</code> 实现</li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li>[ICDE’13] <a href="https://15721.courses.cs.cmu.edu/spring2017/papers/08-oltpindexes2/bwtree-icde2013.pdf">The Bw-Tree: A B-tree for New Hardware Platforms</a></li><li>[PVLDB’13] LLAMA: A Cache/Storage Subsystem for Modern Hardware</li><li>[SIGMOD’18] Building a Bw-Tree Takes More Than Just Buzz Words</li><li>[PODS’21] ArkDB: A Key-Value Engine for Scalable Cloud Storage Services</li><li>Sled: <a href="https://docs.rs/sled/0.34.1/sled/doc/sled_architectural_outlook/index.html#caching">https://docs.rs/sled/0.34.1/sled/doc/sled_architectural_outlook/index.html#caching</a> (已不再维护)</li><li>数据库月报的 Bw-Tree 栏目：<a href="http://mysql.taobao.org/monthly/2018/11/01/">http://mysql.taobao.org/monthly/2018/11/01/</a></li><li>Indexing on Modern Hardware: Hekaton and Beyond</li><li><a href="https://github.com/spacejam/sled">https://github.com/spacejam/sled</a></li><li>CMU 15-721</li></ol><h3 id="二手材料"><a href="#二手材料" class="headerlink" title="二手材料"></a>二手材料</h3><ul><li>Bw-Tree技术解读 - 翰明的文章 - 知乎 <a href="https://zhuanlan.zhihu.com/p/29314464">https://zhuanlan.zhihu.com/p/29314464</a></li><li><a href="https://nan01ab.github.io/2019/09/LLAMA.html">https://nan01ab.github.io/2019/09/LLAMA.html</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Raft Basic Notes</title>
      <link href="/2022/04/15/Raft-Basic-Notes/"/>
      <url>/2022/04/15/Raft-Basic-Notes/</url>
      
        <content type="html"><![CDATA[<p>本来打算介绍 Etcd 的 Raft，然后抽离开视线来讲讲 etcd-raft 怎么用，它怎么抽象的。但是读了一下 raftexample 发现不太现实，感觉 etcd-raft 的外部逻辑和实现是严重耦合的，所以或许我们不得不从实现开始，了解一下 etcd-raft 大概提供了什么样的抽象, 然后再介绍一下官方的  raftexample 的内容，便于我们实现简单的 raft 服务器。</p><p>这里先复习一下 Basic Raft，然后 Paper 是一回事，怎么响应这个并发的事件这些也没啥问题，然后看看 <a href="https://github.com/Qihoo360/floyd">floyd</a> 这个项目是怎么实现的。</p><h2 id="Raft-复习"><a href="#Raft-复习" class="headerlink" title="Raft 复习"></a>Raft 复习</h2><p>基本上来面试的大佬都会 Raft，但我其实已经忘光了，这里尝试用最快的方式建起 Raft 的基本概念。以后有更新也尽量直接在这个地方补充。</p><p>另外，这里只介绍小论文里面的基础部分，小论文没提到的我都不太想介绍。工程优化太多了，最开始入门的时候还是不要搞太复杂，那么开始吧。</p><p>Raft 使用一个 RSM 模型：</p><p><img src="https://image.mwish.me/blog-image/170FFACD-191C-474F-833E-06A1A36E1150.png" alt="170FFACD-191C-474F-833E-06A1A36E1150"></p><p>额，这图其实做了一些暗示：</p><ol><li>Log 和 State Machine 是分开来存储的</li><li>通过某种回调来写 State Machine，写完之后才能通知 client</li></ol><p>那么进入算法部分，Raft 除了成员变更，基础算法包括：</p><ol><li>Leader Election</li><li>Log Replication</li><li>Safety</li></ol><p>同时，这里有需要持久化的内容表（暂不包括 snapshot）：</p><p><img src="https://image.mwish.me/blog-image/CABFCF9B-9C07-48C1-9718-380E659F5DD7.png" alt="CABFCF9B-9C07-48C1-9718-380E659F5DD7"></p><p>其实可以发现这部分非常非常精简。而 Log 包含的内容如下：</p><ol><li>Command for state machine (用户定义)</li><li>Leader Term (我感觉也相当于确定了 Leader)</li></ol><p>Raft 的 Invariant 有：</p><ol><li>对于一个给定的 Term，至多只有一个 Leader</li><li>Leader 不会 Truncate 自己的日志，它是 Append Only 的（这里涉及安全性一节）</li><li>对于任何两条日志，如果 <code>index</code> 和 <code>term</code> 相同，那么它们之前的内容都相同</li><li>如果某个 <code>term</code> 的 <code>Log</code> 被 Commit, 那么 <code>term</code> 比它大的所有 Leader 都应该包含它</li><li>一条已经 Apply 到状态机的日志，不会被在同一个位置提交（感觉是 trivial 的，推出 Commit 了才能 Apply？）</li></ol><p>RPC 包含：</p><ol><li>AppendEntries: 维护心跳包、同步 Log</li><li>RequestVote: 投票</li></ol><h3 id="Leader-Election"><a href="#Leader-Election" class="headerlink" title="Leader Election"></a>Leader Election</h3><ol><li>启动的时候，集群都是 follower</li><li>没有收到 Leader 的心跳包或者 Candidate 的选举，在 <code>electionTimeout</code> 的时间后，<strong>发起选举</strong></li></ol><p>若发起选举：</p><ol><li><code>++term</code>, 状态变成 <code>candidate</code>，广播 requestVoteRPC</li><li>给自己投票</li><li>在 <code>electionTimeout</code> 内收到 <code>1/n</code> 以上的选票，成为 <code>term</code> 的 leader</li></ol><p>对于 follower:</p><ol><li>对同一个 <code>term</code> 只能给出一个成功的 RequestVote</li></ol><p>(个人好奇，某个 candidate 收到了 term 更高的 candidate 的 RequestVote 信息，也会变为 follower)</p><h3 id="Log-Replication"><a href="#Log-Replication" class="headerlink" title="Log Replication"></a>Log Replication</h3><p>Leader 可以为 client 提供服务, 日志复制有几个位点：</p><ul><li><code>[snapshot/0, applied, committed, current log]</code></li></ul><p>Commit 的日志 Apply 到状态机是安全的，当:</p><ol><li>Leader 将 Log 复制到 1/2 以上的服务器时，就可以 Commit</li><li>在 Leader 将自己 term 的日志复制后，Leader 之前的日志 <em>可以 Commit</em> （这里有个问题，是说 Leader 之前的日志可以 commit，但不代表 Leader 自己的日志可以 Commit，然后这是可以 Commit）<ol><li>这里细节上有个 match 操作，会匹配到相同的日志，根据之前的性质，这之前的东西都相同了。然后可以覆盖。这个日志号叫 <code>nextIndex</code>, 不需要持久化</li><li>大部分情况是没有问题的，只有 Leader crash 的时候，可能出现这个问题</li></ol></li></ol><p>Leader 会给每个成员提供 <code>nextIndex</code> 和 <code>matchIndex</code>. <code>nextIndex</code> 表示下一次尝试对齐/同步的起始位置，<code>matchIndex</code> 表示已经对齐的位置。</p><p>上面说的部分是 Leader 做日志同步和提交的部分，日志同步的时候，Leader 的 <code>committed</code> 水位可能比 follower 高，需要推高 <code>follower</code> 的 <code>committed</code> 水位。Leader Committed 的推高应该是 <code>match</code> 成功才能使用的（就是同步成功）。</p><h3 id="Safety"><a href="#Safety" class="headerlink" title="Safety"></a>Safety</h3><p>这是最需要理解的一节。我们要保证 <code>Commit</code> 过的日志不会被覆盖。这一节的限制包括了 Leader Election 的限制，和选上之后如何处理之前未 <code>Commit</code> 的条目（其实我瞎想的是选 Commit 最大的，然后把别的都 Truncate 了，不过实际上这可能导致 Leader 最新推进的 <code>Commit</code> 没有提交）</p><p>选举限制：Candidate 的 RPC 包含日志信息，这里会给 <code>current log</code>, <code>follower</code> 在投票的时候，会拒绝掉 <code>candidate.current.term &lt; current_log.current.term || (candidate.current.term == current_log.current.term &amp;&amp; candidate.current.index &lt; current_log.current.index)</code> 的日志</p><blockquote><p>5.4.3 使用了反证法来证明它的正确性，任何 commit 日志必定复制到了 1/2 以上的机器，投票也要 1/2 以上的机器。新 Leader 拿到投票，必定已经包含了这条日志。</p></blockquote><p>之前 term 提交的限制：此外，Leader 必须靠提交一条自己 term 的日志，来保证之前的日志提交。</p><blockquote><p>Figure8 描述了这种场景，如果 Leader 单独提交之前的日志，那就会挂：<br><img src="https://image.mwish.me/blog-image/057E9A5F-8EAF-4482-B9C9-47E4BC31BC64.png" alt="057E9A5F-8EAF-4482-B9C9-47E4BC31BC64"></p></blockquote><p>对于 Follower Crash, 这里会发送 AppendEntities RPC, 直到日志对齐。</p><h4 id="一个误区"><a href="#一个误区" class="headerlink" title="一个误区"></a>一个误区</h4><p>之前看到下图，感觉很 confusing，不知道 <code>1 1 1 3</code> 那个是咋当选的：</p><p><img src="https://image.mwish.me/blog-image/committed.png" alt="committed"></p><p>后来发现，我原来的想法是有一点误区的。Leader 的 Commit 必须要日志过半，但能够被选为 Leader，它一定包含已 Commit 的最后日志，所以，覆盖别的日志是安全的。然后我的误区是，<code>AppendEntities RPC</code> 必须和 Commit 类似，要一下补齐用户丢失的所有 Log。但 <code>AppendEntities RPC</code> 的 Logs 实际上是可以一条一条发的。</p><h4 id="CommitIndex-和-ApplyIndex-的持久化"><a href="#CommitIndex-和-ApplyIndex-的持久化" class="headerlink" title="CommitIndex 和 ApplyIndex 的持久化"></a>CommitIndex 和 ApplyIndex 的持久化</h4><p>本来这部分在作者 PHD 论文里面介绍的很细，本质上 commitIndex 和 applyIndex 都是可以恢复出来的。不过工程上，可以根据幂等之类的语义，持久化以优化 applyIndex.</p><p>话说我前年在逼乎好像提过这个问题：<a href="https://www.zhihu.com/question/382888510">https://www.zhihu.com/question/382888510</a></p><h3 id="时间和可用性"><a href="#时间和可用性" class="headerlink" title="时间和可用性"></a>时间和可用性</h3><p><code>broadcastTime &lt;&lt; electionTimeout &lt;&lt; MTBF</code> 以 TiKV 为例，这个 timeout 是 10S: <a href="https://asktug.com/t/tikv-raft-election-timeout-10s/999">https://asktug.com/t/tikv-raft-election-timeout-10s/999</a> 。</p><p>broadcastTime 也应该比 electionTimeout 小一个数量级。这里有个问题是，这个时间是怎么决定的呢？实际上 <code>broadcastTime</code> 一多，本身心跳也会多，然后 TiKV 本身是 multi-raft 什么的，心跳包数量会非常多，然后这个时间短会把集群打爆，所以时间可以设置长点。论文里推荐的时间是：</p><blockquote><p>Raft’s RPCs typically require the recipient to persist information to stable storage, so the broadcast time may range from 0.5ms to 20ms, depending on storage technology. As a result, the election timeout is likely to be somewhere between 10ms and 500ms.</p></blockquote><p>这几个时间还是很重要的，我感觉很多是在 0-1.5 倍这个时间选出来的？</p><h3 id="集群成员变更"><a href="#集群成员变更" class="headerlink" title="集群成员变更"></a>集群成员变更</h3><p>Raft Group 可能一般就是 3、5个成员，但是因为机器变更导致的 membership change 会是线上低频但一直有的行为。我们首先想的是，通过一条内部的 Log，即 <code>旧配置 -&gt; 新配置</code> 的 Log，来切换到新配置的状态。但有个问题是，配置从 $C<em>{old}$ 切成 $C</em>{new}$ 的时候，可能有下图所示的状态：</p><p><img src="https://image.mwish.me/blog-image/v2-45dd50e08934f1dfc42dbc83251bfe76_r.jpeg" alt="v2-45dd50e08934f1dfc42dbc83251bfe76_r"></p><p>在这里，$C<em>{old}$ 是 <code>&#123;1, 2, 3&#125;</code>，$C</em>{new}$ 是 <code>&#123;1, 2, 3, 4, 5&#125;</code>，比方说 Server 3 是 Leader，同步了 membership change 的日志，然后 commit 了，1和2收到了信息，但是没有 Commit，这个时候，1、2 中的选举可以给对方投票，因为满足安全性；3、4、5 同理，结果是这里有两个 Majority 了（<code>2/3</code> 和 <code>3/5</code>）。</p><p>这个时候，Raft 会切入到一个过渡时期，叫 <code>Joint Consensus</code>，它需要理解两种配置：</p><ol><li>$C<em>{new}$ 和 $C</em>{old}$ 任何一个机器都可以成为 Leader</li><li>Election 和 Commit 都需要 $C<em>{new}$ 和 $C</em>{old}$ <strong>双方</strong> 的 Majority</li></ol><p>Joint Consensus 引入了一个 $C_{old, new}$ 中间状态，如下图：</p><p><img src="https://image.mwish.me/blog-image/487347AA-3308-4821-B662-2F8EE3720BFB.png" alt="487347AA-3308-4821-B662-2F8EE3720BFB"></p><p>加入 $C<em>{old, new}$ 这样的配置变更日志之后，**即使这条变更日志没有 Commit, 集群也会采用它指定的 Conf，这表示，变更日志会在 $C</em>{old, new}$ 达成 Majority 后提交**. 一旦 $C<em>{old, new}$ 提交了，那么，只有采用这个配置的集群可以成为 Leader。这个时候，Leader 可以再创建一条 $C</em>{new}$ 的日志，提交完成之后，$C<em>{new} - C</em>{old}$ 集合中的服务器可以关掉了。</p><blockquote><p>正确性: $C<em>{old}$ 和 $C</em>{new}$ 如 Figure 11，会在不同的时间内生效，由 $C_{old, new}$ 提交为 Barrier。</p></blockquote><p>问题：</p><ol><li>新加入的机器，没有任何日志，可能要 <code>InstallSnapshot</code> 或经过长期同步？<ol><li>这里引入了 Learner，不需要投票、只接收 Leader 日志的阶段。</li></ol></li><li>在 Propose $C<em>{new}$ 的时候，Leader 可能并不在 $C</em>{new}$ 中。这个协议还是可以运行的，但是 <code>Majority</code> 并不包括 Leader。在 $C_{new}$ 提交之后，才能发生 Leader 转移。</li><li>采用新配置时，旧配置没有收到 Heartbeat，可能 <code>++term</code> 然后变 candidate，随之会影响一些没收到 $C_{new}$ 日志的机器，把它们 term 也搞起来。这里的方案是，Leader 存在的时候，不会切 Leader 重新选举；然后 Server 在一次选举之间，如果收到了更高 <code>term</code> 的请求，也要等待一定时间，防止心跳把自己打炸</li></ol><p>那么，为什么 <code>Conf</code> 需要直接用 new 的呢？走 Committed 在进入下一阶段的目的是在第一阶段达成两方的 Majority，第二阶段只需要新的 Majority，它们不相交。而直接用的目的是不用追踪大部分机器的 <code>CommitIndex</code>:</p><blockquote><p>If servers adopted $C<em>{new}$ only when they learned that $C</em>{new}$ was committed, Raft leaders would have a difficult time knowing when a majority of the old cluster had adopted it. They would need to track which servers know of the entry’s commitment, and the servers would need to persist their commit index to disk; neither of these mechanisms is required in Raft. Instead, each server adopts $C<em>{new}$ as soon as that entry exists in its log, and the leader knows it’s safe to allow further conﬁguration changes as soon as the $C</em>{new}$ entry has been committed. Unfortunately, this decision does imply that a log entry for a conﬁguration change can be removed (if leadership changes); in this case, a server must be prepared to fall back to the previous conﬁguration in its log.</p></blockquote><p>有的地方实现会采用单步变更，但是实际上单步变更会导致一定的集群不可用问题，详见：作者的 <a href="https://github.com/ongardie/dissertation#chapter-4-cluster-membership-changes">https://github.com/ongardie/dissertation#chapter-4-cluster-membership-changes</a> 和二手文章 <a href="https://zhuanlan.zhihu.com/p/359206808">https://zhuanlan.zhihu.com/p/359206808</a></p><h3 id="Snapshot-和-Log-Compaction"><a href="#Snapshot-和-Log-Compaction" class="headerlink" title="Snapshot 和 Log Compaction"></a>Snapshot 和 Log Compaction</h3><p>Snapshot 的职责归功于状态机，而非 Raft。它应用于已经 <code>Applied</code> 的数据，然后由各个机器 <strong>分别</strong> 进行，通过 InstallSnapshot 传输。（InstallSnapshot 还可以分多次发，神必）</p><p>作者认为，Log Compaction 是非 Leader 主导的，但是毕竟是已经 Applied 的数据了，所以也没那么 Care。</p><p>在收到 Snapshot 之后，可以 Truncate 后续的 Log，等 AppendEntities 把自己整活了。这个时候估摸着也可以是个 Learner 啥的，不给系统瞎 vote 添乱。</p><h3 id="Client-交互"><a href="#Client-交互" class="headerlink" title="Client 交互"></a>Client 交互</h3><h4 id="一般的读写操作"><a href="#一般的读写操作" class="headerlink" title="一般的读写操作"></a>一般的读写操作</h4><p>Raft 是一个 Leader-Based 的一致性协议，下面的形式是为了保证 Linearizable 而要求的</p><p>一般的写消息要么会让 client 走到 Leader 上，要么从节点负责转发给 Leader，而 Apply 之后能够收到消息。如果 Leader Crash 了，这些操作可能就 Timeout。而读操作可以依靠在读发出后，写一条 no-op 或者等待写操作完成，来做相关的保证（总之，收到读请求到读状态机之间，一定要有一条日志，来保证同步完成）。读也可以使用大论文描述的 Lease。</p><p>当然，Zookeeper 允许本地读，这种方式只能保证 Serializable (Zookeeper 论文提的是 A-Linearizable)。</p><h4 id="写重试"><a href="#写重试" class="headerlink" title="写重试"></a>写重试</h4><p>对于写，可以给每个请求一个 Seq，重试的时候，论文提到，可以维护一个 seq，发现 FSM 里面有这个 seq，可以直接返回成功。当然这肯定没问题，但万一是没 commit 或者 commit 了的没同步，怎么办呢？这里可以：</p><ol><li>Apply 的阶段，做 Seq 的去重</li><li>维护一个集合，来区分 <code>&#123;Commit 但没有 Apply&#125;</code> 和 <code>&#123;没有 Commit&#125;</code> 的 Seq 集合。</li></ol><h2 id="Some-Quiz"><a href="#Some-Quiz" class="headerlink" title="Some Quiz"></a>Some Quiz</h2><p>Quiz 可以见：<a href="https://ongardie.net/static/raft/userstudy/quizzes.html">https://ongardie.net/static/raft/userstudy/quizzes.html</a></p><p>老实说我 2 错了，因为实在不知道那个为 <code>1 1 1 3</code> 的是怎么当选的…详细原因可以看我 Safety 那节下面的勘误。</p><h2 id="Qihoo360-floyd"><a href="#Qihoo360-floyd" class="headerlink" title="Qihoo360/floyd"></a>Qihoo360/floyd</h2><p>Qihoo360/floyd 是一个简单的 Raft 实现，它提供了 KV、分布式锁的功能。相对 Etcd 提供一个轻量的 Raft 模块，floyd 耦合的比较重，甚至把存储数据、Log、Raft 的 Index 等信息都丢到了一个 CF，很多 C++ 代码感觉也写的比较乱。但它差不多只有数千行，而且展示了如何实现一个 Basic Raft。这些还是比较重要的，因为本身实现一个并发的状态机就要有各种坑，你可能还要处理 RPC 的各种 corner case。所以有个简单的项目借鉴还是求之不得。</p><p>它对 Raft 论文支持如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">功能</th><th>是否支持</th></tr></thead><tbody><tr><td style="text-align:center">领导选举/日志同步/安全性</td><td>是</td></tr><tr><td style="text-align:center">Client</td><td>是</td></tr><tr><td style="text-align:center">Log Compaction</td><td>否</td></tr><tr><td style="text-align:center">Membership Change</td><td>有支持单步变更的接口，但没实现</td></tr><tr><td style="text-align:center">Learner</td><td>无</td></tr></tbody></table></div><p><code>floyd/include/floyd.h</code> 表示了它对外的接口，简单表示如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Floyd</span>  &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">static</span> Status <span class="title">Open</span><span class="params">(<span class="type">const</span> Options&amp; options, Floyd** floyd)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">Floyd</span>() &#123; &#125;</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">Floyd</span>();</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Write</span><span class="params">(<span class="type">const</span> std::string&amp; key, <span class="type">const</span> std::string&amp; value)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Delete</span><span class="params">(<span class="type">const</span> std::string&amp; key)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Read</span><span class="params">(<span class="type">const</span> std::string&amp; key, std::string* value)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">DirtyRead</span><span class="params">(<span class="type">const</span> std::string&amp; key, std::string* value)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// ttl is millisecond</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">TryLock</span><span class="params">(<span class="type">const</span> std::string&amp; name, <span class="type">const</span> std::string&amp; holder, <span class="type">uint64_t</span> ttl)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">UnLock</span><span class="params">(<span class="type">const</span> std::string&amp; name, <span class="type">const</span> std::string&amp; holder)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// return true if leader has been elected</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">GetLeader</span><span class="params">(std::string* ip_port)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">GetLeader</span><span class="params">(std::string* ip, <span class="type">int</span>* port)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">HasLeader</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">IsLeader</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">GetAllServers</span><span class="params">(std::set&lt;std::string&gt;* nodes)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// used for debug</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">GetServerStatus</span><span class="params">(std::string* msg)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// log level can be modified</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">set_log_level</span><span class="params">(<span class="type">const</span> <span class="type">int</span> log_level)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// No coping allowed</span></span><br><span class="line">  <span class="built_in">Floyd</span>(<span class="type">const</span> Floyd&amp;);</span><br><span class="line">  <span class="type">void</span> <span class="keyword">operator</span>=(<span class="type">const</span> Floyd&amp;);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>而 <code>example/simple/t.cc</code> 描述了一个简单的使用 Case，非常简单易懂：<a href="https://github.com/mapleFU/floyd-notes/blob/mwish-notes/floyd/example/simple/t.cc#L18">https://github.com/mapleFU/floyd-notes/blob/mwish-notes/floyd/example/simple/t.cc#L18</a></p><p>它内部实现如下（我图画的有点乱，以自己看得懂为准，有修改意见可以随便喷）：</p><p><img src="https://image.mwish.me/blog-image/DDAC89FE-87C2-4E59-9657-CEC2EB3721B8.png" alt="DDAC89FE-87C2-4E59-9657-CEC2EB3721B8"></p><ul><li>部分消息的结构体定义在 <code>proto/floyd.proto</code>，包括 Raft 日志的结构和状态机的日志结构</li><li>持久状态存储在 RocksDB 中，有下列两类<ul><li><code>RaftLog</code>: 存储论文中的 <code>Log[]</code></li><li><code>RaftMeta</code>: 存储 Term, VoteFor, commitIndex, applyIndex，后两者在 Raft Paper 中不要求持久化, 不过工程上持久化一下也没啥毛病。任何一个 Get/Set 接口, RaftMeta 本身都不会走缓存(可能有 RocksDB 的 Cache), 直接进 RocksDB.</li></ul></li><li>共享的状态被封装到 <code>FloydContext</code> 中，它持有 <code>RaftLog</code> 和 <code>RaftMeta</code> 的状态，在各个对象间共享，Commit 推高 Commit 后，会提高 <code>FloydContext</code> 中的内存状态，而触发 <code>Apply</code>，同时，Apply 也会更新这个状态。它负责逻辑比较混杂：<ul><li>[Persistent] 负责读取 <code>RaftMeta</code>，维护 <code>commitIndex</code>、<code>applyIndex</code>、<code>voteFor</code>、<code>term</code> 等</li><li>[Volatile] 负责集群的 Role，一些内存 <code>BecomeLeader</code> <code>BecomeFollower</code> 的逻辑会走它。</li></ul></li><li>FloydApply 将 Committed 的用户日志 <code>Apply</code> 到数据存储中</li><li>Peers会存放一些配置的 IP，以及仅对 Leader 有用的 <code>nextIndex</code> 和 <code>matchIndex</code></li></ul><p>在这里，系统中也有不少线程，最主要的是：</p><ol><li><code>floyd_primary_thread</code>：只有一个的线程，负责定时发起 HeartBeat（<code>AppendEntities RPC</code>）、检查 Leader （查看是否 electionTimeout）、处理用户的 RPC</li><li><code>floyd_peer_thread</code>：理论上，Raft Group 每个成员，这里都会多一个 <code>floyd_peer_thread</code>。它负责给每个成员发送 RPC，并通过 <code>FloydContext</code> 来变更状态.</li></ol><h3 id="Leader-Election-1"><a href="#Leader-Election-1" class="headerlink" title="Leader Election"></a>Leader Election</h3><h4 id="Sender"><a href="#Sender" class="headerlink" title="Sender"></a>Sender</h4><p>一个 <code>FloydImpl</code> 启动后，<code>floyd_primary_thread</code> 会检查自己的状态，如果 timeout 了，可能要变更为 Candidate. 注意变成 Candidate 之后，递增了 Term，然后给了自己一票。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//! 如果没有 Leader, 把自身变成 Candidate, 然后通知 Peer 线程.</span></span><br><span class="line"><span class="comment">//! 再触发一个 CheckLeader, 相当于 ElectionTimeout.</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">FloydPrimary::LaunchCheckLeader</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="function">slash::MutexLock <span class="title">l</span><span class="params">(&amp;context_-&gt;global_mu)</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (context_-&gt;role == Role::kFollower || context_-&gt;role == Role::kCandidate) &#123;</span><br><span class="line">    <span class="keyword">if</span> (options_.single_mode) &#123;</span><br><span class="line">      <span class="comment">// 忽略 SingleMode</span></span><br><span class="line">...</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (context_-&gt;last_op_time + options_.check_leader_us &lt; slash::<span class="built_in">NowMicros</span>()) &#123;</span><br><span class="line">      context_-&gt;<span class="built_in">BecomeCandidate</span>();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 吐槽: 实现上下面进行了 3次 RocksDB Batch 写, 因为每次 Set 都会写, 这是真的牛批...</span></span><br><span class="line">      raft_meta_-&gt;<span class="built_in">SetCurrentTerm</span>(context_-&gt;current_term);</span><br><span class="line">      raft_meta_-&gt;<span class="built_in">SetVotedForIp</span>(context_-&gt;voted_for_ip);</span><br><span class="line">      raft_meta_-&gt;<span class="built_in">SetVotedForPort</span>(context_-&gt;voted_for_port);</span><br><span class="line">      <span class="built_in">NoticePeerTask</span>(kHeartBeat);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 在 ElectionTimeout 之后, 尝试再次调度 checkLeader</span></span><br><span class="line">  <span class="built_in">AddTask</span>(kCheckLeader);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// when adding task to peer thread, we can consider that this job have been in the network</span></span><br><span class="line"><span class="comment">// even it is still in the peer thread&#x27;s queue</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">FloydPrimary::NoticePeerTask</span><span class="params">(TaskType type)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; peer : (*peers_)) &#123;</span><br><span class="line">    <span class="keyword">switch</span> (type) &#123;</span><br><span class="line">    <span class="keyword">case</span> kHeartBeat:</span><br><span class="line">      peer.second-&gt;<span class="built_in">AddRequestVoteTask</span>();</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> kNewCommand:</span><br><span class="line">      peer.second-&gt;<span class="built_in">AddAppendEntriesTask</span>();</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里会用 <code>RequestVote</code> 来做 kHeartbeat（你可能会很奇怪，Heartbeat 不是 AppendEntry 吗？不过它 AppendEntry 又会走到 <code>kNewCommand</code>，我觉得有点乱），然后触发所有 <code>Peer</code> 线程的 <code>RequestVote</code>，触发如下内容：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Peer::RequestVoteRPC</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">uint64_t</span> last_log_term;</span><br><span class="line">  <span class="type">uint64_t</span> last_log_index;</span><br><span class="line">  CmdRequest req;</span><br><span class="line"><span class="comment">// 初始化 RequestVote RPC</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="function">slash::MutexLock <span class="title">l</span><span class="params">(&amp;context_-&gt;global_mu)</span></span>;</span><br><span class="line">    raft_log_-&gt;<span class="built_in">GetLastLogTermAndIndex</span>(&amp;last_log_term, &amp;last_log_index);</span><br><span class="line"></span><br><span class="line">    req.<span class="built_in">set_type</span>(Type::kRequestVote);</span><br><span class="line">    CmdRequest_RequestVote* request_vote = req.<span class="built_in">mutable_request_vote</span>();</span><br><span class="line">    request_vote-&gt;<span class="built_in">set_ip</span>(options_.local_ip);</span><br><span class="line">    request_vote-&gt;<span class="built_in">set_port</span>(options_.local_port);</span><br><span class="line">    request_vote-&gt;<span class="built_in">set_term</span>(context_-&gt;current_term);</span><br><span class="line">    request_vote-&gt;<span class="built_in">set_last_log_term</span>(last_log_term);</span><br><span class="line">    request_vote-&gt;<span class="built_in">set_last_log_index</span>(last_log_index);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 同步发送请求.</span></span><br><span class="line">  CmdResponse res;</span><br><span class="line">  Status result = pool_-&gt;<span class="built_in">SendAndRecv</span>(peer_addr_, req, &amp;res);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!result.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">  <span class="function">slash::MutexLock <span class="title">l</span><span class="params">(&amp;context_-&gt;global_mu)</span></span>;</span><br><span class="line">  <span class="comment">// RequestVote 发生 RPC 错误</span></span><br><span class="line">  <span class="keyword">if</span> (!result.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/***</span></span><br><span class="line"><span class="comment">   * 下列为正常的 Raft 处理逻辑</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 对方的 Term 比自身高, 设置状态为 Follower, 更新 Term.</span></span><br><span class="line">  <span class="keyword">if</span> (res.<span class="built_in">request_vote_res</span>().<span class="built_in">term</span>() &gt; context_-&gt;current_term) &#123;</span><br><span class="line">    <span class="comment">// RequestVote fail, maybe opposite has larger term, or opposite has</span></span><br><span class="line">    <span class="comment">// longer log. if opposite has larger term, this node will become follower</span></span><br><span class="line">    <span class="comment">// otherwise we will do nothing</span></span><br><span class="line">    context_-&gt;<span class="built_in">BecomeFollower</span>(res.<span class="built_in">request_vote_res</span>().<span class="built_in">term</span>());</span><br><span class="line">    raft_meta_-&gt;<span class="built_in">SetCurrentTerm</span>(context_-&gt;current_term);</span><br><span class="line">    <span class="comment">// 实际上相当于清空 ip/port.</span></span><br><span class="line">    raft_meta_-&gt;<span class="built_in">SetVotedForIp</span>(context_-&gt;voted_for_ip);</span><br><span class="line">    raft_meta_-&gt;<span class="built_in">SetVotedForPort</span>(context_-&gt;voted_for_port);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 如果自身状态还是 Follower, 且对方的 Term 不比自己高, 那么要么投给自己, 要么没投.</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (context_-&gt;role == Role::kCandidate) &#123;</span><br><span class="line">    <span class="comment">// kOk means RequestVote success, opposite vote for me</span></span><br><span class="line">    <span class="keyword">if</span> (res.<span class="built_in">request_vote_res</span>().<span class="built_in">vote_granted</span>() == <span class="literal">true</span>) &#123;    <span class="comment">// granted</span></span><br><span class="line">      <span class="comment">// However, we need check whether this vote is vote for old term</span></span><br><span class="line">      <span class="comment">// we need ignore these type of vote.</span></span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      <span class="comment">// 可以成为 Leader 啦!</span></span><br><span class="line">      <span class="keyword">if</span> (<span class="built_in">CheckAndVote</span>(res.<span class="built_in">request_vote_res</span>().<span class="built_in">term</span>())) &#123;</span><br><span class="line">        context_-&gt;<span class="built_in">BecomeLeader</span>();</span><br><span class="line">        <span class="built_in">UpdatePeerInfo</span>();</span><br><span class="line">        primary_-&gt;<span class="built_in">AddTask</span>(kHeartBeat, <span class="literal">false</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// Note(mwish): 对方没有投票给自己, 怎么就变成 Follower 了.</span></span><br><span class="line">      <span class="comment">// 这个地方没有 Bug(因为 context_ 变更不会导致错误), 但是会很容易引起 bug</span></span><br><span class="line">      <span class="comment">// 我觉得可以全部 comment 掉.</span></span><br><span class="line">      context_-&gt;<span class="built_in">BecomeFollower</span>(res.<span class="built_in">request_vote_res</span>().<span class="built_in">term</span>());</span><br><span class="line">      raft_meta_-&gt;<span class="built_in">SetCurrentTerm</span>(context_-&gt;current_term);</span><br><span class="line">      raft_meta_-&gt;<span class="built_in">SetVotedForIp</span>(context_-&gt;voted_for_ip);</span><br><span class="line">      raft_meta_-&gt;<span class="built_in">SetVotedForPort</span>(context_-&gt;voted_for_port);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里在状态变更的时候，持有了 <code>global_mu_</code>，然后有个「半数选票」的逻辑：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//! 如果非本 term, 则无效, 否则 increment vote_quorum, 然后返回本 term 是否达到 1/2.</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">Peer::CheckAndVote</span><span class="params">(<span class="type">uint64_t</span> vote_term)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 检测 ABA 问题.</span></span><br><span class="line">  <span class="keyword">if</span> (context_-&gt;current_term != vote_term) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 半数检查</span></span><br><span class="line">  <span class="keyword">return</span> (++context_-&gt;vote_quorum) &gt; (options_.members.<span class="built_in">size</span>() / <span class="number">2</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Receiver"><a href="#Receiver" class="headerlink" title="Receiver"></a>Receiver</h4><p>此外，对应处理 <code>RequestVote RPC</code> 的逻辑涉及选举和安全性, 内容如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//! 响应投票 RPC.</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">FloydImpl::ReplyRequestVote</span><span class="params">(<span class="type">const</span> CmdRequest&amp; request, CmdResponse* response)</span> </span>&#123;</span><br><span class="line">  <span class="function">slash::MutexLock <span class="title">l</span><span class="params">(&amp;context_-&gt;global_mu)</span></span>;</span><br><span class="line">  <span class="type">bool</span> granted = <span class="literal">false</span>;</span><br><span class="line">  CmdRequest_RequestVote request_vote = request.<span class="built_in">request_vote</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * If RPC request or response contains term T &gt; currentTerm: set currentTerm = T, convert to follower (5.1)</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * 变成 follower, 然后设置 VoteFor.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">if</span> (request_vote.<span class="built_in">term</span>() &gt; context_-&gt;current_term) &#123;</span><br><span class="line">    context_-&gt;<span class="built_in">BecomeFollower</span>(request_vote.<span class="built_in">term</span>()); <span class="comment">// 推高自己的 term.</span></span><br><span class="line">    raft_meta_-&gt;<span class="built_in">SetCurrentTerm</span>(context_-&gt;current_term);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// if caller&#x27;s term smaller than my term, then I will notice him</span></span><br><span class="line">  <span class="keyword">if</span> (request_vote.<span class="built_in">term</span>() &lt; context_-&gt;current_term) &#123;</span><br><span class="line">    <span class="built_in">LOGV</span>(INFO_LEVEL, info_log_, <span class="string">&quot;FloydImpl::ReplyRequestVote: Leader %s:%d term %lu is smaller than my %s:%d current term %lu&quot;</span>,</span><br><span class="line">        request_vote.<span class="built_in">ip</span>().<span class="built_in">c_str</span>(), request_vote.<span class="built_in">port</span>(), request_vote.<span class="built_in">term</span>(), options_.local_ip.<span class="built_in">c_str</span>(), options_.local_port,</span><br><span class="line">        context_-&gt;current_term);</span><br><span class="line">    <span class="built_in">BuildRequestVoteResponse</span>(context_-&gt;current_term, granted, response);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 论文: 安全性, 不能给 Log 比自己旧的投票.</span></span><br><span class="line"></span><br><span class="line">  <span class="type">uint64_t</span> my_last_log_term = <span class="number">0</span>;</span><br><span class="line">  <span class="type">uint64_t</span> my_last_log_index = <span class="number">0</span>;</span><br><span class="line">  raft_log_-&gt;<span class="built_in">GetLastLogTermAndIndex</span>(&amp;my_last_log_term, &amp;my_last_log_index);</span><br><span class="line">  <span class="comment">// if votedfor is null or candidateId, and candidated&#x27;s log is at least as up-to-date</span></span><br><span class="line">  <span class="comment">// as receiver&#x27;s log, grant vote</span></span><br><span class="line">  <span class="keyword">if</span> ((request_vote.<span class="built_in">last_log_term</span>() &lt; my_last_log_term) ||</span><br><span class="line">      ((request_vote.<span class="built_in">last_log_term</span>() == my_last_log_term) &amp;&amp; (request_vote.<span class="built_in">last_log_index</span>() &lt; my_last_log_index))) &#123;</span><br><span class="line">    <span class="built_in">BuildRequestVoteResponse</span>(context_-&gt;current_term, granted, response);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// vote_for 不能给这个 term 已经投过票的做操作.</span></span><br><span class="line">  <span class="keyword">if</span> (vote_for_.<span class="built_in">find</span>(request_vote.<span class="built_in">term</span>()) != vote_for_.<span class="built_in">end</span>()</span><br><span class="line">      &amp;&amp; vote_for_[request_vote.<span class="built_in">term</span>()] != std::<span class="built_in">make_pair</span>(request_vote.<span class="built_in">ip</span>(), request_vote.<span class="built_in">port</span>())) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 给予选票.</span></span><br><span class="line">  vote_for_[request_vote.<span class="built_in">term</span>()] = std::<span class="built_in">make_pair</span>(request_vote.<span class="built_in">ip</span>(), request_vote.<span class="built_in">port</span>());</span><br><span class="line">  context_-&gt;<span class="built_in">BecomeFollower</span>(request_vote.<span class="built_in">term</span>());</span><br><span class="line">  <span class="comment">// Note(mwish): -&gt; 难道这个地方不应该做一个 Batch Op 的吗, orz...</span></span><br><span class="line">  raft_meta_-&gt;<span class="built_in">SetCurrentTerm</span>(context_-&gt;current_term);</span><br><span class="line">  raft_meta_-&gt;<span class="built_in">SetVotedForIp</span>(context_-&gt;voted_for_ip);</span><br><span class="line">  raft_meta_-&gt;<span class="built_in">SetVotedForPort</span>(context_-&gt;voted_for_port);</span><br><span class="line">  <span class="comment">// Got my vote</span></span><br><span class="line">  <span class="built_in">GrantVote</span>(request_vote.<span class="built_in">term</span>(), request_vote.<span class="built_in">ip</span>(), request_vote.<span class="built_in">port</span>());</span><br><span class="line">  granted = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">  context_-&gt;last_op_time = slash::<span class="built_in">NowMicros</span>();</span><br><span class="line">  <span class="built_in">BuildRequestVoteResponse</span>(context_-&gt;current_term, granted, response);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="竞选失败"><a href="#竞选失败" class="headerlink" title="竞选失败"></a>竞选失败</h4><p>如果没有 Leader, <code>floyd_primary_thread</code> 会不停调用 <code>CheckLeader</code>，这里的条件是：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">context_-&gt;last_op_time + options_.check_leader_us &lt; slash::<span class="built_in">NowMicros</span>()</span><br></pre></td></tr></table></figure><p>这里会根据 <code>last_op_time</code> 来 Leader 相关的操作时间。接收成功的 <code>RequestVote</code> 和任何 <code>AppendEntities</code> 都会更新这个时间（题外话，这里不是有效 Leader 的 <code>AppendEntities</code> 都会更新，可能是 Leader 心跳包是 <code>RequestVote</code>，我觉得 tmd 好诡异）</p><h3 id="Log-Replication-1"><a href="#Log-Replication-1" class="headerlink" title="Log Replication"></a>Log Replication</h3><p>外部的请求会走到 <code>AppendEntries</code></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">FloydPrimary::NoticePeerTask</span><span class="params">(TaskType type)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; peer : (*peers_)) &#123;</span><br><span class="line">    <span class="keyword">switch</span> (type) &#123;</span><br><span class="line">    <span class="keyword">case</span> kHeartBeat:</span><br><span class="line">...</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> kNewCommand:</span><br><span class="line">      peer.second-&gt;<span class="built_in">AddAppendEntriesTask</span>();</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们回忆一下，选上 Leader 的时候会做一些初始化：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//! 成为了 Leader, 可以更新 Peer 的信息了.</span></span><br><span class="line"><span class="comment">//! Q: 这个地方不会有并发吗...</span></span><br><span class="line"><span class="comment">//! A: 你本机理论上只有 Leader 线程会改，相对论保证你没有并发.</span></span><br><span class="line"><span class="comment">//!</span></span><br><span class="line"><span class="comment">//! 初始化 nextIndex 为 Leader 的 index, matchIndex 为 0.</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Peer::UpdatePeerInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; pt : (*peers_)) &#123;</span><br><span class="line">    pt.second-&gt;<span class="built_in">set_next_index</span>(raft_log_-&gt;<span class="built_in">GetLastLogIndex</span>() + <span class="number">1</span>);</span><br><span class="line">    pt.second-&gt;<span class="built_in">set_match_index</span>(<span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数比较长，我们会分几部分讲，并顺便介绍 <code>Peer</code> 。第一部分是构造和发送请求：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Peer::AppendEntriesRPC</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">uint64_t</span> prev_log_index = <span class="number">0</span>;</span><br><span class="line">  <span class="type">uint64_t</span> num_entries = <span class="number">0</span>;</span><br><span class="line">  <span class="type">uint64_t</span> prev_log_term = <span class="number">0</span>;</span><br><span class="line">  <span class="type">uint64_t</span> last_log_index = <span class="number">0</span>;</span><br><span class="line">  <span class="type">uint64_t</span> current_term = <span class="number">0</span>;</span><br><span class="line">  CmdRequest req;</span><br><span class="line">  CmdRequest_AppendEntries* append_entries = req.<span class="built_in">mutable_append_entries</span>();</span><br><span class="line">  &#123;</span><br><span class="line">  <span class="function">slash::MutexLock <span class="title">l</span><span class="params">(&amp;context_-&gt;global_mu)</span></span>;</span><br><span class="line">  prev_log_index = next_index_ - <span class="number">1</span>;</span><br><span class="line">  last_log_index = raft_log_-&gt;<span class="built_in">GetLastLogIndex</span>();</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * LOGV(INFO_LEVEL, info_log_, &quot;Peer::AppendEntriesRPC: next_index_ %d last_log_index %d peer_last_op_time %lu nowmicros %lu&quot;,</span></span><br><span class="line"><span class="comment">   *     next_index_.load(), last_log_index, peer_last_op_time, slash::NowMicros());</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">if</span> (next_index_ &gt; last_log_index &amp;&amp; peer_last_op_time + options_.heartbeat_us &gt; slash::<span class="built_in">NowMicros</span>()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  peer_last_op_time = slash::<span class="built_in">NowMicros</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (prev_log_index != <span class="number">0</span>) &#123;</span><br><span class="line">    Entry entry;</span><br><span class="line">    <span class="keyword">if</span> (raft_log_-&gt;<span class="built_in">GetEntry</span>(prev_log_index, &amp;entry) != <span class="number">0</span>) &#123;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      prev_log_term = entry.<span class="built_in">term</span>();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  current_term = context_-&gt;current_term;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 下面这些和论文一样.</span></span><br><span class="line">  </span><br><span class="line">  req.<span class="built_in">set_type</span>(Type::kAppendEntries);</span><br><span class="line">  append_entries-&gt;<span class="built_in">set_ip</span>(options_.local_ip);</span><br><span class="line">  append_entries-&gt;<span class="built_in">set_port</span>(options_.local_port);</span><br><span class="line">  append_entries-&gt;<span class="built_in">set_term</span>(current_term);</span><br><span class="line">  append_entries-&gt;<span class="built_in">set_prev_log_index</span>(prev_log_index);</span><br><span class="line">  append_entries-&gt;<span class="built_in">set_prev_log_term</span>(prev_log_term);</span><br><span class="line">  append_entries-&gt;<span class="built_in">set_leader_commit</span>(context_-&gt;commit_index);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 获取 [next_index_, last_log_index] 之间的 LogEntry.</span></span><br><span class="line">  <span class="comment">// 发送受到 `Options` 的限制, 最多发送 append_entries_count_once 个</span></span><br><span class="line">  <span class="comment">//  或者 `append_entries_size_once` bytes.</span></span><br><span class="line">  Entry *tmp_entry = <span class="keyword">new</span> <span class="built_in">Entry</span>();</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">uint64_t</span> index = next_index_; index &lt;= last_log_index; index++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (raft_log_-&gt;<span class="built_in">GetEntry</span>(index, tmp_entry) == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// TODO(ba0tiao) how to avoid memory copy here</span></span><br><span class="line">      Entry *entry = append_entries-&gt;<span class="built_in">add_entries</span>();</span><br><span class="line">      *entry = *tmp_entry;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    num_entries++;</span><br><span class="line">    <span class="keyword">if</span> (num_entries &gt;= options_.append_entries_count_once</span><br><span class="line">        || (<span class="type">uint64_t</span>)append_entries-&gt;<span class="built_in">ByteSize</span>() &gt;= options_.append_entries_size_once) &#123;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">delete</span> tmp_entry;</span><br><span class="line"></span><br><span class="line">  CmdResponse res;</span><br><span class="line">  Status result = pool_-&gt;<span class="built_in">SendAndRecv</span>(peer_addr_, req, &amp;res);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// ... </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的主要内容是 Raft 怎么构造一个 AppendEntry 请求的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">  &#123;</span><br><span class="line">  <span class="function">slash::MutexLock <span class="title">l</span><span class="params">(&amp;context_-&gt;global_mu)</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (!result.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// here we may get a larger term, and transfer to follower</span></span><br><span class="line">  <span class="comment">// so we need to judge the role here</span></span><br><span class="line">  <span class="keyword">if</span> (context_-&gt;role == Role::kLeader) &#123;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * receiver has higer term than myself, so turn from candidate to follower</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (res.<span class="built_in">append_entries_res</span>().<span class="built_in">term</span>() &gt; context_-&gt;current_term) &#123;</span><br><span class="line">      context_-&gt;<span class="built_in">BecomeFollower</span>(res.<span class="built_in">append_entries_res</span>().<span class="built_in">term</span>());</span><br><span class="line">      raft_meta_-&gt;<span class="built_in">SetCurrentTerm</span>(context_-&gt;current_term);</span><br><span class="line">      raft_meta_-&gt;<span class="built_in">SetVotedForIp</span>(context_-&gt;voted_for_ip);</span><br><span class="line">      raft_meta_-&gt;<span class="built_in">SetVotedForPort</span>(context_-&gt;voted_for_port);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (res.<span class="built_in">append_entries_res</span>().<span class="built_in">success</span>() == <span class="literal">true</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (num_entries &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        match_index_ = prev_log_index + num_entries;</span><br><span class="line">        <span class="comment">// only log entries from the leader&#x27;s current term are committed</span></span><br><span class="line">        <span class="comment">// by counting replicas</span></span><br><span class="line">        <span class="keyword">if</span> (append_entries-&gt;<span class="built_in">entries</span>(num_entries - <span class="number">1</span>).<span class="built_in">term</span>() == context_-&gt;current_term) &#123;</span><br><span class="line">          <span class="built_in">AdvanceLeaderCommitIndex</span>();</span><br><span class="line">          apply_-&gt;<span class="built_in">ScheduleApply</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        next_index_ = prev_log_index + num_entries + <span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="type">uint64_t</span> adjust_index = std::<span class="built_in">min</span>(res.<span class="built_in">append_entries_res</span>().<span class="built_in">last_log_index</span>() + <span class="number">1</span>,</span><br><span class="line">                                       next_index_ - <span class="number">1</span>);</span><br><span class="line">      <span class="keyword">if</span> (adjust_index &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// Prev log don&#x27;t match, so we retry with more prev one according to</span></span><br><span class="line">        <span class="comment">// response</span></span><br><span class="line">        next_index_ = adjust_index;</span><br><span class="line">        <span class="built_in">AddAppendEntriesTask</span>();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Receiver-1"><a href="#Receiver-1" class="headerlink" title="Receiver"></a>Receiver</h4><p><code>Receiver</code> 的逻辑特别清晰：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">FloydImpl::ReplyAppendEntries</span><span class="params">(<span class="type">const</span> CmdRequest&amp; request, CmdResponse* response)</span> </span>&#123;</span><br><span class="line">  <span class="type">bool</span> success = <span class="literal">false</span>;</span><br><span class="line">  CmdRequest_AppendEntries append_entries = request.<span class="built_in">append_entries</span>();</span><br><span class="line">  <span class="function">slash::MutexLock <span class="title">l</span><span class="params">(&amp;context_-&gt;global_mu)</span></span>;</span><br><span class="line">  <span class="comment">// update last_op_time to avoid another leader election</span></span><br><span class="line">  context_-&gt;last_op_time = slash::<span class="built_in">NowMicros</span>();</span><br><span class="line">  <span class="comment">// Ignore stale term</span></span><br><span class="line">  <span class="comment">// if the append entries leader&#x27;s term is smaller than my current term, then the caller must an older leader</span></span><br><span class="line">  <span class="keyword">if</span> (append_entries.<span class="built_in">term</span>() &lt; context_-&gt;current_term) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">BuildAppendEntriesResponse</span>(success, context_-&gt;current_term, raft_log_-&gt;<span class="built_in">GetLastLogIndex</span>(), response);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> ((append_entries.<span class="built_in">term</span>() &gt; context_-&gt;current_term) </span><br><span class="line">      || (append_entries.<span class="built_in">term</span>() == context_-&gt;current_term &amp;&amp; </span><br><span class="line">        (context_-&gt;role == kCandidate || (context_-&gt;role == kFollower &amp;&amp; context_-&gt;leader_ip == <span class="string">&quot;&quot;</span>)))) &#123;</span><br><span class="line"></span><br><span class="line">    context_-&gt;<span class="built_in">BecomeFollower</span>(append_entries.<span class="built_in">term</span>(),</span><br><span class="line">        append_entries.<span class="built_in">ip</span>(), append_entries.<span class="built_in">port</span>());</span><br><span class="line">    raft_meta_-&gt;<span class="built_in">SetCurrentTerm</span>(context_-&gt;current_term);</span><br><span class="line">    raft_meta_-&gt;<span class="built_in">SetVotedForIp</span>(context_-&gt;voted_for_ip);</span><br><span class="line">    raft_meta_-&gt;<span class="built_in">SetVotedForPort</span>(context_-&gt;voted_for_port);</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>先过滤掉参数，再来：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span> (append_entries.<span class="built_in">prev_log_index</span>() &gt; raft_log_-&gt;<span class="built_in">GetLastLogIndex</span>()) &#123;</span><br><span class="line">    <span class="built_in">BuildAppendEntriesResponse</span>(success, context_-&gt;current_term, raft_log_-&gt;<span class="built_in">GetLastLogIndex</span>(), response);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Append entry</span></span><br><span class="line">  <span class="keyword">if</span> (append_entries.<span class="built_in">prev_log_index</span>() &lt; raft_log_-&gt;<span class="built_in">GetLastLogIndex</span>()) &#123;</span><br><span class="line">    raft_log_-&gt;<span class="built_in">TruncateSuffix</span>(append_entries.<span class="built_in">prev_log_index</span>() + <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// we compare peer&#x27;s prev index and term with my last log index and term</span></span><br><span class="line">  <span class="type">uint64_t</span> my_last_log_term = <span class="number">0</span>;</span><br><span class="line">  Entry entry;</span><br><span class="line">  <span class="keyword">if</span> (append_entries.<span class="built_in">prev_log_index</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">    my_last_log_term = <span class="number">0</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (raft_log_-&gt;<span class="built_in">GetEntry</span>(append_entries.<span class="built_in">prev_log_index</span>(), &amp;entry) == <span class="number">0</span>) &#123;</span><br><span class="line">    my_last_log_term = entry.<span class="built_in">term</span>();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (append_entries.<span class="built_in">prev_log_term</span>() != my_last_log_term) &#123;</span><br><span class="line">    <span class="built_in">BuildAppendEntriesResponse</span>(success, context_-&gt;current_term, raft_log_-&gt;<span class="built_in">GetLastLogIndex</span>(), response);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  std::vector&lt;<span class="type">const</span> Entry*&gt; entries;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; append_entries.<span class="built_in">entries</span>().<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">    entries.<span class="built_in">push_back</span>(&amp;append_entries.<span class="built_in">entries</span>(i));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (append_entries.<span class="built_in">entries</span>().<span class="built_in">size</span>() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (raft_log_-&gt;<span class="built_in">Append</span>(entries) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="built_in">BuildAppendEntriesResponse</span>(success, context_-&gt;current_term, raft_log_-&gt;<span class="built_in">GetLastLogIndex</span>(), response);</span><br><span class="line">      <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (append_entries.<span class="built_in">leader_commit</span>() != context_-&gt;commit_index) &#123;</span><br><span class="line">    <span class="built_in">AdvanceFollowerCommitIndex</span>(append_entries.<span class="built_in">leader_commit</span>());</span><br><span class="line">    apply_-&gt;<span class="built_in">ScheduleApply</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  success = <span class="literal">true</span>;</span><br><span class="line">  <span class="comment">// only when follower successfully do appendentries, we will update commit index</span></span><br><span class="line">  <span class="built_in">BuildAppendEntriesResponse</span>(success, context_-&gt;current_term, raft_log_-&gt;<span class="built_in">GetLastLogIndex</span>(), response);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实就很简单。</p><h3 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">FloydImpl::ExecuteCommand</span><span class="params">(<span class="type">const</span> CmdRequest&amp; request,</span></span></span><br><span class="line"><span class="params"><span class="function">                                 CmdResponse *response)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Append entry local</span></span><br><span class="line">  std::vector&lt;<span class="type">const</span> Entry*&gt; entries;</span><br><span class="line">  Entry entry;</span><br><span class="line">  <span class="built_in">BuildLogEntry</span>(request, context_-&gt;current_term, &amp;entry);</span><br><span class="line">  entries.<span class="built_in">push_back</span>(&amp;entry);</span><br><span class="line">  response-&gt;<span class="built_in">set_type</span>(request.<span class="built_in">type</span>());</span><br><span class="line">  response-&gt;<span class="built_in">set_code</span>(StatusCode::kError);</span><br><span class="line"></span><br><span class="line">  <span class="type">uint64_t</span> last_log_index = raft_log_-&gt;<span class="built_in">Append</span>(entries);</span><br><span class="line">  <span class="keyword">if</span> (last_log_index &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> Status::<span class="built_in">IOError</span>(<span class="string">&quot;Append Entry failed&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Notify primary then wait for apply</span></span><br><span class="line">  primary_-&gt;<span class="built_in">AddTask</span>(kNewCommand);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &#123;</span><br><span class="line">  <span class="function">slash::MutexLock <span class="title">l</span><span class="params">(&amp;context_-&gt;apply_mu)</span></span>;</span><br><span class="line">  <span class="keyword">while</span> (context_-&gt;last_applied &lt; last_log_index) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!context_-&gt;apply_cond.<span class="built_in">TimedWait</span>(<span class="number">1000</span>)) &#123;</span><br><span class="line">      <span class="keyword">return</span> Status::<span class="built_in">Timeout</span>(<span class="string">&quot;FloydImpl::ExecuteCommand Timeout&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这里，不管是 <code>Get</code> 还是 <code>Set</code>，都会起一个 Command, 然后走状态机。这里不会根据 Seq 来重试，没了就是没了，没那么多花头。</p><h3 id="Recall-线程模型"><a href="#Recall-线程模型" class="headerlink" title="Recall: 线程模型"></a>Recall: 线程模型</h3><p>这里需要注意到，<code>floyd_primary_thread</code>线程会单线程的维护 <code>kHeartbeat</code>、<code>kNewCommand</code>，这些水位可能会由 Master 和 Peer 变更。<code>Peer</code> 的任务是单线程的，这是说，对单个 <code>Peer</code>，不会有两个并发的写操作。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>xv6 labs 2021 report</title>
      <link href="/2022/04/06/xv6-labs-2021-report/"/>
      <url>/2022/04/06/xv6-labs-2021-report/</url>
      
        <content type="html"><![CDATA[<p>为啥会在这个节点做 xv6 lab 呢…其实最早是去年12月看 <code>perfbook</code> 的时候，感觉没有简单的 OS 实现的知识的话，很多东西啃的不太顺，比如 <code>spinlock</code> 为什么要关中断、中断的 <code>perf</code> 采样之类的。1月做了 lab1-2，中间基本搁置了，然后趁着居家办公这三周把所有的内容做完了。果然还是得找个不那么忙的工作才能好好学些东西…</p><p>言归正传，清明节啥都没做，基本除了录一个关于动画的 podcast、看一本厕纸基本就把这个后三个 lab 清掉了。</p><h2 id="一些流水账"><a href="#一些流水账" class="headerlink" title="一些流水账"></a>一些流水账</h2><p>耗时：每个 lab 平均耗时大概 3-4 小时，然后看代码和 book 大概要花掉每节 1/2 的时间。加上效率低的时候，我大概 60-80 小时做完了所有的内容（没有计时，只凭回忆和<code>每个 lab 的耗时 * (1.5 - 2.0)</code> 算的）。有些需要看的论文暂时还没看。感觉全看完大概 100h？不知道是不是我写的太慢还是怎么回事，和我打 Baldr Sky 的时间差不多了…</p><p>每个 lab （除了 mmap ）代码量不多，通常在 150loc 左右。不过你要跟着 hint 去想怎么写。这些 lab 基本上是「让你熟悉 xv6 代码」，而不是让你造一些相对复杂的数据结构（即使是 lock lab，让你造 scalable 的并发结构，其实结构上也很简单）。偏向策略而非实现</p><p>推荐可以对照着下面的材料看：</p><ol><li>陈海波 现代操作系统</li><li>rCore-Tutorial</li></ol><p>我个人对 xv6 book 的一些笔记放在了 GitHub 上：<a href="https://github.com/mapleFU/xv6-riscv">https://github.com/mapleFU/xv6-riscv</a></p><p>debug 主要靠 lab4 的 <code>backtrace</code>。之后我把 <code>backtrace</code> 抽成了一个 commit, 查问题的时候 cherry-pick 上来就行了。虽说我也会用 gdb 来 debug，不过实际帮助不是很大，可能是因为代码都比较简单吧，不如 backtrace 然后查原因。</p><h3 id="Lab1"><a href="#Lab1" class="headerlink" title="Lab1"></a>Lab1</h3><p>写一些 xv6 的用户态接口。和 POSIX 接口不完全一样。</p><p>lab1 实现的时候有个坑，就是 fork 之后一定要正常 exit。这里查的时候出现了关闭的时候无法正常关闭的 bug，导致失败。</p><p>这一节介绍了 6.s081 的 user-space 接口. 包括：</p><ol><li>进程相关的 fork/exit/wait/exec</li><li>IO 相关的 open/read/write，用户要理解两张表的概念：进程有个 fd 的表，fork 之后 fd 不变；dup 只有有一个指向不同 fd，但是同一个文件的表。跟 Dup 无关，文件资源本身有一个引用表，叫做打开文件表，共享偏移量，来做引用计数。然后有个 v-node 表，记录文件信息和 ref-cnt</li><li>pipes, 比如 stdin stdout</li><li><code>cd</code> 不是 system call，而是一个目录切换</li></ol><h3 id="Lab2"><a href="#Lab2" class="headerlink" title="Lab2"></a>Lab2</h3><p>Lab2 内容是给 xv6 添加一些 syscall，属于没卵意思的那种。<br>Process 本身记录单个进程，有个 <code>proc.h</code> 记录结构体的内容，然后 update 这个或者读这个内容还要走 <code>spinlock</code>，然后：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void syscall(void)</span><br></pre></td></tr></table></figure><p>这里会从寄存器找到对应的 syscall number。外部函数调用的时候也会设置这个值（<code>user/usys.pl</code> 会生成 <code>.S</code> 汇编）。</p><h3 id="Lab3"><a href="#Lab3" class="headerlink" title="Lab3"></a>Lab3</h3><p>Lab3 内容和 PageTable 结合，关键点在于 Walk 函数和页表的标记：</p><ol><li>Part1 是添加一个类似 vdso 的 Page, 这个 Page 需要在 <code>proc.c</code> 里面申请，然后挂在 <code>struct proc</code> 上，由 <code>freeproc</code> 释放。同时，这里 PAGE 也需要注意挂在高位。然后剩下的内容包括低位，这里会申请内存给 <code>sz</code> ，包括进程的元信息，GuardPage 和剩下的栈</li><li>Part2 没啥好说的，就是使用 <code>vmprint</code>, 来 visit 页表</li><li>Part3 主要在硬件 + 软件上，设置 PTE_A 来处理问题</li></ol><h3 id="Lab4"><a href="#Lab4" class="headerlink" title="Lab4"></a>Lab4</h3><p>Lab4 其实不太难，但是我莫名其妙被卡了很久，因为几个我自己都没想明白的很弱智的问题。</p><ul><li>Part1 是 calling convention 相关的问题，涉及下面几个内容 <a href="https://blog.mwish.me/2020/09/19/Integer-Endian/">https://blog.mwish.me/2020/09/19/Integer-Endian/</a> ，<a href="https://blog.mwish.me/2020/06/07/RISC-V-%E5%85%A5%E9%97%A8-Part2/">https://blog.mwish.me/2020/06/07/RISC-V-%E5%85%A5%E9%97%A8-Part2/</a> . 回答相关的问题就行了，不过我没编译过 <code>.asm</code> 文件，这个非常有意思</li><li>Part2 是一个 backtrace 的实验，这个地方有几个坑：栈目前的顶在 <code>sp</code>, 顶是地址最低的地方，底在 <code>fp</code>，<code>fp</code> 其实不是必须的。然后有一个 <code>ra</code>, 是返回的指令的地址，实际上这里打印的是这个地址。这两地方我一开始都没搞清楚</li><li>Part3 是内核态调用户态代码，细节不太多，不过很有意思，内核要设置对应的 <code>sepc</code> 到别的位置，然后让它在旧的栈上执行新的代码，因为没有参数，所以没有问题。然后要恢复32个用户寄存器。为什么是 32 个呢？因为代码可能做任何事情。</li></ul><p><strong>Part2</strong> 对 debug 非常重要。</p><h3 id="Lab5"><a href="#Lab5" class="headerlink" title="Lab5"></a>Lab5</h3><p>Lab5 也不太难，不过查问题过程还是比较有意思的。这个 lab 需要设置成 cow 的，为此需要：</p><ol><li>我把 vm 模块添加了 <code>uint8</code> 的 ref_cnt 的 map, 由一个 spinlock 保护，<code>kalloc</code> 会递增它，<code>kref</code> 添加对应的 <code>refcnt</code>，<code>kfree</code> 只在 ref_cnt 为 0 的时候使用</li><li>在 sv39 上，借助了 RSW （软件需要的位）来使用。因为在 COW 的时候，只有 <code>PTE_X</code> 的页面，我才会标记成 RSW + 取消 PTE_W。我有个地方做的不太好，Cow 如果是写两遍都会标记成这样。估计 <code>ref_cnt = 1</code> 的时候我可以不拷贝，直接改写。</li><li>有一些代码需要添加额外的检查，这个我查了好一会儿的 Bug，比如一些 vm 越界访问，不应该再走 walk。因为用户已经在访问错误的地址了</li><li>不是类型安全的带来了很多问题，我觉得不应该犯，感觉类型还是很重要的</li></ol><h3 id="Lab6"><a href="#Lab6" class="headerlink" title="Lab6"></a>Lab6</h3><p>Lab6 要你在用户态（甚至是本机上，而不是 xv6 上）写一些并发容器。<code>Barrier</code> 有一点点小小难。这个 Lab 应该是最简单的 lab 了，熟悉 POSIX 线程、信号那套基本2小时内搞定</p><h3 id="Lab7"><a href="#Lab7" class="headerlink" title="Lab7"></a>Lab7</h3><p>不难，但是非常鬼畜。要你模仿一个网卡设备，处理 DMA。给了一本手册看网卡怎么处理的，然后你要在上面做内存映射文件。</p><p>这个我觉得指引不是很好，基本上在对着手册和 xv6 的 macro 照着做，而且老实说我被卡了很久…最后一看代码没改多少。</p><h3 id="Lab8"><a href="#Lab8" class="headerlink" title="Lab8"></a>Lab8</h3><p>Lab8 基本上是 scalable data structure。和 perfbook 的知识可以对上，这里有两部分：</p><ol><li>Scalable Allocator</li><li>Scalable Hashtable + LRU</li></ol><p>Lab 一个要求是数据必须是「准」的，就是不太允许出现还有资源的时候，还返回分配失败。所以很多东西需要 Steal。不过我个人喜欢从一个中心化节点保存数据，然后一些节点来这 Batch Steal，这样处理我感觉相对简单一些，锁协议也相对简单些。</p><p>Part2 相对有点小麻烦，需要你详细的做一下行为的对齐。</p><h3 id="Lab9"><a href="#Lab9" class="headerlink" title="Lab9"></a>Lab9</h3><p>比较简单，对着做就行…这里内容是：</p><ol><li>添加一个 symlink 的接口并实现</li><li>让 FS 支持两级的索引</li></ol><p>我觉得可以多看看 xv6 book 的 fs 一节，看看从 Log 到上层用户层 <code>struct file</code> 是怎么组织的，看完了写这两个 Part 基本和切菜一样。</p><h3 id="Lab10"><a href="#Lab10" class="headerlink" title="Lab10"></a>Lab10</h3><p>不难，不过算是工程量比较多的 Lab 了，基本上是 Lab3 + Lab5 结合。需要完成整个 <code>mmap</code> 的链路。不过有的地方比较简单，比如 <code>mmap</code> 没要求和 cow 结合到一起。</p><h2 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h2><ol><li>线程调度了解了一些基本的机制，虽然不了解具体实现，但是，能完整阅读 <code>boost::Context</code> 等代码</li><li>Syscall、中断和锁系统能够联系在一起了，也对硬件的 PMO 等接口有了初步理解，对信号的操作了解了不少</li><li>fs 对 log 层有了一些初步了解</li></ol><p>接下来不准备看这些附带的 paper 了，准备先看完 perfbook，感觉没什么障碍了，之后会再去看看 Linux 相关的书，了解一些具体的细节。</p><p>附上自己的一个二次元 podcast: <a href="https://www.xiaoyuzhoufm.com/episode/624b2ae7abceb019a955249b">https://www.xiaoyuzhoufm.com/episode/624b2ae7abceb019a955249b</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>bthread 调度的机制</title>
      <link href="/2022/03/30/bthread-%E8%B0%83%E5%BA%A6%E7%9A%84%E6%9C%BA%E5%88%B6/"/>
      <url>/2022/03/30/bthread-%E8%B0%83%E5%BA%A6%E7%9A%84%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>bthread 是一个用户态的 <code>Fiber</code> 库，它的入口在 <code>incubator-brpc/src/bthread</code>，它对外提供下面一组 API:</p><ul><li>以不同优先级和不同的调度参数创建 bthread 线程</li><li>提供了 rwlock, barrier, mutex, condvar 之类的 bthread 同步原语</li><li>bthread local 相关的配置</li></ul><p>我们以 <code>bthread_start_background</code>为例, 这里介绍一下 bthread 调度相关的机制。</p><h2 id="TaskControl-TaskGroup-和-Queue"><a href="#TaskControl-TaskGroup-和-Queue" class="headerlink" title="TaskControl, TaskGroup 和 Queue"></a>TaskControl, TaskGroup 和 Queue</h2><p><code>TaskControl</code> 是一个全局唯一的中心控制器，用来做 bthread 相关的调度。<code>TaskGroup</code> 是物理工作线程的调度上下文。他们通过 Queue 来通信。</p><p>下面是一些全局共有的上下文：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">BAIDU_CASSERT</span>(<span class="built_in">sizeof</span>(TaskControl*) == <span class="built_in">sizeof</span>(butil::atomic&lt;TaskControl*&gt;), atomic_size_match);</span><br><span class="line"></span><br><span class="line"><span class="type">pthread_mutex_t</span> g_task_control_mutex = PTHREAD_MUTEX_INITIALIZER;</span><br><span class="line"><span class="comment">// Referenced in rpc, needs to be extern.</span></span><br><span class="line"><span class="comment">// Notice that we can&#x27;t declare the variable as atomic&lt;TaskControl*&gt; which</span></span><br><span class="line"><span class="comment">// are not constructed before main().</span></span><br><span class="line">TaskControl* g_task_control = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> BAIDU_THREAD_LOCAL TaskGroup* tls_task_group;</span><br><span class="line"><span class="function"><span class="keyword">extern</span> <span class="title">void</span> <span class="params">(*g_worker_startfn)</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure><p>我们晚点看看 <code>TaskControl</code> 的创建，这里直接看 <code>bthread_start_background</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">bthread_start_background</span><span class="params">(<span class="type">bthread_t</span>* __restrict tid,</span></span></span><br><span class="line"><span class="params"><span class="function">                             <span class="type">const</span> <span class="type">bthread_attr_t</span>* __restrict attr,</span></span></span><br><span class="line"><span class="params"><span class="function">                             <span class="type">void</span> * (*fn)(<span class="type">void</span>*),</span></span></span><br><span class="line"><span class="params"><span class="function">                             <span class="type">void</span>* __restrict arg)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 拿到 TaskGroup, 这个对应的 thread 本身是 worker.</span></span><br><span class="line">  <span class="comment">// 可能是 bthread 创建子线程.</span></span><br><span class="line">    bthread::TaskGroup* g = bthread::tls_task_group;</span><br><span class="line">    <span class="keyword">if</span> (g) &#123;</span><br><span class="line">        <span class="comment">// start from worker</span></span><br><span class="line">        <span class="keyword">return</span> g-&gt;<span class="built_in">start_background</span>&lt;<span class="literal">false</span>&gt;(tid, attr, fn, arg);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> bthread::<span class="built_in">start_from_non_worker</span>(tid, attr, fn, arg);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们先从 <code>start_from_non_worker</code> 开始看：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 从 non_worker 开始进行调度, 如果这里 attr 标记了 `no_signal`, 里面会走到 REMOTE = true.</span></span><br><span class="line"><span class="function">BUTIL_FORCE_INLINE <span class="type">int</span></span></span><br><span class="line"><span class="function"><span class="title">start_from_non_worker</span><span class="params">(<span class="type">bthread_t</span>* __restrict tid,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">const</span> <span class="type">bthread_attr_t</span>* __restrict attr,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">void</span> * (*fn)(<span class="type">void</span>*),</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">void</span>* __restrict arg)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 拿到全局的 TaskControl.</span></span><br><span class="line">    TaskControl* c = <span class="built_in">get_or_new_task_control</span>();</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> == c) &#123;</span><br><span class="line">        <span class="keyword">return</span> ENOMEM;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (attr != <span class="literal">NULL</span> &amp;&amp; (attr-&gt;flags &amp; BTHREAD_NOSIGNAL)) &#123;</span><br><span class="line">        <span class="comment">// Remember the TaskGroup to insert NOSIGNAL tasks for 2 reasons:</span></span><br><span class="line">        <span class="comment">// 1. NOSIGNAL is often for creating many bthreads in batch,</span></span><br><span class="line">        <span class="comment">//    inserting into the same TaskGroup maximizes the batch.</span></span><br><span class="line">        <span class="comment">// 2. bthread_flush() needs to know which TaskGroup to flush.</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">// 这里相当于记忆化, 如果是 no_signal 会倾向于丢到一个 TaskGroup.</span></span><br><span class="line">        TaskGroup* g = tls_task_group_nosignal;</span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> == g) &#123;</span><br><span class="line">            g = c-&gt;<span class="built_in">choose_one_group</span>();</span><br><span class="line">            tls_task_group_nosignal = g;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> g-&gt;<span class="built_in">start_background</span>&lt;<span class="literal">true</span>&gt;(tid, attr, fn, arg);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 否则会选中一个 TaskGroup 发送.</span></span><br><span class="line">    <span class="keyword">return</span> c-&gt;<span class="built_in">choose_one_group</span>()-&gt;<span class="built_in">start_background</span>&lt;<span class="literal">true</span>&gt;(</span><br><span class="line">        tid, attr, fn, arg);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么我们再看看 <code>choose_one_group</code> 是什么逻辑，哦就是个 random 啊：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用 fastrand, 随机选择一个 Group</span></span><br><span class="line"><span class="function">TaskGroup* <span class="title">TaskControl::choose_one_group</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> ngroup = _ngroup.<span class="built_in">load</span>(butil::memory_order_acquire);</span><br><span class="line">    <span class="keyword">if</span> (ngroup != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> _groups[butil::<span class="built_in">fast_rand_less_than</span>(ngroup)];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="literal">false</span>) &lt;&lt; <span class="string">&quot;Impossible: ngroup is 0&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来看看 <code>start_background</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里分成两部分, 一部分从对象池获取并初始化一个 TaskMeta, 然后 dispatch 给</span></span><br><span class="line"><span class="comment">// ready_to_run 系列的函数实际运行.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="type">bool</span> REMOTE&gt;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">TaskGroup::start_background</span><span class="params">(<span class="type">bthread_t</span>* __restrict th,</span></span></span><br><span class="line"><span class="params"><span class="function">                                <span class="type">const</span> <span class="type">bthread_attr_t</span>* __restrict attr,</span></span></span><br><span class="line"><span class="params"><span class="function">                                <span class="type">void</span> * (*fn)(<span class="type">void</span>*),</span></span></span><br><span class="line"><span class="params"><span class="function">                                <span class="type">void</span>* __restrict arg)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (__builtin_expect(!fn, <span class="number">0</span>)) &#123;</span><br><span class="line">        <span class="keyword">return</span> EINVAL;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">const</span> <span class="type">int64_t</span> start_ns = butil::<span class="built_in">cpuwide_time_ns</span>();</span><br><span class="line">  <span class="comment">// 强制带一个 attr.</span></span><br><span class="line">    <span class="type">const</span> <span class="type">bthread_attr_t</span> using_attr = (attr ? *attr : BTHREAD_ATTR_NORMAL);</span><br><span class="line">    butil::ResourceId&lt;TaskMeta&gt; slot;</span><br><span class="line">    TaskMeta* m = butil::<span class="built_in">get_resource</span>(&amp;slot);</span><br><span class="line">    <span class="keyword">if</span> (__builtin_expect(!m, <span class="number">0</span>)) &#123;</span><br><span class="line">        <span class="keyword">return</span> ENOMEM;</span><br><span class="line">    &#125;</span><br><span class="line"> <span class="comment">// 初始化 bthread 的状态.</span></span><br><span class="line">    <span class="built_in">CHECK</span>(m-&gt;current_waiter.<span class="built_in">load</span>(butil::memory_order_relaxed) == <span class="literal">NULL</span>);</span><br><span class="line">    m-&gt;stop = <span class="literal">false</span>;</span><br><span class="line">    m-&gt;interrupted = <span class="literal">false</span>;</span><br><span class="line">    m-&gt;about_to_quit = <span class="literal">false</span>;</span><br><span class="line">    m-&gt;fn = fn;</span><br><span class="line">    m-&gt;arg = arg;</span><br><span class="line">    <span class="built_in">CHECK</span>(m-&gt;stack == <span class="literal">NULL</span>);</span><br><span class="line">    m-&gt;attr = using_attr;</span><br><span class="line">    m-&gt;local_storage = LOCAL_STORAGE_INIT;</span><br><span class="line">    m-&gt;cpuwide_start_ns = start_ns;</span><br><span class="line">    m-&gt;stat = EMPTY_STAT;</span><br><span class="line">    m-&gt;tid = <span class="built_in">make_tid</span>(*m-&gt;version_butex, slot);</span><br><span class="line">    *th = m-&gt;tid;</span><br><span class="line">    <span class="keyword">if</span> (using_attr.flags &amp; BTHREAD_LOG_START_AND_FINISH) &#123;</span><br><span class="line">        <span class="built_in">LOG</span>(INFO) &lt;&lt; <span class="string">&quot;Started bthread &quot;</span> &lt;&lt; m-&gt;tid;</span><br><span class="line">    &#125;</span><br><span class="line">    _control-&gt;_nbthreads &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (REMOTE) &#123;</span><br><span class="line">        <span class="built_in">ready_to_run_remote</span>(m-&gt;tid, (using_attr.flags &amp; BTHREAD_NOSIGNAL));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">ready_to_run</span>(m-&gt;tid, (using_attr.flags &amp; BTHREAD_NOSIGNAL));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>反正没有构造函数还是蛮丑的。<code>REMOTE</code> 表示是否调用的函数自身也跑在这个 <code>TaskGroup</code> 下面</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 尝试 push 到 rq 中, 如果队列满了, 说明创建了太多任务, 会需要 sleep 一下.</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">TaskGroup::push_rq</span><span class="params">(<span class="type">bthread_t</span> tid)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (!_rq.<span class="built_in">push</span>(tid)) &#123;</span><br><span class="line">        <span class="comment">// Created too many bthreads: a promising approach is to insert the</span></span><br><span class="line">        <span class="comment">// task into another TaskGroup, but we don&#x27;t use it because:</span></span><br><span class="line">        <span class="comment">// * There&#x27;re already many bthreads to run, inserting the bthread</span></span><br><span class="line">        <span class="comment">//   into other TaskGroup does not help.</span></span><br><span class="line">        <span class="comment">// * Insertions into other TaskGroups perform worse when all workers</span></span><br><span class="line">        <span class="comment">//   are busy at creating bthreads (proved by test_input_messenger in</span></span><br><span class="line">        <span class="comment">//   brpc)</span></span><br><span class="line">        <span class="built_in">flush_nosignal_tasks</span>();</span><br><span class="line">        <span class="built_in">LOG_EVERY_SECOND</span>(ERROR) &lt;&lt; <span class="string">&quot;_rq is full, capacity=&quot;</span> &lt;&lt; _rq.<span class="built_in">capacity</span>();</span><br><span class="line">        <span class="comment">// TODO(gejun): May cause deadlock when all workers are spinning here.</span></span><br><span class="line">        <span class="comment">// A better solution is to pop and run existing bthreads, however which</span></span><br><span class="line">        <span class="comment">// make set_remained()-callbacks do context switches and need extensive</span></span><br><span class="line">        <span class="comment">// reviews on related code.</span></span><br><span class="line">        ::<span class="built_in">usleep</span>(<span class="number">1000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">TaskGroup::ready_to_run</span><span class="params">(<span class="type">bthread_t</span> tid, <span class="type">bool</span> nosignal)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">push_rq</span>(tid);</span><br><span class="line">    <span class="keyword">if</span> (nosignal) &#123;</span><br><span class="line">        ++_num_nosignal;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// signal 应该是 batch signal 的.</span></span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> additional_signal = _num_nosignal;</span><br><span class="line">        _num_nosignal = <span class="number">0</span>;</span><br><span class="line">        _nsignaled += <span class="number">1</span> + additional_signal;</span><br><span class="line">        _control-&gt;<span class="built_in">signal_task</span>(<span class="number">1</span> + additional_signal);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>_rq</code> 是一个 <code>WorkStealingQueue&lt;bthread_t&gt;</code>, 这个 queue 提供了 <code>push</code> <code>pop</code> 和 <code>steal</code>, 特殊的, <code>push</code> 和 <code>pop</code> 不可能并行, 但是可能有一堆 <code>steal</code> 在和他们并行.</p><p>这里 <code>signal_task</code> 会根据任务的数量，来对 <code>ParkingLot</code> 调用对应的 signal, 这里会走到 <code>futex</code> 那一套上：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">TaskControl::signal_task</span><span class="params">(<span class="type">int</span> num_task)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (num_task &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// TODO(gejun): Current algorithm does not guarantee enough threads will</span></span><br><span class="line">    <span class="comment">// be created to match caller&#x27;s requests. But in another side, there&#x27;s also</span></span><br><span class="line">    <span class="comment">// many useless signalings according to current impl. Capping the concurrency</span></span><br><span class="line">    <span class="comment">// is a good balance between performance and timeliness of scheduling.</span></span><br><span class="line">    <span class="keyword">if</span> (num_task &gt; <span class="number">2</span>) &#123;</span><br><span class="line">        num_task = <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 选中一个 ParkingLot.</span></span><br><span class="line">    <span class="comment">// 这里要寻找 1-2 个 worker 来唤醒.</span></span><br><span class="line">    <span class="type">int</span> start_index = butil::<span class="built_in">fmix64</span>(<span class="built_in">pthread_numeric_id</span>()) % PARKING_LOT_NUM;</span><br><span class="line">    num_task -= _pl[start_index].<span class="built_in">signal</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (num_task &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; PARKING_LOT_NUM &amp;&amp; num_task &gt; <span class="number">0</span>; ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (++start_index &gt;= PARKING_LOT_NUM) &#123;</span><br><span class="line">                start_index = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            num_task -= _pl[start_index].<span class="built_in">signal</span>(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 还有任务(感觉概率很小), 可能需要动态调度 worker.</span></span><br><span class="line">    <span class="keyword">if</span> (num_task &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">        FLAGS_bthread_min_concurrency &gt; <span class="number">0</span> &amp;&amp;    <span class="comment">// test min_concurrency for performance</span></span><br><span class="line">        _concurrency.<span class="built_in">load</span>(butil::memory_order_relaxed) &lt; FLAGS_bthread_concurrency) &#123;</span><br><span class="line">        <span class="comment">// <span class="doctag">TODO:</span> Reduce this lock</span></span><br><span class="line">        <span class="built_in">BAIDU_SCOPED_LOCK</span>(g_task_control_mutex);</span><br><span class="line">        <span class="keyword">if</span> (_concurrency.<span class="built_in">load</span>(butil::memory_order_acquire) &lt; FLAGS_bthread_concurrency) &#123;</span><br><span class="line">            <span class="built_in">add_workers</span>(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好，后台这块就丢进任务池子就没事了.</p><p>这里再注意一下 <code>ready_to_run_remote</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">TaskGroup::ready_to_run_remote</span><span class="params">(<span class="type">bthread_t</span> tid, <span class="type">bool</span> nosignal)</span> </span>&#123;</span><br><span class="line">    _remote_rq._mutex.<span class="built_in">lock</span>();</span><br><span class="line">    <span class="keyword">while</span> (!_remote_rq.<span class="built_in">push_locked</span>(tid)) &#123;</span><br><span class="line">        <span class="built_in">flush_nosignal_tasks_remote_locked</span>(_remote_rq._mutex);</span><br><span class="line">        <span class="built_in">LOG_EVERY_SECOND</span>(ERROR) &lt;&lt; <span class="string">&quot;_remote_rq is full, capacity=&quot;</span></span><br><span class="line">                                &lt;&lt; _remote_rq.<span class="built_in">capacity</span>();</span><br><span class="line">        ::<span class="built_in">usleep</span>(<span class="number">1000</span>);</span><br><span class="line">        _remote_rq._mutex.<span class="built_in">lock</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (nosignal) &#123;</span><br><span class="line">        ++_remote_num_nosignal;</span><br><span class="line">        _remote_rq._mutex.<span class="built_in">unlock</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> additional_signal = _remote_num_nosignal;</span><br><span class="line">        _remote_num_nosignal = <span class="number">0</span>;</span><br><span class="line">        _remote_nsignaled += <span class="number">1</span> + additional_signal;</span><br><span class="line">        _remote_rq._mutex.<span class="built_in">unlock</span>();</span><br><span class="line">        _control-&gt;<span class="built_in">signal_task</span>(<span class="number">1</span> + additional_signal);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里会塞到 <code>_remote_rq</code> 中. 逻辑和之前 <code>_rq</code> 其实差不多。</p><h2 id="TaskGroup-是怎么运行-bthread-的"><a href="#TaskGroup-是怎么运行-bthread-的" class="headerlink" title="TaskGroup 是怎么运行 bthread 的"></a>TaskGroup 是怎么运行 bthread 的</h2><p>还记得<code>TaskControl::signal_task</code> 调用了 <code>add_workers</code> 吗，这里实际上跟进去就是 <code>TaskGroup</code> 具体的逻辑了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">pthread_create</span>(&amp;_workers[i + old_concurency], <span class="literal">NULL</span>, worker_thread, <span class="keyword">this</span>);</span><br></pre></td></tr></table></figure><p>显然，我们要看 <code>worker_thread</code> 了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span>* <span class="title">TaskControl::worker_thread</span><span class="params">(<span class="type">void</span>* arg)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">run_worker_startfn</span>();    </span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> BAIDU_INTERNAL</span></span><br><span class="line">    logging::ComlogInitializer comlog_initializer;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 里面拿到了 task_control, 然后会创建一个 TaskGroup 挂在物理线程 TLS 下.</span></span><br><span class="line">    TaskControl* c = <span class="built_in">static_cast</span>&lt;TaskControl*&gt;(arg);</span><br><span class="line">    TaskGroup* g = c-&gt;<span class="built_in">create_group</span>();</span><br><span class="line">    TaskStatistics stat;</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> == g) &#123;</span><br><span class="line">        <span class="built_in">LOG</span>(ERROR) &lt;&lt; <span class="string">&quot;Fail to create TaskGroup in pthread=&quot;</span> &lt;&lt; <span class="built_in">pthread_self</span>();</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    BT_VLOG &lt;&lt; <span class="string">&quot;Created worker=&quot;</span> &lt;&lt; <span class="built_in">pthread_self</span>()</span><br><span class="line">            &lt;&lt; <span class="string">&quot; bthread=&quot;</span> &lt;&lt; g-&gt;<span class="built_in">main_tid</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 绑定物理线程的任务</span></span><br><span class="line">    tls_task_group = g;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// nworkers 统计量增加</span></span><br><span class="line">    c-&gt;_nworkers &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    g-&gt;<span class="built_in">run_main_task</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 销毁自身</span></span><br><span class="line"></span><br><span class="line">    stat = g-&gt;<span class="built_in">main_stat</span>();</span><br><span class="line">    BT_VLOG &lt;&lt; <span class="string">&quot;Destroying worker=&quot;</span> &lt;&lt; <span class="built_in">pthread_self</span>() &lt;&lt; <span class="string">&quot; bthread=&quot;</span></span><br><span class="line">            &lt;&lt; g-&gt;<span class="built_in">main_tid</span>() &lt;&lt; <span class="string">&quot; idle=&quot;</span> &lt;&lt; stat.cputime_ns / <span class="number">1000000.0</span></span><br><span class="line">            &lt;&lt; <span class="string">&quot;ms uptime=&quot;</span> &lt;&lt; g-&gt;<span class="built_in">current_uptime_ns</span>() / <span class="number">1000000.0</span> &lt;&lt; <span class="string">&quot;ms&quot;</span>;</span><br><span class="line">    tls_task_group = <span class="literal">NULL</span>;</span><br><span class="line">    g-&gt;<span class="built_in">destroy_self</span>();</span><br><span class="line">    c-&gt;_nworkers &lt;&lt; <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面 <code>TaskGroup::run_main_task</code> 了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 物理线程的主要循环.</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">TaskGroup::run_main_task</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">bvar::PassiveStatus&lt;<span class="type">double</span>&gt; <span class="title">cumulated_cputime</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        get_cumulated_cputime_from_this, <span class="keyword">this</span>)</span></span>;</span><br><span class="line">    std::unique_ptr&lt;bvar::PerSecond&lt;bvar::PassiveStatus&lt;<span class="type">double</span>&gt; &gt; &gt; usage_bvar;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 拿到对应自身对应的 TaskGroup 对象, 这里不需要操作它</span></span><br><span class="line">    TaskGroup* dummy = <span class="keyword">this</span>;</span><br><span class="line">    <span class="type">bthread_t</span> tid;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// wait_task 会等待下一个任务, 如果返回值为 0, 就退出</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="built_in">wait_task</span>(&amp;tid)) &#123;</span><br><span class="line">        <span class="comment">// 运行完下一个任务.</span></span><br><span class="line">        TaskGroup::<span class="built_in">sched_to</span>(&amp;dummy, tid);</span><br><span class="line">        <span class="built_in">DCHECK_EQ</span>(<span class="keyword">this</span>, dummy);</span><br><span class="line">        <span class="built_in">DCHECK_EQ</span>(_cur_meta-&gt;stack, _main_stack);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// sched_to 只是运行单个任务,</span></span><br><span class="line">        <span class="keyword">if</span> (_cur_meta-&gt;tid != _main_tid) &#123;</span><br><span class="line">            TaskGroup::<span class="built_in">task_runner</span>(<span class="number">1</span><span class="comment">/*skip remained*/</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 一些相关的配置, 记录 CPU-Time</span></span><br><span class="line">        <span class="keyword">if</span> (FLAGS_show_per_worker_usage_in_vars &amp;&amp; !usage_bvar) &#123;</span><br><span class="line">            <span class="type">char</span> name[<span class="number">32</span>];</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(OS_MACOSX)</span></span><br><span class="line">            <span class="built_in">snprintf</span>(name, <span class="built_in">sizeof</span>(name), <span class="string">&quot;bthread_worker_usage_%&quot;</span> PRIu64,</span><br><span class="line">                     <span class="built_in">pthread_numeric_id</span>());</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">            <span class="built_in">snprintf</span>(name, <span class="built_in">sizeof</span>(name), <span class="string">&quot;bthread_worker_usage_%ld&quot;</span>,</span><br><span class="line">                     (<span class="type">long</span>)<span class="built_in">syscall</span>(SYS_gettid));</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">            usage_bvar.<span class="built_in">reset</span>(<span class="keyword">new</span> bvar::PerSecond&lt;bvar::PassiveStatus&lt;<span class="type">double</span>&gt; &gt;</span><br><span class="line">                             (name, &amp;cumulated_cputime, <span class="number">1</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Don&#x27;t forget to add elapse of last wait_task.</span></span><br><span class="line">    <span class="built_in">current_task</span>()-&gt;stat.cputime_ns += butil::<span class="built_in">cpuwide_time_ns</span>() - _last_run_ns;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里有几个关键点：</p><ol><li><code>wait_task</code></li><li><code>TaskGroup::sched_to</code></li><li><code>TaskGroup::task_runner</code></li></ol><p>第一个 <code>wait_task</code> 可以和之前的联动：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">TaskGroup::wait_task</span><span class="params">(<span class="type">bthread_t</span>* tid)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> BTHREAD_DONT_SAVE_PARKING_STATE</span></span><br><span class="line">        <span class="comment">// 如果 stop 了, 就润走.</span></span><br><span class="line">        <span class="keyword">if</span> (_last_pl_state.<span class="built_in">stopped</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 等待有任务, 需要 signal 等方式来调用.</span></span><br><span class="line">        _pl-&gt;<span class="built_in">wait</span>(_last_pl_state);</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">steal_task</span>(tid)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">        <span class="type">const</span> ParkingLot::State st = _pl-&gt;<span class="built_in">get_state</span>();</span><br><span class="line">        <span class="keyword">if</span> (st.<span class="built_in">stopped</span>()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">steal_task</span>(tid)) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        _pl-&gt;<span class="built_in">wait</span>(st);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    &#125; <span class="keyword">while</span> (<span class="literal">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从 remote_rq 中 steal 任务.</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">steal_task</span><span class="params">(<span class="type">bthread_t</span>* tid)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (_remote_rq.<span class="built_in">pop</span>(tid)) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> BTHREAD_DONT_SAVE_PARKING_STATE</span></span><br><span class="line">  _last_pl_state = _pl-&gt;<span class="built_in">get_state</span>();</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">  <span class="keyword">return</span> _control-&gt;<span class="built_in">steal_task</span>(tid, &amp;_steal_seed, _steal_offset);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而 <code>TaskControl::steal_task</code> 会分别从 <code>_rq</code> 和 <code>_remote_rq</code> 拿：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">TaskControl::steal_task</span><span class="params">(<span class="type">bthread_t</span>* tid, <span class="type">size_t</span>* seed, <span class="type">size_t</span> offset)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 1: Acquiring fence is paired with releasing fence in _add_group to</span></span><br><span class="line">    <span class="comment">// avoid accessing uninitialized slot of _groups.</span></span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> ngroup = _ngroup.<span class="built_in">load</span>(butil::memory_order_acquire<span class="comment">/*1*/</span>);</span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> == ngroup) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> Don&#x27;t return inside `for&#x27; iteration since we need to update |seed|</span></span><br><span class="line">    <span class="type">bool</span> stolen = <span class="literal">false</span>;</span><br><span class="line">    <span class="type">size_t</span> s = *seed;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; ngroup; ++i, s += offset) &#123;</span><br><span class="line">        TaskGroup* g = _groups[s % ngroup];</span><br><span class="line">        <span class="comment">// g is possibly NULL because of concurrent _destroy_group</span></span><br><span class="line">        <span class="keyword">if</span> (g) &#123;</span><br><span class="line">            <span class="keyword">if</span> (g-&gt;_rq.<span class="built_in">steal</span>(tid)) &#123;</span><br><span class="line">                stolen = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (g-&gt;_remote_rq.<span class="built_in">pop</span>(tid)) &#123;</span><br><span class="line">                stolen = <span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    *seed = s;</span><br><span class="line">    <span class="keyword">return</span> stolen;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="sched-to"><a href="#sched-to" class="headerlink" title="sched_to"></a>sched_to</h3><p>这是最重要的函数了，涉及了具体 Fiber 的运行、切栈</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">TaskGroup::sched_to</span><span class="params">(TaskGroup** pg, <span class="type">bthread_t</span> next_tid)</span> </span>&#123;</span><br><span class="line">    TaskMeta* next_meta = <span class="built_in">address_meta</span>(next_tid);</span><br><span class="line">    <span class="keyword">if</span> (next_meta-&gt;stack == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        ContextualStack* stk = <span class="built_in">get_stack</span>(next_meta-&gt;<span class="built_in">stack_type</span>(), task_runner);</span><br><span class="line">        <span class="keyword">if</span> (stk) &#123;</span><br><span class="line">            next_meta-&gt;<span class="built_in">set_stack</span>(stk);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// stack_type is BTHREAD_STACKTYPE_PTHREAD or out of memory,</span></span><br><span class="line">            <span class="comment">// In latter case, attr is forced to be BTHREAD_STACKTYPE_PTHREAD.</span></span><br><span class="line">            <span class="comment">// This basically means that if we can&#x27;t allocate stack, run</span></span><br><span class="line">            <span class="comment">// the task in pthread directly.</span></span><br><span class="line">            next_meta-&gt;attr.stack_type = BTHREAD_STACKTYPE_PTHREAD;</span><br><span class="line">            next_meta-&gt;<span class="built_in">set_stack</span>((*pg)-&gt;_main_stack);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Update now_ns only when wait_task did yield.</span></span><br><span class="line">    <span class="built_in">sched_to</span>(pg, next_meta);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>get_stack</code> 会拿到一个栈，这里还是由对象池申请的定长对象。这里 <code>task_runner</code> 函数负责具体运行。</p><p>这里需要着重看一下 <code>bthread_make_fcontext</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">StackStorage</span> &#123;</span><br><span class="line">     <span class="type">int</span> stacksize;</span><br><span class="line">     <span class="type">int</span> guardsize;</span><br><span class="line">    <span class="comment">// Assume stack grows upwards.</span></span><br><span class="line">    <span class="comment">// http://www.boost.org/doc/libs/1_55_0/libs/context/doc/html/context/stack.html</span></span><br><span class="line">    <span class="type">void</span>* bottom;</span><br><span class="line">    <span class="type">unsigned</span> valgrind_stack_id;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Clears all members.</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">zeroize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        stacksize = <span class="number">0</span>;</span><br><span class="line">        guardsize = <span class="number">0</span>;</span><br><span class="line">        bottom = <span class="literal">NULL</span>;</span><br><span class="line">        valgrind_stack_id = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// Allocate a piece of stack.</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">allocate_stack_storage</span><span class="params">(StackStorage* s, <span class="type">int</span> stacksize, <span class="type">int</span> guardsize)</span></span>;</span><br><span class="line"><span class="comment">// Deallocate a piece of stack. Parameters MUST be returned or set by the</span></span><br><span class="line"><span class="comment">// corresponding allocate_stack_storage() otherwise behavior is undefined.</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">deallocate_stack_storage</span><span class="params">(StackStorage* s)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">StackType</span> &#123;</span><br><span class="line">    STACK_TYPE_MAIN = <span class="number">0</span>,</span><br><span class="line">    STACK_TYPE_PTHREAD = BTHREAD_STACKTYPE_PTHREAD,</span><br><span class="line">    STACK_TYPE_SMALL = BTHREAD_STACKTYPE_SMALL,</span><br><span class="line">    STACK_TYPE_NORMAL = BTHREAD_STACKTYPE_NORMAL,</span><br><span class="line">    STACK_TYPE_LARGE = BTHREAD_STACKTYPE_LARGE</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">ContextualStack</span> &#123;</span><br><span class="line">    <span class="type">bthread_fcontext_t</span> context;</span><br><span class="line">    StackType stacktype;</span><br><span class="line">    StackStorage storage;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> StackClass&gt; <span class="keyword">struct</span> <span class="title class_">StackFactory</span> &#123;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">Wrapper</span> : <span class="keyword">public</span> ContextualStack &#123;</span><br><span class="line">        <span class="function"><span class="keyword">explicit</span> <span class="title">Wrapper</span><span class="params">(<span class="type">void</span> (*entry)(<span class="type">intptr_t</span>))</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">allocate_stack_storage</span>(&amp;storage, *StackClass::stack_size_flag,</span><br><span class="line">                                       FLAGS_guard_page_size) != <span class="number">0</span>) &#123;</span><br><span class="line">                storage.<span class="built_in">zeroize</span>();</span><br><span class="line">                context = <span class="literal">NULL</span>;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 创建一个带有 entry 的 fcontext, 到时候会回退.</span></span><br><span class="line">            context = <span class="built_in">bthread_make_fcontext</span>(storage.bottom, storage.stacksize, entry);</span><br><span class="line">            stacktype = (StackType)StackClass::stacktype;</span><br><span class="line">        &#125;</span><br><span class="line">        ~<span class="built_in">Wrapper</span>() &#123;</span><br><span class="line">            <span class="keyword">if</span> (context) &#123;</span><br><span class="line">                context = <span class="literal">NULL</span>;</span><br><span class="line">                <span class="built_in">deallocate_stack_storage</span>(&amp;storage);</span><br><span class="line">                storage.<span class="built_in">zeroize</span>();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">static</span> ContextualStack* <span class="title">get_stack</span><span class="params">(<span class="type">void</span> (*entry)(<span class="type">intptr_t</span>))</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> butil::<span class="built_in">get_object</span>&lt;Wrapper&gt;(entry);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">return_stack</span><span class="params">(ContextualStack* sc)</span> </span>&#123;</span><br><span class="line">        butil::<span class="built_in">return_object</span>(<span class="built_in">static_cast</span>&lt;Wrapper*&gt;(sc));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>话说回来，之前写 xv6 lab 的时候踩过一个栈增长的坑，x86 栈是自上而下增长的，栈的 bottom 在一个高地址，所以 <code>allocate_stack_storage</code> 注意一下这个 <code>bottom</code> 是 <code>malloc() + STACK_SIZE</code>.</p><p><code>bthread_make_fcontext</code> 基本上是从 <code>boost::Context</code> 偷来的，我们这直接看看 boost 的 RISC-V 代码：<a href="https://github.com/boostorg/context/blob/develop/src/asm/make_riscv64_sysv_elf_gas.S">https://github.com/boostorg/context/blob/develop/src/asm/make_riscv64_sysv_elf_gas.S</a></p><p>这里有两个要注意的地方：</p><ol><li>只保存了 callee-saved 的寄存器，因为 caller saved 我们之后会看到</li><li><code>ra</code> 设置成了 <code>_exit</code>，这个是做一个兜底，如果 <code>fiber</code> 结尾不调度给别的 fiber 或者返回 main, 这里就会直接 exit.</li></ol><p>我们和 <code>task_runner</code> 联动看：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 实际运行 task 在 task_runner 内, TaskMeta 任务执行的时候也会包装这么一层.</span></span><br><span class="line"><span class="comment">// 它有两个调用源: bthread 的栈里调用, TaskGroup 在 run_main_task 里调用.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// m-&gt;fn 的函数可能会调 起 bthread 的任务、bthread_usleep.</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">TaskGroup::task_runner</span><span class="params">(<span class="type">intptr_t</span> skip_remained)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> tls_task_group is volatile since tasks are moved around</span></span><br><span class="line">    <span class="comment">//       different groups.</span></span><br><span class="line">    TaskGroup* g = tls_task_group;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!skip_remained) &#123;</span><br><span class="line">        <span class="keyword">while</span> (g-&gt;_last_context_remained) &#123;</span><br><span class="line">            RemainedFn fn = g-&gt;_last_context_remained;</span><br><span class="line">            g-&gt;_last_context_remained = <span class="literal">NULL</span>;</span><br><span class="line">            <span class="built_in">fn</span>(g-&gt;_last_context_remained_arg);</span><br><span class="line">            g = tls_task_group;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> NDEBUG</span></span><br><span class="line">        --g-&gt;_sched_recursive_guard;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="comment">// A task can be stopped before it gets running, in which case</span></span><br><span class="line">        <span class="comment">// we may skip user function, but that may confuse user:</span></span><br><span class="line">        <span class="comment">// Most tasks have variables to remember running result of the task,</span></span><br><span class="line">        <span class="comment">// which is often initialized to values indicating success. If an</span></span><br><span class="line">        <span class="comment">// user function is never called, the variables will be unchanged</span></span><br><span class="line">        <span class="comment">// however they&#x27;d better reflect failures because the task is stopped</span></span><br><span class="line">        <span class="comment">// abnormally.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// Meta and identifier of the task is persistent in this run.</span></span><br><span class="line">        TaskMeta* <span class="type">const</span> m = g-&gt;_cur_meta;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (FLAGS_show_bthread_creation_in_vars) &#123;</span><br><span class="line">            <span class="comment">// <span class="doctag">NOTE:</span> the thread triggering exposure of pending time may spend</span></span><br><span class="line">            <span class="comment">// considerable time because a single bvar::LatencyRecorder</span></span><br><span class="line">            <span class="comment">// contains many bvar.</span></span><br><span class="line">            g-&gt;_control-&gt;<span class="built_in">exposed_pending_time</span>() &lt;&lt;</span><br><span class="line">                (butil::<span class="built_in">cpuwide_time_ns</span>() - m-&gt;cpuwide_start_ns) / <span class="number">1000L</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Not catch exceptions except ExitException which is for implementing</span></span><br><span class="line">        <span class="comment">// bthread_exit(). User code is intended to crash when an exception is</span></span><br><span class="line">        <span class="comment">// not caught explicitly. This is consistent with other threading</span></span><br><span class="line">        <span class="comment">// libraries.</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 目前这里应该都是 0, 嘻嘻.</span></span><br><span class="line">        <span class="type">void</span>* thread_return;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 运行 m-&gt;fn().</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            thread_return = m-&gt;<span class="built_in">fn</span>(m-&gt;arg);</span><br><span class="line">        &#125; <span class="built_in">catch</span> (ExitException&amp; e) &#123;</span><br><span class="line">            thread_return = e.<span class="built_in">value</span>();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Group is probably changed</span></span><br><span class="line">        g = tls_task_group;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// <span class="doctag">TODO:</span> Save thread_return</span></span><br><span class="line">        (<span class="type">void</span>)thread_return;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Logging must be done before returning the keytable, since the logging lib</span></span><br><span class="line">        <span class="comment">// use bthread local storage internally, or will cause memory leak.</span></span><br><span class="line">        <span class="comment">// <span class="doctag">FIXME:</span> the time from quiting fn to here is not counted into cputime</span></span><br><span class="line">        <span class="keyword">if</span> (m-&gt;attr.flags &amp; BTHREAD_LOG_START_AND_FINISH) &#123;</span><br><span class="line">            <span class="built_in">LOG</span>(INFO) &lt;&lt; <span class="string">&quot;Finished bthread &quot;</span> &lt;&lt; m-&gt;tid &lt;&lt; <span class="string">&quot;, cputime=&quot;</span></span><br><span class="line">                      &lt;&lt; m-&gt;stat.cputime_ns / <span class="number">1000000.0</span> &lt;&lt; <span class="string">&quot;ms&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Clean tls variables, must be done before changing version_butex</span></span><br><span class="line">        <span class="comment">// otherwise another thread just joined this thread may not see side</span></span><br><span class="line">        <span class="comment">// effects of destructing tls variables.</span></span><br><span class="line">        KeyTable* kt = tls_bls.keytable;</span><br><span class="line">        <span class="keyword">if</span> (kt != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="built_in">return_keytable</span>(m-&gt;attr.keytable_pool, kt);</span><br><span class="line">            <span class="comment">// After deletion: tls may be set during deletion.</span></span><br><span class="line">            tls_bls.keytable = <span class="literal">NULL</span>;</span><br><span class="line">            m-&gt;local_storage.keytable = <span class="literal">NULL</span>; <span class="comment">// optional</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Increase the version and wake up all joiners, if resulting version</span></span><br><span class="line">        <span class="comment">// is 0, change it to 1 to make bthread_t never be 0. Any access</span></span><br><span class="line">        <span class="comment">// or join to the bthread after changing version will be rejected.</span></span><br><span class="line">        <span class="comment">// The spinlock is for visibility of TaskGroup::get_attr.</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">BAIDU_SCOPED_LOCK</span>(m-&gt;version_lock);</span><br><span class="line">            <span class="keyword">if</span> (<span class="number">0</span> == ++*m-&gt;version_butex) &#123;</span><br><span class="line">                ++*m-&gt;version_butex;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">butex_wake_except</span>(m-&gt;version_butex, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        g-&gt;_control-&gt;_nbthreads &lt;&lt; <span class="number">-1</span>;</span><br><span class="line">        <span class="comment">// 这个设置一个回收掉 m 的 callback.</span></span><br><span class="line">        g-&gt;<span class="built_in">set_remained</span>(TaskGroup::_release_last_context, m);</span><br><span class="line">        <span class="comment">// task_group 完成一次调度.</span></span><br><span class="line">        <span class="built_in">ending_sched</span>(&amp;g);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">while</span> (g-&gt;_cur_meta-&gt;tid != g-&gt;_main_tid);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Was called from a pthread and we don&#x27;t have BTHREAD_STACKTYPE_PTHREAD</span></span><br><span class="line">    <span class="comment">// tasks to run, quit for more tasks.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数是整个 bthread 调度的核中核，我们理一下：</p><ol><li>拿到现有 <code>TaskGroup</code> ，即现有 worker </li><li>执行 <code>_last_context_remained</code>，清理掉 <code>TaskGroup</code> 上一次执行对应的资源</li><li>在循环中，拿到 bthread 栈对应的 meta，这是需要执行的对象</li><li>运行 <code>m-&gt;fn()</code>，这里是真正的逻辑<ol><li>需要注意的是，<code>m-&gt;fn()</code> 运行的时候，可能发生上下文切换，比如 <code>m-&gt;fn()</code> 里面调用了 <code>bthread_usleep</code>.</li></ol></li><li>清理上下文</li><li>调用 <code>ending_sched</code></li></ol><p><code>(3)</code> 这就是用户给 <code>bthread_start_background</code> 任务具体被执行的 point 了！</p><h4 id="sched-to-具体逻辑"><a href="#sched-to-具体逻辑" class="headerlink" title="sched_to 具体逻辑"></a>sched_to 具体逻辑</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">TaskGroup::sched_to</span><span class="params">(TaskGroup** pg, TaskMeta* next_meta)</span> </span>&#123;</span><br><span class="line">    TaskGroup* g = *pg;</span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> NDEBUG</span></span><br><span class="line">    <span class="keyword">if</span> ((++g-&gt;_sched_recursive_guard) &gt; <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Recursively(&quot;</span> &lt;&lt; g-&gt;_sched_recursive_guard - <span class="number">1</span></span><br><span class="line">                   &lt;&lt; <span class="string">&quot;) call sched_to(&quot;</span> &lt;&lt; g &lt;&lt; <span class="string">&quot;)&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="comment">// Save errno so that errno is bthread-specific.</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> saved_errno = errno;</span><br><span class="line">    <span class="type">void</span>* saved_unique_user_ptr = tls_unique_user_ptr;</span><br><span class="line"></span><br><span class="line">    TaskMeta* <span class="type">const</span> cur_meta = g-&gt;_cur_meta;</span><br><span class="line">    <span class="type">const</span> <span class="type">int64_t</span> now = butil::<span class="built_in">cpuwide_time_ns</span>();</span><br><span class="line">    <span class="type">const</span> <span class="type">int64_t</span> elp_ns = now - g-&gt;_last_run_ns;</span><br><span class="line">    g-&gt;_last_run_ns = now;</span><br><span class="line">    cur_meta-&gt;stat.cputime_ns += elp_ns;</span><br><span class="line">    <span class="keyword">if</span> (cur_meta-&gt;tid != g-&gt;<span class="built_in">main_tid</span>()) &#123;</span><br><span class="line">        g-&gt;_cumulated_cputime_ns += elp_ns;</span><br><span class="line">    &#125;</span><br><span class="line">    ++cur_meta-&gt;stat.nswitch;</span><br><span class="line">    ++ g-&gt;_nswitch;</span><br><span class="line">    <span class="comment">// Switch to the task</span></span><br><span class="line">    <span class="keyword">if</span> (__builtin_expect(next_meta != cur_meta, <span class="number">1</span>)) &#123;</span><br><span class="line">        <span class="comment">// 这里把 _cur_meta 设置成要执行的 cur_meta.</span></span><br><span class="line">        g-&gt;_cur_meta = next_meta;</span><br><span class="line">        <span class="comment">// Switch tls_bls</span></span><br><span class="line">        cur_meta-&gt;local_storage = tls_bls;</span><br><span class="line">        tls_bls = next_meta-&gt;local_storage;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Logging must be done after switching the local storage, since the logging lib</span></span><br><span class="line">        <span class="comment">// use bthread local storage internally, or will cause memory leak.</span></span><br><span class="line">        <span class="keyword">if</span> ((cur_meta-&gt;attr.flags &amp; BTHREAD_LOG_CONTEXT_SWITCH) ||</span><br><span class="line">            (next_meta-&gt;attr.flags &amp; BTHREAD_LOG_CONTEXT_SWITCH)) &#123;</span><br><span class="line">            <span class="built_in">LOG</span>(INFO) &lt;&lt; <span class="string">&quot;Switch bthread: &quot;</span> &lt;&lt; cur_meta-&gt;tid &lt;&lt; <span class="string">&quot; -&gt; &quot;</span></span><br><span class="line">                      &lt;&lt; next_meta-&gt;tid;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (cur_meta-&gt;stack != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (next_meta-&gt;stack != cur_meta-&gt;stack) &#123;</span><br><span class="line">                <span class="built_in">jump_stack</span>(cur_meta-&gt;stack, next_meta-&gt;stack);</span><br><span class="line">                <span class="comment">// probably went to another group, need to assign g again.</span></span><br><span class="line">                g = tls_task_group;</span><br><span class="line">            &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> NDEBUG</span></span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// else pthread_task is switching to another pthread_task, sc</span></span><br><span class="line">                <span class="comment">// can only equal when they&#x27;re both _main_stack</span></span><br><span class="line">                <span class="built_in">CHECK</span>(cur_meta-&gt;stack == g-&gt;_main_stack);</span><br><span class="line">            &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// else because of ending_sched(including pthread_task-&gt;pthread_task)</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;bthread=&quot;</span> &lt;&lt; g-&gt;<span class="built_in">current_tid</span>() &lt;&lt; <span class="string">&quot; sched_to itself!&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (g-&gt;_last_context_remained) &#123;</span><br><span class="line">        RemainedFn fn = g-&gt;_last_context_remained;</span><br><span class="line">        g-&gt;_last_context_remained = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="built_in">fn</span>(g-&gt;_last_context_remained_arg);</span><br><span class="line">        g = tls_task_group;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Restore errno</span></span><br><span class="line">    errno = saved_errno;</span><br><span class="line">    tls_unique_user_ptr = saved_unique_user_ptr;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> NDEBUG</span></span><br><span class="line">    --g-&gt;_sched_recursive_guard;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    *pg = g;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 <code>sched_to</code> 中，我们要先理解 <code>jump_stack</code> 才能理解 <code>sched_to</code>, <code>jump_stack</code> 也是 <code>boost::Context</code> 抄来的：<a href="https://github.com/boostorg/context/blob/develop/src/asm/jump_riscv64_sysv_elf_gas.S">https://github.com/boostorg/context/blob/develop/src/asm/jump_riscv64_sysv_elf_gas.S</a></p><ol><li>保存所有 callee-saved registers</li><li>把 ra 设置成需要 jump 到的目标</li><li>恢复所有新的 called-saved registers</li></ol><p>那么，我们假设有多个 <code>bthread</code>,  <code>TaskGroup</code> 的 worker 调用了 <code>sched_to</code>, 然后系统会挑选第一个 bthread 来执行。假设执行完了，这里又回回到这个调度点。同时，<code>TaskGroup::sched_to</code> 这个函数在 <code>jump_stack</code> 前后可能被不同的线程执行！</p><p>知道这个，再看一些上下文代码就会清晰很多了。</p><h3 id="ending-sched"><a href="#ending-sched" class="headerlink" title="ending_sched"></a>ending_sched</h3><p>bthread 调度的时候，实际上如果 <code>task_runner</code> 在 bthread 中调用，那么它不会退出，只会随着 <code>ending_sched</code> 切到别的上下文。<code>ending_sched</code> 在这里做了 bthread 的调度和回收工作。可能在 <code>ending_sched</code> 结束后，bthread 就运行一个新的栈了。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 一个调度完成了, 尝试调度运行到下一组 task.</span></span><br><span class="line"><span class="comment">// 这里通过 TaskGroup::task_runner 来包装了一层 Task, 它可能又在 task_runner 被调用.</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">TaskGroup::ending_sched</span><span class="params">(TaskGroup** pg)</span> </span>&#123;</span><br><span class="line">    TaskGroup* g = *pg;</span><br><span class="line">    <span class="type">bthread_t</span> next_tid = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// Find next task to run, if none, switch to idle thread of the group.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//    BTHREAD_FAIR_WSQ 会有帮助吗?</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> BTHREAD_FAIR_WSQ</span></span><br><span class="line">    <span class="comment">// When BTHREAD_FAIR_WSQ is defined, profiling shows that cpu cost of</span></span><br><span class="line">    <span class="comment">// WSQ::steal() in example/multi_threaded_echo_c++ changes from 1.9%</span></span><br><span class="line">    <span class="comment">// to 2.9%</span></span><br><span class="line">    <span class="type">const</span> <span class="type">bool</span> popped = g-&gt;_rq.<span class="built_in">pop</span>(&amp;next_tid);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="type">const</span> <span class="type">bool</span> popped = g-&gt;_rq.<span class="built_in">steal</span>(&amp;next_tid);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 简单控制一下, 如果 rq 没有, remote 也没有, 才会设置成 main_tid.</span></span><br><span class="line">    <span class="comment">// 这就要等待唤醒了.</span></span><br><span class="line">    <span class="keyword">if</span> (!popped &amp;&amp; !g-&gt;<span class="built_in">steal_task</span>(&amp;next_tid)) &#123;</span><br><span class="line">        <span class="comment">// Jump to main task if there&#x27;s no task to run.</span></span><br><span class="line">        next_tid = g-&gt;_main_tid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 拿到现有的 meta, 可能之后要被回收了.</span></span><br><span class="line">    TaskMeta* <span class="type">const</span> cur_meta = g-&gt;_cur_meta;</span><br><span class="line">    <span class="comment">// 定下下一个需要跳转的栈</span></span><br><span class="line">    TaskMeta* next_meta = <span class="built_in">address_meta</span>(next_tid);</span><br><span class="line">    <span class="comment">// 需要创建栈.</span></span><br><span class="line">    <span class="keyword">if</span> (next_meta-&gt;stack == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (next_meta-&gt;<span class="built_in">stack_type</span>() == cur_meta-&gt;<span class="built_in">stack_type</span>()) &#123;</span><br><span class="line">            <span class="comment">// also works with pthread_task scheduling to pthread_task, the</span></span><br><span class="line">            <span class="comment">// transferred stack is just _main_stack.</span></span><br><span class="line">            next_meta-&gt;<span class="built_in">set_stack</span>(cur_meta-&gt;<span class="built_in">release_stack</span>());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 创建 Stack,</span></span><br><span class="line">            ContextualStack* stk = <span class="built_in">get_stack</span>(next_meta-&gt;<span class="built_in">stack_type</span>(), task_runner);</span><br><span class="line">            <span class="keyword">if</span> (stk) &#123;</span><br><span class="line">                next_meta-&gt;<span class="built_in">set_stack</span>(stk);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// stack_type is BTHREAD_STACKTYPE_PTHREAD or out of memory,</span></span><br><span class="line">                <span class="comment">// In latter case, attr is forced to be BTHREAD_STACKTYPE_PTHREAD.</span></span><br><span class="line">                <span class="comment">// This basically means that if we can&#x27;t allocate stack, run</span></span><br><span class="line">                <span class="comment">// the task in pthread directly.</span></span><br><span class="line">                next_meta-&gt;attr.stack_type = BTHREAD_STACKTYPE_PTHREAD;</span><br><span class="line">                next_meta-&gt;<span class="built_in">set_stack</span>(g-&gt;_main_stack);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">sched_to</span>(pg, next_meta);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有一个问题是，<code>fcontext</code> 的 <code>ra</code> 是 <code>_exit</code>，这里不会出现碰到结尾直接退出的问题吗？答案是 <code>ending_sched</code> 的时候，直接把你这个栈给准备灭了，等下一次调度到别的地方的时候，直接把你这个整个栈换了。这样就不会走到 <code>_exit</code> 啦~</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Notes: BigTable</title>
      <link href="/2022/03/21/Notes-BigTable/"/>
      <url>/2022/03/21/Notes-BigTable/</url>
      
        <content type="html"><![CDATA[<p>本文很短记录一下 BigTable 论文的一些内容。因为论文比较老了，而且感觉更加注重分布式，单机部分其实 SSTable 影响比较大，但是在今年已经遍地 RocksDB 了，看着多少有点老调重弹。</p><p>BigTable 提供了高吞吐量的批处理和及时响应的读，它似乎对非批的更新也有一定支持，比如在 Google Percolator 那里看到的。</p><p>BigTable 最早论文还是零几年，系统抽象和现在很多调调其实是反着来的（也可以说现在的调调是反他的）：</p><ol><li>不支持关系模型</li><li>将底层位置、分布、格式之类的暴露给用户</li><li>value 都是 string</li><li>不支持多行事务</li></ol><p>它在 chapter 3 描述了自己的数据模型，是一个一行多列多 ts 的宽表：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(row: string, column: string, time: i64) -&gt; string</span><br></pre></td></tr></table></figure><p>然后布局数据大概如下：</p><p><img src="https://image.mwish.me/blog-image/4154B725-09D7-4ED7-ACA8-AFCEC0C03C5B.png" alt="4154B725-09D7-4ED7-ACA8-AFCEC0C03C5B"></p><p><code>reverse(www.cnn.com)</code> 有三个 CF，每个 CF 如上所示。关于原子性，内容如下：</p><blockquote><p>对同一个行关键字的读或者写操作都是原子的（不管读或者写这一行里多少个不同列），这个 设计决策能够使用户很容易的理解程序在对同一个行进行并发更新操作时的行为。</p></blockquote><p>BigTable 会按照行来分区，分区单位是 <code>Tablet</code>, 列里定义分为<code>family:qualifier</code>, 如上图，<code>anchor</code> 是列族，<code>anchor:qualifier</code> 才能具体的确定一个列。这里还可以在 CF 上指定一些权限、access 方式，比如只读等。</p><p>BigTable 的定义中还有个 ts。读会优先读取最新的 ts，然后 ts 本身可以用户指定，这里可以设置一些新的 ts GC 策略，比如保留 n 个版本的或者 n 天的 ts，BigTable 会帮助你做 GC。</p><p>回顾一下，这里可以把它的模型当作一个多层的、多行多列的模型。行中的列可以是稀疏的。</p><h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><p><img src="https://image.mwish.me/blog-image/4CA43388-1439-4668-BC05-F355BCD57407.png" alt="4CA43388-1439-4668-BC05-F355BCD57407"></p><ul><li>BigTable 运行在一个多租户的系统上，可能和 HDFS、MR 等混部（论文没有描写，但是我非常好奇这个是怎么隔离的 orz..）</li><li>BigTable 内部文件是 SSTable 格式的，这个格式我不会细写，看 Google 的 LevelDB 就差不多了</li><li>BigTable 依赖 <strong>Chubby</strong> 做分布式锁服务，这个可以类似 Zookeeper. 它需要 Chubby 来保证至多只有一个 Master、存储 BigTable 的 Metadata；用来给 Tablet Server 探活等</li></ul><p>除了上面这些 Building Block，BigTable 还有下列功能：</p><ol><li>提供给用户的 SDK</li><li>Master Server：给 Tablet Server 分配 Tablets、负责 Tablet Server 的成员变更和负载均衡、对 GFS 来 GC、负责建立表和 CF 的 Schema 操作</li><li>Tablet Server：管理一组 tablets. 存储会下放到共享存储 GFS 中，所以存储不太需要 replica. （不过这里感觉没有考虑那种不太均衡的读负载带来的问题，比方说特别热点的读，写感觉估摸着可以靠创建 Bucket 来解决）。</li></ol><p>实际上，对于 BigTable，它的 TabletServer 可以当成一个「无状态的存储层」，控制信息存储在 Chubby 等地方，数据实际落在一个存储层上。此外，这里的数据还是按照 Key 来进行 Range Partition 的。这里的 Key 可以类似的当作 <code>RowKey:CF</code>，为了保证单行事务，感觉同一个 Row 应该是要在同一个机器上的。</p><h3 id="Tablet-的定位"><a href="#Tablet-的定位" class="headerlink" title="Tablet 的定位"></a>Tablet 的定位</h3><p><img src="https://image.mwish.me/blog-image/3FDB7ADA-8801-4D11-B072-7944082FE226.png" alt="3FDB7ADA-8801-4D11-B072-7944082FE226"></p><p>这里使用一个三层 Btree 的模型来定位到具体 Tablet 的分配，这些数据在 BigTable 本身是会存放在 TabletServer 上的（其实我感觉这些东西本身也可以分开存，比如这些路由信息存放在一些相对稳定不会被乱迁移的机器？）。客户端可以缓存这些路由信息，所以实际上访问这个表流量不太大，大部分都被 client 给缓存下来了。</p><h3 id="Tablet-的分配"><a href="#Tablet-的分配" class="headerlink" title="Tablet 的分配"></a>Tablet 的分配</h3><p>论文没有介绍 TabletServer 的负载是怎么样做负载均衡的，我们也无从得知。</p><p>系统依靠 Chubby 来保证整个系统只有一个 Master 进程。Master 进程要维护 Tablet 在 TabletServer 中的分配，同时要保证这个分配和上面的 Figure 4 的 Tablet 位置信息是一致的。Master 启动的时候，大致流程如下：</p><h4 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h4><p><strong>启动</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 在 Chubby 抢到 Master 对应的分布式锁, 表示 Master 是独占的。</span><br><span class="line">2. 扫描 Chubby 的 TabletServer, 知道挂了哪些 TabletServer</span><br><span class="line">3. 和 TabletServer 通信, 来指导挂了哪些 Tablets</span><br><span class="line">4. 扫描 METADATA, 来分配未分配的 Tablets. 如果 METADATA 还没有分配, 那就保证它先辈分配.</span><br></pre></td></tr></table></figure><p><strong>运行期间</strong></p><blockquote><p>在任何一个时刻，一个 Tablet 只能分配给一个 Tablet 服务器。Master 服务器记录了当前有哪些活跃的 Tablet 服务器、哪些 Tablet 分配给了哪些 Tablet 服务器、哪些 Tablet 还没有被分配。当一个 Tablet 还没有被分配、 并且刚好有一个 Tablet 服务器有足够的空闲空间装载该 Tablet 时，Master 服务器会给这个 Tablet 服务器发送 一个请求，把 Tablet 分配给这个服务器。</p></blockquote><p><strong>出现变更的时候</strong></p><p>Master 本身会管理 Tablet 在 TabletServer 上的分配情况。同时，也借助 Chubby 维护 TabletServer 是否活跃、Tablet 的具体分配情况。</p><p>TabletServer 本身启动的时候，也会在 Chubby 下面创建一个临时的文件，Master 这样就可以监听 TabletServer 的上线和异常下线。TabletServer 也可以记录</p><p><strong>Split 和 Merge</strong></p><p>某个 Tablet 或者 Region 可能会太大/太小了，需要 Split/Merge 了。这个时候 TabletServer 会和 Master 联动来做 Merge/Split，来完成 Tablet 的重新分配</p><h3 id="Tablet-服务"><a href="#Tablet-服务" class="headerlink" title="Tablet 服务"></a>Tablet 服务</h3><p><img src="https://image.mwish.me/blog-image/A8B964E6-6E0F-4624-832F-E62D49F5AB10.png" alt="A8B964E6-6E0F-4624-832F-E62D49F5AB10"></p><p>需要注意的是，这里存储都并非 LevelDB 的 Disk，而是一个分布式文件系统。这造成各种操作的 GAP 远比简单的 LSM-Tree 大。</p><p>SSTable 这里也要注意粒度问题。</p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><ol><li><p>可以进行一些分割，将一些 CF 存储在同一个 SSTable。来提升局部性。METADATA 的数据以这种方式被优化</p></li><li><p>SSTable 指定一些特定的压缩方式：</p><blockquote><p>很多客户程序使用了“两遍”的、可定制的压缩方式。第一遍采用 Bentley and McIlroy’s 方式[6]，这种方式在一个 很大的扫描窗口里对常见的长字符串进行压缩；第二遍是采用快速压缩算法，即在一个 16KB 的小扫描窗口 中寻找重复数据。两个压缩的算法都很快，在现在的机器上，压缩的速率达到 100-200MB/s，解压的速率达 到 400-1000MB/s。</p></blockquote></li><li><p>使用 BlockCache / BloomFilter</p></li></ol><h3 id="Log-和恢复流"><a href="#Log-和恢复流" class="headerlink" title="Log 和恢复流"></a>Log 和恢复流</h3><p>上面几个都比较好推，下面一个相对来说特殊一些。一台 TabletServer 可能有成百上千的 Tablets，每个 Tablet 会有自己的 Redo log 流和 SSTable。但是都有写入的时候，如果往这么多 Redo Log 流写的话，对下层压力会很大。这里 BigTable 会把日志流聚合，写到 <code>TabletServer</code> 为粒度的日志文件。这让写日志快了很多。</p><p>这给恢复和迁移带来了一些麻烦。因为原本恢复逻辑大概是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 找到自己 Region 对应的 Redo Log</span><br><span class="line">2. Redo</span><br></pre></td></tr></table></figure><p>现在变成了：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 找到之前的 Log 流</span><br><span class="line">2. 把日志按照 (table，row name，log sequence number) 排序</span><br><span class="line">2.1. Master 找到日志, 先将日志分割成 64MB 的段，之后在不同的 Tablet 服务器对段进行并行排序</span><br><span class="line">3. 按照之前逻辑恢复</span><br></pre></td></tr></table></figure><h3 id="Tablet-加速恢复"><a href="#Tablet-加速恢复" class="headerlink" title="Tablet 加速恢复"></a>Tablet 加速恢复</h3><p>在调度的时候，Tablet 做 minor compaction，把未 Flush 的 Redo Log 刷到 SST，这个会恢复或者调度期带来一些小小的停写，但是能减少调度/恢复期间的时间。</p><h2 id="HBase-对-BigTable-的实现"><a href="#HBase-对-BigTable-的实现" class="headerlink" title="HBase 对 BigTable 的实现"></a>HBase 对 BigTable 的实现</h2><p>BigTable 论文在 OSDI’06 发布。而 Apache HBase 也在 06 年写下第一行代码。</p><p>HBase 被描述为一个持久的、分布式的、稀疏的、多维的表。按照 Column Family 被存储在不同的地方。它的体系结构类似 BigTable:</p><p><img src="https://image.mwish.me/blog-image/36142E10-C8AB-401E-B5E9-BC67A8C5ECD2.png" alt="36142E10-C8AB-401E-B5E9-BC67A8C5ECD2"></p><p>我们有下面的映射关系：</p><ol><li>分布式文件系统 -&gt; HDFS</li><li>Chubby -&gt; ZooKeeper</li><li>Tablet -&gt; Region</li><li>TabletServer -&gt; RegionServer</li></ol><p>对于元信息，它存储在了特殊的表中: <a href="https://hbase.apache.org/book.html#arch.catalog">https://hbase.apache.org/book.html#arch.catalog</a> 。这个表也会随着 Region 调度被调度。</p><p>而对于 WAL，HBase 会存放 WAL，行级别的事务只会写一条 WAL，来保证行操作原子性：<a href="https://hbase.apache.org/book.html#wal">https://hbase.apache.org/book.html#wal</a> 。在上面的论文里，Google BigTable 支持单个 WAL 流，而小米的优化提供了多个 WAL，来打散 HDFS 串行写，优化写。对于读，这里会把 Block 缓存在内存的 BlockCache 中。</p><p>比较细的地方在于 Region 迁移/Merge/Split 相关的，Merge 和 Split 都依赖迁移操作，这里可能会将要操作的多个 Region 移动到同一个 RegionServer 来操作。</p><p>对于 Load Balance，原论文中没有提到，这里提供了一些相对复杂的策略，包括根据负载来迁移：<a href="https://hbase.apache.org/book.html#regions.arch.assignment">https://hbase.apache.org/book.html#regions.arch.assignment</a></p><p>HBase 的目录在：<a href="https://github.com/apache/hbase">https://github.com/apache/hbase</a> ，服务器主要路径在 <code>hbase-server</code> 下的 master 和 region-server 的目录分别是</p><p>HBase 宕机恢复和原论文差不多，值得一提的是迁移相关的部分。这里可能受到 Region 调度和分裂的影响，所以做的相对细致很多。我们这里会介绍一下 HBase 管控相关的一些信息</p><p>HBase 的 ZooKeeper 中，会缓存如下的信息，具体我摘录一些调度有关的信息：</p><ul><li><code>meta-region-server</code>: 存储 <code>hbase:meta</code> 这张元数据表的 RegionServer 的访问地址</li><li><code>region-in-transition</code>: 在 Region 的迁移过程中，这里 RegionServer 会在这里变更 Region 的状态，Master 会 watch 对应的节点，触发更新 <code>hbase:meta</code> 表的映射。</li></ul><h3 id="客户端行为"><a href="#客户端行为" class="headerlink" title="客户端行为"></a>客户端行为</h3><p>client 会访问 <code>zk</code> 提供的 <code>hbase:meta</code> 表，这个表大概内容如下：</p><p><img src="https://image.mwish.me/blog-image/B7A7AB65-C139-4269-9740-645059300C4F.png" alt="B7A7AB65-C139-4269-9740-645059300C4F"></p><p>Client 会读取 <code>meta-region-server</code> 这个 ZNode，然后访问 <code>hbase</code> 的元信息，位置信息。访问到之后，具体的路由会被缓存在 client 上。这个内容其实是 <code>&lt;某个对应的 StartKey, EndKey, 分配在什么 RegionServer 的什么 Region&gt;</code>.</p><p>关键是访问失效，RegionServer 能够发现对应 Region 不在自己上面，Client 会清缓存然后重新访问 <code>meta-region-server</code>，然后更新缓存。</p><h3 id="RegionServer"><a href="#RegionServer" class="headerlink" title="RegionServer"></a>RegionServer</h3><p><img src="https://image.mwish.me/blog-image/C9D9DD35-CDE3-4A06-A932-BBADEEF336C2.png" alt="C9D9DD35-CDE3-4A06-A932-BBADEEF336C2"></p><p>HBase 的写入会有一个 <code>sequenceid</code>, 根据 <code>sequenceid</code> 做一些日志推进。HLog 本身是按照时间之类的滚的，然后可能有复制节点在读取这些数据。当保证没有 Flush 的最后一个 MemStore 也大于某个 WAL 的 sequence 之后，这个 WAL 可以被放到别的地方。</p><p>这里的 WAL (HLog) 会写 <code>WAL</code> 文件，<code>WAL</code> 写入之后按照一定条件会切换到写新的文件，当 MemTable Flush 成为 HFile 之后，这里会把 <code>WAL</code> 移动到 <code>oldWALS</code>，等改被这个 <code>WAL</code> 文件没有被 replica 读，并 GC。</p><p>上述描述了 Minor Compaction 的流程。Major Compaction 这里是 Tiered Compaction，因为 HBase 本身适合读多写少的场景. HBase 对 Compaction 提供了专门的线程池做任务隔离（我脑洞一下，感觉 Compaction 任务本身也可以下发到别的机器上）。</p><h3 id="Region-迁移-分裂-合并"><a href="#Region-迁移-分裂-合并" class="headerlink" title="Region 迁移/分裂/合并"></a>Region 迁移/分裂/合并</h3><h4 id="基础-Procedure-V2"><a href="#基础-Procedure-V2" class="headerlink" title="基础: Procedure V2"></a>基础: Procedure V2</h4><p>这个好像是由国人 Committer 张铎老师完成的。这一部分我感觉相当复杂，会涉及 Master、Zk、RegionServer 三方的状态，所以比较复杂. </p><p>在这里，每个 Task 会被分成多个子任务，这里增加了一个 Procedure V2 的模块，然后会把任务写成一个 Task，分成多步来执行。这里可以看：</p><ol><li><a href="https://www.slidestalk.com/HBaseGroup/HBaseProcedureV236713">https://www.slidestalk.com/HBaseGroup/HBaseProcedureV236713</a></li><li><a href="http://www.nosqlnotes.com/technotes/hbase/procedure-v2/">http://www.nosqlnotes.com/technotes/hbase/procedure-v2/</a></li></ol><p>对于 Region 状态迁移，这里切分成了下面的状态，以写 <code>MasterRegion</code> 为分布式的 Coordinator，来推定最终的状态。当然实际上这个是很难的，我们可以对比一下 TiKV + PD （即基于 Multi-Raft 的方案）:</p><ol><li>TiKV 分成了多个 Raft Group，每个 Raft Group 是一个自洽的小圈子</li><li>Raft Group 会给 PD 上报心跳，根据心跳来决议最终的状态</li><li>Region 本身，会有一个 Epoch，根据 Epoch 来决定最终的状态。PD 在做分裂的时候会发送一个 Task，然后发送 Region 分裂的任务，这个任务上调度会是幂等的</li></ol><p>那么，TiKV 这个可以参考：<a href="https://pingcap.com/zh/blog/tikv-source-code-reading-20">https://pingcap.com/zh/blog/tikv-source-code-reading-20</a></p><p>那为什么 Procedure V2 这些这么复杂呢，因为它调度有好几部分：</p><ol><li>Master 的内存</li><li>存储的路由表，即 <code>hbase:meta</code></li><li>RegionServer 的状态</li></ol><p>这个可能 Master Assign 了一个任务，然后 RegionServer 执行了一部分，然后挂到 zk 上，这个时候 Master Crash 了，然后 Master 拉起来之后，可能要根据 Heartbeat 或者什么重建。这个时候，不过不一致，可能会返回 RIT 错误。</p><p>Procedure V2 框架会做什么呢？它会把 <code>MasterRegion</code> 当作 <code>Coordinator</code>, 决定最终的事务状态。然后如果状态不一致，它会尝试推进或者尝试 Abort，做了一个分布式的状态机。（感觉有点像 saga 或者 tcc？其实挺 Hack 的）</p><p><img src="https://image.mwish.me/blog-image/82A72356-3129-4F8E-AB38-36B898FF3CB9.png" alt="82A72356-3129-4F8E-AB38-36B898FF3CB9"></p><p>这个地方可以分成多组状态，然后实现了 <code>rollback</code> 等操作，来推进或者回退。</p><h4 id="Region-Split-Merge-迁移"><a href="#Region-Split-Merge-迁移" class="headerlink" title="Region Split/Merge/迁移"></a>Region Split/Merge/迁移</h4><p>这里可以看看：<a href="https://blog.cloudera.com/apache-hbase-region-splitting-and-merging/">https://blog.cloudera.com/apache-hbase-region-splitting-and-merging/</a>  和 <a href="https://popesaga.github.io/2020/11/13/HBase%20%E5%AD%A6%E4%B9%A0%EF%BC%9ARegion%20%E8%BF%81%E7%A7%BB%E3%80%81%E5%90%88%E5%B9%B6%E3%80%81%E5%88%86%E8%A3%82%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/#Assignment-Manager-V2">https://popesaga.github.io/2020/11/13/HBase%20%E5%AD%A6%E4%B9%A0%EF%BC%9ARegion%20%E8%BF%81%E7%A7%BB%E3%80%81%E5%90%88%E5%B9%B6%E3%80%81%E5%88%86%E8%A3%82%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/#Assignment-Manager-V2</a></p><p>还是挺复杂的，要考虑：</p><ol><li>Procedure V2 的恢复</li><li>分裂、合并的策略，包括触发条件（负载均衡、查找到具体分裂的点），可以参考 <code>StochasticLoadBalancer</code> 策略</li><li>分裂、合并的过程中，会从一台 WAL 涉及到2台 WAL，对应的 HFile 也需要迁移或者 GC。</li></ol><h1 id="最后的话"><a href="#最后的话" class="headerlink" title="最后的话"></a>最后的话</h1><p>这里的 lessons 一节相当有意思，我觉得句句金句。这里说的大致内容还是说，分布式系统的设计要依赖简单的接口，在加入接口之前要想到用户怎么用，然后尽量把依赖和自己都搞简单一些，因为反过来说，很多软件本身很大，但是它的一些边角功能可能相对没那么靠谱；同时，要添加功能的时候，要想到用户可能怎么用，过多的功能和配置会把你的系统搞得很恶心，所以很多时候提供一个简单的 kernel 也挺好的（当然，在现今内卷和细化的环境下，大家也会做各种搅屎棍功能）。</p><p>论文的 lessons 还讲到一些 checksum 之类的问题，我觉得郭宽在知乎的答案其实是相对靠谱的：<a href="https://zhuanlan.zhihu.com/p/338893564">https://zhuanlan.zhihu.com/p/338893564</a> 。</p><p>当初看 BigTable 之前，感觉里面的东西可能比较旧了，而且单行事务的模型可能相对 TiKV 或者 Spanner 那套已经比较 Naive 了，不过 BigTable 仍然很清晰的描述了怎么在共享存储上构建系统。一些比较细节的问题是：Region 成员变更、Region 的 HLog 流、HLog 切分、备份的时候出现新 Region 和旧 Region 不在同一条 HLog 上。这些问题现在做云上一些共享存储的系统还是会碰到的，也是可以参考的。</p><p>像一些新的系统可能会把 Log 接到一些异构的系统，比如 BookKeeper 之类的系统上。不过我感觉很多实现还是跟论文讨论的差不多的。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li>OSDI’06 BigTable: <a href="https://research.google.com/archive/bigtable-osdi06.pdf">https://research.google.com/archive/bigtable-osdi06.pdf</a></li><li>BigTable 的翻译：<a href="https://arthurchiao.art/blog/google-bigtable-zh/">https://arthurchiao.art/blog/google-bigtable-zh/</a></li><li>HBase Book: <a href="https://hbase.apache.org/book.html">https://hbase.apache.org/book.html</a></li><li>《HBase原理与实践》 胡争、范欣欣著。</li><li>HBase Compaction: <a href="http://hbasefly.com/2016/07/13/hbase-compaction-1/">http://hbasefly.com/2016/07/13/hbase-compaction-1/</a></li><li></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>InfluxDB 模型和存储引擎入门</title>
      <link href="/2022/03/17/InfluxDB-%E7%9B%B8%E5%85%B3%E6%9D%90%E6%96%99/"/>
      <url>/2022/03/17/InfluxDB-%E7%9B%B8%E5%85%B3%E6%9D%90%E6%96%99/</url>
      
        <content type="html"><![CDATA[<p>InfluxDB 分为这里所列的版本：<a href="https://www.influxdata.com/products/editions/">https://www.influxdata.com/products/editions/</a> </p><h2 id="数据模型和查询"><a href="#数据模型和查询" class="headerlink" title="数据模型和查询"></a>数据模型和查询</h2><p>参考：<a href="https://docs.influxdata.com/influxdb/v2.1/reference/key-concepts/data-elements/">https://docs.influxdata.com/influxdb/v2.1/reference/key-concepts/data-elements/</a> 和 <a href="https://docs.influxdata.com/enterprise_influxdb/v1.9/concepts/glossary/">https://docs.influxdata.com/enterprise_influxdb/v1.9/concepts/glossary/</a></p><p><img src="https://image.mwish.me/blog-image/DBBF4749-218C-493E-A56E-4A6060E21AC7.png" alt="DBBF4749-218C-493E-A56E-4A6060E21AC7"></p><ul><li>Database: 数据库</li><li>Timestamp: 时间戳，</li><li>Measurement: A measurement acts as a container for tags, fields, and timestamps.</li><li>Field: 分为 <code>&lt;Field Key, Field Value&gt;</code>，Field Key 是名称字符串，Field Value 是只支持基本类型的值。所有的 Field 组成了一个 <strong>Field Set</strong>，<strong>Field 上的值是不会建索引的</strong>。</li><li>Tags 是提供 <code>Point</code> 的元数据，有点类似 index，tags 按照 <code>string</code> 的方式存储. 所有的 tags 组成了 tag set。单个 Tag 包含 <code>Tag Key</code> 和 <code>Tag Value</code>. 对于每个 tag key, tag value 可以构成一个类似 Card 的概念<ul><li>可以理解成，tag 本身都是 string 类型</li><li>tag 可以构建索引</li></ul></li></ul><p>那么，如上所述，InfluxDB 的 Schema 如下表示：</p><p><img src="https://image.mwish.me/blog-image/31928802-5350-4AE7-844F-AF8F1049115A.png" alt="31928802-5350-4AE7-844F-AF8F1049115A"></p><p>理解了上面的东西之后，需要理解 <strong>Series</strong> 和 <strong>Series Key</strong> 这两个概念：</p><p><img src="https://image.mwish.me/blog-image/A06BB0EF-D68C-491A-85C1-574E0DFCAC6F.png" alt="A06BB0EF-D68C-491A-85C1-574E0DFCAC6F"></p><p>和 <strong>Series</strong>: 包含 <strong>timestamp</strong> 和</p><p><img src="https://image.mwish.me/blog-image/5F759A4F-F31C-4855-9FAF-4F1A691E36D8.png" alt="5F759A4F-F31C-4855-9FAF-4F1A691E36D8"></p><p>看到没有，这里相当于统计信息给抽出来了，一个 <code>Series Key</code> 对应一个 <code>Series</code>，而这个 <code>Series</code> 有着多个 <code>&lt;Timestamp, Field Value&gt;</code> 组下面才定义到具体的信息：</p><p>Point: 对应的单个 <code>Series Key</code> + <code>&lt;Timestamp + Field Value&gt;</code>, 可以理解成数据库的「行」。</p><p>最后，measurement 类似 RDBMS 的 <strong>表</strong>，而这里给出一个 <code>Bucket</code> 的概念，可以设置多个 <strong>measurement</strong>，并且设置一些 expire time 之类的条件。</p><p>以上就是 InfluxDB 的基本概念，具体一些 Schema 定义可以看：<a href="https://docs.influxdata.com/influxdb/v2.1/reference/key-concepts/data-schema/">https://docs.influxdata.com/influxdb/v2.1/reference/key-concepts/data-schema/</a></p><h3 id="Line-Protocol"><a href="#Line-Protocol" class="headerlink" title="Line Protocol"></a>Line Protocol</h3><p>InfluxDB 可以使用 Line Protocol: <a href="https://github.com/influxdata/influxdb/tree/master/tsdb#line-protocol">https://github.com/influxdata/influxdb/tree/master/tsdb#line-protocol</a></p><h3 id="query-amp-latency"><a href="#query-amp-latency" class="headerlink" title="query &amp; latency"></a>query &amp; latency</h3><p>Timescale 给出了一个 benchmark，我觉得这种 benchmark 肯定都是自己吊打别人，但是对衡量数量级来说帮助很大，如下图：</p><p><a href="https://www.timescale.com/blog/content/images/2022/01/20200716_Timescale_Blog_InfluxBenchmarks.jpg">https://www.timescale.com/blog/content/images/2022/01/20200716_Timescale_Blog_InfluxBenchmarks.jpg</a></p><p><img src="https://image.mwish.me/blog-image/20200716_Timescale_Blog_InfluxBenchmarks.jpeg" alt="20200716_Timescale_Blog_InfluxBenchmarks"></p><p>可以看到，对这个的查询包含一些近实时的查询，而数据可能能在 ~100ms 左右的时间完成一些简单的 GroupBy。</p><h2 id="Shard"><a href="#Shard" class="headerlink" title="Shard"></a>Shard</h2><blockquote><p>Sharding is the horizontal partitioning of data in a database. Each partition is called shard. InfluxDB stores data in shard groups, which are organized by retention policy and store data with timestamps that fall within a specific time interval. </p></blockquote><p>因为时序数据库是一个偏分析的场景，所以按照时间分片是一个相对自然的策略。这个分片有一个 RP(Retention Policy)，是说保留具体内容的时间。我们都知道，Bucket 本身有一个过期时间配置，Shard Group 会按照 Bucket 的时间再切细一点，做过期时间配置：</p><p><img src="https://image.mwish.me/blog-image/F0977952-F7E5-464A-9002-58D8C328A9CB.png" alt="F0977952-F7E5-464A-9002-58D8C328A9CB"></p><p>再开源 InfluxDB 上，一个 Shard Group 只有一个 Shard，感觉很无力：</p><p><img src="https://image.mwish.me/blog-image/A9DA7AAC-234A-4AEE-BA33-85EE761211A9.png" alt="A9DA7AAC-234A-4AEE-BA33-85EE761211A9"></p><p><strong>InfluxDB Enterprise</strong>  则不一样，它可以配置 Shard 的复制等功能：<a href="https://docs.influxdata.com/enterprise_influxdb/v1.9/features/clustering-features/#shard-movement">https://docs.influxdata.com/enterprise_influxdb/v1.9/features/clustering-features/#shard-movement</a> 。</p><p>InfluxDB 的 Cluster 版本现在设计如下：<a href="https://docs.influxdata.com/enterprise_influxdb/v1.8/concepts/clustering/">https://docs.influxdata.com/enterprise_influxdb/v1.8/concepts/clustering/</a></p><p>replication factor 如果设置为 <code>X</code>，那么一个 <code>N</code> 个 Data Node 的集群会配置 <code>floor(N/X)</code> 个 <code>Shard</code>，然后这里会保证每个几乎机器都会被复制这些东西：</p><blockquote><p>For example we have a shard group for <code>2016-09-19</code> that has two shards <code>1</code> and <code>2</code>. Shard <code>1</code> is replicated to servers <code>A</code> and <code>B</code> while shard <code>2</code> is copied to servers <code>C</code> and <code>D</code>.</p></blockquote><p>(我也不知道为什么这么设计，有人可以告诉我吗？)</p><p>这里会根据 <code>hash</code> 挑选写入的 shard，来做热点写打散：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// key is measurement + tagset</span></span><br><span class="line"><span class="comment">// shardGroup is the group for the values based on timestamp</span></span><br><span class="line"><span class="comment">// hash with fnv and then bucket</span></span><br><span class="line">shard := shardGroup.shards[fnv.New64a(key) % <span class="built_in">len</span>(shardGroup.Shards)]</span><br></pre></td></tr></table></figure><p>写入的时候，可以配置 write-consistency，不过我感觉基本都是 RWN 都不算的简单同步复制的变种：<a href="https://docs.influxdata.com/enterprise_influxdb/v1.8/concepts/clustering/#write-consistency">https://docs.influxdata.com/enterprise_influxdb/v1.8/concepts/clustering/#write-consistency</a></p><p>这里还有个 hinted handoff，和 Dynamo 那套一样，都是故障时写顺延。</p><h3 id="Compaction-amp-Deletion"><a href="#Compaction-amp-Deletion" class="headerlink" title="Compaction &amp; Deletion"></a>Compaction &amp; Deletion</h3><p>因为热点是写优化的，所以某个 ShardGroup 再不会写之后，相对来说会变成冷的，可以切成一些读优化、省空间的结构。而 Shard Group 本身也会过期，所以是需要删除的。</p><h2 id="一些-Schema-相关的讨论"><a href="#一些-Schema-相关的讨论" class="headerlink" title="一些 Schema 相关的讨论"></a>一些 Schema 相关的讨论</h2><p><a href="https://docs.influxdata.com/enterprise_influxdb/v1.9/concepts/schema_and_data_layout/">https://docs.influxdata.com/enterprise_influxdb/v1.9/concepts/schema_and_data_layout/</a></p><p>基本上是在教你「怎么用我们的数据库」。</p><h2 id="存储引擎-TSM-Time-Structured-Merge-Tree"><a href="#存储引擎-TSM-Time-Structured-Merge-Tree" class="headerlink" title="存储引擎: TSM(Time-Structured Merge Tree)"></a>存储引擎: TSM(Time-Structured Merge Tree)</h2><p>每一个 Shard 都包含着 WAL 和 TSM 文件，这类似 LSM 的 WSL 和 SSTable。TSM 存储引擎包含：</p><ol><li>内存索引：<strong>跨 Shards 共享</strong>，提供对 <code>measurements</code>、<code>tags</code> 和 <code>series</code> 的快速访问。<em>这个可能会持久化成下面的 TSI。</em></li><li>WAL：Shard 的写入优化格式</li><li>Cache：对 TSM 的 WAL 缓存，类似 LevelDB/RocksDB 的 MemTable（我一眼以为是 BlockCache）</li><li>TSM Files: 类似 SSTable，但着重于列式、压缩的格式</li><li>FileStore: TSM Files 的 Manager，控制文件层面的增删访</li><li>Compactor/Compactor Planner: 压缩相关。这里是希望把数据转成更读友好的形式</li><li>Compression: 因为是列式数据，所以需要特定的压缩。有的 Pattern 是固定的压缩方式，有的 Pattern 则是根据数据分布来压缩的。</li></ol><p>需要注意的是，对引擎的写入是 Batch 写入的，可能用户的客户端/agent会 Batch 采样数据过来，然后往热的 <code>Shard Group</code> 写数据。</p><h3 id="WAL"><a href="#WAL" class="headerlink" title="WAL"></a>WAL</h3><p>当写入请求过来的时候，会先往 WAL 里面写入。WAL 以 10MB 为一个 <code>Segment</code>，然后批量压缩写入，格式如下：<a href="https://github.com/influxdata/influxdb/blob/master/tsdb/engine/tsm1/wal.go#L705-L722">https://github.com/influxdata/influxdb/blob/master/tsdb/engine/tsm1/wal.go#L705-L722</a></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">// The entries values are encode as follows:</span><br><span class="line">//</span><br><span class="line">// For each key and slice of values, first a 1 byte type for the []Values</span><br><span class="line">// slice is written.  Following the type, the length and key bytes are written.</span><br><span class="line">// Following the key, a 4 byte count followed by each value as a 8 byte time</span><br><span class="line">// and N byte value.  The value is dependent on the type being encoded.  float64,</span><br><span class="line">// int64, use 8 bytes, boolean uses 1 byte, and string is similar to the key encoding,</span><br><span class="line">// except that string values have a 4-byte length, and keys only use 2 bytes.</span><br><span class="line">//</span><br><span class="line">// This structure is then repeated for each key an value slices.</span><br><span class="line">//</span><br><span class="line">// ┌────────────────────────────────────────────────────────────────────┐</span><br><span class="line">// │                           WriteWALEntry                            │</span><br><span class="line">// ├──────┬─────────┬────────┬───────┬─────────┬─────────┬───┬──────┬───┤</span><br><span class="line">// │ Type │ Key Len │   Key  │ Count │  Time   │  Value  │...│ Type │...│</span><br><span class="line">// │1 byte│ 2 bytes │ N bytes│4 bytes│ 8 bytes │ N bytes │   │1 byte│   │</span><br><span class="line">// └──────┴─────────┴────────┴───────┴─────────┴─────────┴───┴──────┴───┘</span><br></pre></td></tr></table></figure><p>整个 Batch 在组织成如上格式之后，在写入的时候还会被 snappy 压缩：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">b, err := entry.Encode(bytes)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">bytesPool.Put(bytes)</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>, err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">encBuf := bytesPool.Get(snappy.MaxEncodedLen(<span class="built_in">len</span>(b)))</span><br><span class="line"></span><br><span class="line">compressed := snappy.Encode(encBuf, b)</span><br></pre></td></tr></table></figure><p>文档上显示，单台机器上，每个 <code>Shard</code> 都会有一个 WAL 流，InfluxDB 致力于将其改成同一个 WAL 流。</p><h3 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h3><blockquote><p>The Cache is an in-memory copy of all data points current stored in the WAL. The points are organized by the key, which is the measurement, <a href="https://docs.influxdata.com/enterprise_influxdb/v1.9/concepts/glossary/#tag-set">tag set</a>, and unique <a href="https://docs.influxdata.com/enterprise_influxdb/v1.9/concepts/glossary/#field">field</a>. Each field is kept as its own time-ordered range. The Cache data is not compressed while in memory.</p></blockquote><p>这里提供同一种类型的快速访问. 看实际代码，<code>Cache</code> 会把实际存储 dispatch 到一个叫 <code>ring</code> 的结构体上。这是一个 Bucket + Concurrency Hash Map，逻辑大概如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ring is a structure that maps series keys to entries.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// ring is implemented as a crude hash ring, in so much that you can have</span></span><br><span class="line"><span class="comment">// variable numbers of members in the ring, and the appropriate member for a</span></span><br><span class="line"><span class="comment">// given series key can always consistently be found. Unlike a true hash ring</span></span><br><span class="line"><span class="comment">// though, this ring is not resizeable—there must be at most 16 members in the</span></span><br><span class="line"><span class="comment">// ring, and the number of members must always be a power of 2.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// ring works as follows: Each member of the ring contains a single store, which</span></span><br><span class="line"><span class="comment">// contains a map of series keys to entries. A ring always has 16 partitions,</span></span><br><span class="line"><span class="comment">// and a member takes up one or more of these partitions (depending on how many</span></span><br><span class="line"><span class="comment">// members are specified to be in the ring)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// To determine the partition that a series key should be added to, the series</span></span><br><span class="line"><span class="comment">// key is hashed and the first 8 bits are used as an index to the ring.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="keyword">type</span> ring <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// The unique set of partitions in the ring.</span></span><br><span class="line"><span class="comment">// len(partitions) &lt;= len(continuum)</span></span><br><span class="line">partitions []*partition</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *ring)</span></span> split(n <span class="type">int</span>) []storer &#123;</span><br><span class="line">storers := <span class="built_in">make</span>([]storer, n)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; n; i++ &#123;</span><br><span class="line">storers[i], _ = newring(<span class="built_in">len</span>(r.partitions))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, p := <span class="keyword">range</span> r.partitions &#123;</span><br><span class="line">r := storers[i%n].(*ring)</span><br><span class="line">r.partitions[i] = p</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> storers</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// partition provides safe access to a map of series keys to entries.</span></span><br><span class="line"><span class="keyword">type</span> partition <span class="keyword">struct</span> &#123;</span><br><span class="line">mu    sync.RWMutex</span><br><span class="line">store <span class="keyword">map</span>[<span class="type">string</span>]*entry</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意 <code>store</code> 存储的 <code>map[string]*entry</code>，这里实际上是：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// entry is a set of values and some metadata.</span></span><br><span class="line"><span class="keyword">type</span> entry <span class="keyword">struct</span> &#123;</span><br><span class="line">mu     sync.RWMutex</span><br><span class="line">values Values <span class="comment">// All stored values.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// The type of values stored. Read only so doesn&#x27;t need to be protected by</span></span><br><span class="line"><span class="comment">// mu.</span></span><br><span class="line">vtype <span class="type">byte</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个 <code>Values</code> 就是前面 WAL 写的时候那个，是不是一切都连起来了！</p><h3 id="TSM-文件"><a href="#TSM-文件" class="headerlink" title="TSM 文件"></a>TSM 文件</h3><p>TSM 文件类似 LSM 的 SSTable，包含下面几个区域：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">+--------+------------------------------------+-------------+--------------+</span><br><span class="line">| Header |               Blocks               |    Index    |    Footer    |</span><br><span class="line">|5 bytes |              N bytes               |   N bytes   |   4 bytes    |</span><br><span class="line">+--------+------------------------------------+-------------+--------------+</span><br><span class="line"></span><br><span class="line">+--------------------------------------------------------------------+</span><br><span class="line">│                           Blocks                                   │</span><br><span class="line">+---------------------+-----------------------+----------------------+</span><br><span class="line">|       Block 1       |        Block 2        |       Block N        |</span><br><span class="line">+---------------------+-----------------------+----------------------+</span><br><span class="line">|   CRC    |  Data    |    CRC    |   Data    |   CRC    |   Data    |</span><br><span class="line">| 4 bytes  | N bytes  |  4 bytes  | N bytes   | 4 bytes  |  N bytes  |</span><br><span class="line">+---------------------+-----------------------+----------------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">│                                   Index                                     │</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">│ Key Len │   Key   │ Type │ Count │Min Time │Max Time │ Offset │  Size  │...│</span><br><span class="line">│ 2 bytes │ N bytes │1 byte│2 bytes│ 8 bytes │ 8 bytes │8 bytes │4 bytes │   │</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line">+--------------------------------------------------+</span><br><span class="line">| Type  |  Len  |   Timestamps    |      Values    |</span><br><span class="line">|1 Byte | VByte |     N Bytes     |    N Bytes     │</span><br><span class="line">+--------------------------------------------------+</span><br></pre></td></tr></table></figure><p>详细见：<a href="https://docs.influxdata.com/influxdb/v1.8/concepts/storage_engine/">https://docs.influxdata.com/influxdb/v1.8/concepts/storage_engine/</a></p><p>需要注意 TSM 和 SSTable 的区别：</p><ol><li>单个 Block 里面只有同一个 Series Key，里面的类型是相同的，可以用 Column Compression 来处理。除此之外，它还有 Timestamps 区段。</li><li>不同的 Block 可能拥有相同的 Series Key</li><li>Series Key 按顺序排放</li></ol><h3 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h3><ol><li>内存拿到 Snapshot，然后 Compact 到文件上</li><li>Level Compaction: 类似 LevelDB</li><li>Index Optimization: engine 层好像不做这个，文档上写的是 Level4 大量堆积之后，拆分到一个存储/读均优化的结构。</li><li>Full Compaction</li></ol><p>需要注意的是，这里很鸡贼，说是 Level Compaction，实际上是 Tiered Compaction. 热文件是多写少读的，可以理解，最后数据冷了应该可以 Full Compaction 或者 Index Optimization，做成读优化的结构。</p><h3 id="Write-Update-Delete-Query"><a href="#Write-Update-Delete-Query" class="headerlink" title="Write / Update / Delete / Query"></a>Write / Update / Delete / Query</h3><p>这里着重需要理解 Delete。Write 这边会先进 Cache，然后等待 <code>WriteSnapshot</code> 进行。Update 就直接更新，等 Compaction 操作，因为这边会先读上面再读下面。Delete 的流程很诡异，这里会给内存删除，然后给每个有这个 key 的文件写一个 Tombstone 文件。读的时候做 Merge，感觉他这个对更新和删除就不是很友好。</p><p>查询这边其实就类似 LevelDB 查询了。不过我好像没太看到一些算子下推的操作，感觉对 AP Workload 支持一般般？</p><h3 id="关键路径代码"><a href="#关键路径代码" class="headerlink" title="关键路径代码"></a>关键路径代码</h3><p>写入入口, 会把请求分发到 <code>Cache</code> 和 <code>WAL</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// WritePoints writes metadata and point data into the engine.</span></span><br><span class="line"><span class="comment">// It returns an error if new points are added to an existing key.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *Engine)</span></span> WritePoints(ctx context.Context, points []models.Point) <span class="type">error</span></span><br></pre></td></tr></table></figure><p><code>CompactCache</code> 会完成 WAL -&gt; TSM, 这里调用 <code>WriteSnapshot</code> 做 类似 Major Compaction 的操作：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// compactCache continually checks if the WAL cache should be written to disk.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *Engine)</span></span> compactCache()</span><br><span class="line"></span><br><span class="line"><span class="comment">// WriteSnapshot writes a Cache snapshot to one or more new TSM files.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Compactor)</span></span> WriteSnapshot(cache *Cache, logger *zap.Logger) ([]<span class="type">string</span>, <span class="type">error</span>) </span><br></pre></td></tr></table></figure><p>而下列会构建 TSM 具体的 Blocks, 也包含了相同类型列的 Compression。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *cacheKeyIterator)</span></span> encode()</span><br></pre></td></tr></table></figure><p>Compact 关注：</p><p>最上层触发在：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(e *Engine)</span></span> compact(wg *sync.WaitGroup)</span><br></pre></td></tr></table></figure><p>下面逻辑：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CompactFull writes multiple smaller TSM files into 1 or more larger files.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Compactor)</span></span> CompactFull(tsmFiles []<span class="type">string</span>, logger *zap.Logger) ([]<span class="type">string</span>, <span class="type">error</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// CompactFast writes multiple smaller TSM files into 1 or more larger files.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Compactor)</span></span> CompactFast(tsmFiles []<span class="type">string</span>, logger *zap.Logger) ([]<span class="type">string</span>, <span class="type">error</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment">// writeNewFiles writes from the iterator into new TSM files, rotating</span></span><br><span class="line"><span class="comment">// to a new file once it has reached the max TSM file size.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Compactor)</span></span> writeNewFiles(generation, sequence <span class="type">int</span>, src []<span class="type">string</span>, iter KeyIterator, throttle <span class="type">bool</span>, logger *zap.Logger) ([]<span class="type">string</span>, <span class="type">error</span>)</span><br></pre></td></tr></table></figure><h2 id="索引-TSI-Time-Series-Index"><a href="#索引-TSI-Time-Series-Index" class="headerlink" title="索引: TSI (Time Series Index)"></a>索引: TSI (Time Series Index)</h2><p>InfluxDB 有一个 <code>Series Cardinality</code> 的概念，其实很好理解。回顾一下，<code>Series Key</code> 组成是：</p><p><img src="https://image.mwish.me/blog-image/A5A862C7-9674-4364-82D2-E122BF5F644A.png" alt="A5A862C7-9674-4364-82D2-E122BF5F644A"></p><p>这里我们会发现，对于 <code>email</code> 和 <code>status</code> 这两个 tag，这个 tag 我们虽然支持一堆 string 形式的 key，但是它的选择空间可能不是很大，这里提供了一定的优化空间。同时，如果 <code>Series Key</code> 数量很多，那这个可能会生成过多需要查询的 Index，这给系统带来了很大开销。</p><p>还有一种场景，如上，指定 <code>status = start</code>，不指定 email，也总得 AP 吧，这里处理就得扫一堆 TSM 的 Index 了。</p><p>这个地方，这里提供了反向索引，它对 <code>&lt;measurement, tag set&gt;</code> 中 <code>measurement</code> 和 Tag 的任意一项到 Series Key 提供了映射。它也是一个有序结构。它的目的如下：</p><blockquote><p>The goal is that the number of series should be unbounded by the amount of memory on the server hardware. Importantly, the number of series that exist in the database will have a negligible impact on database startup time.</p></blockquote><p>可以看到，TSI 大概有这几种类型：</p><ul><li><strong>Index</strong>: TSI instance，单个 Shard 会有一个 Index</li><li><strong>Partition</strong>: Index 内部会分成多个 <strong>Partition</strong>，来做 IO 和并发。每个 Partition 会对应不同的存储文件。</li><li><strong>LogFile</strong>: TSI 的日志文件</li><li><strong>IndexFile</strong>: TSI 最重要的部分之一，表示对应的实际索引</li></ul><p>Partition 这个概念很让人困惑。实际上这是个写入优化的措施。写入的时候，利用 Partition 来做并行化，读取的时候，需要从每个 Partition 来 PointGet，或者 Merge Partition 的结果。我个人感觉这东西稍微有点过度设计了…</p><p>可以看到，它对外提供了下列接口（实际上是 <code>tsdb/index.go</code> 的 <code>Index</code> 这个 interface，TSM 内存那节有个类似的）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ForEachMeasurementName iterates over all measurement names in the index,</span></span><br><span class="line"><span class="comment">// applying fn. It returns the first error encountered, if any.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// ForEachMeasurementName does not call fn on each partition concurrently so the</span></span><br><span class="line"><span class="comment">// call may provide a non-goroutine safe fn.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(i *Index)</span></span> ForEachMeasurementName(fn <span class="function"><span class="keyword">func</span><span class="params">(name []<span class="type">byte</span>)</span></span> <span class="type">error</span>) <span class="type">error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// MeasurementExists returns true if a measurement exists.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(i *Index)</span></span> MeasurementExists(name []<span class="type">byte</span>) (<span class="type">bool</span>, <span class="type">error</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// MeasurementHasSeries returns true if a measurement has non-tombstoned series.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(i *Index)</span></span> MeasurementHasSeries(name []<span class="type">byte</span>) (<span class="type">bool</span>, <span class="type">error</span>)</span><br><span class="line"></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>和写入：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CreateSeriesIfNotExists creates a series if it doesn&#x27;t exist or is deleted.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(i *Index)</span></span> CreateSeriesIfNotExists(key, name []<span class="type">byte</span>, tags models.Tags) <span class="type">error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CreateSeriesListIfNotExists creates a list of series if they doesn&#x27;t exist in bulk.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(i *Index)</span></span> CreateSeriesListIfNotExists(keys [][]<span class="type">byte</span>, names [][]<span class="type">byte</span>, tagsSlice []models.Tags) <span class="type">error</span></span><br></pre></td></tr></table></figure><p>对于任何写入，这边会内存有各种 mapping，写 WAL。最后构建成 TSI File，格式参照：<a href="https://github.com/influxdata/influxdb/blob/master/tsdb/index/tsi1/doc.go#L65">https://github.com/influxdata/influxdb/blob/master/tsdb/index/tsi1/doc.go#L65</a> ，分为：</p><ul><li>Series Block: 存放了所有 Series Key，用 Hash Index 来加速</li><li>Tag Block: 存放了 Tag Key, Tag Value 到 Series Key 的映射，可能有多个 Block</li><li>Measurement Block: 存放 Measurement 的映射</li></ul><p>注意，这中间还有 key 的 HashMap，来加速查找。同时，这里有合并多个 TSI 的需求，这里会写入 HLL++，并记录 key 和删除的 key，当合并的时候，可以根据 HLL 计算出大概的结果和空间放大，来调度 Compaction。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/influxdata/influxdb/tree/master/tsdb">https://github.com/influxdata/influxdb/tree/master/tsdb</a></p><ul><li>TSI： <a href="https://github.com/influxdata/influxdb/tree/master/tsdb/index">https://github.com/influxdata/influxdb/tree/master/tsdb/index</a> <ul><li>文档：<a href="https://github.com/influxdata/influxdb/blob/master/tsdb/index/tsi1/doc.go">https://github.com/influxdata/influxdb/blob/master/tsdb/index/tsi1/doc.go</a></li></ul></li><li>TSM：<a href="https://github.com/influxdata/influxdb/tree/master/tsdb/engine">https://github.com/influxdata/influxdb/tree/master/tsdb/engine</a><ul><li>文档：<a href="https://github.com/influxdata/influxdb/blob/master/tsdb/engine/tsm1/DESIGN.md">https://github.com/influxdata/influxdb/blob/master/tsdb/engine/tsm1/DESIGN.md</a></li></ul></li><li>一些协议：<a href="https://github.com/influxdata/influxdb/blob/master/tsdb/internal/fieldsindex.proto">https://github.com/influxdata/influxdb/blob/master/tsdb/internal/fieldsindex.proto</a></li><li>官方一些 detail 文档：<a href="https://docs.influxdata.com/enterprise_influxdb/v1.9/concepts/time-series-index/">https://docs.influxdata.com/enterprise_influxdb/v1.9/concepts/time-series-index/</a></li></ul><p>博客：</p><ul><li>这里有一系列博客，简中大部分 InfluxDB 的二手文档基本都参考了这个： <a href="http://hbasefly.com/2017/12/08/influxdb-1/">http://hbasefly.com/2017/12/08/influxdb-1/</a> </li><li>Compaction 看代码看的我有点点晕，参考了：<a href="https://www.jianshu.com/p/601d97507c0f">https://www.jianshu.com/p/601d97507c0f</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Dapper and Tracing</title>
      <link href="/2022/03/02/Dapper-and-Tracing/"/>
      <url>/2022/03/02/Dapper-and-Tracing/</url>
      
        <content type="html"><![CDATA[<h1 id="Dapper"><a href="#Dapper" class="headerlink" title="Dapper"></a>Dapper</h1><p>Dapper 感觉最早是 Google 的追踪系统。实际系统的链路会非常长，从上游发起一个搜索，到下游运行，下游可能又是个分布式请求。如果最终结果是上游出现满请求/问题，需要能够找到对应的选项。本身请求的监控是有用的，通过监控，开发者能够知道每个阶段大概的耗时。但对于偶现的查询，可能无法找到对应的耗时来源，需要具体的请求-阶段耗时。</p><p>这里还有个问题，就是定位到的结果也要分锅什么的，慢只是一个结果。可能某个系统多租户没做好，然后来个傻逼用户打一堆 AP 请求过来，把别的地方的请求搞慢了。这些地方也要根据 tracing 之类的来分锅。</p><p>竟然要分锅，这里暗含了几件事：</p><ol><li>这个系统对性能的影响，应该要在预期之内，不能太大</li><li>可能可以全打，或者精细的按照一些配置来输出</li><li>可能可以 hack 进一些基本的工具，包括 rpc、runtime 等（作者说不需要手工编码的部分，强调了对应用的透明，但我感觉为了一些细粒度的排查，还是需要的吧）</li></ol><h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><p>一个调用的链路如下文所示：</p><p><img src="https://image.mwish.me/blog-image/img1.png" alt="img1"></p><p>基本的思路是，这里需要有一些 context （大概可以用类似 snowflake 之类的方式生成）:</p><ol><li>跟踪标识符(message identifiers)</li><li>时间戳(timestamped events)。</li></ol><p>这里是单个的跟踪关系，dapper 这里非常有意思，考虑了层次的/并发的跟踪关系：</p><p><img src="https://image.mwish.me/blog-image/img2.png" alt="img2"></p><p>如上，这里其实是有一个（多个） <code>Span</code> 对象的，Root 本身构建了一个 Span 对象，然后调用下层的时候也会起 Span。这里可以有一个很显著的事实：Span 是可以跨机器的。</p><p>还有个很奇怪的问题是时间戳的偏移，这里本身靠请求发出的时间 &gt; 请求收到的时间保证。（TODO：不过感觉这个是个特别工程的问题了，可以看看这些系统是具体怎么实现的了）。</p><p>Dapper 在使用的时候，可能会被丢到 Thread Local Storage 系统里，或者和某个 Context 对象绑定，具体而言：</p><ol><li>这个 context 开销尽量小，然后可能可以丢到 TLS 或者某个 <code>context</code> 参数里</li><li>在异步调用、起别的线程的时候，能够正确处理它们的所有权</li></ol><p>这个时候还要注意到一点，这些大公司可能用的是一套 RPC，RPC 可能又会定义一些 runtime 之类的，trace 得很好的和他们做到一起。这里还可以加入一些 annotation，注入一些标记：</p><p><img src="https://image.mwish.me/blog-image/img4.png" alt="img4"></p><p>这个我感觉就依赖一些奇怪的内存申请了。论文里还提到可以存 key-value, counter，不过我觉得就是一个多模/语义的问题了。</p><h2 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h2><p><img src="https://image.mwish.me/blog-image/img5.png" alt="img5"></p><p>这里分为三个阶段：</p><ol><li>log 到本地文件</li><li>Dapper 的 deamon 把它弄到某个 collector 里面</li><li>最后写到 BigTable 里面，对 模型为 trace_id/span/span_cnt</li></ol><p>同时，这里 latency 从 15s - 2min，不算很延迟敏感。这里还有一些重要数据要走 OOB，我个人感觉这里暗示了有一些 tracing 可以是「重要的」。</p><p>上图也表明，tracing 大概包括：</p><ol><li>客户端和对应的 Dapper daemon</li><li>Collectors</li><li>一个时序的库，用来存储这样的数据</li></ol><h2 id="Tracing-的开销和应对"><a href="#Tracing-的开销和应对" class="headerlink" title="Tracing 的开销和应对"></a>Tracing 的开销和应对</h2><p>毕竟要在线上系统跑，肯定要考虑性能问题，考虑 Root Span 需要分配 unique id ，论文描述：</p><blockquote><p>根span的创建和销毁需要损耗平均204纳秒的时间，而同样的操作在其他span上需要消耗176纳秒</p><p>如果一个span没有被采样的话，那么这个额外的span下创建annotation的成本几乎可以忽略不计，他由在Dapper运行期对ThreadLocal查找操作构成，这平均只消耗9纳秒。如果这个span被计入采样的话，会用一个用字符串进行标注—在图4中有展现—平均需要消耗40纳秒。这些数据都是在2.2GHz的x86服务器上采集的。</p><p>在Dapper运行期写入到本地磁盘是最昂贵的操作，但是他们的可见损耗大大减少，因为写入日志文件和操作相对于被跟踪的应用系统来说都是异步的。</p></blockquote><p>Dapper 将自己的进程设置为 Linux 调度最低的优先级，然后在实践中，占用资源一般非常非常低。</p><p>同时，采样率对性能会产生影响，内容如下：</p><p><img src="https://image.mwish.me/blog-image/table2.png" alt="table2"></p><p>Dapper 能够可变的、自适应的、aggressive 的采样。上层还支持了一些二级采样，继续 discard 一些数据。</p><h1 id="百度大搜的一些方案"><a href="#百度大搜的一些方案" class="headerlink" title="百度大搜的一些方案"></a>百度大搜的一些方案</h1><p>如果你真的查过一些问题，你就会知道，Dapper 很好，但是很多东西你会希望更多的日志、更高的自由度、必要的时候有一些定制的信息，这里可以参考百度大搜的方案：</p><ol><li><a href="https://mp.weixin.qq.com/s/BMbdk5RviLG1Ftlo-qRsDQ">https://mp.weixin.qq.com/s/BMbdk5RviLG1Ftlo-qRsDQ</a></li><li><a href="https://mp.weixin.qq.com/s/IHVUnyhJr4fhiopMLOJqjA">https://mp.weixin.qq.com/s/IHVUnyhJr4fhiopMLOJqjA</a></li></ol><p>这个方案相对来说可能和开放方案不是 100% 对齐。里面对数据的可追踪性做了考量，我认为，有意思的地方在于：</p><ol><li>希望开启根据某些特征采样的时候，一定能开启</li><li>支持全量的采样</li></ol><p>我觉得这两点还是比较重要的</p><h2 id="采样的一些讨论"><a href="#采样的一些讨论" class="headerlink" title="采样的一些讨论"></a>采样的一些讨论</h2><p>上述 baidu 的系统通过一些资源开销完成了完全的采样. 关于 Dapper 本身的采样，可以看 <code>&lt;Uncertainty in Aggregate Estimates from Sampled Distributed Traces&gt;</code>，Google 在这篇论文对采样和概率做了量化描述。</p><h2 id="Trace-工业界实践"><a href="#Trace-工业界实践" class="headerlink" title="Trace: 工业界实践"></a>Trace: 工业界实践</h2><p>工业界有着不少的实践，或许最值得瞅一眼的入门是 Opentracing。有的体系过于庞大，我们会一步一步介绍这个系统是怎么构建的。</p><h3 id="brpc-tracing-客户端实现的一个简单例子"><a href="#brpc-tracing-客户端实现的一个简单例子" class="headerlink" title="brpc tracing: 客户端实现的一个简单例子"></a>brpc tracing: 客户端实现的一个简单例子</h3><p>介绍这玩意一方面是它是 Dapper 描述的客户端的一个很好的实现，另一方面我上班用的是 brpc… 出于私心瞅一眼。</p><p>入口可以看到 <code>Collector</code> 和 <code>Span</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// described in http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36356.pdf</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Span</span> : <span class="keyword">public</span> bvar::Collected &#123;</span><br><span class="line"><span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">SpanDB</span>;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">Forbidden</span> &#123;&#125;;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="comment">// Call CreateServerSpan/CreateClientSpan instead.</span></span><br><span class="line">    <span class="built_in">Span</span>(Forbidden) &#123;&#125;</span><br><span class="line">    ~<span class="built_in">Span</span>() &#123;&#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// 生成的 TraceID, 每个链路是唯一的.</span></span><br><span class="line">    <span class="type">uint64_t</span> _trace_id;</span><br><span class="line">  <span class="comment">// 生成的 SpanID, 会被串联到一起.</span></span><br><span class="line">    <span class="type">uint64_t</span> _span_id;</span><br><span class="line">    <span class="type">uint64_t</span> _parent_span_id;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// </span></span><br><span class="line">    <span class="type">uint64_t</span> _log_id;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* 下面这几个字段可以放到一起理解, 有点像 brpc 逻辑, 确定谁是 server</span></span><br><span class="line"><span class="comment">  谁是 client, 和一些对应的处理 */</span></span><br><span class="line">  <span class="comment">// ClientID</span></span><br><span class="line">    <span class="type">bthread_id_t</span> _base_cid;</span><br><span class="line">    <span class="type">bthread_id_t</span> _ending_cid;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// svc 对应的 ip 和 port</span></span><br><span class="line">    butil::EndPoint _remote_side;</span><br><span class="line">  <span class="comment">// SpanType 可以是 Server 和 Client</span></span><br><span class="line">    SpanType _type;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// TODO(mwish): 这是什么几把</span></span><br><span class="line">    <span class="type">bool</span> _async;</span><br><span class="line">    ProtocolType _protocol;</span><br><span class="line">    <span class="type">int</span> _error_code;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">  一些 brpc internal 的记录, 想看的话可以认真看的话倒是可以看看</span></span><br><span class="line"><span class="comment">  这个就和我们的内容无关了</span></span><br><span class="line"><span class="comment">  </span></span><br><span class="line"><span class="comment">    int  _request_size;</span></span><br><span class="line"><span class="comment">    int  _response_size;</span></span><br><span class="line"><span class="comment">    int64_t _base_real_us;</span></span><br><span class="line"><span class="comment">    int64_t _received_real_us;</span></span><br><span class="line"><span class="comment">    int64_t _start_parse_real_us;</span></span><br><span class="line"><span class="comment">    int64_t _start_callback_real_us;</span></span><br><span class="line"><span class="comment">    int64_t _start_send_real_us;</span></span><br><span class="line"><span class="comment">    int64_t _sent_real_us;</span></span><br><span class="line"><span class="comment">    std::string _full_method_name;</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">// Format: </span></span><br><span class="line">    <span class="comment">//   time1_us \s annotation1 &lt;SEP&gt;</span></span><br><span class="line">    <span class="comment">//   time2_us \s annotation2 &lt;SEP&gt;</span></span><br><span class="line">    <span class="comment">//   ...</span></span><br><span class="line">  <span class="comment">// Annotation 会按照上述的</span></span><br><span class="line">    std::string _info;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 和 SpanID 一样的一些本地 ctx 标记</span></span><br><span class="line">    Span* _local_parent;</span><br><span class="line">    Span* _next_client;</span><br><span class="line">    Span* _tls_next;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>我们首先关注一下这个类型的成员.</p><p><code>Channel::CallMethod</code> 里面，描述了作为 client 发送请求的对应 Span 和行为，调用了 <code>Span::CreateClientSpan</code>。</p><p>这里接收一个请求的时候，会初始化它（以 HTTP Server 为例）：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">Span* span = <span class="literal">NULL</span>;</span><br><span class="line"><span class="type">const</span> std::string&amp; path = req_header.<span class="built_in">uri</span>().<span class="built_in">path</span>();</span><br><span class="line"><span class="type">const</span> std::string* trace_id_str = req_header.<span class="built_in">GetHeader</span>(<span class="string">&quot;x-bd-trace-id&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">IsTraceable</span>(trace_id_str)) &#123;</span><br><span class="line">  <span class="comment">// 从 rpc 请求拿到 id, 没有的话</span></span><br><span class="line">  <span class="type">uint64_t</span> trace_id = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> (trace_id_str) &#123;</span><br><span class="line">    trace_id = <span class="built_in">strtoull</span>(trace_id_str-&gt;<span class="built_in">c_str</span>(), <span class="literal">NULL</span>, <span class="number">10</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 拿到 SpanID(服务器).</span></span><br><span class="line">  <span class="type">uint64_t</span> span_id = <span class="number">0</span>;</span><br><span class="line">  <span class="type">const</span> std::string* span_id_str = req_header.<span class="built_in">GetHeader</span>(<span class="string">&quot;x-bd-span-id&quot;</span>);</span><br><span class="line">  <span class="keyword">if</span> (span_id_str) &#123;</span><br><span class="line">    span_id = <span class="built_in">strtoull</span>(span_id_str-&gt;<span class="built_in">c_str</span>(), <span class="literal">NULL</span>, <span class="number">10</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 拿到 parent span id.</span></span><br><span class="line">  <span class="type">uint64_t</span> parent_span_id = <span class="number">0</span>;</span><br><span class="line">  <span class="type">const</span> std::string* parent_span_id_str =</span><br><span class="line">    req_header.<span class="built_in">GetHeader</span>(<span class="string">&quot;x-bd-parent-span-id&quot;</span>);</span><br><span class="line">  <span class="keyword">if</span> (parent_span_id_str) &#123;</span><br><span class="line">    parent_span_id = <span class="built_in">strtoull</span>(parent_span_id_str-&gt;<span class="built_in">c_str</span>(), <span class="literal">NULL</span>, <span class="number">10</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  span = Span::<span class="built_in">CreateServerSpan</span>(</span><br><span class="line">    path, trace_id, span_id, parent_span_id, msg-&gt;<span class="built_in">base_real_us</span>());</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* 一些 RPC 的上下文设置, 不感兴趣就别看了嘻嘻 */</span></span><br><span class="line">  accessor.<span class="built_in">set_span</span>(span);</span><br><span class="line">  span-&gt;<span class="built_in">set_log_id</span>(cntl-&gt;<span class="built_in">log_id</span>());</span><br><span class="line">  span-&gt;<span class="built_in">set_remote_side</span>(user_addr);</span><br><span class="line">  span-&gt;<span class="built_in">set_received_us</span>(msg-&gt;<span class="built_in">received_us</span>());</span><br><span class="line">  span-&gt;<span class="built_in">set_start_parse_us</span>(start_parse_us);</span><br><span class="line">  span-&gt;<span class="built_in">set_protocol</span>(is_http2 ? PROTOCOL_H2 : PROTOCOL_HTTP);</span><br><span class="line">  span-&gt;<span class="built_in">set_request_size</span>(imsg_guard-&gt;<span class="built_in">parsed_length</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，这个地方，如果没有给 <code>trace_id</code> , <code>log_id</code> 的话，这两个会是 <code>0</code>，那我们细看一下对应的逻辑：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Span* <span class="title">Span::CreateServerSpan</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> std::string&amp; full_method_name,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">uint64_t</span> trace_id, <span class="type">uint64_t</span> span_id, <span class="type">uint64_t</span> parent_span_id,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int64_t</span> base_real_us)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 从内存池获取 Span 对象.</span></span><br><span class="line">    Span* span = butil::<span class="built_in">get_object</span>&lt;Span&gt;(<span class="built_in">Forbidden</span>());</span><br><span class="line">    <span class="keyword">if</span> (__builtin_expect(span == <span class="literal">NULL</span>, <span class="number">0</span>)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    span-&gt;_trace_id = (trace_id ? trace_id : <span class="built_in">GenerateTraceId</span>());</span><br><span class="line">    span-&gt;_span_id = (span_id ? span_id : <span class="built_in">GenerateSpanId</span>());</span><br><span class="line">    span-&gt;_parent_span_id = parent_span_id;</span><br><span class="line">    span-&gt;_log_id = <span class="number">0</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* 一些内部逻辑 */</span></span><br><span class="line">    span-&gt;_base_cid = INVALID_BTHREAD_ID;</span><br><span class="line">    span-&gt;_ending_cid = INVALID_BTHREAD_ID;</span><br><span class="line">    span-&gt;_type = SPAN_TYPE_SERVER;</span><br><span class="line">    span-&gt;_async = <span class="literal">false</span>;</span><br><span class="line">    span-&gt;_protocol = PROTOCOL_UNKNOWN;</span><br><span class="line">    span-&gt;_error_code = <span class="number">0</span>;</span><br><span class="line">    span-&gt;_request_size = <span class="number">0</span>;</span><br><span class="line">    span-&gt;_response_size = <span class="number">0</span>;</span><br><span class="line">    span-&gt;_base_real_us = base_real_us;</span><br><span class="line">    span-&gt;_received_real_us = <span class="number">0</span>;</span><br><span class="line">    span-&gt;_start_parse_real_us = <span class="number">0</span>;</span><br><span class="line">    span-&gt;_start_callback_real_us = <span class="number">0</span>;</span><br><span class="line">    span-&gt;_start_send_real_us = <span class="number">0</span>;</span><br><span class="line">    span-&gt;_sent_real_us = <span class="number">0</span>;</span><br><span class="line">    span-&gt;_next_client = <span class="literal">NULL</span>;</span><br><span class="line">    span-&gt;_tls_next = <span class="literal">NULL</span>;</span><br><span class="line">    span-&gt;_full_method_name = (!full_method_name.<span class="built_in">empty</span>() ?</span><br><span class="line">                               full_method_name : <span class="built_in">unknown_span_name</span>());</span><br><span class="line">    span-&gt;_info.<span class="built_in">clear</span>();</span><br><span class="line">    span-&gt;_local_parent = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">return</span> span;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里有生成 Span 的逻辑，同时注意到，这个逻辑绑定在了 Runtime 的 bthread 上：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">EndAsParent</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span> == (Span*)bthread::tls_bls.rpcz_parent_span) &#123;</span><br><span class="line">  bthread::tls_bls.rpcz_parent_span = <span class="literal">NULL</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Set tls parent.</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">AsParent</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  bthread::tls_bls.rpcz_parent_span = <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里，它把 trace 上下文挂在了 thread local 的地方。那怎么创建子 Span 呢？内容如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (parent) &#123;</span><br><span class="line">  span-&gt;_trace_id = parent-&gt;<span class="built_in">trace_id</span>();</span><br><span class="line">  span-&gt;_parent_span_id = parent-&gt;<span class="built_in">span_id</span>();</span><br><span class="line">  span-&gt;_local_parent = parent;</span><br><span class="line">  span-&gt;_next_client = parent-&gt;_next_client;</span><br><span class="line">  parent-&gt;_next_client = span;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里挂了一个 Span 的单链表。</p><p>那 Annotation 呢？其实很简单：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Span::Annotate</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* fmt, va_list args)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int64_t</span> anno_time = butil::<span class="built_in">cpuwide_time_us</span>() + _base_real_us;</span><br><span class="line">    butil::<span class="built_in">string_appendf</span>(&amp;_info, BRPC_SPAN_INFO_SEP <span class="string">&quot;%lld &quot;</span>,</span><br><span class="line">                         (<span class="type">long</span> <span class="type">long</span>)anno_time);</span><br><span class="line">    butil::<span class="built_in">string_vappendf</span>(&amp;_info, fmt, args);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里会更新格式，然后丢到 <code>_info</code> 对象里。</p><p>我们再看看它是怎么异步析构的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Span::destroy</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">EndAsParent</span>();</span><br><span class="line">    Span* p = _next_client;</span><br><span class="line">    <span class="keyword">while</span> (p) &#123;</span><br><span class="line">        Span* p_next = p-&gt;_next_client;</span><br><span class="line">        p-&gt;_info.<span class="built_in">clear</span>();</span><br><span class="line">        butil::<span class="built_in">return_object</span>(p);</span><br><span class="line">        p = p_next;</span><br><span class="line">    &#125;</span><br><span class="line">    _info.<span class="built_in">clear</span>();</span><br><span class="line">    butil::<span class="built_in">return_object</span>(<span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ok，此外，这里可能会造一个 LevelDB 对象，然后有一个 <code>Collector</code> 定期把这些数据收集到 LevelDB.</p><p>那采样的逻辑呢？看看这里：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Check this function first before creating a span.</span></span><br><span class="line"><span class="comment">// If rpcz of upstream is enabled, local rpcz is enabled automatically.</span></span><br><span class="line"><span class="comment">// 如果上面开了 trace 就不检查了, 否则看是否开了 `rpcz 和有没有限流`</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">bool</span> <span class="title">IsTraceable</span><span class="params">(<span class="type">bool</span> is_upstream_traced)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">extern</span> bvar::CollectorSpeedLimit g_span_sl;</span><br><span class="line">    <span class="keyword">return</span> is_upstream_traced ||</span><br><span class="line">        (FLAGS_enable_rpcz &amp;&amp; bvar::<span class="built_in">is_collectable</span>(&amp;g_span_sl));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里通过 <code>CollectorSpeedLimit</code> 这个限流器，完成了「低访问不采样，高访问采样」这样的逻辑。</p><h3 id="tokio-tracing"><a href="#tokio-tracing" class="headerlink" title="tokio tracing"></a>tokio tracing</h3><p>Tokio Tracing 的文档见：<a href="https://tracing.rs/tracing/">https://tracing.rs/tracing/</a> . 其实它处理的也是一个 runtime 的问题。因为</p><blockquote><p>The span in which a thread is currently executing is referred to as that thread’s <em>current</em> span.</p></blockquote><p>同时它也处理了一些 <code>field</code> <code>tag</code> 什么的，原论文里面说自己能处理 kv pair 写到 BigTable 什么的，我觉得这里差不多。</p><p><code>tracing-core</code> 实现了一些基础的语义，包括 <code>Span</code> 元信息 <code>MetaData</code>，和 <code>event</code> (记录消息，开 Span 退出 Span 在 tokio-tracing 里面都叫做 <code>event</code>)，大致内容如下：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[derive(Debug)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Event</span>&lt;<span class="symbol">&#x27;a</span>&gt; &#123;</span><br><span class="line">    fields: &amp;<span class="symbol">&#x27;a</span> field::ValueSet&lt;<span class="symbol">&#x27;a</span>&gt;,</span><br><span class="line">    metadata: &amp;<span class="symbol">&#x27;static</span> Metadata&lt;<span class="symbol">&#x27;static</span>&gt;,</span><br><span class="line">    parent: Parent,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[derive(Clone, Debug, PartialEq, Eq, Hash)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Id</span>(NonZeroU64);</span><br><span class="line"></span><br><span class="line"><span class="meta">#[derive(Debug)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Current</span> &#123;</span><br><span class="line">    inner: CurrentInner,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[derive(Debug)]</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">CurrentInner</span> &#123;</span><br><span class="line">    Current &#123;</span><br><span class="line">        id: Id,</span><br><span class="line">        metadata: &amp;<span class="symbol">&#x27;static</span> Metadata&lt;<span class="symbol">&#x27;static</span>&gt;,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="literal">None</span>,</span><br><span class="line">    Unknown,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[derive(Debug)]</span></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">enum</span> <span class="title class_">Parent</span> &#123;</span><br><span class="line">    <span class="comment">/// The new span will be a root span.</span></span><br><span class="line">    Root,</span><br><span class="line">    <span class="comment">/// The new span will be rooted in the current span.</span></span><br><span class="line">    Current,</span><br><span class="line">    <span class="comment">/// The new span has an explicitly-specified parent.</span></span><br><span class="line">    <span class="title function_ invoke__">Explicit</span>(Id),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面是需要的元数据，包括 <code>Parent</code>，<code>Current</code> . 还有一部分重要内容是 <code>Dispatch</code>，文档可见: <a href="https://tracing.rs/tracing_core/struct.dispatch">https://tracing.rs/tracing_core/struct.dispatch</a></p><blockquote><p>Every thread in a program using <code>tracing</code> has a <em>default collector</em>. When events occur, or spans are created, they are dispatched to the thread’s current collector.</p></blockquote><p>dispatch 内容如下：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// `Dispatch` trace data to a [`Collect`].</span></span><br><span class="line"><span class="meta">#[derive(Clone)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Dispatch</span> &#123;</span><br><span class="line">    <span class="meta">#[cfg(feature = <span class="string">&quot;alloc&quot;</span>)]</span></span><br><span class="line">    collector: Kind&lt;Arc&lt;<span class="keyword">dyn</span> Collect + <span class="built_in">Send</span> + <span class="built_in">Sync</span>&gt;&gt;,</span><br><span class="line"></span><br><span class="line">    <span class="meta">#[cfg(not(feature = <span class="string">&quot;alloc&quot;</span>))]</span></span><br><span class="line">    collector: &amp;<span class="symbol">&#x27;static</span> (<span class="keyword">dyn</span> Collect + <span class="built_in">Send</span> + <span class="built_in">Sync</span>),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[cfg(feature = <span class="string">&quot;alloc&quot;</span>)]</span></span><br><span class="line"><span class="meta">#[derive(Clone)]</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">Kind</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="title function_ invoke__">Global</span>(&amp;<span class="symbol">&#x27;static</span> (<span class="keyword">dyn</span> Collect + <span class="built_in">Send</span> + <span class="built_in">Sync</span>)),</span><br><span class="line">    <span class="title function_ invoke__">Scoped</span>(T),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[cfg(feature = <span class="string">&quot;std&quot;</span>)]</span></span><br><span class="line">thread_local! &#123;</span><br><span class="line">    <span class="keyword">static</span> CURRENT_STATE: State = State &#123;</span><br><span class="line">        default: RefCell::<span class="title function_ invoke__">new</span>(Dispatch::<span class="title function_ invoke__">none</span>()),</span><br><span class="line">        can_enter: Cell::<span class="title function_ invoke__">new</span>(<span class="literal">true</span>),</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这部分有个 <code>thread_local</code> 的 <code>State</code> 内容，表示本线程对应的 tracing 上下文。</p><p>下面我们看看 Span 具体是怎么实现的，这部分在 <code>tracing</code> 中：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// A handle representing a span, with the capability to enter the span if it</span></span><br><span class="line"><span class="comment">/// exists.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// If the span was rejected by the current `Collector`&#x27;s filter, entering the</span></span><br><span class="line"><span class="comment">/// span will silently do nothing. Thus, the handle can be used in the same</span></span><br><span class="line"><span class="comment">/// manner regardless of whether or not the trace is currently being collected.</span></span><br><span class="line"><span class="meta">#[derive(Clone)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Span</span> &#123;</span><br><span class="line">    <span class="comment">/// A handle used to enter the span when it is not executing.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// If this is `None`, then the span has either closed or was never enabled.</span></span><br><span class="line">    inner: <span class="type">Option</span>&lt;Inner&gt;,</span><br><span class="line">    <span class="comment">/// Metadata describing the span.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// This might be `Some` even if `inner` is `None`, in the case that the</span></span><br><span class="line">    <span class="comment">/// span is disabled but the metadata is needed for `log` support.</span></span><br><span class="line">    meta: <span class="type">Option</span>&lt;&amp;<span class="symbol">&#x27;static</span> Metadata&lt;<span class="symbol">&#x27;static</span>&gt;&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// A handle representing the capacity to enter a span which is known to exist.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Unlike `Span`, this type is only constructed for spans which _have_ been</span></span><br><span class="line"><span class="comment">/// enabled by the current filter. This type is primarily used for implementing</span></span><br><span class="line"><span class="comment">/// span handles; users should typically not need to interact with it directly.</span></span><br><span class="line"><span class="meta">#[derive(Debug)]</span></span><br><span class="line"><span class="title function_ invoke__">pub</span>(<span class="keyword">crate</span>) <span class="keyword">struct</span> <span class="title class_">Inner</span> &#123;</span><br><span class="line">    <span class="comment">/// The span&#x27;s ID, as provided by `collector`.</span></span><br><span class="line">    id: Id,</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// The collector that will receive events relating to this span.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// This should be the same collector that provided this span with its</span></span><br><span class="line">    <span class="comment">/// `id`.</span></span><br><span class="line">    collector: Dispatch,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里用 <code>DefaultGuard</code> 等内容，很 RAII 的做了一下它们生命周期的变化</p><p>让我们来看看 Span 的 Enter 和 Exit</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[inline]</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">do_enter</span>(&amp;<span class="keyword">self</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(inner) = <span class="keyword">self</span>.inner.<span class="title function_ invoke__">as_ref</span>() &#123;</span><br><span class="line">        inner.collector.<span class="title function_ invoke__">enter</span>(&amp;inner.id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if_log_enabled! &#123; crate::Level::TRACE, &#123;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(_meta) = <span class="keyword">self</span>.meta &#123;</span><br><span class="line">            <span class="keyword">self</span>.<span class="title function_ invoke__">log</span>(ACTIVITY_LOG_TARGET, log::Level::Trace, <span class="built_in">format_args!</span>(<span class="string">&quot;-&gt; &#123;&#125;&quot;</span>, _meta.<span class="title function_ invoke__">name</span>()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[inline]</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">do_exit</span>(&amp;<span class="keyword">self</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(inner) = <span class="keyword">self</span>.inner.<span class="title function_ invoke__">as_ref</span>() &#123;</span><br><span class="line">        inner.collector.<span class="title function_ invoke__">exit</span>(&amp;inner.id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if_log_enabled! &#123; crate::Level::TRACE, &#123;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(_meta) = <span class="keyword">self</span>.meta &#123;</span><br><span class="line">            <span class="keyword">self</span>.<span class="title function_ invoke__">log</span>(ACTIVITY_LOG_TARGET, log::Level::Trace, <span class="built_in">format_args!</span>(<span class="string">&quot;&lt;- &#123;&#125;&quot;</span>, _meta.<span class="title function_ invoke__">name</span>()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看，这里调用了 tracing-core 的内容。OK，那最后一个问题，这里都是 thread-local，那么 tokio 呢？这里可以看 span 的 <code>enter</code> 注释，<code>instrument</code> 和 <code>Span::in_scope</code></p><h3 id="minitrace"><a href="#minitrace" class="headerlink" title="minitrace"></a>minitrace</h3><p><a href="https://github.com/tikv/minitrace-rust">https://github.com/tikv/minitrace-rust</a></p><p>这个项目不力图完善，而是力图快，用 <code>tsc</code> 寄存器等方式大幅度优化了 trace 的性能。比较值得再提的是 ministant: <a href="https://github.com/tikv/minstant">https://github.com/tikv/minstant</a></p><h3 id="Jaeger-amp-OpenTelemetry-OpenTracing"><a href="#Jaeger-amp-OpenTelemetry-OpenTracing" class="headerlink" title="Jaeger &amp; OpenTelemetry(OpenTracing)"></a>Jaeger &amp; OpenTelemetry(OpenTracing)</h3><p>OpenTracing 通过提供了 API 标准，基本上算是做了很不错的事情：<a href="https://github.com/opentracing/specification/blob/master/specification.md">https://github.com/opentracing/specification/blob/master/specification.md</a></p><p>Jaeger 提供了下面 的架构（使用 Kakfa or Direct-to-storage）：</p><p><img src="https://image.mwish.me/blog-image/architecture-v2.png" alt="architecture-v2"></p><p><img src="https://image.mwish.me/blog-image/architecture-v1.png" alt="architecture-v1"></p><p>这里的 DB 可能还需要一些时序/多模之类的需求: 本质上这个和存储日志差不多，半结构化的数据、最近的数据需要高效查询 etc…</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] <a href="https://bigbully.github.io/Dapper-translation/">https://bigbully.github.io/Dapper-translation/</a></p><p>[2] <a href="https://mp.weixin.qq.com/s/BMbdk5RviLG1Ftlo-qRsDQ">https://mp.weixin.qq.com/s/BMbdk5RviLG1Ftlo-qRsDQ</a></p><p>[3] <a href="https://mp.weixin.qq.com/s/IHVUnyhJr4fhiopMLOJqjA">https://mp.weixin.qq.com/s/IHVUnyhJr4fhiopMLOJqjA</a></p><p>[4] <a href="https://zhuanlan.zhihu.com/p/34318538">https://zhuanlan.zhihu.com/p/34318538</a></p><p>[5] <a href="https://www.jaegertracing.io/docs/1.31/architecture/">https://www.jaegertracing.io/docs/1.31/architecture/</a></p><p>[6] <a href="https://tracing.rs/tracing/">https://tracing.rs/tracing/</a></p><p>[7] Dapper, a Large-Scale Distributed Systems Tracing Infrastructure</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>2021 杂书记</title>
      <link href="/2022/02/27/2021-%E6%9D%82%E4%B9%A6%E8%AE%B0/"/>
      <url>/2022/02/27/2021-%E6%9D%82%E4%B9%A6%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>竟然嘴上挂着个想考研社会学的名号，水平有多少另说，书还是得啃的吧。2021 年算是开始入门的一年，当然现在可能门还没入。</p><h2 id="刘擎西方现代思想讲义"><a href="#刘擎西方现代思想讲义" class="headerlink" title="刘擎西方现代思想讲义"></a>刘擎西方现代思想讲义</h2><p>[7/10] 网红书。浅显的介绍。对现代性/韦伯的一些简单介绍，胜在描述的很现实，没讲太多理论，可以说是网红入门书的典范了。内容不是很体系，但是也算浮光掠影过了一下。</p><p>中间还混杂了一些八卦。不过对阅读相当友好。叙述的框架在《古今之变》下进行，前两章在这个框架下走得相当好，从尼采到萨特；但是第四章关于自由主义的讨论还是太浅了，没有沿着什么主线讨论。后面的 Q&amp;A 好评。</p><h2 id="谈美"><a href="#谈美" class="headerlink" title="谈美"></a>谈美</h2><p>[6/10] 在合适的时间写出来的小册子。作者把美视作一种超然于俗生活的崇高体验，同时把美感和快感分割开来，将美视作来源自然、与情感交融的情感体验。同时，再往前一步，给出了情感驱使理智、经验、灵感等来创作。受限于时代，彼时文论和精神分析还方兴未艾，而作者似乎对现代一些的文学作品了解不多，同时也不是很系统的分析。但仍然脉络清晰的给出了自己的意见。</p><p>就感觉…也是很入门性质的小册子，偏扯淡而不是偏论证，看看就得了。</p><h2 id="社会学的邀请"><a href="#社会学的邀请" class="headerlink" title="社会学的邀请"></a>社会学的邀请</h2><p>[9/10] 从三圣的宏大的叙述，到个人构建社会、后现代。再介绍社会学视角下的家庭 教育 宗教。前几章的啰里八嗦让我想扣一分，中间叙述的不错，不过后现代那节讲的不太行。最后一章给我把这一分拉回来了。社会学应该是一种实践。对于码农来说，这种实践应该是开源的、不断进行的。很感谢在这个时候读到这本书。</p><h2 id="惊呆了！原来这就是社会学"><a href="#惊呆了！原来这就是社会学" class="headerlink" title="惊呆了！原来这就是社会学"></a>惊呆了！原来这就是社会学</h2><p>[8/10] 日语名「社会学用语图鉴」，其实对入门书写得还算蛮真诚的。简单介绍了一下社会学家的大概想法。当然，看这本书肯定是不够的，导论多少是隔着靴子挠痒，只看导论也是误入歧途。但多少给了足够的介绍，方便我按图索骥。</p><h2 id="24-7-晚期资本主义与睡眠的终结-晚期资本主义与睡眠的终结"><a href="#24-7-晚期资本主义与睡眠的终结-晚期资本主义与睡眠的终结" class="headerlink" title="24/7:晚期资本主义与睡眠的终结 : 晚期资本主义与睡眠的终结"></a>24/7:晚期资本主义与睡眠的终结 : 晚期资本主义与睡眠的终结</h2><p>[8/10] 小册子。没啥新东西，但是足够有启发性。这本书讲的不是睡眠，但是描述了一种晚期资本主义的文化逻辑，这种逻辑既带有一部分早期资本主义的清教意味，又有消费的源动力。睡眠和死亡是危险的又坚决的离开这个虚幻世界的方法。</p><h2 id="成为动画制作人吧！-做脚踏实地的梦"><a href="#成为动画制作人吧！-做脚踏实地的梦" class="headerlink" title="成为动画制作人吧！ : 做脚踏实地的梦"></a>成为动画制作人吧！ : 做脚踏实地的梦</h2><p>[9/10] 壁吧快乐书。把动画工业整个体系讲的清楚明白，包括并不限于制作人视角中的日本动画制作流程、日本动画公司为什么手头没钱、城市的影响、动画人的收入、为什么动画重要。可以看到里面洋溢的热情。</p><h2 id="有所不为的反叛者-批判、怀疑与想象力"><a href="#有所不为的反叛者-批判、怀疑与想象力" class="headerlink" title="有所不为的反叛者 : 批判、怀疑与想象力"></a>有所不为的反叛者 : 批判、怀疑与想象力</h2><p>[8/10] 历史学。</p><p>匈奴这节看的比较头大，有的讨论虽然是随笔，但是还是要比较多的专业知识的。但是非常好的一点是，作者在论述中，成功把基本的逻辑“考察历史怎么被塑造的”“文化的流变”以及“现代对历史的呼唤”这几个很关键的地方传达给了读者，然后在后文专业的论述中，利用这几个武器来进行论述。可能历史细节我一会儿就忘了，不过这个构造过程我大概是会铭记的</p><h2 id="规训与惩罚-监狱的诞生"><a href="#规训与惩罚-监狱的诞生" class="headerlink" title="规训与惩罚 : 监狱的诞生"></a>规训与惩罚 : 监狱的诞生</h2><p>[10/10] 妙极！兼顾整体之美、分析之巧妙与学科跨度之大。全书展现的是权力运作的轨迹和知识的创造。福柯以一种谱系学的视角，从旧时代的审判入手，这是旧时代国王权力的体现。并描述了他的存在与民主阶层的态度、各阶层的普遍犯罪、权力的失衡和断裂。在过渡到新时代的时候，福柯描述了理想的“教改”形式，并在经济背景下，借助修道院等同一时段知识生产的进程，刻画了知识—权力—规训这一思维路线。并描绘了“全景敞视监狱”这一个民主的场景。再回到现实中，作者对现代监狱和其不尽人意之处再度进行了刻画，把这个系统反直觉的地方再度纳入到这个系统中。</p><h2 id="数据密集型应用系统设计"><a href="#数据密集型应用系统设计" class="headerlink" title="数据密集型应用系统设计"></a>数据密集型应用系统设计</h2><p>俗话说得好，意淫健身…哦不对…</p><p>这书是好书，著名的 ddia，作者对一切都信手拈来。好的不用说了。但是我已经不是入门者了，必须要提醒一下，对于读者来说，这样的书是危险的。我当初读了一遍，然后基本都忘了 orz。现在后面几节 Streaming 的也记得不太清楚了，还是要自己多看论文，多记录。不能沉浸在导论带来的欢愉中。</p><h2 id="System-Design-Interview-An-insider’s-guide-Second-Edition"><a href="#System-Design-Interview-An-insider’s-guide-Second-Edition" class="headerlink" title="System Design Interview : An insider’s guide, Second Edition"></a>System Design Interview : An insider’s guide, Second Edition</h2><p>很好玩的书，一点都不难。各种工业系统扫盲。</p>]]></content>
      
      
      
        <tags>
            
            <tag> acing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2021 acgn</title>
      <link href="/2022/02/11/2021-acgn/"/>
      <url>/2022/02/11/2021-acgn/</url>
      
        <content type="html"><![CDATA[<p>2021 年对我来说是很糟糕的一年，因为看的动画少了不少。原因我也不知道，可能上班上成脑瘫了。</p><p><img src="https://image.mwish.me/blog-image/704AE81B-0BCF-4437-B509-64684BE6F6B7.png" alt="704AE81B-0BCF-4437-B509-64684BE6F6B7"></p><p>看的厕纸倒是多了些，毕竟在马桶上就能看。</p><p>再咋难堪也得做总结的，类似有钱没钱回家过年。希望 22 年能多看些，别跟 21 年一样跟死人没区别。</p><h2 id="Anime"><a href="#Anime" class="headerlink" title="Anime"></a>Anime</h2><h3 id="四叶游戏-クロスゲーム"><a href="#四叶游戏-クロスゲーム" class="headerlink" title="四叶游戏(クロスゲーム)"></a>四叶游戏(クロスゲーム)</h3><p>年轻人的第一部安达充。总感觉是会在 tv 黄金档时间轮播的那种动画。虽说偶尔来写喜闻乐见的剧情，偶尔插科打诨，主线人物夸张的能力和不甚严谨的棒球。但这丝毫不影响本作的感情线和主线的优秀：从第一集的光不知道该不该哭泣，到最后的「可以说谎吗」「去甲子园，投出160KM的球」。安达充写出了足够精彩的比赛，也描绘出了未成熟的少年面对死亡、不知道怎么表达自己情感的人慢慢前进，并在球场上将静静流淌的情感表达出来。</p><p>感兴趣的可以看看第一集先，达到了教科书一般的效果。</p><h3 id="無職転生-～異世界行ったら本気だす"><a href="#無職転生-～異世界行ったら本気だす" class="headerlink" title="無職転生 ～異世界行ったら本気だす"></a>無職転生 ～異世界行ったら本気だす</h3><p>2021 年节奏莫名其妙多的动画。其实没啥说的，有的毒电波就真的很毒电波，比世纪动画初偷看人洗澡电波多了。冈本学很强，制作也好。在 Part1 的时候，回归本真的“异世界”和“成长”感很强。主角一步步走出新手村，然后一步步犯错 — 修正。Part2 的「旅行」感太棒了，有一种切实的「异世界」的漂泊和温馨，也有感情的真挚流露和家庭与爱，和撑起这一切的演出。</p><p>抛开制作不论，第二季的「人是会改变的」和 Ep 23 应该是最重要的地方，这很大程度上也是对这部动画争议的回应了。</p><p>P.S. 魔界大帝可爱</p><h3 id="To-Heart"><a href="#To-Heart" class="headerlink" title="To Heart"></a>To Heart</h3><p>传说中的 Gal 改巅峰之一，AQUAPLUS 的原作，形式偏向单元剧。监督高桥直人是出崎高徒，编排表现能力很强。我个人比较喜欢的回数是 2/4/6/11/13 。相对常靠一些扭曲的情感、非常强烈的冲突、完全揭露角色内心的表达来塑造角色的校园/恋爱动画，To Heart 是更温和、含蓄的，在风格上平淡如水、在恋爱和情感上点到为止，甚至能让你想到自己的校园生活。</p><p>本片的 Op 是这份温馨的缩影之一，从古朴的校园角落到青春的角色，到这种克制的表现，淋漓尽致。</p><p>实际上在观看 \<To Heart\> 的时候，本身也是平淡而美好的。这让本片和《神是中学生》一起成为我本类型最喜欢的作品之一。</p><h3 id="甜梦猫-ミュークルドリーミー"><a href="#甜梦猫-ミュークルドリーミー" class="headerlink" title="甜梦猫 (ミュークルドリーミー)"></a>甜梦猫 (ミュークルドリーミー)</h3><p>其实这应该算 2020 的片？但是是 2021 播完的，片没看完等于没看对吧～</p><p>导演樱井弘明，三丽鸥的片儿，形式很单元剧，属于子供动画。但是莫名其妙适合社畜看。本片的演出风格非常类似漫画，语速快多话语节奏紧凑，有着充足的乐子。有的时候我怀疑这片是不是子供动画，因为里面角色时常暴露出一股社畜摆烂味，而不是少年少女的正面勇敢、坚持；负面的满地打滚和对亲人不理解（和光美抓心对比其实挺明显的），但用这种方式，也能很喜剧的面对了这些问题，而没有逃避它们。</p><p>舞良回和女装回是我最喜欢的两集，尤其是舞良回，面对逝去的亲人保持微笑、乐观、善良和爱，这就是子供动画的醍醐味吧。</p><h3 id="飞跃巅峰2-トップをねらえ2"><a href="#飞跃巅峰2-トップをねらえ2" class="headerlink" title="飞跃巅峰2 (トップをねらえ2!)"></a>飞跃巅峰2 (トップをねらえ2!)</h3><p>如果说，飞跃巅峰1 是庵野秀明和主角一起飞速进化，飞跃巅峰2 就是鹤卷的少年故事：在故事和叙事上的严谨和宏大感少了几分，没有了在学校努力锻炼、转瞬即逝的初恋或者成长到顶天立地，更多的是奇怪的设定、呼唤人类与爱的少女和机器、少女拯救自己。这提供了一种不同维度的浪漫：在太空看日出、与不是少年的人的对峙、时空检察官的房间以及浪漫的千纸鹤。相对 top1，这些意象和诺诺莉莉反而更能代表这样一部很少年的作品。而相同的是，结尾那份横跨万年的浪漫，与未知的人类进化。</p><h3 id="THE-BIG-O-THE-ビッグオー"><a href="#THE-BIG-O-THE-ビッグオー" class="headerlink" title="THE BIG-O (THE ビッグオー)"></a>THE BIG-O (THE ビッグオー)</h3><p>日升的片，单元剧。第一季在 1999 年播出，第二季则在 2003 年。元素有点像蝙蝠侠/楚门的世界。背景是故事里的所有人都失去了记忆，依靠朦胧的爱、道德和疯狂活下去。相对于严谨的世界观或者细致的人物描绘，本片塑造的更接近一种氛围：来源未知的萝卜、失去记忆的城市、朦胧的时钟、不知道在想什么的大人。这些故事对人物和世界观描绘都是不充足的，但是这种朦胧而虚幻的氛围却有一股子美感和奇妙的 PKD 味。</p><p>顺口提一嘴，这片女主有机器人+无口两属性，cv 配的也很出彩，直接加分了。</p><h3 id="新・福音战士剧场版：终-シン・エヴァンゲリオン劇場版-│▌"><a href="#新・福音战士剧场版：终-シン・エヴァンゲリオン劇場版-│▌" class="headerlink" title="新・福音战士剧场版：终(シン・エヴァンゲリオン劇場版:│▌)"></a>新・福音战士剧场版：终(シン・エヴァンゲリオン劇場版:│▌)</h3><p>这片刚上映的时候，因为呆呆兽面包在 s1 上闹腾，出了一些奇怪的节奏。放源之后又在 s1 天天大战。可见 s1 真实 eva 论坛了。</p><p>尽管有着带一定量的设定集，但是 Eva 并不算是那么严谨的作品，或许从角色上理解故事比从世界观上理解要妥帖的多。其实在 Q 那个不知所云（但是很时髦）的内容下，能走到终，给一个完整的结局，是很了不起的。Eva 完全是庵野秀明个人的表达和救赎，在 fin 中，真嗣畅快的和所有人和解，然后向旧的世界做了一个畅快的告别，然后跟一直相信自己的大胸眼镜妹走到了一起。从动画的角度说，真的很畅快，20多年的故事干脆的完结了。随着「再见了，所有的 Eva」，再到沙滩上再一次见面，再到跑出车站，这个故事结束的很畅快。</p><p>本质上，Eva 的故事优秀，很大一部分要归功于角色、Staff 功底。指责TV版旧本身就是不合理的，你看磨砂雪画的绫波微笑多好看。但回头来说，但这更多（TV 后期和 EOE）是很私人的作品，类似城堡这样，指责世界、指责大人、想要逃避又想拥抱，更多是一种痛苦的自我表达和一些毒电波，这些恰好是命中时代命脉的。庵野秀明表达完之后，过了这么多年，终于想明白了，但是和 eoe 不同，我们被甩在身后了，茫然的看着这个后现代的世界。从这个角度上来说，终是很不错的完结作品，而 EOE是伟大的作品。</p><h3 id="DARKER-THAN-BLACK-黒の契約者"><a href="#DARKER-THAN-BLACK-黒の契約者" class="headerlink" title="DARKER THAN BLACK -黒の契約者-"></a>DARKER THAN BLACK -黒の契約者-</h3><p>BONES，奇幻 + 单元剧。特点是逼格、不错的氛围、良好的角色塑造、尚可的世界观和忧伤的悲剧单元剧们。Bones 感觉经常拍一些自己也讲不清剧情的片，靠单元剧和优秀的演出、逼格和角色顶上去。</p><h3 id="歌剧少女！！-かげきしょうじょ"><a href="#歌剧少女！！-かげきしょうじょ" class="headerlink" title="歌剧少女！！(かげきしょうじょ!!)"></a>歌剧少女！！(かげきしょうじょ!!)</h3><p>漫改，被制作限制的非常多的动画，11-12 外包回不禁让人叹息。相对于中文名称类似的《少女☆歌劇》，本片有着迥然相异的风格：有着并不箱庭而封闭的世界、着重舞台下的个人（和更贫穷的多的制作）。受篇幅限制，前期的风格容易让观众把重心放在奇怪的地方，而动画又停在了一个尴尬的位置。但本片的角色塑造相反是出彩的，不同家境、不同心思的少女，为了美与追求出现在了舞台下，纯粹的为了目标努力。并以此为基线，贡献了几个优秀的角色回（我个人相当喜欢 Ep 8）。本片贡献了我的年度最强 ED（其实有三个 ed，双胞胎唱的没在正片放出来），这个 ED 也是作品主题的体现：角色在同样舞台、身穿同样制服，却能以不同方式，展现不同的、属于她们的魅力。</p><h3 id="废弃公主"><a href="#废弃公主" class="headerlink" title="废弃公主"></a>废弃公主</h3><p>榊一郎 + Bones + 吉田玲子。在中古的时代中旅行，巧妙而含蓄的情感在故事中慢慢汇聚。同时，感觉整个故事结构算是拼凑在一起的，每段单独拆开来看都有很不错，合在一起感觉味道怪怪的…吉田玲子脚本不是不行，原作也非常有想法，但是节奏太快导致每一段看起来都很割裂；人物其实都有特色，但是从头到尾女主都刻意保持这种快乐的状态，，想用 JRPG 的简单思维来解决宏大的问题，用温柔而没有记忆的态度对人，感觉我能理解用意，但是仍然觉得很怪异。但这仍然是一部值得看的作品，后期有几回给我的感觉非常之好。</p><h3 id="剧偶像-ゲキドル"><a href="#剧偶像-ゲキドル" class="headerlink" title="剧偶像 (ゲキドル)"></a>剧偶像 (ゲキドル)</h3><p>2021 年最大的神经病动画。有病的企划、有病的剧中剧、有病的剧情、药味的展开。这片不算好看，不过算很乐子的作品，值得看一眼。颇有股子小兔子暗黑无限破的味道。</p><h3 id="赛马娘-Pretty-Derby-第二季"><a href="#赛马娘-Pretty-Derby-第二季" class="headerlink" title="赛马娘 Pretty Derby 第二季"></a>赛马娘 Pretty Derby 第二季</h3><p>2021 年最热的作品之一？很棒，非常棒，其实监督演出水平没有比前座高出一筹，但是脚本和节奏实在是好了不少。相对于前作不知道哪来的便宜老妈和便宜对手，这一作以伤病、理想和羁绊作为主轴，在赛场上和赛场下坚持这一切，加上 cy 真的有钱，所以效果真的不错。但是实际上感情的爆发通常仅仅以一集为界，少了那种一鼓作气的畅快，“为什么要跑步”也是作为一种背景板，而不是使命、责任、更快更高更强的精神——这有点苛责了，但是我没有在上面看到更魂的东西，还是很遗憾的，真的很遗憾。</p><h3 id="雄狮少年"><a href="#雄狮少年" class="headerlink" title="雄狮少年"></a>雄狮少年</h3><p>很有温情的片子。分镜合格，展现了农村城市风采，但只作为背景板。人物除了主角外比较平面，但是能立得住。“舞狮”作为线索，并没有那么多“思乡”的成分，相反在影片中，这是一种对日常的超越和对自我的磨砺。在这个过程中，主角得以有机会改变并超越自我。而重要的是，这份超越并不能直接影响现实，这让它完全与功利世界脱钩，成为了精神上的“狮子”的证明，也见证了“尼采三变”，这恰恰是最巧妙的一点。在广州那段蒙太奇相当棒，在楼上跳舞很像周星驰的电影，而舞狮开始又很像第三新东京市上班的场景，从观众到台上也让我想起了少歌ep1。不过说到底这片舞狮就是一个精神世界象征，而不是一项技艺，莫名挺不国产片的。</p><h3 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h3><ul><li>SSSS.DYNAZENON ：很青春的片子。刚看的时候预期很低，但意外还可以。没什么大事的忧伤回忆、并不实在的战斗和伤害、恰到好处的微妙氛围以及带来这一切的演出。经由怪兽从日常到非日常，在这之中建立关系，最后又回到日常。Ep10 的演出非常值得一看。</li><li>STAR DRIVER 輝きのタクト：三一老师和昴星团一起推荐给我的片子。我成功感受到了来自昴星团的感动，并且感受到了本片中浓浓的青春感，但真没 Get 到这片。剧中剧很不错。</li><li>86: 没播完所以不写了…这片非常动物园种族主义，情感表达也很直接，就直接心理描写的那种。其实我更喜欢塞林格这种含蓄一点的逼逼叨叨。但这片第一季结尾到第二季的演出真的都很不错，而我恰好还中二，也能接受这种表达（可能不同人接受点不一样，我能接受这种动物园种族主义、奇怪表达，却接受不来夏日大作战那种土剧情…）。新人监督没安排好工期感觉也能接受吧。留明年写吧。</li></ul><h2 id="Game"><a href="#Game" class="headerlink" title="Game"></a>Game</h2><h3 id="マルコと銀河竜"><a href="#マルコと銀河竜" class="headerlink" title="マルコと銀河竜"></a>マルコと銀河竜</h3><p>TOKYOTOON 作品，电波系喜剧，4-5小时就能推完，属于短平快。CG 量大充足、动画也做的很不错（还上过作画 mad？）。剧本属于不能深究就看的很愉快的。虽然人物土、故事土而且即视感很强、剧情间割裂感也比较强，但是因为作品基调有点无厘头电波，所以玩的时候也不会太 Care。四五个小时游戏时间里全程都能搞这么欢快也不多见。让我们享受这一切吧！</p><h3 id="蓝宝石般的被害妄想少女"><a href="#蓝宝石般的被害妄想少女" class="headerlink" title="蓝宝石般的被害妄想少女"></a>蓝宝石般的被害妄想少女</h3><p>原橙光作品，现 Steam 上有售，带点社会派推理味道的作品。小游戏非常蛋疼。游戏虽然制作比较简陋，但是真切展现了 80-00 年代的风貌，在视角转换、角色塑造、悬疑方面都比较到位，从遥远记忆中的书信，到一件件案子，最后到法与情。在妄想与现实中切换，跨越漫长的时间，而在这期间我确实感受到了足够的魅力。</p><h3 id="英雄伝説VI-空の軌跡FC"><a href="#英雄伝説VI-空の軌跡FC" class="headerlink" title="英雄伝説VI 空の軌跡FC"></a>英雄伝説VI 空の軌跡FC</h3><p>非常著名的 JRPG，在卡卡布三部曲之后的英雄传说，也是轨迹系列的开始。作为分割商法的一部分，FC/SC 分割的应该是非常自然的。私以为空之轨迹的系统有点旧，刷怪体验也怪怪的，战斗和演出结合的一般般。但是这作满足了 Falcom 的理念，不同角色提供了足量的对话，让这个小小的王国（估计还没江西省大）的不同地区充满了魅力和充盈的体验。玩家和角色一起，在这个温柔的世界中，用脚步丈量国土、结识伙伴、一起解决重大的问题。有的观点并不完美，有点 JRPG 的拧巴味，但这种过于美好的体验、少年冒险的故事还是很 JRPG 醍醐味的。</p><p>FC 打了我国庆前一个月和半个国庆，导致我无力打 SC 了，后面是云的。</p><h3 id="It-Takes-Two"><a href="#It-Takes-Two" class="headerlink" title="It Takes Two"></a>It Takes Two</h3><p>双人游戏的一个新视角，2021 的 TGA 年度游戏，和网友 Rsygg(征婚中) 一起打的。前中期虽然缝合，但是视觉体验和游玩体验真的不错，每一节都有新的体验和畅爽的方式，可以说是很极致的“游戏”了（不过有的地方有点莫名毒电波，你说你为啥要杀小象呢，有病吧），后期关卡涉及有点下降，体验也差了点，但是视觉效果还是到位的。最后，确实是一个很棒的双人游戏。</p><h3 id="金色ラブリッチェ"><a href="#金色ラブリッチェ" class="headerlink" title="金色ラブリッチェ"></a>金色ラブリッチェ</h3><p>SAGA PLANET 这几年混的好像挺好的。我 Galgame 推的比较少，其中很大一部分游戏反而更侧重于男主的描绘，说来 Galgame 这个词不是「美少女游戏」的意思吗！本作则是彻头彻尾的「美少女游戏」，展现女主角魅力的作品，这也导致很难给男主定位。日常 neta 很多很棒，正经讨论是掺水的：上流社会的背景终究只是个幌子，而不是前进的必要推动力。其实这么多线多少就主题就是「自己」的对立与统一，和努力奋斗儿。作为正经评价来说，很难定论表述真的合格了。当然，说了这么多，也尽管知道是放刀子，女主的魅力依然无与伦比。</p><h2 id="Novel"><a href="#Novel" class="headerlink" title="Novel"></a>Novel</h2><p>总结的时候才知道，2021 年看的太少了… 争取 2022 年多看点</p><h3 id="BEATLESS"><a href="#BEATLESS" class="headerlink" title="BEATLESS"></a>BEATLESS</h3><p>机器人/bmg/长谷敏司。比较出乎我意料的作品。自弗兰肯斯坦以降，SF 中的「机器人」以人类的他者、技术（不一定是正面的）的代表、工具理性的实现者、人类自己塑造的神明。阿西莫夫有机器人学，缔造了机器人的三法则，试图和善意的机器人走下去；《太空漫游2001》则粗暴而震撼，人类掐死了机器人——自己的造物——来走向更高的一步。Beatless 描述的是机器人有非凡智慧、但只有工具理性、也受到人类限制的世界。这个世界中，主角选择了将一切复杂的运作交给机器人。面对虚幻的社会和早已度过的奇点，人类在漫长的否认之后重新认可了自己的能动性，然后不安的机器人也获得了人类的信任。或许这本书阅读体验并不友好，不过很久没看到这么浪漫的作品了。</p><h3 id="盛夏之门"><a href="#盛夏之门" class="headerlink" title="盛夏之门"></a>盛夏之门</h3><p>海因莱因著名的「猫」，国内出版的封面都没有猫的，真的垃圾。与其说本书是个科幻，不如说是个海因莱因的「工程师浪漫」表述和喜剧小品。说句题外话，阿西莫夫冷战那会儿不写 SF 了，去写了不少科普作品，来鼓励美国人参与科技。而《盛夏之门》无疑是一部「工程师迷」作品，你能感受到在其中创造的热情。何况还有一只猫！一只猫！一只猫！至于故事本身倒是感觉被借鉴太多了，多少有点乏善可陈。</p><h3 id="盲视"><a href="#盲视" class="headerlink" title="盲视"></a>盲视</h3><p>非常硬的科幻，有种把 SF 写成学术研讨的感觉，作者笔力其实不太行，很多复杂的描写给读者的感觉是「很复杂」，我心想你写不出字可以找人画个艺术画嘛。本作设定相对较多且比较有意思，有着「天堂」「吸血鬼」「罗夏」「感情操作」「精神分裂」等过多的科幻元素，但故事性其实相对弱一些，而且部分故事和设定结合的不是很好，吸血鬼的设定是很自然的推导出来的，耐人寻味的是吸血鬼最后的结果。罗夏/攀爬者和盲视的设定给足了，但是读起来却很不自然很痛苦。最后，看似硬核的 SF，反而表现了科幻里面浓浓的爱。SF 就是爱，爱就是 SF！</p><p>希望作者能成长为这一代的弗诺文奇。</p><h3 id="付喪堂骨董店"><a href="#付喪堂骨董店" class="headerlink" title="付喪堂骨董店"></a>付喪堂骨董店</h3><p>轻小说，前面读起来感觉像低配故事会+奇幻，偏单元剧的形式，适合在马桶上看（请不要真的这样做，为了你的肠子和屁股）。单元回质量参差不齐。但是作者大纲把控应该是一直在线的，某些伏笔竟然真的都用上了。5/6/7 卷质量稳步上升，前面所有的故事都是为了这个盛大的舞台展开的，把前面的「bug」都展开的同时，也在感情上跟读者达成了一种同步，给了一个无比盛大的 Boy Meets Girl 故事。作为小说质量值得讨论，但是确实是最适合「轻小说」这样题材的浪漫作品。</p><h2 id="Comic"><a href="#Comic" class="headerlink" title="Comic"></a>Comic</h2><p>我漫画向来看的很少，相对 2020 年基本上只看了《美伦X》，今年还算多些？</p><h3 id="成惠的世界-成恵の世界"><a href="#成惠的世界-成恵の世界" class="headerlink" title="成惠的世界(成恵の世界)"></a>成惠的世界(成恵の世界)</h3><p>肌肤如雪老师推荐。连载时间比较长的作品，十余年只有十来卷，翻译也不太行，有过动画改编，但质量也一般。也是日本星云赏得主。本作有孤僻的外星人、没什么特点的学生、并不优秀的机器人，在这个日常夹杂科幻的漫画中，角色完美展现了「小小的我被被人所爱，所以要回馈这份爱」的主题。而带有奇幻甚至民俗性质的「猫/鼠/蛇」的设定贯穿全篇，也给了作品悠长却庞大的张力。</p><h3 id="即使如此小镇还是转个不停-それでも町は廻っている"><a href="#即使如此小镇还是转个不停-それでも町は廻っている" class="headerlink" title="即使如此小镇还是转个不停(それでも町は廻っている)"></a>即使如此小镇还是转个不停(それでも町は廻っている)</h3><p>我的年度最佳漫画，带一点 SF 的日常系作品，长鸿有翻译为《女仆咖啡厅》，但这标题其实蛮不恰当的。Shaft 曾经动画化过一版，但我感觉动画化的恰好没有体现出本作的醍醐味。</p><p>石黑正数是一个非常、非常有想法的作者，能将 SF、推理等复杂的元素糅合到日常漫画中，并构造出或温馨、或高效、或惊悚的故事。本作的时间顺序是乱序的，石黑正数描绘这些故事的时候，或从平凡的故事中寻找到意义，比如弟弟第一次度过午夜发现一天就在眼前度过了、姐姐去小学的时候，发现曾经的整个世界变得如此渺小；有侧重于结构的故事，比如第五卷的结尾；也有单纯符合人物和年龄的情感与互动。在看第一卷的时候和最后一卷的时候，剧中的人物和我自己都有了不同。阅读的时候，从第一卷的只有几个主要人物的刻板印象与不耐烦，到最后的漫长的告别和留念。我已经爱上了这个小镇的一切。</p><h3 id="风之谷的娜乌西卡-風の谷のナウシカ"><a href="#风之谷的娜乌西卡-風の谷のナウシカ" class="headerlink" title="风之谷的娜乌西卡(風の谷のナウシカ)"></a>风之谷的娜乌西卡(風の谷のナウシカ)</h3><p>风之谷的动画只拍了一个开头，漫画部分是一个漫长的史诗，刚开始读的时候有点没适应（可能我看的漫画太少了），分镜多少和常见的漫画风格不太一样。漫画描绘了带有神性的娜乌西卡在两国的争斗背景中，探索世界并带着世界走向明天的方式。</p><p>宫崎骏老师是很矛盾的，你看他喜欢飞机蒸汽机钟表机械，但是又热爱环境，喜欢田园牧歌一样的生活，对科技抱着奇怪的态度。有的时候我觉得去翻翻地海之类的作品，反而更能感受到一些他受的影响之类的。风之谷的主题我感觉多少是有过一些变化的，从虫对环境的变化，到最后「生命是黑暗中的光」，这种豹变的主题本身就展现了一种生命的力量。（尽管他本人观点我多少觉得不认可？）</p>]]></content>
      
      
      
        <tags>
            
            <tag> acgn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mwish 2021 summary</title>
      <link href="/2022/01/31/mwish-2021-summary/"/>
      <url>/2022/01/31/mwish-2021-summary/</url>
      
        <content type="html"><![CDATA[<h1 id="2021-日常生活、整体之美与我"><a href="#2021-日常生活、整体之美与我" class="headerlink" title="2021: 日常生活、整体之美与我"></a>2021: 日常生活、整体之美与我</h1><p>随着中国新年的到来，2021 这一年最终还是走到了尾声，我们应该怎么样看待这一年，会不会有什么后悔，以及对未来有什么憧憬呢？我们又能在这三百多天里面，学习到什么特殊的经验，可以在这样的晚上，闲暇的时光中回顾到这么一点点小小的经验呢？</p><h2 id="工作和生活"><a href="#工作和生活" class="headerlink" title="工作和生活"></a>工作和生活</h2><p>工作或者说毕业已经一年半了。其实向来觉得工作没啥好说的，不过今年做的事情也不少了：</p><ol><li>自己做的分布式事务上线了，基本上只有分布式事务的部分，单机部分算是个没怎么打磨的系统，不过现在已经在30%以上的集群上跑着这个功能了</li><li>行列混合存储上线了，其实做的像一个特别简单的 PAX，然后不支持延迟物化那些，算是省了 50% 以上的存储空间？</li><li>（今年最重要的部分？做了小半年）Page 磁盘格式到内存格式的重构，原先的 Page 在磁盘上是个 Thrift 格式，内存中会解析成一个有序的 <code>std::vector&lt;Row&gt;</code>。我独立把磁盘格式改成了一个不需要解析的二进制格式，然后将内存格式也做了连续内存 + Delta 的重构。然后 row format 也改成了类似 MySQL InnoDB Compact 的格式，在各种测试环境下有 30%-一倍的性能提升和占用空间的减小。</li></ol><p>这么一看其实今年压根没做多少事，当7月份，我干活我们组新人来问我「一年以来做了什么」，我陡然发觉，对着工作的一年没有什么记忆。</p><p>我能有什么记忆呢？日常生活总是一成不变的，从遥望着中关村遥远而虚无的幻景，到每天在齿轮上和幻景一样的工作。更有甚者，你的生活本身也就成了这个活动的一部分：</p><ol><li>早上，起床，然后赶去上班</li><li>在公司早上看点博客，处理点紧急事情</li><li>中午吃个饭，逛逛 s1，review 一下代码，下去走一圈回来安静处理一下工作</li><li>下午可能开开会，跟业务扯扯皮，然后安静写代码或者写 RFC；或者对接各种需求的的用户</li><li>晚上吃个饭回来，要么开会讨论方案（其实很水的，一般没啥重要的），要么接着肝代码</li><li>晚上滚回家，有的时候在家里还得处理公司的事情；闲的时候就在家看书看看代码了</li></ol><p>代码和 RFC 部分中，20% 的部分是有意思的、有创造力的部分，需要你结合业界的方案或者一些 paper，来仔细思考它怎么 work 在你的接口上，和已有的内容兼容。其它的部分无非是：</p><ul><li>琐碎（但重要）的工作，比如 Log 的修改，语义的对齐，详细而复杂的测试</li><li>容易设计、容易实现的部分</li><li>急着上线，没法仔细打磨的部分</li><li>跟客户对接</li><li>测试一些各种版本 tools 的性能</li></ul><p><img src="https://image.mwish.me/blog-image/image-20220201031034442.png" alt="image-20220201031034442"></p><p>那么，其实你会发现，有的时候大家自己也不知道发展方向是什么样子的，很多时候在 spin 或者摸鱼，这本身也和 team 发展有关。而在日常生活中，你不能不做这些事情，而且这些东西确实是「重要的」，很多时候你要靠这些东西来找到前进方向。要怎么才能在来问你「bool 上建索引为什么不行」或者「qps 动态增加」的用户中，寻找到宝物呢？</p><p>有一会儿我特别期望组里有几个靠谱的哥们能出主意，告诉我们接下来做什么。这种想法是对的吗？可以说我是一位合格的实现者，能够刨代码、对比方案；但是可能并不是一个合格的给出方向的人。这样的人难免迷失在日常的海洋中。据我观察，边上这样的人还是不少的。反过来说，码农最开心的或许是到一个地方造一个地方的轮子，当一个轮子雇佣兵，随时都能构建新的东西（忽略漫长而痛苦的上线期）。</p><p>生活是另一个部分，在鸣人的厂子边上，大概只能找到 4000+ 一个月的十来平米的单间。当你回到这个「宿舍」，或者周末的时候，要用什么样的仪式感，和什么样的方式，来打造自己的生活呢？在昏暗、寒冷而森严的这片天空下，如何塑造美好的记忆和日常？</p><h3 id="劳动伦理与超越日常"><a href="#劳动伦理与超越日常" class="headerlink" title="劳动伦理与超越日常"></a>劳动伦理与超越日常</h3><p>「努力工作，努力玩」可能是最让我讨厌的话之一，和「周末好好休息，工作日好好上班」差不多讨厌。它暗示了一种劳动伦理的存在，即休息好像是为了工作一样。</p><p>热爱工作的人是什么样子，难道他们不应该以广博的见识、强大的执行力、完善的架构能力让我们尊重？只有工作的人是什么样子，难道我们不应该是丰富的，而应该是贫乏的？难道「玩」不应该是「我想要这么做」「我一定要这么做」「这是我生活的一部分」？</p><p>回到生活中，这些剩余的部分可以给我们带来上班的时候的余裕，也可以带来一些新的技能、一些超然的体验。它们可以是「庸俗的」、可以是「痛苦的」，也可以是快乐而超然的。但是，猎奇也好、奋斗也好，这些东西应该能够「带来美好的记忆」。</p><p>于我而言，ACGN 已经成了生活的一部分，周末拉人看片，翻翻 staff 看演出或者找一些很魂的 SF 是快乐的源泉。固然这本身也是庸俗的，但我相信这样的追求本身是存粹的，我能够在其中获取力量。来构成我美好的记忆。</p><p><img src="https://image.mwish.me/blog-image/A95D3E44-7D8A-46AA-B456-AA71BE00F115.png" alt="A95D3E44-7D8A-46AA-B456-AA71BE00F115"></p><p>在这其中，我觉得重要的是：</p><ol><li>即使在日常和琐碎的细节中，也不要放弃思考。这有点像那什么阿里打低星的 pua，但是你怎么看待自己边上的环境对你是很重要的。你可以看到大机械下面各个部件是怎么运转的，你在大机器里面在做什么，什么是你想要的，下一步要做什么，你如果不跑路可以做什么</li><li>有一定的执行力和坚持的能力，能够在琐碎的日常中保持自我。这点看上去和之前是矛盾的，但是我认为，对自己想做的事情还是得坚持一下。</li></ol><p><img src="https://image.mwish.me/blog-image/83D363D6-F6D3-4E38-82FD-0C54946AFA6F.png" alt="83D363D6-F6D3-4E38-82FD-0C54946AFA6F"></p><ol><li>不一定要有那么详细的计划，但要保证事情在前进。本人去年实际上在这点上是有不少缺陷的，几个想做的项目和一些工作上的事情都没有足够的保证运行良好。</li><li>抽点时间出来学点想要的东西吧～</li></ol><p>日常生活和劳动伦理是被占有、侵占的。睡眠是我们的防线，而爱好和向往能够给我们画出一个方向；执行力则能够保证这些方向能够向前。</p><p>当然，回头来看，也有能力能够带来的一些余裕。我的一些好友能把工作、想做的事情和探索性质的东西很有机的结合在一起，在日常中把大部分时间变成了这种「非日常」的工作。这是非常令人羡慕的。</p><h2 id="整体之美"><a href="#整体之美" class="headerlink" title="整体之美"></a>整体之美</h2><p>一个大学生出学系统结构、流水线会是什么看法？看到汇编会是什么想法？如果他能够知道一些上层的行为，比如看过 <code>&lt;MonetDB/X100&gt;</code> 的论文，再高屋建瓴的从 code 到指令的性能有一层把握，他的兴趣、看到的东西会不会不一样？而我的好朋友最近甚至很少看 db 的文章，而是看了很多 Arch 有关的东西，来加深自己对系统的了解。我也渐渐感受到，很多时候一些整体性的、整个链路的理解看上去很像胡吹，但是当你把它们联系起来的时候，你会诞生非常多的自己的分析与看法。这就是整体之美。</p><p>2021 年我越来越希望能够看到一些整体之美：</p><ol><li>一些整个链路上考虑全面的计算机设计，比如 MonetX100, Morsel 调度, InnoDB 的 MVCC + GC 等。</li><li>一些学科性质的跨学科带来的宽阔视角，比如《规训与惩罚》和《社会与政治运动讲义》。作者的写作能力通常来自于对整个系统、对历史的深刻了解，已经广阔的知识。</li></ol><p>这份对基础的重视和理解让今年阅读的论文和理解能力提高不少，我希望在 SF、ACGN、学习之类的诸多领域，都能把握到这样的整体之美。</p><h2 id="闲话"><a href="#闲话" class="headerlink" title="闲话"></a>闲话</h2><p>2022 年已经到了，虽然今年没多少假期，但是我还是希望能拥抱一些变化，最好能润去上海上班。能把高达、小魔女 Doremi 这几部看完，英语整好点。</p><p>祝大家新年快乐！</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Database System Concepts 7th</title>
      <link href="/2022/01/30/Database-System-Concepts-7th/"/>
      <url>/2022/01/30/Database-System-Concepts-7th/</url>
      
        <content type="html"><![CDATA[<p>前面使用部分不太感兴趣，直接从第十章开始看</p><h2 id="Ep10-大数据分析"><a href="#Ep10-大数据分析" class="headerlink" title="Ep10 大数据分析"></a>Ep10 大数据分析</h2><p>偏向大数据一些的基础架构。回头写。</p><h2 id="Ep-11-数据分析"><a href="#Ep-11-数据分析" class="headerlink" title="Ep 11 数据分析"></a>Ep 11 数据分析</h2><p>偏向利用 Ep10 拿到的结果再做一些分析。回头写。</p><h2 id="Ep12-物理存储系统"><a href="#Ep12-物理存储系统" class="headerlink" title="Ep12 物理存储系统"></a>Ep12 物理存储系统</h2><p>首先存储是分层的，具体而言是：</p><ol><li>cache</li><li>main memory</li><li>flash memory(SSD)</li><li>磁盘存储（感觉经常在商业系统存一些冷数据）</li><li>光学存储器（类似 DVD）</li><li>磁带存储器</li></ol><p>此外存储器还有接口，对应物理接口和一些协议栈：</p><ol><li>SATA 总线</li><li>PCIe 总线</li></ol><p>在协议上也有区别</p><ol><li>NVMe 协议</li><li>SCSI 协议</li></ol><p>此外，硬件接口也有区别，最常见的是 mSATA 和 M.2. 这个可以去 jd 搜搜，一看就懂。</p><p>具体可看：<a href="https://sjtu-sjtug.feishu.cn/docs/doccnfdnoqmgt6qqko5GM0tAKkh#">https://sjtu-sjtug.feishu.cn/docs/doccnfdnoqmgt6qqko5GM0tAKkh#</a> 和 《深入浅出 SSD》这两个材料。</p><p>存储设备在互联网上可能以 SAN 的形式组织，这种形式提供了盘一样的访问接口，现在也有 ifiniBand 之类的方式。此外还有 NAS 之类的，提供网络文件系统的形式（我在家组了个 NAS 放片，爽的）。</p><h3 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h3><p>以 sector 为形式组织，受限于物理的访问，磁盘生命取决于保存和访问。对外提供的性能大概是：</p><ol><li>2-20ms 的 seek time</li><li>旋转时间: 可能又是个位数 ms</li><li>传输：50-200MB/s</li><li>sector: 可能是 512B</li></ol><h3 id="闪存"><a href="#闪存" class="headerlink" title="闪存"></a>闪存</h3><p>SSD 性质看看我之前介绍就行，in short，长一点的可以看之前那个： </p><ol><li>我之前抄的：<a href="https://zhuanlan.zhihu.com/p/430451374">https://zhuanlan.zhihu.com/p/430451374</a></li><li>长一点的，感谢 SJTU：<a href="https://sjtu-sjtug.feishu.cn/docs/doccnfdnoqmgt6qqko5GM0tAKkh#">https://sjtu-sjtug.feishu.cn/docs/doccnfdnoqmgt6qqko5GM0tAKkh#</a> </li></ol><p>关于性能，可以到数千 MB/s, 同时有一定的并行读写能力。我感觉现在一般大公司内部都一堆 SSD 来 Handle 用户的写入</p><h3 id="RAID"><a href="#RAID" class="headerlink" title="RAID"></a>RAID</h3><p>上大学的时候背过 RAID0-RAID5 应付考试，现在全忘光了，感觉再背一遍也没什么意思，就主要讲讲思路吧。</p><ol><li>冗余以提高可靠性<ol><li>这点对现在的人其实有点 confusing，为什么呢，现在的时代很多时候可能单机都不需要考虑数据的靠谱，靠 GFS Style 的备份之类的是更常见的 idiom. 跟群友讨论了下，ebs/GFS 这种感觉目前还是领先地位的，RAID0 RAID1 是可以用的</li></ol></li><li>并行以提高性能<ol><li>感觉这个在 SSD 上用处有限，HDD 上倒是好一些？</li></ol></li></ol><h2 id="EP13-数据存储结构"><a href="#EP13-数据存储结构" class="headerlink" title="EP13 数据存储结构"></a>EP13 数据存储结构</h2><p>这章感觉也很 trivial，就讨论了各种存储的结构：</p><ol><li>架设在行存中的数据库</li><li>架设在列存中的数据库</li><li>内存数据库/NVM 数据库</li></ol><h3 id="行存的数据组织"><a href="#行存的数据组织" class="headerlink" title="行存的数据组织"></a>行存的数据组织</h3><p>传统的 RDBMS 会以 Block/Page 为粒度组织系统，本身 HDD/SDD 都是基于块的存储设备。它们的大小通常为 4kB/8kB/16kB。</p><p>假设 Page 大小是固定的。定长记录可以从 Catalog 里面知道长度，直接顺序存就行，变长记录可能需要一些特殊方式：</p><p><img src="https://image.mwish.me/blog-image/E4DE3EA7-EA78-4FE0-9A54-1F6459096D96.png" alt="E4DE3EA7-EA78-4FE0-9A54-1F6459096D96"></p><p>上图是 PG 中的处理形式，PG 的 HeapPage 单个 Page 内会这样组织数据。这里有个很清晰的问题是，在数据删除比较多的时候会怎么重新组织，这个时候它会在 Vacuum 阶段处理这些数据。</p><p>此外，MySQL 的 InnoDB Page 内部记录组织会更复杂一些。采用了链表+minmax+稀疏索引的形式。究其原因，InnoDB 对写操作支持要好很多，这些都可以算在写操作的支持里面。</p><h4 id="大对象存储"><a href="#大对象存储" class="headerlink" title="大对象存储"></a>大对象存储</h4><p>MySQL 的 Page 要求 Btr 的 Page 会至少存储两个 record, 多的纪录会放到 BLOB 对象和 Page 中。</p><p>PostgreSQL 有 TOAST 对象，具体如下：<a href="https://cch1996.github.io/2020/09/22/postgres-04/">https://cch1996.github.io/2020/09/22/postgres-04/</a></p><p>简单来说，TOAST 记录会放在 TOAST 表中。</p><h3 id="文件记录的组织"><a href="#文件记录的组织" class="headerlink" title="文件记录的组织"></a>文件记录的组织</h3><ol><li>HeapFile 组织，记录放在文件的人和地方</li><li>顺序文件组织</li><li>B+Tree 文件组织</li><li>Hashing 文件组织</li></ol><p>Record 的组织可以看我之前写的内容的 Tuple 部分：<a href="https://zhuanlan.zhihu.com/p/457605514">https://zhuanlan.zhihu.com/p/457605514</a></p><p>对于传统的 RDBMS，在 Stonebraker 的<a href="https://book.douban.com/subject/17665384/">文章</a> 中，表示虽然文件系统可能会有一些特殊的组织方式，不会按文件的格式顺序存放所有块，但是直接用文件组织的话，开销是比较小的。新时代随着 SPDK 等技术的发展，这个可能会有一点变化，但是程序员我感觉也不用太关注。</p><p>对于 Page 的组织，PostgreSQL 做的简单一些，会放在 Database Cluster 的空间中，PG 除了表文件，还有对应的 <code>_fsm</code> （空间空间映射）和 <code>_vm</code> （可见性映射），通过在 fsm 的标记找到可用的 Page，然后找到写入的 Page。</p><p>InnoDB 这个要复杂一些：</p><ol><li>Extent （区）：连续存放 64 个 Page，希望提高 Page 分配的局部性</li><li>Segment（段）：存放不同类型的数据，比如叶子结点段、非叶子结点段。Segment 会向 OS 申请 Extent 大小的存储空间。</li></ol><p>回收的时候，PG 根据 Freeze/Vacuum 和 <code>_vm</code> 的标记来回收，InnoDB 则会根据 Extent 的链表（XDES）来做回收</p><h4 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h4><p>数据根据某个 key 划分成多个文件/空间。这种方式能够将单个库拆分、做冷热分离，但也会影响跟这个 key 无关的请求。</p><h4 id="Catalog"><a href="#Catalog" class="headerlink" title="Catalog"></a>Catalog</h4><p>一般 Catalog 可以全部保持在内存中，存储的时候要持久化。</p><h3 id="Buffer-Pool-Manager"><a href="#Buffer-Pool-Manager" class="headerlink" title="Buffer Pool Manager"></a>Buffer Pool Manager</h3><p>掠过不谈，反正就经典 Pin, Cache Replacement, Dirty 之类的。看 InnoDB 策略、ARC 基本就行了。</p><p>这里还有个写顺序和 WAL 的问题，略过不谈，反正 recovery system 可以讲。</p><p>本质上就是预测用户行为，然后丢缓存之类的。</p><h3 id="面向列的存储"><a href="#面向列的存储" class="headerlink" title="面向列的存储"></a>面向列的存储</h3><p>没啥说的，基本参考 abadi 的 Columnar DBMS，存储看我这篇：<a href="https://zhuanlan.zhihu.com/p/457889634">https://zhuanlan.zhihu.com/p/457889634</a></p><h3 id="Main-Memory-DB"><a href="#Main-Memory-DB" class="headerlink" title="Main-Memory DB"></a>Main-Memory DB</h3><p>感觉这部分讲的还是内存上的，行列都讲，就写的不是很清晰，没啥意思。</p><h2 id="Ep14-索引结构"><a href="#Ep14-索引结构" class="headerlink" title="Ep14 索引结构"></a>Ep14 索引结构</h2><p>B+Tree 都看吐了，我一个字都不想写。就跟 Btree 比一下简单一些，Btree 省空间一点，但是没啥意义，很容易被抹平。</p><p>SSD 上的 Btree Style 索引：</p><ol><li>BwTree</li><li>FDTree</li><li>MassTree</li></ol><p>我个人反正感觉这些东西反而很多都没用上，除了 ms 的论文，就 Ark 用了下 BwTree。不知道是这些结构本身不靠谱，还是 TP 系统和 Btree 已经是时代的眼泪了。</p><p>Btree 本身是为 HDD 那样的结构设计的，在 SSD 上，Btree 还是有优势的，因为内存和 SSD 还是有 gap 的，而且 Btr 本身会有一些很细的优化，比如 trxn 之类的，但是这套东西也还是很难实现的。以 BwTree 为例：</p><p>BwTree 做了：</p><ol><li>Mapping Table: 对 Node 或者写入的映射</li><li>写入类似 Log 的形式存放，Btree 也预留了空间</li><li>无锁</li></ol><p>主存上的索引类似 ART.</p><p>还有 hashing 索引什么的，我感觉这些国内材料比较少，我自己也没写过，就不谈了。</p><p>LSM 是新时代的宠儿，因为实现比 Btr 简单，性能不错，写性能很好（设计者认为，读是很好优化的）可调整可预测，还有 RocksDB 什么的。这里还有些 WiscKey 之类的 SSD 友好结构，不过 WiscKey 设计也有一些问题，比如: <a href="https://www.skyzh.dev/posts/articles/2021-08-07-lsm-kv-separation-overview/">https://www.skyzh.dev/posts/articles/2021-08-07-lsm-kv-separation-overview/</a> 。此外 LSM 虽然本身是一个写优化的结构，但是它的思路被放到了很多 HTAP 类似的读写混合系统里面。</p><p>这里还提到了 Buffer Tree，我觉得有点类似 FD-Tree, 把更新搞到一个缓冲区（Delta），然后先找 Delta 再找下面，Buffer 满了之后按一定策略来下推。</p><p>位图索引（我记得 PG 有这个），本身和列存那套差不多，当然这套东西也可以做到 Btree 上(防止一个 Page 放不下？)。删除记录可能在定位的地方产生洞，这里可以用一个 exist 的位图表示，不过我觉得 TUM 的 PDT 思路好一些，它用了一个偏移量的 B树（Position Delta Tree）来表述。此外：</p><ol><li>如果只有某个值出现的比较多，可以单独给它一个索引</li><li>如果叶子结点发现可以位图压缩，那就用</li></ol><p>上面这些优化我感觉都是看上去能省空间，但是实际情况有点 confusing 的，暂且不表吧。</p><p>空间结构：k-d-B 树。这名字有点复杂，可以先看 k-d 树：<a href="https://oi-wiki.org/ds/kdt/#_3">https://oi-wiki.org/ds/kdt/#_3</a> 。k-d 树形态上是一个 Binary Search Tree，这里相当于提供了一个 Btree 的形式。</p><h2 id="Ep15-查询执行"><a href="#Ep15-查询执行" class="headerlink" title="Ep15 查询执行"></a>Ep15 查询执行</h2><p>直接看这个就行，对应本章的笔记：<a href="https://zhuanlan.zhihu.com/p/349943902">https://zhuanlan.zhihu.com/p/349943902</a></p><h2 id="Ep16-查询优化"><a href="#Ep16-查询优化" class="headerlink" title="Ep16 查询优化"></a>Ep16 查询优化</h2><p>统计信息参见：<a href="https://zhuanlan.zhihu.com/p/350255430">https://zhuanlan.zhihu.com/p/350255430</a></p><p>执行计划的估计可以参考：</p><ol><li>Selinger 的 System R 优化器</li><li>Graefe Goetz 的 Cascades/Volcano Planner</li></ol><p>我感觉上面 15-721 的 slide 写的很详细，目测 noisepage 参考 Columbia 抄了个 Cascade Planner。</p><p>关于连接顺序的，基本是个 DP。不过复杂度很高，基本是 $O(3^n)$, Selinger 那篇采用了 <strong>启发式</strong> 做一些优化，比如：</p><ol><li>outer join 最后 Plan</li><li>Selection 先下推 （这个在一些 case，比如 A Join B, 选择在 B 的字段，且 JOIN 可以走索引的场景下，工作的不是很好）</li><li>Projection 先下推</li></ol><p>然后有一些 interesting order 或者 physical properties 的方式来施加一些限制。</p><p>Cascades/Volcano 框架则有下列的思想：</p><ol><li>有一些被称为物理等价规则(physical equivalence rule) 的规则，来完成 transform。通常这些规则一般都是原子的，即不能被别的规则组合出来</li><li>这些规则是和代价估计结合在一起的</li><li>memorization 来存储最优的形式</li><li>保存一些子结构</li></ol><p>有一个很重要的东西是 Join Order 的选择，其实是这样的：</p><ol><li>表多直接遗传算法了，比如 PG 那种，超过 12个表直接遗传算法</li><li>传统的 Selinger 那篇文章，只考虑了 left deep tree。有一些复杂的算法会考虑 bushy tree，比如 dpccp</li></ol><p>有一个重要的话题是子查询的优化，可以把一些 EXIST 之类的改成 Semijoin，不过这个规则有点啰嗦，PG 有一块就是处理子查询，我看的人一愣一愣的…TUM 有一篇处理任意子查询的论文，这里有个二手博客：<a href="https://zhuanlan.zhihu.com/p/60380557">https://zhuanlan.zhihu.com/p/60380557</a></p><p>有一个比较重要的部分是物化视图，随着最近 OLAP 系统的火热，物化视图越来越热门。不过老大难的问题是物化视图的更新，最新的参考 Google 的 Napa 系统。老大难的问题是物化视图的选择（类似索引选择）和更新（实时性 — 写性能 — 成本），Napa 用一个 ts 来让你自己选。我们考虑下面的更新：</p><ol><li>JOIN: 相当于单条记录 Join 另一张表，然后增加/删除记录</li><li>Selection/Projection: Selection 可能好处理一些，直接区间操作就行；Projection 可能要记录数据的来源/counting，在其上操作</li><li>Agg: count/sum/avg 这些比较好处理，min/max 可能需要在有序集合上处理。维护 min/max 的插入很简单，但是要在上面处理删除是很难得。</li></ol><p>还有一些 advance 的内容，15-721 也有列，包括：</p><ol><li>top-K 优化</li><li>adaptive 的查询处理</li><li>参数化的查询优化</li><li>共享扫描、多查询优化</li></ol><h2 id="Ep17-事务"><a href="#Ep17-事务" class="headerlink" title="Ep17 事务"></a>Ep17 事务</h2><p>事务有着 ACID 的概念，这里我看到过介绍的最好的是 DDIA 那本书：</p><ol><li>A: 事务本身多个操作是可以原子性 abort 的</li><li>C: 对外的状态满足某些一致性约束</li><li>I: 可见性之类的东西受到约束</li><li>D: 提交、掉电之后还在</li></ol><p>串行化是假设事务一个接一个执行的情况，这种情况叫「串行化」。而并发控制组件（concurrency-control）会控制事务的访问。对于逻辑上等同于串行化的调度，成为「冲突可串行化」。同时，通过事务的读写关系，能定义事务之间的<em>偏序</em>关系。</p><p>这里（ <a href="https://zhuanlan.zhihu.com/p/293533311）介绍了一种用图描绘冲突的方式，我觉得是一种相当好的定义方式。">https://zhuanlan.zhihu.com/p/293533311）介绍了一种用图描绘冲突的方式，我觉得是一种相当好的定义方式。</a></p><p>这里调度还要考虑「可恢复（reconverable）」和「无级联调度（cascadeless）」:</p><ol><li>可恢复调度指的是，A depends on B,  A commit 了, B 没有 commit, 那么可能 B abort 了，A 就没法恢复了。</li><li>A-&gt;B-&gt;C，C abort 了，那 B/A 需要级联 abort。OCC 中可能遇到这种情况，S2PL 应该不会。</li></ol><p>然后这里介绍了一下隔离级别，可以参考我之前发的那玩意。隔离级别可以用 锁、ts、MVCC 或者组合来实现，这些概念其实是可以杂糅在一起的，具体还是看具体实现。</p><h2 id="Ep18-并发控制"><a href="#Ep18-并发控制" class="headerlink" title="Ep18 并发控制"></a>Ep18 并发控制</h2><p>这节感觉是有点难度的，讨论了传统的各种并发控制，和一些杂项。然后讨论了一下 Online DDL 之类的。</p><p>协议部分见：</p><ol><li><a href="https://zhuanlan.zhihu.com/p/294657612">https://zhuanlan.zhihu.com/p/294657612</a></li><li><a href="https://zhuanlan.zhihu.com/p/298576970">https://zhuanlan.zhihu.com/p/298576970</a></li></ol><p>然后 Online DDL 基本是 快照读 + 排序 + 追增量。Percolator + F1 是在写的时候做了状态兼容，把追增量这部替换掉了，其实是差不多的。</p><h2 id="Ep19-恢复系统"><a href="#Ep19-恢复系统" class="headerlink" title="Ep19 恢复系统"></a>Ep19 恢复系统</h2><p>见：<a href="https://zhuanlan.zhihu.com/p/397469987">https://zhuanlan.zhihu.com/p/397469987</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> database, reading </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Transaction, OCC and modern hardware</title>
      <link href="/2022/01/28/Transaction-OCC-and-modern-hardware/"/>
      <url>/2022/01/28/Transaction-OCC-and-modern-hardware/</url>
      
        <content type="html"><![CDATA[<p>事务处理很多成果是在上世纪完成的，在本世纪初，关于事务的研究是相对较少的。占主导地位的是 2PL 协议，作为最标准的并发控制实现。但是，本世纪关于事务有着不同变化：</p><ol><li><p>由于应用上的不同需求，相对上世纪，本世纪的应用有了显著的变化：显然，上世纪没有这么大规模的、高事务提交的互联网应用，现在的应用可能有数 M甚至数百M 的 qps，希望 ~10ms 的时间内完成一个事务。</p></li><li><p>同时，新时代也有硬件性能的飞速变化，这点主要体现在：</p><ol><li>CPU 单核撞上了功耗墙，但也拥有了更多的核心；</li><li>缓存大量提升，L3/L2/L1 Cache 变得大了很多；</li><li>存储也有同样的提升，SSD 取代了 HDD 成为了硬件的宠儿，NVMe 等协议提供了助力，同时也有 SPDK 等 Bypass 的技术；</li><li>同时，分布式事务的实现变得更加重要了。</li></ol></li></ol><p>应用侧的需求、硬件的提升甚至软件栈变薄，给事务处理带来了一些变化。然而，最著名的靠谱开源数据库 MySQL、PostgreSQL 使用的还是上世纪九十年代的模型；比较常见的 Google Percolator 等模型在单机事务上还是比较简单的；H-Store/VoltDB 的方式似乎没有很主流的被采纳。</p><p><img src="https://image.mwish.me/blog-image/C5C7DF9D-3E2E-4319-B086-FE4190228FB8.png" alt="C5C7DF9D-3E2E-4319-B086-FE4190228FB8"></p><p>我们可以套用到 MySQL 这样传统的 RDBMS 中：</p><ol><li>ARIES 那样的 Undo Redo Log</li><li>MV2PL, 采用 Delta Space 存储变更的版本</li><li>采用 Btree 索引</li><li>并发本身和 2PL 有关，模型是线程（PG 甚至是进程），然后本身 Btree 之类的也会有一些 Latch Protocol</li></ol><p>它可以很方便的做一些内部的优化，比如说：对于 counter，它可以维护计数器锁，使用 Page 相关的逻辑物理日志，来达到细粒度的更改。</p><p>同时，并发控制可以分为乐观的/悲观的，大概划分如下：</p><p><img src="https://image.mwish.me/blog-image/F3F65886-E3F4-4F68-B301-92A7CEC90B55.png" alt="F3F65886-E3F4-4F68-B301-92A7CEC90B55"></p><p>OCC 本身是一种乐观并发协议，1981 年 <code>&lt;On Optimistic Methods for Concurrency Control&gt;</code> 中被提出。在近十年中，因为模型的变化，使用者认为，它在低数据 contention 的情况下会有良好的性能。</p><p>本文主要关注并发控制部分，并主要关注单机事务。</p><h2 id="On-Optimistic-Methods-for-Concurrency-Control"><a href="#On-Optimistic-Methods-for-Concurrency-Control" class="headerlink" title="On Optimistic Methods for Concurrency Control"></a>On Optimistic Methods for Concurrency Control</h2><p>本论文是 OCC 的提出，在 1982 年发表在 TODS (Transactions on Database Systems) 上, 本论文提出的方法是基于时间戳的方法，并且提出了基本的模型。需要注意的是，类似 T-Tree，当时 Memory/Cache 之类的模型和现在也略有不同。</p><p>Optimistic 表示：</p><blockquote><p>Most current approaches to concurrency control in database systems rely on locking of data objects as a control mechanism. In this paper, two families of nonlocking concurrency controls are presented. The methods used are “optimistic” in the sense that they rely mainly on transaction backup as a control mechanism, “hoping” that conflicts between transactions will not occur. Applications for which these methods should be more efficient than locking are discussed.</p></blockquote><p>作者认为，事务本身因为访问盘的 latency gap 和 多核心等原因会需要并发执行，而 2PL 有几个问题：</p><ol><li>Lock 会给读或者不产生冲突的事务也带来开销</li><li>Deadlock</li><li>Lock 需要等待事务执行完毕才能释放</li><li>Lock 只有在 worst case 才有用</li></ol><p>也就是说，可以手动推导出下列的前提：</p><ol><li>正在执行的事务本身需要的数据数量占数据总量较小</li><li>修改热点概率较小</li></ol><p>在这个前提下，可以使用 OCC 的方式，来高效执行，并且避免死锁。当然，死罪可免，活罪难逃，遇到活锁的情况下，可能可以退化为悲观的事务等方法来处理（Doug Lea 在设计一些数据结构提到过类似的方法，提供 global lock，如果重试失败集采，那么使用 Global lock）。同时，这里读事务会几乎不带来开销。（What about MVCC?）</p><p><img src="https://image.mwish.me/blog-image/3BABC5DC-0A29-4463-84DE-37BE2845A7A6.png" alt="3BABC5DC-0A29-4463-84DE-37BE2845A7A6"></p><p>这里切分为了 read/validation/write 三个阶段，值得一提的是，这里大部分还是 read 在内存操作，write 阶段切换一下 read 的时候的指针，然后 read 本身读都是原子的。因此作者认为，write 本身是非常快能完成的。<strong>文中表示了 Write 阶段很快而且是串行的。</strong></p><h3 id="Read-Write-阶段"><a href="#Read-Write-阶段" class="headerlink" title="Read/Write 阶段"></a>Read/Write 阶段</h3><p>这里需要提供下列的原语</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create --  创建对象, 返回 handler</span><br><span class="line">delete(handler) -- 删除对象 handler</span><br><span class="line">read(handler, i) -- 读取对象 handler 的字段 i</span><br><span class="line">write(handler, i, v) -- 给对象 handler 的 i 赋值 v</span><br><span class="line"></span><br><span class="line">copy(n) -- 拷贝对象 n, 返回一个新的 handler</span><br><span class="line">exchange(handler1, handler2) -- 交换 </span><br></pre></td></tr></table></figure><p>然后，需要在 read 阶段提供 <code>tcreate</code> , <code>tdelete</code>, <code>tread</code>, <code>twrite</code> 等方法，使用上面的原语来操作。同时，事务开始和结束分别使用 <code>tbegin</code> 和 <code>tend</code> 操作。事务的内部结构里保存了 <code>WriteSet</code> 还有 <code>DeleteSet</code>、<code>ReadSet</code>，同时有一个 <code>copy</code> 数组。具体操作就读的时候拷贝到 <code>copy</code> 数组，创建删除之类的处理好对应集合，把 handler 丢到 <code>Set</code> 中。</p><p>当 Validation 完成之后，这里逻辑就基本上是把 <code>WriteSet</code> 和 <code>DeleteSet</code> 去 apply。然后我这边截取一段假设，这里论文使用了串行 write，因为：</p><blockquote><p>Note that since objects are virtual (objects are referred to by name, not by physical address), the exchange operation, and hence the write phase, can be made quite fast: essentially, all that is necessary is to exchange the physical address parts of the two object descriptors.</p></blockquote><h3 id="Validation-Phase"><a href="#Validation-Phase" class="headerlink" title="Validation Phase"></a>Validation Phase</h3><p>这里只描述了 Serializable 的验证，论文使用了时间戳有关的协议。对于一个给定的事务 <code>T(i)</code>, 都能找到一个 <code>t(i)</code> 来表达事务执行的时间。事务读写的时候，需要保证 <code>t</code> 的顺序，即是事务的顺序。那么，这里可以给到一些条件，对于 <code>t(i) &lt; t(j)</code></p><p>一: <code>T(i)</code> 在 <code>T(j)</code> 读阶段之前完成了写阶段</p><p>应该不需要怎么理解，很 trivial</p><p>二：<code>T(j)</code> 在进入 Write Phase 之前, <code>T(i)</code> 完成了 Write Phase ，且 <code>WriteSet(i)</code> 和 <code>ReadSet(j)</code> 无交集</p><p>这里后来怎么改都行，但是不能读到之前改的地方</p><p>三：<code>T(i)</code> 的 WriteSet 和 <code>T(j)</code> 的 <code>ReadSet</code> / <code>WriteSet</code> 都没有交集。且 <code>T(i)</code> 在 <code>T(j)</code> 之前完成 Read Phase</p><p>这里有点点复杂，是说 <code>T(i)</code> 的没有影响到 <code>T(j)</code> 的事务。</p><p>下图也同样说明了这三条规则对应的时间范围：</p><p><img src="https://image.mwish.me/blog-image/57BC7AB9-C874-4F0C-BD3E-07F1C5E69FE4.png" alt="57BC7AB9-C874-4F0C-BD3E-07F1C5E69FE4"></p><p>Rule3 还是相对复杂一些，关于这点可以从 CMU 的 slide 里面偷一下图：</p><p><img src="https://image.mwish.me/blog-image/FAF180FF-6C3F-42EF-BAEF-BE41229EDD86.png" alt="FAF180FF-6C3F-42EF-BAEF-BE41229EDD86"></p><h4 id="Transaction-Number"><a href="#Transaction-Number" class="headerlink" title="Transaction Number"></a>Transaction Number</h4><p>对事务 T, 需要找到对应的时间戳，这里选用的是 Validation 的时间戳。</p><blockquote><p>Here we use the simple solution of maintaining a global integer counter tnc (transaction number counter); when a transaction number is needed, the counter is incremented, and the resulting value returned. Also, transaction numbers must be assigned somewhere before validation, since the validation conditions above require knowledge of the transaction number of the transaction being validated.</p></blockquote><p>这里也讲了为啥不在 Read 或者 Begin 的时候拿时间戳。如果 <code>t(i) &lt; t(j)</code>, 但 <code>T(j)</code> 更早进入 Validation，那就需要等待 <code>T(i)</code> 了。在 Validation Phase 拿到 TS 能自然满足这个条件</p><h4 id="一些工程考量"><a href="#一些工程考量" class="headerlink" title="一些工程考量"></a>一些工程考量</h4><p>如果读事务很长，那么，它很有可能 Starve，这里解决方式是留一些事务的 WriteSet 到内存中（类似 MVCC 了）：</p><blockquote><p>We solve this problem by only requiring the concurrency control to maintain some finite number of the most recent write sets where the number is large enough to validate almost all transactions (we say write set a is more recent than write set b if the transaction number associated with a is greater than that associated with 6). In the case of transactions like T, if old write sets are unavailable, validation fails, and the transaction is backed up (probably to the beginning). </p></blockquote><p>此外，这里活锁导致问题的时候，可以用全局锁或者降级到悲观的方式来处理。</p><h3 id="Serial-Validation"><a href="#Serial-Validation" class="headerlink" title="Serial Validation"></a>Serial Validation</h3><p>论文中，Validation Phase 和 Write Phase 都是串行执行的，Read Phase 是并行执行的，但是后续会串行 Validation 然后写（我感觉这个也太怪了…）。记 <code>tnc</code> 为 全局事务counter，那么有：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">tbegin() &#123;</span><br><span class="line">初始化 CreateSet, ReadSet, WriteSet, DeleteSet</span><br><span class="line">StartTn := tnc</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">tend() &#123;</span><br><span class="line">  临界区开始</span><br><span class="line">FinishTn := tnc</span><br><span class="line">valid := true</span><br><span class="line">for t from start tn + 1 to finish tn do</span><br><span class="line">if (write set of transaction with transaction number t intersects read set)</span><br><span class="line">then valid := false</span><br><span class="line">  if valid</span><br><span class="line">    # 完成写阶段后 inc tnc.</span><br><span class="line">then ((write phase); tnc := tnc + 1; tn := tnc))</span><br><span class="line">if valid</span><br><span class="line">then ( cleanup )</span><br><span class="line">else ( backup )</span><br><span class="line">  临界区结束</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述情况很容易验证是合法的，因为 <code>tend</code> 整个就是串行的，<code>(3)</code> 之所以不需要是因为进这个阶段就读写完了。</p><p>对于单核系统+验证/写入本身会非常快的场景，上面差不多就够用了，但是多核系统或者要 I/O 的话，可能我们就希望并行处理了。</p><p>有一种优化的方式是，进入临界区之前，读一下 <code>tnc</code>, 作为 <code>midTn</code>，然后先做一次验证。读取 tnc 之后，后续的提交事务 ts 都是大于 <code>tnc</code> 的。这里先模糊做一次 <code>[StartTn + 1, midTn]</code> 内的检查（是开始到现在已经提交的事务），再进临界区的时候，再拿到一个具体的 <code>FinishTn</code>，做验证。</p><p>这里的核心逻辑就是检测 <code>[StartTn, FinishTn]</code> 这个 Window 中的写没有和本事务的读冲突。</p><p>因为查询没有编号，所以这里不需要给查询作 tnc increment.</p><p>再回顾一下这一段，这里本身把 Validation 串行操作了，其中关键的部分在于 <code>tnc</code> 的读取和增加，再之前的 Rules 中，Rule1/Rule2 是显而易见的，这里通过 tnc 递增和验证区间来保证；拿到这个 id 之后，再去检查读写。</p><h3 id="Parallel-Validation"><a href="#Parallel-Validation" class="headerlink" title="Parallel Validation"></a>Parallel Validation</h3><p>在这里，validation 阶段将会变成并行的。这里将会使用所有的三条规则。</p><p>关于 Rule2, 验证规则和之前是相同的，对 Rule 3，这里需要维护一个 <code>active</code> 事务集合。那么，validation 如下(这里分别记 <code>&lt;</code> 和 <code>&gt;</code> 为临界区的开始和结束)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">tend() &#123;</span><br><span class="line">&lt;</span><br><span class="line">    FinishTn := tnc</span><br><span class="line">    FinishActive := &#123;拷贝一份 active&#125;</span><br><span class="line">    active.Append(&#123;本事务 id&#125;)</span><br><span class="line">&gt;</span><br><span class="line"></span><br><span class="line">检查 [StartTn + 1, FinishTn] 中, 读集合是否和它们的写集合冲突</span><br><span class="line">检查 FinishActive 中，它的写是否与自身的读冲突</span><br><span class="line"></span><br><span class="line">if valid:</span><br><span class="line">then (</span><br><span class="line">(write phase)</span><br><span class="line">&lt;</span><br><span class="line">tnc := tnc + 1</span><br><span class="line">tn := tnc</span><br><span class="line">active.erase(&#123;本事务 id&#125;)</span><br><span class="line">&gt;</span><br><span class="line">)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>显然，这里是没问题的～</p><h2 id="概念补充"><a href="#概念补充" class="headerlink" title="概念补充"></a>概念补充</h2><p>这里有一个 Validation 顺序的问题，实际上，原论文描述的就是一种 BOCC(Backward OCC) 的算法，当事务进入 validation 阶段的时候，它会与之前进 Validation 的事务验证。</p><blockquote><p>Backward Validation: Check whether the committing txn intersects its read/write sets with those of any txns that have already committed.</p></blockquote><p><img src="https://image.mwish.me/blog-image/DB4555BD-7807-478C-81FD-316C74FEDD2B.png" alt="DB4555BD-7807-478C-81FD-316C74FEDD2B"></p><p>Forward Validation 在提交的时候广播自己的 WriteSet，让读取的事务来做一些判断。读取事务可以当即判断，也可以 Buffer 一些，最后一起判断。</p><blockquote><p>Forward Validation: Check whether the committing txn intersects its read/write sets with any active txns that have not yet committed.</p></blockquote><p><img src="https://image.mwish.me/blog-image/4957A2A6-1267-4612-9C76-6DA6FF12EF93.png" alt="4957A2A6-1267-4612-9C76-6DA6FF12EF93"></p><p>此外，我们还可以考虑基于版本的 OCC，每个数据项和一个写入版本相关联，读取的时候拿到一个时间戳，成功提交的事务会带一个唯一的时间戳写入。验证的时候通过 ts 比对来进行验证：读取的 w-ts 和现有的 w-ts 一样，就没啥问题，这里 15-445 slide 演示了相关的例子。</p><p>具体一些细节可以在： <a href="https://wangziqi2013.github.io/article/2018/03/21/Analyzing-OCC-Anomalies-and-Solutions.html">https://wangziqi2013.github.io/article/2018/03/21/Analyzing-OCC-Anomalies-and-Solutions.html</a> 这里看看。</p><h2 id="OCC-评估"><a href="#OCC-评估" class="headerlink" title="OCC 评估"></a>OCC 评估</h2><p><code>&lt;Main Memory Database Systems&gt;</code> 里面描述了一种现状：关于性能，实际上大家各执一词，有的时候 Benchmark 的结果甚至是相反的。我们可以大概知道 OCC 在低冲突的情况下，有相对好一些的性能。我可以大概复述一段这个车轱辘话：</p><blockquote><p>有的比较认为，悲观事务 Blocking (wound-wait?) 优于 悲观事务重启 (wait-die?)，但一些研究有相反的结论。在另一些对比中，乐观并发模式比 基于锁的并发模式更优，有的则相反。有一个比较令人信服的结论由 Agrawal 等人的出，他们表示，在低数据竞争的场景下，乐观并发性能更优，但冲突增加的时候，由于 rollback 和 restart，出现了更高的冲突率。</p></blockquote><p><code>&lt;Staring into the Abyss: An Evaluation of Concurrency Control with One Thousand Cores&gt;</code> 这篇论文发表于 VLDB’14. 本身是描述 OCC/2PL/TS/MVCC/H-Store 等协议在 1000核心的模拟器下并发的。采用硬件寄存器来并发有比较优的效率:</p><p><img src="https://image.mwish.me/blog-image/CE64E7F2-9568-4A42-AD43-EAA8131EB290.png" alt="CE64E7F2-9568-4A42-AD43-EAA8131EB290"></p><p>需要注意的是，这里的 counter 肯定不是线性增长的，atomic counter 可以参考下列性能表：</p><p><img src="https://image.mwish.me/blog-image/WechatIMG82.jpeg" alt="WechatIMG82"></p><p>这篇文章显示，OCC 的拷贝数据、ts 申请等方式会带来不小的瓶颈。这里的问题是能否 Partition（counter 层次的 Partition），更高的性能可能导致一些语义上的变化，比如不原子递增的 counter，甚至类似 snowflake 那样带有 id 的 counter。</p><p>本文中，OCC 性能受制于时间戳分配、拷贝到 private space、高冲突下的 abort。</p><p>我觉得这篇文章有一定的参考价值，但是意义没那么大，因为很多东西和实现细节关系很大，本身是有很多优化和商榷空间的，文章中瓶颈在 timestamp 分配上也是可以理解的。</p><h2 id="MVOCC"><a href="#MVOCC" class="headerlink" title="MVOCC"></a>MVOCC</h2><p><img src="https://image.mwish.me/blog-image/D4A2FD3F-B881-421D-B11C-458EA5A9AD0C.png" alt="D4A2FD3F-B881-421D-B11C-458EA5A9AD0C"></p><p>对于 MVOCC 而言，可以给每个数据带上一个 begin-ts 和 end-ts，这里就不用拷贝事务的 private space 了，取而代之的是 GC 问题。</p><p>还需要注意的是，MVCC 并不是万灵药，它不会在任何场景都能提供优化。它提供的更像是一种对抗 读/写混合的防颠簸。</p><p>在 benchmark 中，论文测试了下列三种负载：</p><ol><li>read-only (100% reads)</li><li>read-intensive (80% reads, 20% updates)</li><li>update-intensive (20% reads, 80% updates).</li></ol><p>论文里记号如下：</p><p><img src="https://image.mwish.me/blog-image/D6E37BA2-6115-4E2A-8540-C02C6AFC725B.png" alt="D6E37BA2-6115-4E2A-8540-C02C6AFC725B"></p><p>在低竞争的测试下，MVOCC 有着尚可的性能，报告如下：</p><p><img src="https://image.mwish.me/blog-image/EAD56C87-EDB8-452D-80B0-5F14C2909524.png" alt="EAD56C87-EDB8-452D-80B0-5F14C2909524"></p><p>很符合直觉的，在高数据竞争的情况下，有如下 case:</p><p><img src="https://image.mwish.me/blog-image/90BDE6B4-B17D-40BE-8E5E-849EBC623311.png" alt="90BDE6B4-B17D-40BE-8E5E-849EBC623311"></p><p>再混合负载下，给出一定写，增加读，MVOCC 本身受读事务干扰较小，而随着写冲突增加，它可以立马性能下降给你看：</p><p><img src="https://image.mwish.me/blog-image/08ACD15D-C2A3-47EA-A380-CB814782A18E.png" alt="08ACD15D-C2A3-47EA-A380-CB814782A18E"></p><p>论文还有 TPC-C 测试等，如下图：</p><p><img src="https://image.mwish.me/blog-image/1723F877-F9AD-43CE-A01A-88874F6C94BC.png" alt="1723F877-F9AD-43CE-A01A-88874F6C94BC"></p><p>笔者认为，本文给的策略还是相对靠谱的，感觉比较靠谱的是类似 Hekaton 那样，在同一套模型上支持乐观 + 悲观的形式，方便适合各种何样的负载。</p><h2 id="Hekaton"><a href="#Hekaton" class="headerlink" title="Hekaton"></a>Hekaton</h2><p>本协议是一个基于验证的协议，本身是 MVCC 的. 论文乐观的假设了碰到的冲突的事务都会成功，并且用无锁并发来实现这样一个模型：</p><p><img src="https://image.mwish.me/blog-image/DDC124F9-1D35-420E-B0E8-651E37EB7AE4.png" alt="DDC124F9-1D35-420E-B0E8-651E37EB7AE4"></p><h2 id="HyPer"><a href="#HyPer" class="headerlink" title="HyPer"></a>HyPer</h2><p>本协议是一个基于验证的协议，本身是 MVCC 的. 有趣的地方是谓词锁的实现。</p><p>这里用再次 Scan 的方式来验证，同时，它会保留谓词锁，而不是数据的锁，来减轻开销。</p><p><img src="https://image.mwish.me/blog-image/2F6E5D66-44A7-4FAB-B5D5-62045A6FF2A0.png" alt="2F6E5D66-44A7-4FAB-B5D5-62045A6FF2A0"></p><h2 id="Silo-Speedy-Transactions-in-Multicore-In-Memory-Databases"><a href="#Silo-Speedy-Transactions-in-Multicore-In-Memory-Databases" class="headerlink" title="Silo: Speedy Transactions in Multicore In-Memory Databases"></a>Silo: Speedy Transactions in Multicore In-Memory Databases</h2><p>本协议是一个基于 TS 的协议. Silo 本身是设计在新硬件上的，特点是 Batch 来取 Ts</p><p><img src="https://image.mwish.me/blog-image/2B014146-E822-4198-9DE2-085512A9271C.png" alt="2B014146-E822-4198-9DE2-085512A9271C"></p><h2 id="TicToc"><a href="#TicToc" class="headerlink" title="TicToc"></a>TicToc</h2><p>本协议是一个基于 TS 的协议. 之前的协议可能都要拿到一个具体的 ts, TicToc 做出的优化是，拿到一个大概的 ts 范围，而不取具体的时间戳。</p><p><img src="https://image.mwish.me/blog-image/27916230-345F-43AC-996F-AF4F539D29C8.png" alt="27916230-345F-43AC-996F-AF4F539D29C8"></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] On Optimistic Methods for Concurrency Control</p><p>[2] Transaction Processing on Modern Hardware</p><p>[3] <a href="https://wangziqi2013.github.io/article/2018/03/21/Analyzing-OCC-Anomalies-and-Solutions.html">https://wangziqi2013.github.io/article/2018/03/21/Analyzing-OCC-Anomalies-and-Solutions.html</a></p><p>[4] An Empirical Evaluation of In-Memory Multi-Version Concurrency Control</p><p>[5] Staring into the Abyss: An Evaluation of Concurrency Control with One Thousand Cores</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>谈谈格式: 列存</title>
      <link href="/2022/01/15/format-thinking-2/"/>
      <url>/2022/01/15/format-thinking-2/</url>
      
        <content type="html"><![CDATA[<h2 id="列式存储"><a href="#列式存储" class="headerlink" title="列式存储"></a>列式存储</h2><p>自 GFS/Hadoop 时代以来，在一个无 Schema 的存储上存储用户想要的数据也成为了用户的重要需求。Stonebraker 批判了这种情况，在 Redbook 4th 上，坚持用户还是需要 Schema 的。事实证明这些 Schema 确实是很好的东西。尽管有类似 Apache Hudi 这样的系统和部分系统用户存储行式的数据。但数据仓库都倾向于将数据存储成列/行列混合的格式。</p><p>简单来说，这样的存储方式有几种好处：</p><ol><li>对某几列数据的访问，能够有不错的局部性和更低的信息熵</li><li>相同的 type 可以用一些非通用（snappy，zstd 等）方式来压缩、延迟物化。同时能减小占用的空间. 通常占用空间这点是会被忽略的，但是它能起到很多意想不到的收益</li><li>更好的 IPC、对 SIMD 的利用</li></ol><p>对于列的存储来说，我们仍然有很多通用的格式，例如 Parquet、ORC。部分 shared-nothing 的数据仓库自己会实现一些格式，ClickHouse；也有数据仓库用这些开放的 Parquet 格式来提供支持，比如 databend。这些格式有共性、也有不同的地方。</p><p>同时，也需要注意，把一行存成列式不一定代表每列都分开存，可能有一定的折衷方案，比如数个 column 一起存。</p><p>此外，有一些项目也在为列式计算提供帮助。Apache Arrow 是一个处理计算和交换格式的项目，用 SIMD 等形式完成计算。</p><p>我们将简单介绍一些列式存储和压缩的想法，然后介绍一些通用的思路。编码本身是一种 speed 和 compression ratio 的 trade-off，而计算系统可能能利用压缩的优势，来减小它带来的开销，大大提高查询性能。</p><h2 id="编码的单位-clusters-skipping"><a href="#编码的单位-clusters-skipping" class="headerlink" title="编码的单位/clusters/skipping"></a>编码的单位/clusters/skipping</h2><p><img src="https://image.mwish.me/blog-image/BC69D6D1-43EA-4991-9191-D215CAADD766.png" alt="BC69D6D1-43EA-4991-9191-D215CAADD766"></p><p>Zone Maps 提供了一种便于 skipping 的抽象。</p><p>具体可以参考：<a href="https://zhuanlan.zhihu.com/p/354334895">https://zhuanlan.zhihu.com/p/354334895</a></p><h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h2><h3 id="C-Store-提到的方法"><a href="#C-Store-提到的方法" class="headerlink" title="C-Store 提到的方法"></a>C-Store 提到的方法</h3><p>C-Store 论文提到过一些编码的形式，这部分标记在论文的 RS 部分：</p><p><strong>Type 1</strong>:有序的且大部分值相同的序列</p><p>这种序列用 <code>(v, f, n)</code> 来表示</p><blockquote><p><em>f</em> is the position in the column where <em>v</em> first appears, and <em>n</em> is the number of times <em>v</em> appears in the column.</p></blockquote><p>为了支持 query, c-store 对这个结构支持了 B树索引，加快了对这个内容的查找。</p><p><strong>Type 2:</strong> 无序且大部分值相同的序列</p><p>这种序列用 <em>(v, b)</em> 来编码，<strong>v</strong> 是可能的值，<strong>b</strong> 是是这个值的数的 bitset:</p><blockquote><p>For example, given a column of integers 0,0,1,1,2,1,0,2,1, we can Type 2-encode this as three pairs: (0, 110000100), (1, 001101001), and (2,000010010).</p></blockquote><p>这里也实现了 <code>&lt;position, value&gt;</code> 的 B+Tree 查找结构。</p><p><strong>Type 3</strong>: 有序且值较少相同的序列</p><p>采用 Delta 的形式进行编码（我感觉这里有点怪，因为 delta 本身应该和压缩没关系，感觉像是用了 delta + varint 啥的…）</p><p><strong>Type 4</strong>: 无序，且值较少相同的序列，相对比较难编码。</p><h3 id="The-Design-and-Implementation-of-Modern-Column-Oriented-Database-Systems"><a href="#The-Design-and-Implementation-of-Modern-Column-Oriented-Database-Systems" class="headerlink" title="The Design and Implementation of Modern Column-Oriented Database Systems"></a>The Design and Implementation of Modern Column-Oriented Database Systems</h3><p>这里提到了几种编码方式</p><h4 id="RLE-Run-Length-Encoding"><a href="#RLE-Run-Length-Encoding" class="headerlink" title="RLE: Run Length Encoding"></a>RLE: Run Length Encoding</h4><p>同上述的 <strong>type 1</strong>。</p><h4 id="Bit-Vec-Encoding"><a href="#Bit-Vec-Encoding" class="headerlink" title="Bit-Vec Encoding"></a>Bit-Vec Encoding</h4><p>同上述的 <strong>type 2</strong></p><p>需要注意的是，bit-vec encoding 还能够进一步压缩，如果 bitmap 很多 0 或者 很多 1，可以用标准的压缩算法压缩；也可以用 RLE 的方式来压缩。Oracle Byte-Aligned Bitmap (Oracle’s BBC) 和 WAH(word-aligned hybrid)提供了一种方案。当然，这种方案只有数据非常稀疏的时候，才值得使用。</p><h4 id="Dictionary"><a href="#Dictionary" class="headerlink" title="Dictionary"></a>Dictionary</h4><p>Dictionary 某种意义上和 Bit-Vec Encoding 很像，我个人理解可以放在不同场景使用。它对某一列的数据构建了一个字典表，然后里面的数据表示在字典的哪一项。当然，如果数据分布很多的话，这个字典会膨胀的非常大。</p><p>一般的情况下，数据可能会以「每个 Block/File/ …」 不同粒度的大小来构建字典。保证字典本身不会膨胀很大。</p><p>对于一些相同模式的字符串，字典编码可以让他们每一项有相同的长度，这也能大大加速查询、降低存储空间。</p><p>此外，考虑到对上层执行的优化，而不仅仅是压缩的话，字典压缩可能要考虑一些奇怪的东西：</p><ol><li>在构建的时候是一次性构建，还是碰到新的值，就给一个新的</li><li>字典的 order 和原本的 order 是否一样呢？比如我们把几个字符串字典压缩了，然后需要排序或者取 top 之类的，可能希望这个序号和原来有一样的顺序（Order-preserving encoding）</li></ol><p>在 Dictionary Encoding 构建的时候，可能要考虑：</p><ol><li>值的 <strong>cardinal number</strong> 有多少种</li><li>包括这些数据，处理的时候，是否能 Fit 在 L1/L2 Cache 中</li><li>是否需要让数据 byte-aligned. 按位对齐的数据通常来说处理会快很多，不过压缩/解压缩 CPU 开销也更大</li></ol><p>在解析的时候，单纯 Dictionary Encoding 也能够很好的解析到单个值上。此外还有一些保序的压缩算法，比如 ALM 或者 ZIL。</p><h4 id="Frame-Of-Reference-FOR"><a href="#Frame-Of-Reference-FOR" class="headerlink" title="Frame Of Reference (FOR)"></a>Frame Of Reference (FOR)</h4><p>当数据有一定局部性的时候，可能可以组织成 frame 的形式，例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1003, 1001, 1007, 1006, 1004</span><br></pre></td></tr></table></figure><p>可以组织成：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1000, 3, 1, 7, 6, 4</span><br></pre></td></tr></table></figure><p>的形式。这里可以注意，<code>3, 1, 7, 6, 4</code> 是以 Delta 的形式存储的，更多的时候可能会让它们占尽量少的位，例如以 varint 的方式存储。</p><h4 id="Increment-Encoding"><a href="#Increment-Encoding" class="headerlink" title="Increment Encoding"></a>Increment Encoding</h4><p>Increment Encoding 常见于 Key 的压缩编码。对于 key/value 的上层输入，常常会有相同前缀/后缀的 string，可以采用增量编码。LevelDB 使用了前缀压缩 + Restart。</p><p>具体可见 wiki。</p><h4 id="The-Patching-Technique-Mostly-Encoding"><a href="#The-Patching-Technique-Mostly-Encoding" class="headerlink" title="The Patching Technique / Mostly Encoding"></a>The Patching Technique / Mostly Encoding</h4><p>上述有的方法中，不一定适合完整的集合，比方说，只在某一段中，数据是有局部性的。Patching 相当于：</p><ol><li>有一些控制段，表示某几段是以特殊编码方式存储数据的</li><li>在控制段外，不压缩。</li></ol><p>此外，如果有极限的值的话，可以标注出来，做特殊处理：</p><p><img src="https://image.mwish.me/blog-image/30D10CA5-E03F-480A-9FE2-E907512FB0DD.png" alt="30D10CA5-E03F-480A-9FE2-E907512FB0DD"></p><h3 id="杂谈"><a href="#杂谈" class="headerlink" title="杂谈"></a>杂谈</h3><p>对于编码的选择，有一些论文表示了如何自动切换，以达到很好的效果。例如 SIGMOD 2021 的 CodecDB。</p><p>有很多可供参考的代码，比如 ORC/Parquet 的压缩格式，和 Facebook 的时序数据库 Gorilla（提出了时间压缩的 delta-of-delta，double 类型的压缩方式）。</p><p>关于 int 的压缩，可以看：<a href="https://kkc.github.io/2021/01/30/integer-compression-note/">https://kkc.github.io/2021/01/30/integer-compression-note/</a> 和 <a href="https://arxiv.org/pdf/1908.10598.pdf">https://arxiv.org/pdf/1908.10598.pdf</a></p><h2 id="ORC-Parquet"><a href="#ORC-Parquet" class="headerlink" title="ORC/Parquet"></a>ORC/Parquet</h2><p>Apache ORC 和 Apache Parquet 可以说是列式存储这些开放格式的事实标准了。它们有很多相同的部分，也有部分区别</p><h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>ORC 全称是：Optimized Row Columnar。这个格式本身似乎是为 Hadoop 项目设计的。</p><p><img src="https://image.mwish.me/blog-image/OrcFileLayout.png" alt="OrcFileLayout"></p><p>我们以 ORC v3 为例介绍一下这里的基本原理。忽略 Index Data 部分。多个行会被组织成 RowGroup/Stripe （名词很多，懂意思就行），然后里面切分为 Column。</p><p>ORC 文件解析是从后往前的，在 HDFS 中，文件内容本身是不会直接被修改的，所以一些元信息会被存在文件的尾部。为便于更新，元信息可能用 PB 描述。Postscript 部分包含整个文件的元信息，而 File Footer 部分可能包含各个 Stripe 的信息，便于获致更具体的文件信息。</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">message </span><span class="title class_">Footer</span> &#123;</span><br><span class="line"> <span class="comment">// the length of the file header in bytes (always 3)</span></span><br><span class="line"> <span class="keyword">optional</span> <span class="type">uint64</span> headerLength = <span class="number">1</span>;</span><br><span class="line"> <span class="comment">// the length of the file header and body in bytes</span></span><br><span class="line"> <span class="keyword">optional</span> <span class="type">uint64</span> contentLength = <span class="number">2</span>;</span><br><span class="line"> <span class="comment">// the information about the stripes</span></span><br><span class="line"> <span class="keyword">repeated</span> StripeInformation stripes = <span class="number">3</span>;</span><br><span class="line"> <span class="comment">// the schema information</span></span><br><span class="line"> <span class="keyword">repeated</span> Type types = <span class="number">4</span>;</span><br><span class="line"> <span class="comment">// the user metadata that was added</span></span><br><span class="line"> <span class="keyword">repeated</span> UserMetadataItem metadata = <span class="number">5</span>;</span><br><span class="line"> <span class="comment">// the total number of rows in the file</span></span><br><span class="line"> <span class="keyword">optional</span> <span class="type">uint64</span> numberOfRows = <span class="number">6</span>;</span><br><span class="line"> <span class="comment">// the statistics of each column across the file</span></span><br><span class="line"> <span class="keyword">repeated</span> ColumnStatistics statistics = <span class="number">7</span>;</span><br><span class="line"> <span class="comment">// the maximum number of rows in each index entry</span></span><br><span class="line"> <span class="keyword">optional</span> <span class="type">uint32</span> rowIndexStride = <span class="number">8</span>;</span><br><span class="line"> <span class="comment">// Each implementation that writes ORC files should register for a code</span></span><br><span class="line"> <span class="comment">// 0 = ORC Java</span></span><br><span class="line"> <span class="comment">// 1 = ORC C++</span></span><br><span class="line"> <span class="comment">// 2 = Presto</span></span><br><span class="line"> <span class="comment">// 3 = Scritchley Go from https://github.com/scritchley/orc</span></span><br><span class="line"> <span class="comment">// 4 = Trino</span></span><br><span class="line"> <span class="keyword">optional</span> <span class="type">uint32</span> writer = <span class="number">9</span>;</span><br><span class="line"> <span class="comment">// information about the encryption in this file</span></span><br><span class="line"> <span class="keyword">optional</span> Encryption encryption = <span class="number">10</span>;</span><br><span class="line"> <span class="comment">// the number of bytes in the encrypted stripe statistics</span></span><br><span class="line"> <span class="keyword">optional</span> <span class="type">uint64</span> stripeStatisticsLength = <span class="number">11</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>文件的主体部分被分为多个 Stripe，在别的格式中，它可能被称为 RowGroup。它包含：</p><ol><li>数据的索引</li><li>各列的数据</li><li>Stripe 的 Footer</li></ol><p>Stripe 支持下列格式的各种数据：</p><p><img src="https://image.mwish.me/blog-image/TreeWriters.png" alt="TreeWriters"></p><p>在 Stripe 的指示下，可以把 Column 做如下的压缩：</p><ol><li>RLE</li><li>Dictionary</li><li>Delta</li></ol><p>对于 Column，ORCFile 定义 <code>Stream</code> 为一串字节流。这里有如下分类：</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">message </span><span class="title class_">Stream</span> &#123;</span><br><span class="line"> <span class="keyword">enum </span><span class="title class_">Kind</span> &#123;</span><br><span class="line">   <span class="comment">// boolean stream of whether the next value is non-null</span></span><br><span class="line">   PRESENT = <span class="number">0</span>;</span><br><span class="line">   <span class="comment">// the primary data stream</span></span><br><span class="line">   DATA = <span class="number">1</span>;</span><br><span class="line">   <span class="comment">// the length of each value for variable length data</span></span><br><span class="line">   LENGTH = <span class="number">2</span>;</span><br><span class="line">   <span class="comment">// the dictionary blob</span></span><br><span class="line">   DICTIONARY_DATA = <span class="number">3</span>;</span><br><span class="line">   <span class="comment">// deprecated prior to Hive 0.11</span></span><br><span class="line">   <span class="comment">// It was used to store the number of instances of each value in the</span></span><br><span class="line">   <span class="comment">// dictionary</span></span><br><span class="line">   DICTIONARY_COUNT = <span class="number">4</span>;</span><br><span class="line">   <span class="comment">// a secondary data stream</span></span><br><span class="line">   SECONDARY = <span class="number">5</span>;</span><br><span class="line">   <span class="comment">// the index for seeking to particular row groups</span></span><br><span class="line">   ROW_INDEX = <span class="number">6</span>;</span><br><span class="line">   <span class="comment">// original bloom filters used before ORC-101</span></span><br><span class="line">   BLOOM_FILTER = <span class="number">7</span>;</span><br><span class="line">   <span class="comment">// bloom filters that consistently use utf8</span></span><br><span class="line">   BLOOM_FILTER_UTF8 = <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// Virtual stream kinds to allocate space for encrypted index and data.</span></span><br><span class="line">   ENCRYPTED_INDEX = <span class="number">9</span>;</span><br><span class="line">   ENCRYPTED_DATA = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// stripe statistics streams</span></span><br><span class="line">   STRIPE_STATISTICS = <span class="number">100</span>;</span><br><span class="line">   <span class="comment">// A virtual stream kind that is used for setting the encryption IV.</span></span><br><span class="line">   FILE_STATISTICS = <span class="number">101</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">required</span> Kind kind = <span class="number">1</span>;</span><br><span class="line"> <span class="comment">// the column id</span></span><br><span class="line"> <span class="keyword">optional</span> <span class="type">uint32</span> column = <span class="number">2</span>;</span><br><span class="line"> <span class="comment">// the number of bytes in the file</span></span><br><span class="line"> <span class="keyword">optional</span> <span class="type">uint64</span> length = <span class="number">3</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在下面的段，描述了它们是怎么被支持的：<a href="https://orc.apache.org/specification/ORCv2/">https://orc.apache.org/specification/ORCv2/</a> 的 Column Encodings 一节。</p><h4 id="变长字段和-Null"><a href="#变长字段和-Null" class="headerlink" title="变长字段和 Null"></a>变长字段和 Null</h4><p><img src="https://image.mwish.me/blog-image/541FB4E7-28A0-4029-B88B-23AC48B38B5D.png" alt="541FB4E7-28A0-4029-B88B-23AC48B38B5D"></p><p>这里有不同的模式，比方说，direct 存放：</p><ol><li>Null 的集合，以 RLE 的形式存放</li><li>Data，连续的非 Null 内容</li><li>Length 具体的长度</li></ol><p>而 dictionary 则用字典来存储。</p><h3 id="Parquet-和-Dremel"><a href="#Parquet-和-Dremel" class="headerlink" title="Parquet 和 Dremel"></a>Parquet 和 Dremel</h3><p>（需要注意的是，Parquet 这个词很容易读错，可以去搜搜看你读错了吗）</p><p>Parquet 的主要思路来源于 Google 的 Dremel。Google 大量数据用 Protobuf 存储，所以当时搞列存，也要兼容它。推过内部系统的话就知道兼容是一个强需求了。</p><p><img src="https://image.mwish.me/blog-image/FileLayout.gif" alt="FileLayout"></p><p>我们不关注这个格式和 ORC 的细微区别，比如 RowGroup 或者 Stripe 的命名。Dremel 关注一个包含 <code>optional</code>, <code>repeated</code> 且可能嵌套的结构是怎么实现的：</p><p><img src="https://image.mwish.me/blog-image/9F45A74A-9E03-4731-A00F-3758C8C9E81B.png" alt="9F45A74A-9E03-4731-A00F-3758C8C9E81B"></p><p><img src="https://image.mwish.me/blog-image/F541F4F8-D061-4C2B-98BB-9EFC5F07AA0E.png" alt="F541F4F8-D061-4C2B-98BB-9EFC5F07AA0E"></p><p>如 Schema 所示，这里有嵌套的数据结构，还有 repeated 和 optional，这意味着，需要一些额外的标志来解析数据在哪一行。Dremel 引入了 <code>repetition levels</code> 和 <code>Deﬁnition Levels</code> 两个向量，来做一些这样的 Resolve。</p><h3 id="ACID-Indexes"><a href="#ACID-Indexes" class="headerlink" title="ACID / Indexes"></a>ACID / Indexes</h3><p>实际上，ORC 的新版本有对 ACID 的支持，也有 Index 相关的信息，可以存放一些 Bloom Filter 之类的索引。</p><p>对于列式数据来说，实际上可以有一些稀疏索引之类的优化，能给到 field 大概的位置。在 ClickHouse 的 MergeTree 里面，有大概的实现。同时，如果以行的方式，进行增量更新的话，这里写放大会比较大。Kudu、SAP HANA 之类的产品为更新提供了方案。</p><p>也就是说，根据我个人的看法，ACID/Indexes 更像一个上层的需求。ORC 对这些有原生支持，但是你可以手动在 Parquet 里面增加支持，例如 <a href="https://github.com/datafuselabs/databend#design-overview">databend 架构</a> 维护了 sparse index 和 min max 信息。这些通用的格式在这些方面也有着不错的逻辑。</p><h2 id="DB-直接在压缩的数据上进行计算"><a href="#DB-直接在压缩的数据上进行计算" class="headerlink" title="DB: 直接在压缩的数据上进行计算"></a>DB: 直接在压缩的数据上进行计算</h2><p>SIGMOD 2006 的 <em>Integrating Compression and Execution in Column-Oriented Database Systems</em> 论文，描述了怎么能够在压缩的数据上进行计算。它描述的是一种类似延迟物化的思路，在压缩的数据上进行计算，它对数据进行了下列抽象：</p><p><img src="https://image.mwish.me/blog-image/59A466B0-BFA7-4FF6-8789-D999BE5502FD.png" alt="59A466B0-BFA7-4FF6-8789-D999BE5502FD"></p><p><code>Block</code> 在 RLE 中指的是单个条目和对应内容，在 Bit-Vector/字典 中指的是单个值、非连续的一组信息（比如全0 或者全1）。它提供了一个 <code>DataSource</code> operator，允许把各种条件下推下去。比方说，bit-vector、字典都可以处理一些 Eq 之类的 Expr。</p><p>对于 JOIN 来说，它可以直接在 RLE 上运行。对于 Bit-vector，执行 Nested Loop Join 且里侧为 bit-vector 的时候，可以执行一些优化：</p><p><img src="https://image.mwish.me/blog-image/49439B4B-D687-4F2D-9357-4BDD83C7709C.png" alt="49439B4B-D687-4F2D-9357-4BDD83C7709C"></p><p>它还抽了一下下面的 API：</p><blockquote><p><code>isOneValue()</code> returns whether or not the block contains just one value (and many positions for that value). <code>isValueSorted()</code> returns whether or not the block’s values are sorted (blocks with one value are trivially sorted). <code>isPosContig()</code> returns whether the block contains a consecutive subset of a column (i.e. for a given position range within a column, the block contains all values located in that range).</p></blockquote><p>然后有对应的优化范围：</p><p><img src="https://image.mwish.me/blog-image/188A1F7D-D245-4EAD-9F37-CFF44FD341CA.png" alt="188A1F7D-D245-4EAD-9F37-CFF44FD341CA"></p><p>总之，这里提供了一些 domain-specific 的优化方式。</p><h2 id="Apache-Arrow"><a href="#Apache-Arrow" class="headerlink" title="Apache Arrow"></a>Apache Arrow</h2><p>不同于上述的存储格式，Arrow 更多的是一个交换格式和计算格式。利用 SIMD、Vectorize 等方式，完成跨语言的、高效的内存计算，同时也支持和 Parquet 的转化和 nested structure。</p><p>Apache Arrow 目前是没有延迟物化支持的。</p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>不同的格式、不同的数据有不同的特征。这里文章没有涉及一些复杂东西，比如 Streaming Parsing 等需求。笔者描述了列存、行存、RPC 等不同格式的需求和特征，及自己对一些特性的看法。感性的也可以在下方评论交流。鉴于笔者水平不行，行文可能存在诸多纰漏。敬请谅解。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>谈谈格式</title>
      <link href="/2022/01/14/format-thinking/"/>
      <url>/2022/01/14/format-thinking/</url>
      
        <content type="html"><![CDATA[<p>一个程序员的工作可能包括：服务器实现了 HTTP 或者 Rpc 协议，接受用户发送来的 JSON/文本/RPC Idl，然后用 JSON/文本/RPC idl，给一些其他服务发送请求，拿到想要拿到的东西。上述处理完之后，可能对数据库 CRUD，在 RDBMS 中，程序员可能定义了表，表中的一行有多个列。用户可能会更新某几行数据的某几列，然后把请求返回给用户。写完数据库后，可能会有 binlog 流/CDC 流，去异步的把你的写入导出到某个数据仓库里头，这里可能会把行组织成类似 Apache ORC 或者 Apache Parquet  的形式，便于快速做分析。</p><p>在这个流程中，用户可能和 JSON、Protobuf、数据库的行等东西打了交道，而计算机可能最终只知道 0和1，bit 和 byte。这里面隐藏了无数的编码：</p><ol><li>接口请求/返回值的编码：可能是 JSON、Protobuf、Thrift、Avro 等格式。在这里，用户预期 debug 方便，能够对接口进行一定的修改、扩展。</li><li>数据库的行 Schema，本身可能要求读/写性能和存储空间的高效、节约，便于CPU 高效在内存访问行上的数据，这里还有一些小小的区分：<ol><li>Schema-on-read/Schemaless: 不一定要求系统存储同一个模式，可能同时存在多个版本的数据</li><li>某个行集合的数据，拥有相同的 Schema</li></ol></li><li>ORC / Parquet 的 Schema，和行的 Schema 相比，可能还会把列存在一起。</li></ol><p>程序员可能每天或多或少要和它们打交道。这些数据格式需求是不一样的。尽管有一些学术上多维的区分，比如说：</p><ol><li>数据是否有 Schema</li><li>是否支持 nested</li><li>存储的行列</li><li>是否支持 Streaming</li><li>是否 human-readable</li><li>是否是和某个语言绑定的（例如 Python pickle, Java Serialize 等，ddia 认为这些编码的兼容性不是很好，同时可能有些安全隐患、性能缺陷）</li></ol><p>但我们这边还是松散的随便扯扯，而且尽量不讨论语言绑定的东西。下面有一张扯图，图一乐？我们这里也不会涉及消息边界等内容。</p><p><img src="https://image.mwish.me/blog-image/2B9240B1-E512-4373-8666-775B6051EB91.png" alt="2B9240B1-E512-4373-8666-775B6051EB91"></p><p>另外，本文只代表本人个人理解和一些记录。如有错误还烦请各位读者矫正。</p><h2 id="接口的编码数据"><a href="#接口的编码数据" class="headerlink" title="接口的编码数据"></a>接口的编码数据</h2><h3 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h3><p>一个常用的选项是 HTTP + REST + JSON.  按照分类，JSON 可以视作 弱schema + human-readable 的数据。这样的数据也包括 XML。JSON 被诟病的地方如下：</p><ol><li>格式上性能不一定很好，包括本身空间大小较大</li><li>对二进制数据不一定有很好的支持</li><li>…</li></ol><p>上面这些内容让它可能会受到一定的诟病，但是对于接口而言，它有着开发方便、程序员可读、跨语言等诸多优点，此外，它的工具链相当齐全（当然，这也有 fast-JSON 等问题？）。JSON 已经支持了大规模的 web 系统，相信它还会起到很多的作用。</p><p>关于空间放大就不谈了，都 JSON 了，也别考虑这个了。</p><h3 id="Thrift-amp-amp-Protocol-Buffer-常见的-rpc-消息格式"><a href="#Thrift-amp-amp-Protocol-Buffer-常见的-rpc-消息格式" class="headerlink" title="Thrift &amp;&amp; Protocol Buffer: 常见的 rpc 消息格式"></a>Thrift &amp;&amp; Protocol Buffer: 常见的 rpc 消息格式</h3><p>尽管 pb 有不同版本，thrift 也是不同格式，但是它们原理是类似的。可以看：<a href="https://thrift.apache.org/static/files/thrift-20070401.pdf">https://thrift.apache.org/static/files/thrift-20070401.pdf</a></p><p>协议上，thrift 本身是二进制的协议，对于给定的格式描述文件，它能够生成出对应语言的 序列化/反序列化 代码。用于处理这样的格式。（当然，不同语言处理可能有一定的问题，比如 thrift-0.9.2 生成的 C++ 代码中，生成了 <code>virtual dtor</code> 和 copy ctor，但是没有生成 <code>move ctor</code> ）。</p><ul><li><a href="https://github.com/apache/thrift/blob/master/doc/specs/thrift-binary-protocol.md">https://github.com/apache/thrift/blob/master/doc/specs/thrift-binary-protocol.md</a></li><li><a href="https://github.com/apache/thrift/blob/master/doc/specs/thrift-compact-protocol.md">https://github.com/apache/thrift/blob/master/doc/specs/thrift-compact-protocol.md</a></li></ul><p>Thrift 本身对于每个字段需要做一些定义，比如：</p><figure class="highlight thrift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">TweetType</span> </span>&#123;</span><br><span class="line">    TWEET,       <span class="comment">// 1</span></span><br><span class="line">    RETWEET = <span class="number">2</span>, <span class="comment">// 2</span></span><br><span class="line">    DM = <span class="number">0</span>xa,    <span class="comment">// 3</span></span><br><span class="line">    REPLY</span><br><span class="line">&#125;                <span class="comment">// 4</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Tweet</span> </span>&#123;</span><br><span class="line">    <span class="number">1</span>: <span class="keyword">required</span> <span class="type">i32</span> userId;</span><br><span class="line">    <span class="number">2</span>: <span class="keyword">required</span> <span class="type">string</span> userName;</span><br><span class="line">    <span class="number">3</span>: <span class="keyword">required</span> <span class="type">string</span> text;</span><br><span class="line">    <span class="number">4</span>: <span class="keyword">optional</span> Location loc;</span><br><span class="line">    <span class="number">5</span>: <span class="keyword">optional</span> TweetType tweetType = TweetType.TWEET <span class="comment">// 5</span></span><br><span class="line">    <span class="number">16</span>: <span class="keyword">optional</span> <span class="type">string</span> language = <span class="string">&quot;english&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们不讨论编码细节，它大致会将每个字段做编码，表示成：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Binary protocol field header and field value:</span><br><span class="line">+--------+--------+--------+--------+...+--------+</span><br><span class="line">|tttttttt| field id        | field value         |</span><br><span class="line">+--------+--------+--------+--------+...+--------+</span><br><span class="line"></span><br><span class="line">Binary protocol stop field:</span><br><span class="line">+--------+</span><br><span class="line">|00000000|</span><br><span class="line">+--------+</span><br></pre></td></tr></table></figure><ol><li>字段类型</li><li><strong>字段 id</strong></li><li>字段值</li><li>Stop field</li></ol><p>Compact 格式与上述类似，不过采取了更紧凑的格式，不影响我们前面介绍的逻辑：<a href="https://github.com/apache/thrift/blob/master/doc/specs/thrift-compact-protocol.md#struct-encoding">https://github.com/apache/thrift/blob/master/doc/specs/thrift-compact-protocol.md#struct-encoding</a></p><p>需要注意的是，这样的格式花了不少部分在处理兼容性上。可以当作这是字段 id 参与实现的。假设传来的字段没有某个字段 id，这里会在解析后的结果做对应的标记；如果传来的包含自己的 idl 没有定义的 field id，这里也会跳过去。通过这种方式，thrift 完成了一些扩展性的支持。</p><p>当然，这也衍生了一些骚操作。如果你的 thrift 结构有 10个字段，但你又的地方只关心两个字段，你可以写个只有对应两个字段的 idl，让它生成结构来解析。那问题来了，这个停止是什么情况呢？假设原本有 0-10 个字段，然后这个解析检测到 stop field 就会停止，所以不会有问题</p><p>那么，这个结构一些放大在什么地方呢？本身 字段类型、字段 id 会有一部分空间放大，然后变长字段存储也有部分放大。</p><p>thrift 和 pb 经常用于作为一些 Rpc 对应的格式，因为便于增和改，这使得它们在开发上有着一定的优势。同时，虽然它们本身不是 human-readable 的，但是 thrift 会生成一些转化成 <code>DebugString</code> 或者 JSON 的方式。</p><h4 id="代码生成和效率"><a href="#代码生成和效率" class="headerlink" title="代码生成和效率"></a>代码生成和效率</h4><p>默认生成的 cpp 代码其实比较草台，对于 cpp 代码而言，可以指定生成模版代码、生成带 move 的代码、开启一些编译相关的优化来提升性能。</p><h3 id="Avro"><a href="#Avro" class="headerlink" title="Avro"></a>Avro</h3><p>Avro 的编码模式可以见： <a href="https://avro.apache.org/docs/current/spec.html">https://avro.apache.org/docs/current/spec.html</a> 。这里不讨论 Avro 的 JSON 模式。相对于 Pb/Thrift，Avro 的二进制格式不会携带 <code>type</code> 和 <code>field id</code>. 相对的，它应该标示出写入自己的应该是什么 Schema。</p><p>这里 Avro 的交互可能包含双方的 Schema 交换，因为读者需要知道写者的编码，例如：<a href="https://avro.apache.org/docs/current/spec.html#Handshake">https://avro.apache.org/docs/current/spec.html#Handshake</a></p><p>如上所述，Avro 的空间少去了 字段类型、字段 id 的空间放大，<strong>是一个还算紧凑的格式</strong>，但本身它需要知道数据是什么版本的。当然，我们最好不需要每条 Avro 数据都带一个 JSON 的格式描述文件，这里可能有不同的方式，来使这个开销变得更小：</p><ol><li>通过 Handshake 交换版本</li><li>有一个版本号 <code>[0, 1, 2, 3]</code>. 然后自己二进制数据带上这个版本号，让读者能够成功解析</li><li>对于一些大文件，可能可以在文件头带上 Avro 格式描述，然后后面存放同一个版本的写入内容。</li></ol><p>Avro 可以用于 RPC，但笔者在生产中少有见到用 Avro 做交换格式的地方。似乎它的使用场景更多还是在存储数据的时候使用。如果有读者知道对应的场景不妨联系笔者。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>大部分 RPC 格式中，用户希望有一定的 Schema，同时也支持对结构进行一些变更。用户通过 Rpc 发送的信息通常不会很大，而且大部分时候也并不应该很大，例如 pb 在官方文档中<a href="https://developers.google.com/protocol-buffers/docs/techniques">表示</a>，它不应该处理 Large Data Sets。如果你有数 kB 甚至数 MB 的数据，那么你可能要考虑一下一些其他的方式。毕竟，对这些 RPC 消息的解析一般包含连续或者不连续内存的 memcpy。</p><h2 id="行格式"><a href="#行格式" class="headerlink" title="行格式"></a>行格式</h2><h3 id="需求和大概的设计"><a href="#需求和大概的设计" class="headerlink" title="需求和大概的设计"></a>需求和大概的设计</h3><p>在关系型数据库中，我们有行 (Row/Tuple) 和 列 (Column/Attribute) ，直观的描述如下所述：</p><p><img src="https://image.mwish.me/blog-image/700px-Relational_database_terms.svg.png" alt="700px-Relational_database_terms.svg"></p><p>这样的格式本身是用户定义的，列可以是变长/定长的（行也显然可以）。我们忽略 BLOB 等对象。用户通常会有下列的请求：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> table.col1, table.col5 <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> table.col3 <span class="operator">&lt;</span> <span class="number">100</span>;</span><br></pre></td></tr></table></figure><p>我们不考虑索引等优化，也不考虑 Row 是以 k-v 还是 Page 的形式组织，仅从行的方面考虑，这里需要读到对应每个行的 <code>col1</code> <code>col5</code> 和 <code>col3</code> 字段。</p><p>通常，RPC 协议要求的是对变更敏感，且能够完整解析。而行格式更多不会完全解析，而是要求能在内存中快速寻找到每行中用户指定的列。同时，行的大小会占用盘/内存的空间，故其大小也应受限制。</p><p>一般的数据库当中，会有 <code>Catalog System</code>。大部分情况下，可以认为，在某张表中，每行的 Schema 都是相同的。这给我们提供了很大的便利。当然，这里可能加一列之类的 DDL 执行的时候，系统需要做比较多的事情，来给原来的每行添加一列。之前也看到阿里的数据库团队对这点进行的优化: <a href="http://mysql.taobao.org/monthly/2020/03/01/">http://mysql.taobao.org/monthly/2020/03/01/</a></p><p>此外，这里还要关注某列数据为 <code>null</code> 的情况。这一点也会影响格式的实现。另外一个影响实现的内容是变长字段（甚至 nested 字段）的存储。</p><p>最后一点需要注意的是，我们刚才谈及 RPC 协议等，它们大部分都是非常通用的协议。但是对于行数据来说，它们通常和数据库系统别的地方实现有很强的相关度：</p><ol><li>是否使用读时模式？</li><li>行是怎么被组织的？是被存储到 kv 中，还是被存储到 Page 中？</li><li>有没有什么特殊的记录和标记，例如行删除、事务标记等？</li><li>有没有什么 hidden column。</li></ol><p>为了简化描述，我们将集中于 <code>Tuple</code> 和 <code>Attribute</code> 相关的内容，并忽略那些上层的部分（尽管它们对实现者或者某些用户来说可能更加重要）</p><h3 id="PostgreSQL"><a href="#PostgreSQL" class="headerlink" title="PostgreSQL"></a>PostgreSQL</h3><p><img src="https://image.mwish.me/blog-image/0A3074B3-A1EA-4CAE-80DC-BA37D2C40CC0.png" alt="0A3074B3-A1EA-4CAE-80DC-BA37D2C40CC0"></p><p>PG 的 Page 格式如上所述。我们关注：</p><ol><li>Tuple Header 里面包含了下面的信息：<ol><li>Tuple 中是否有值为 Null 的 Attribute</li><li>如果有值为 Null 的 Attribute，那么后面会存放一个 BitSet，来表示第 <code>i</code> 个字段的数据是否是 Null</li></ol></li><li>Tuple 里面会存储所有的数据<ol><li>对于 Null 的 Attribute，不会存储对应的值</li><li>对于非 Null 的数据<ol><li>如果是定长的数据，那么，这里直接会存储对应的内容，比如如果是 i32，那就存储 4bytes。</li><li>如果是变长的数据，那么，这里会存储 1b 或者 4b 的长度，再存储对应的内容。</li></ol></li></ol></li></ol><p>我们假设某个表格式是 <code>(i32, i64, bytes, i32)</code>，那么，可能存储的格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 对于数据 (1, 2, &quot;abc&quot;, 4), 可能是:</span><br><span class="line">[Header: 没有有 Null 的字段] [1(4bytes), 2(8bytes), [3(1bytes), &quot;abc&quot;(3bytes)], 4(4bytes)]</span><br><span class="line"></span><br><span class="line">-- 对于数据 (1, 2, 一个很长的字符串, 4), 可能是:</span><br><span class="line">[Header: 没有有 Null 的字段] [1(4bytes), 2(8bytes), [长度(4bytes), 很长的字符串], 4(4bytes)]</span><br><span class="line"></span><br><span class="line">-- 对于数据 (1, 2, Null, 4), 可能是:</span><br><span class="line">[Header: 有 Null 的字段] [1byte, 表示第三个字段是 Null] [1(4bytes), 2(8bytes), 4(4bytes)]</span><br></pre></td></tr></table></figure><p>当然，对于计算机来说，访问未对齐的数据可能是有额外开销的。PostgreSQL 还指定了让数据对齐的选项。</p><p>比如对 <code>(i32, i64, i32)</code>，如果都不为 Null，<em>可能</em>有：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">i32 存放的: 4bytes</span><br><span class="line">padding: 4bytes &lt;-- 注意这个</span><br><span class="line">i64: 8bytes</span><br><span class="line">i32: 4bytes</span><br></pre></td></tr></table></figure><p>（注：以上例子只作为 padding 的演示，实际上数据可能被编排为 <code>(i32, i32, i64)</code> ）</p><p>下面我们来看看</p><p>如果有变长字段、Null 字段的话，需要读取第 <code>k</code> 列，可能要每列读过来，找到第一列：</p><ol><li>判断它是否是 Null，如果是，那么偏移量不变</li><li>如果不是 Null：<ol><li>是定长的话，跳过对应长度即可</li><li>是变长数据的话，可能要读取它的长度，再跳过对应的长度</li></ol></li></ol><p>比方说，假设像 <code>(i32, i64, i32)</code> 的 Tuple 中，<strong>保证没有数据是 Null</strong>。那我们可以知道（考虑 padding，假设和之前描述的格式一样）：</p><ol><li>第一列偏移量肯定是 <code>0</code></li><li>第二列偏移量肯定是 <code>8</code></li><li>第三列偏移量肯定是 <code>16</code></li></ol><p>具体一些细节优化内容可以在 PostgreSQL 的 <code>src/include/access/htup_details.h</code> 等文件里找到。PG 也可以用 schema cache 加速字段寻址。</p><h4 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h4><p>PG 的格式本身应该是比较省空间的。空间放大来自于：</p><ol><li>Null BitSet</li><li>存放字符串长度的区域</li></ol><p>同时，读取 PG 偏后的字段，可能会导致较低的性能，所以 PG 可能会这样处理格式：</p><ol><li>先存放 <strong>非 Null</strong> 且<strong>定长</strong>的列</li><li>在存放 <strong>定长</strong> 且 <strong>可能为 Null</strong> 的列</li><li>存放变长的列</li></ol><p>此外，有一些别的格式（非 PG）可能会考虑下面几种变体：</p><ol><li>每隔几列添加一个索引，比方说，每隔8列插入一个偏移量，寻找第 <code>(8n + k)</code> 列的时候，可以通过这个偏移量，先寻找到 <code>8n</code> 列的偏移量，再处理。笔者认为，这种方法相当于空间换 CPU 时间。虽然笔者本人没有试验过，但是这种方法可能对列很多的数据有一定的效果。</li><li>把格式做成偏移量固定的格式。比方说，如果  <code>(i32, i64, i32)</code> 中第二列是 Null，也写对应的 8byte。这种方式让每个字段有一个固定的偏移量，能够快速完成寻址。笔者个人不是很喜欢这种方法，因为对于稀疏格式，它可能带来极大的空间放大。</li></ol><h3 id="InnoDB-Compact"><a href="#InnoDB-Compact" class="headerlink" title="InnoDB Compact"></a>InnoDB Compact</h3><ol><li><a href="https://mariadb.com/kb/en/innodb-compact-row-format/">https://mariadb.com/kb/en/innodb-compact-row-format/</a></li><li><a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-row-format.html">https://dev.mysql.com/doc/refman/5.7/en/innodb-row-format.html</a></li></ol><p>InnoDB 是笔者心中的开源的地表最强存储引擎，Compact 格式在 MySQL 5.7 之后，作为 MySQL 的默认存储格式而存在。这种格式有着更小的空间大小，相对来说比 DYNAMIC 格式更耗费 CPU 一些。</p><p><img src="https://image.mwish.me/blog-image/21_619_e2fcf037b107485.jpeg" alt="21_619_e2fcf037b107485"></p><p>（图片来自：<a href="https://www.alibabacloud.com/forum/read-446）">https://www.alibabacloud.com/forum/read-446）</a></p><p>我们忽略一些特殊字段，可以看到，这个格式除了一些标志位，会有：</p><ol><li>Nullable Bitmap （同我们之前介绍的 Null BitSet）</li><li>Column Length Fields：变长字段的内容</li><li>具体的数据</li></ol><p>这里相当于把之前 PG 存放的变长字段长度放到了一个独立的区域中。</p><h3 id="杂项-Google-FlatBuffers"><a href="#杂项-Google-FlatBuffers" class="headerlink" title="杂项: Google FlatBuffers"></a>杂项: Google FlatBuffers</h3><p>FlatBuffers 是 Google 的一种序列化格式，相对而言，它是更通用的一种格式，强调了快速的解析（甚至不需要解析），我们可以看到它和行格式有一些异曲同工之妙。它的定义如：<a href="https://google.github.io/flatbuffers/flatbuffers_internals.html">https://google.github.io/flatbuffers/flatbuffers_internals.html</a></p><p><img src="https://image.mwish.me/blog-image/GD4XrgCFBDro_c0FAGwOzSsAAAAAbj0JAAAB.jpeg" alt="GD4XrgCFBDro_c0FAGwOzSsAAAAAbj0JAAAB"></p><p>这里，它会有一些数据来指向数据具体存放的地方，以保证不需要解析即可访问。同时，这个结构还支持 nested 和一定程度上的更新：</p><p><img src="https://image.mwish.me/blog-image/GI9ytQBfig2BZtYCAAZUtV0AAAAAbj0JAAAB.jpeg" alt="GI9ytQBfig2BZtYCAAZUtV0AAAAAbj0JAAAB"></p><p>详细内容可以参考：<a href="https://engineering.fb.com/2015/07/31/android/improving-facebook-s-performance-on-android-with-flatbuffers/">https://engineering.fb.com/2015/07/31/android/improving-facebook-s-performance-on-android-with-flatbuffers/</a> </p><h3 id="Order-Preserving-Row-Encoding"><a href="#Order-Preserving-Row-Encoding" class="headerlink" title="Order Preserving Row Encoding"></a>Order Preserving Row Encoding</h3><p>如果要把行格式存储到 key-value 的 key 中，对于 ordered key-value，显然会希望这些 key 是可以 scan</p><ul><li><a href="https://activesphere.com/blog/2018/08/17/order-preserving-serialization">https://activesphere.com/blog/2018/08/17/order-preserving-serialization</a></li><li><a href="https://github.com/facebook/mysql-5.6/wiki/MyRocks-record-format">https://github.com/facebook/mysql-5.6/wiki/MyRocks-record-format</a></li></ul><p>上面是通用格式，值得一提的是，对字符串编码，两种格式处理方式不一样：</p><ul><li>FoundationDB 会使用 <code>0x00 0xff</code> 转换 <code>0x00</code>，然后每个类型的字段都有自己的开头（一个固定的 byte）和结尾（0x00）等标志。解析的时候，遇到 0x00，需要前瞻一个 byte，查看下一个 byte 是什么。用 <code>0x00 0xff</code> 是因为一个性质：如果一个字符串包含内容 <code>0x00</code>, 那么它小于所有真实的内容，大于结束在这里的字符串（即 <code>0x00</code> 表示字符串完了的内容），在这里完结的字符串要么就终止了，要么开启下一个 type 标记，下一个 type 标记必定不会用 <code>0xFF</code> 作为开头</li><li>MyRocks 这套把字符串分成 Group，比如 8 个为一组，每一组附赠一个 byte 来描述这个 Group 的状态，这个比较 trickey 的是空字符串的处理，我曾经空字符串不留内容，显然这是个 bug。</li></ul><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>关于行格式，大部分时候我们不会和 pb 一样，全部读取/反序列化，通常，访问会只访问对应的 column，这要求我们快速读取 column。当然，有的用户也会定义一些变长字段，然后在里面存放 pb 数据。</p><p>行格式的逻辑通常和数据库的其他组织挂钩，但我们仍然能看到一些相同的工程设计。除了上面我提到的，还可以看看 TiDB / OB 的行格式，并考量它们是如何权衡 CPU开销和格式空间的开销的。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>An Overview of Query Optimization in Relational Systems</title>
      <link href="/2021/11/05/An-Overview-of-Query-Optimization-in-Relational-Systems/"/>
      <url>/2021/11/05/An-Overview-of-Query-Optimization-in-Relational-Systems/</url>
      
        <content type="html"><![CDATA[<p>这是 1998 年的关于 RDBMS 优化器的论文，旨在指出 70 年代到当时的优化器的变化。SQL 的优化器可以说是一个并不新颖的领域了，虽然新技术常有提出，但是很多还是在 Selinger 优化器和 Cascades 优化器的框架下。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>DB 的上层可以分为 Query Optimizer 和 Query Execution Engine，15-721 给出过一个比较合适的图：</p><p><img src="https://image.mwish.me/blog-image/9D7B6B21-4DFC-4768-B508-E1D6B3C3B5AE.png" alt="9D7B6B21-4DFC-4768-B508-E1D6B3C3B5AE"></p><p>这里区分了 Physical Operators 和 Logical Operators. 这两个并不是一对一关系。Physical 的意思大概是更接近具体执行的步骤，它会被丢给 Execution Engine 执行。</p><p>产生一个 Optimal 的 Plan 是一个 NP-Hard 的问题，而优化器本身也有许多技巧来进行优化，不过话说回来，优化器在有的时候也没有承担那么复杂的逻辑，比如在 TP 系统中，所有优化都依赖“索引”，简单的优化器直接做很多基于规则的优化和索引推断就行。</p><p>言归正传，论文认为 Query Optimization 需要：</p><ol><li>Search Space: Plan 的生成空间</li><li>Cost Estimation: 估算一个 Plan 是不是好</li><li>Enumeration algorithm: 枚举出对应的 Plan</li></ol><p>上面感觉其实在说废话，但是挺重要的，因为 (1) 要包含最好的结果，(2) 要又快又准，(3) 要高效。</p><h3 id="System-R-Optimizer"><a href="#System-R-Optimizer" class="headerlink" title="System-R Optimizer"></a>System-R Optimizer</h3><p>这篇论文简短介绍了 System-R 优化器的 Select-Project-Join (SPJ) 部分</p><p><img src="https://image.mwish.me/blog-image/465761AC-C4FA-472A-8CE4-88AF87E57A59.png" alt="465761AC-C4FA-472A-8CE4-88AF87E57A59"></p><p>System-R 优化器认识到了 Join 的 associative 和 commutative，同时 Join 有两种实现：Nested Loop Join 和 Sort-Merge Join. Scan 可以是 Index Scan (可以在 cluster index 或者是 secondary index 上)，或者 Sequential Scan。</p><p>这里有一些启发式的部分：Predict 应该尽早被执行。</p><p>System-R 优化器依赖统计信息、对 Selection Selectivity 的分析（事后看虽然朴素，不过也比较有启发性了）、具体分析 io-cost 和 cpu-cost 的公式（其实我也不太清楚这个 2020 年有没有很好的量化公式）。通过上面的信息，System-R Optimizer 能够拿到估计中的：</p><ol><li>物理的 Operation Node 输出的大概数目</li><li>输出的 Tuples 的顺序</li><li>Operator 大概的 cost</li></ol><p>System-R 用 DP 来找到 best plan，只处理左深树来减少 search space，通过 interesting order 来处理顺序。</p><p>找 best plan 的时候，算法大概如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1. j = set of join nodes</span><br><span class="line">2. for (i in 1...|j|):</span><br><span class="line">3.     for s in &#123;all length i subsets of j&#125;</span><br><span class="line">4.       bestPlan = &#123;&#125;</span><br><span class="line">5.       for s&#x27; in &#123;all length d-1 subsets of s&#125;</span><br><span class="line">6.            subplan = optjoin(s&#x27;)</span><br><span class="line">7.            plan = best way to join (s-s&#x27;) to subplan</span><br><span class="line">8.            if (cost(plan) &lt; cost(bestPlan))</span><br><span class="line">9.               bestPlan = plan</span><br><span class="line">10.      optjoin(s) = bestPlan</span><br><span class="line">11. return optjoin(j)</span><br></pre></td></tr></table></figure><p>这里的 best way to join 实际上还要考虑到只有左深树。基本上就是 Join(subOptimal, {remain}). 然后找到最优的子 plan.</p><p>另外，这里有个 interesting order 的内容，简单的说，在上面的 subOptimal 中，不能只考虑“下面几张表 join 的时候最优的是哪棵树“，还要考虑表 Operator 输出的属性的顺序。这个 interesting order 的内容为后续一些 “physical properties” 的设计提供了基础。</p><blockquote><p>Intuitively, a physical property is any characteristic of a plan that is not sharedby all plans for the samelogical expression,but can impact the cost of subscqucntoperations</p></blockquote><p>虽然上述的设计很优雅也很有启发性，但是这些没有讲述什么 logical transformations 和扩展 search space 的部分。</p><h2 id="Search-Space"><a href="#Search-Space" class="headerlink" title="Search Space"></a>Search Space</h2><p>SQL 会有很多 transformation 的部分，有的时候我们可以当作这些一定能起到作用，做逻辑上的优化，比如 System-R 很多时候就是这么执行的。但是也有一些很可能能起到作用的 transformation。</p><p>这里说的比较绕，贴一下原文：</p><blockquote><p>It should be noted that trunsfonnations do not necessarily reduce cost and therefore must be applied in a cost-based manner by the enum algorirhm to ensure a positive benejit.</p></blockquote><p>在这里面，Optimizer 可能会把 Plan 格式变更若干次。保证开始是一个逻辑计划，最后是一个可以丢给 Execution Engine 的东西就行了。</p><p>关于这个我找了找 Starburst 有关的论文：<a href="https://zhuanlan.zhihu.com/p/369771981">https://zhuanlan.zhihu.com/p/369771981</a> ，Starburst 会生成一个便于优化的 QGM，便于对整个树做一些逻辑优化。不过批评者认为这些优化不一定考虑到了 Page/Block 相关的信息。</p><h3 id="Commuting-Between-Operators"><a href="#Commuting-Between-Operators" class="headerlink" title="Commuting Between Operators"></a>Commuting Between Operators</h3><p>很多 transformation 用到了算子的交换律。</p><h4 id="Generalizing-Join-Sequencing"><a href="#Generalizing-Join-Sequencing" class="headerlink" title="Generalizing Join Sequencing"></a>Generalizing Join Sequencing</h4><p>在 System-R 优化器中，只会考虑 left-deep tree。但实际上，原则上我们可以考虑 bushy tree，近日的 DPCCP 开始计入相关的内容，正面面对 bushy tree。同时，System-R 优化器将笛卡尔积丢到最后处理，但是实际上这个也可能被显著优化，比方说在 BI 系统中，对笛卡尔积的优化是很重要的。</p><p>在一个可扩展的系统中，可能会允许搜索 bushy tree （这个需要物化 Join 结果）或者笛卡尔积。（当然这个也是比较难推断下来具体该不该这么做的）。</p><h4 id="Outerjoin-and-Join"><a href="#Outerjoin-and-Join" class="headerlink" title="Outerjoin and Join"></a>Outerjoin and Join</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Join(R, S LOJ T) = Join(R, s) LOJ T</span><br></pre></td></tr></table></figure><p>这些操作能让 Joins 在 <code>Join + outerjoins</code> 之前执行</p><h4 id="Group-By-and-Join"><a href="#Group-By-and-Join" class="headerlink" title="Group-By and Join"></a>Group-By and Join</h4><p><img src="https://image.mwish.me/blog-image/58149849-AF28-49B6-9210-8C69D0A0DFC7.png" alt="58149849-AF28-49B6-9210-8C69D0A0DFC7"></p><p>早期的一些优化器中，SPJ 会在 Group By 之前执行. Figure 4 的 Transformation 在 Join 之前即可处理 Group By. 比如在 <code>Select DISTINCT</code> 的时候，这里可能会把部分 Group By 下推，这一定情况下可以减少 Join 的数量。此外，如果 Group By 可以利用 R1 的 order，那么显然是好的。</p><p>这里把 Group By 下推给 G1，一定程度上，这可以减少 Join 的数量。不过这也要求能把 Group By 做一定的拆分。</p><h3 id="Reducing-Multi-Block-Queries-to-Single-Block"><a href="#Reducing-Multi-Block-Queries-to-Single-Block" class="headerlink" title="Reducing Multi-Block Queries to Single-Block"></a>Reducing Multi-Block Queries to Single-Block</h3><h4 id="Merging-Views"><a href="#Merging-Views" class="headerlink" title="Merging Views"></a>Merging Views</h4><p>对于简单的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Q = Join(R, V)</span><br><span class="line">V = View of Join(S, T)</span><br></pre></td></tr></table></figure><p>Q 是可以拆开来然后进行 join order optimize 的，不过话又说回来，上一节降到了 Group By 和 DISTINCT 下推，这里的展开可能是反着两个下推的。我们可能要重新执行 Figure 4 的流程</p><h4 id="Merging-Nested-Subqueries"><a href="#Merging-Nested-Subqueries" class="headerlink" title="Merging Nested Subqueries"></a>Merging Nested Subqueries</h4><p>子查询相当相当重要。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> Emp.Name</span><br><span class="line"><span class="keyword">FROM</span> Emp</span><br><span class="line"><span class="keyword">WHERE</span> Emp.Dept <span class="keyword">IN</span></span><br><span class="line">(</span><br><span class="line"><span class="keyword">SELECT</span> Dept.Dept <span class="keyword">FROM</span> Dept</span><br><span class="line"><span class="keyword">WHERE</span> Dept.Loc <span class="operator">=</span> <span class="string">&#x27;xxx&#x27;</span></span><br><span class="line"><span class="keyword">AND</span> Emp.Emp <span class="operator">=</span> Dept.Mgr</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>(1) 当内部查询部不带有外部查询( uncorrelated ) 的情况下，内部查询只需要执行一次。</p><p>如果内部查询和外部查询相关，需要外部查询中的变量，那就麻烦了。例如上面的 SELECT 可以 cast 成：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> Emp E, Dept D</span><br><span class="line"><span class="keyword">WHERE</span> E.Dept <span class="operator">=</span> D.Dept</span><br><span class="line"><span class="keyword">AND</span> D.Loc <span class="operator">=</span> <span class="string">&#x27;xxx&#x27;</span> <span class="keyword">AND</span> E.Emp <span class="operator">=</span> D.Mgr</span><br></pre></td></tr></table></figure><p>转化的流程取决于内部表达式的复杂度，即有无 quantifiers (例如 ALL, EXIST)、aggregates 或者都没有。(2) 在最简单的场景下，如上面，Table 可以改成一个 Semijoin:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Semijoin(Emp, Dept, Emp.Dept <span class="operator">=</span> Dept.Dept) <span class="operator">=</span> Project(<span class="keyword">Join</span>(Emp, Dept), Emp.<span class="operator">*</span>)</span><br></pre></td></tr></table></figure><p>当子查询有 subquery 的时候，情况可能需要转化成 LOJ 或者 ROJ:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> Dept.name</span><br><span class="line"><span class="keyword">FROM</span> Dept</span><br><span class="line"><span class="keyword">WHERE</span> Dept.num<span class="operator">-</span><span class="keyword">of</span><span class="operator">-</span>machines <span class="operator">&gt;=</span></span><br><span class="line">(</span><br><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(Emp.<span class="operator">*</span>)</span><br><span class="line"><span class="keyword">FROM</span> Emp</span><br><span class="line"><span class="keyword">WHERE</span> Dept.name <span class="operator">=</span> Emp.Dept_name</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><code>SELECT Count(Emp.*)</code> 是个 agg，这里麻烦的地方是，如果 <code>Dept.name</code> 相等的 <code>Emp</code> 是不存在的，那么这个条件显然是满足的。所以这里的逻辑是：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Select</span> Dept.name <span class="keyword">FROM</span> Dept <span class="keyword">LEFT</span> <span class="keyword">OUTER</span> <span class="keyword">JOIN</span> Emp <span class="keyword">ON</span> Dept.name <span class="operator">=</span> Emp.Dept_name <span class="keyword">Group</span> <span class="keyword">BY</span> Dept.name </span><br><span class="line"><span class="keyword">HAVING</span> Dept.num<span class="operator">-</span><span class="keyword">of</span><span class="operator">-</span>machines <span class="operator">&lt;</span> <span class="built_in">COUNT</span>(Emp.<span class="operator">*</span>)</span><br></pre></td></tr></table></figure><p>这里相当于 Dept LOJ 内部 agg 的表。这个的优化可以依赖之前提的，后处理 LOJ</p><h3 id="Using-Semijoin-Like-Techniques-for-Optimizing-Multi-Block-Queries"><a href="#Using-Semijoin-Like-Techniques-for-Optimizing-Multi-Block-Queries" class="headerlink" title="Using Semijoin Like Techniques for Optimizing Multi-Block Queries"></a>Using Semijoin Like Techniques for Optimizing Multi-Block Queries</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> DepAvgSal <span class="keyword">As</span> (</span><br><span class="line"><span class="keyword">SELECT</span> E.did, <span class="built_in">Avg</span>(E.Sal) <span class="keyword">AS</span> avgsal</span><br><span class="line"><span class="keyword">FROM</span> Emp E</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> E.did</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> E.eid, E.sal</span><br><span class="line"><span class="keyword">FROM</span> Emp E, Dept D, DepAvgSal v</span><br><span class="line"><span class="keyword">WHERE</span> E.did <span class="operator">=</span> D.did <span class="keyword">AND</span> E.did <span class="operator">=</span> V.did</span><br><span class="line"><span class="keyword">AND</span> E.age <span class="operator">&lt;</span> <span class="number">30</span> <span class="keyword">AND</span> D.budget <span class="operator">&gt;</span> <span class="number">100</span>k</span><br><span class="line"><span class="keyword">AND</span> E.sal <span class="operator">&gt;</span> V.avgsal</span><br></pre></td></tr></table></figure><p>这里面，SQL 可以被优化为 <code>E.did</code> 相关的 view</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> partialresult <span class="keyword">AS</span></span><br><span class="line">(</span><br><span class="line"><span class="keyword">SELECT</span> E.id, E.sal, E.did</span><br><span class="line"><span class="keyword">FROM</span> Emp E, Dept D</span><br><span class="line"><span class="keyword">WHERE</span> E.did <span class="operator">=</span> D.did <span class="keyword">AND</span> E.age <span class="operator">&lt;</span> <span class="number">30</span></span><br><span class="line"><span class="keyword">AND</span> D.budget <span class="operator">&gt;</span> <span class="number">100</span>k</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">View</span> <span class="keyword">Filter</span> <span class="keyword">AS</span> </span><br><span class="line">(</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> P.did <span class="keyword">FROM</span> partialresult P</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> LimitedAvgSal <span class="keyword">AS</span> (</span><br><span class="line"><span class="keyword">SELECT</span> E.did, <span class="built_in">Avg</span>(E.sal) <span class="keyword">AS</span> avgsal</span><br><span class="line"><span class="keyword">FROM</span> Emp E, <span class="keyword">Filter</span> F</span><br><span class="line"><span class="keyword">WHERE</span> E.did <span class="operator">=</span> F.did <span class="keyword">GROUP</span> <span class="keyword">BY</span> E.did</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>这种操作将子查询变更为不重复访问的查询。</p><h2 id="Statistics-And-Cost-Estimation"><a href="#Statistics-And-Cost-Estimation" class="headerlink" title="Statistics And Cost Estimation"></a>Statistics And Cost Estimation</h2><p>上面的部分介绍了一些 Logical 的 Transformation。对于一个表达式树，我们要考量的资源可能有：</p><ul><li>CPU time</li><li>IO cost</li><li>memory</li><li>bandwidth</li></ul><p>Cost Estimation 是希望快捷又准确的计算这些值。System-R 给出了一个基本的框架：</p><ol><li>对存储的数据做一些分析</li><li>对每个 Operator，给出一个评估策略：<ol><li>输出数据的一些统计值</li><li>操作的 cost</li></ol></li></ol><p>关于 (1), 这里有两个问题：</p><ul><li>我们需要什么数据</li><li>我们什么时候获取/更新这些统计数据</li></ul><h3 id="Statistical-Summaries-of-Data"><a href="#Statistical-Summaries-of-Data" class="headerlink" title="Statistical Summaries of Data"></a>Statistical Summaries of Data</h3><h4 id="Base-Data"><a href="#Base-Data" class="headerlink" title="Base Data"></a>Base Data</h4><p>一个关键点是，我们需要知道 tuples 和相关的 pages 的大概数目。这些信息是物理的数据，独立于 expression 的 selectivity 这样的逻辑数据，并且和后者一起做出决策。我们需要知道各个列相关的一些协助预测的信息。</p><p>在很多 RDBMS 中，等深（equi-depth）直方图可以用来统计信息。在直方图的单个 Bucket 里，可以当作数据是 uniform distribution 的。如果缺少直方图，可以保存数值的 min/max（需要注意的是，实践中，这里也会处理一些极大极小值，保留次大值之类的）。</p><p>我们可能要为所有的 Column 都构建对应的 Histogram，当然，一个查询可能会有多列的 condition。一般我们不会为列的 pairs 维护 histogram，这样会造成巨大的空间放大，但我们可能维护相关的 distinct value（不同的值）。</p><h4 id="Propagation-of-Statistical-Information"><a href="#Propagation-of-Statistical-Information" class="headerlink" title="Propagation of Statistical Information"></a>Propagation of Statistical Information</h4><p>histogram 可以支持在插入后更新数据，也可以在某个统计信息不是很准的 SELECT 之后，根据 SELECT 的结果，更新数据，不过不太好的一点是，如果有的列被频繁更新，但是很少读取，这些数据可能会失真。当我们有多个条件的时候，可能会取各个 Column 的 Selectivity 的积，这可能导致问题变严重。</p><p>不过有的系统可能只会用一些 Column 的统计信息。一些系统在 Join 的时候也可以给 Histogram 做 “Join”，不过这涉及 Histogram 的对齐工作。</p><h4 id="Cost-Computation"><a href="#Cost-Computation" class="headerlink" title="Cost Computation"></a>Cost Computation</h4><p>这里要求把 CPU，IO 等考虑上，也提到了分布式系统中，也要考虑 IO 开销（不知道 snowflake 和 ClickHouse 做了吗）。这里还提到对 RDBMS，Buffer Pool  相关的策略对预测影响也很高。</p><h2 id="Enumeration-Architectures"><a href="#Enumeration-Architectures" class="headerlink" title="Enumeration Architectures"></a>Enumeration Architectures</h2><p>System-R 优化器会根据表访问方法、Join 方法构建搜索策略。当添加新的 transformation 和新的 physical operator 的时候，希望有一个可扩展（extensible）的 optimizer。这里关注了自底向上的 Starburst 和自顶向下的 Volcano/Cascades，他们的共同点是：</p><ol><li>使用 generalized cost functions + physical properties + operator nodes</li><li>使用规则引擎，让 transformation 能够更新 query expression / operator trees</li></ol><h3 id="Starburst"><a href="#Starburst" class="headerlink" title="Starburst"></a>Starburst</h3><p>Starburst 被构建在 DB2 中，有 Query Rewrite 和 Plan Optimization 两个阶段。它被证明有不错的性能，但是也有一定的问题。</p><p>Starburst 会把查询构建成 QGM，其中 <code>box</code> 代表 table 相关的 query block，每个 box 会描述数据是否有序、predicate 相关的策略。</p><p>在 rewrite 阶段，系统有很多的 rules，每个 rule 包含<code>&lt;判断 apply 的条件, apply 的流程&gt;</code> .这些 rules 按顺序排布。</p><p>在 plan optimization 阶段，QGM 会产生对应的 physical operators，这个产生方法可能有某种 dsl 来描述。每个 Plan 有自己的 selectivity, physical properties，cost。</p><h3 id="Volcano-Cascades"><a href="#Volcano-Cascades" class="headerlink" title="Volcano/Cascades"></a>Volcano/Cascades</h3><p>starburst 会先生成一组 QGM，Volcano/Cascades 会有逻辑到物理的变化。借助 memo 来做具体的实现。</p>]]></content>
      
      
      
        <tags>
            
            <tag> database, optimizer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SSD as Cache and CacheLib</title>
      <link href="/2021/11/01/SSD-as-Cache-and-CacheLib/"/>
      <url>/2021/11/01/SSD-as-Cache-and-CacheLib/</url>
      
        <content type="html"><![CDATA[<h2 id="SSD-特性回顾"><a href="#SSD-特性回顾" class="headerlink" title="SSD 特性回顾"></a>SSD 特性回顾</h2><p>SSD 的重要组成部分是 NAND Flash，在介绍 SSD 的时候，我们需要理解 NAND Flash 的一些基本性质。</p><p>Flash 包含很多 Block，而 Block 通常由很多 Page 组成。读取 (read) 的单位通常是 Page，Program 也是针对单个 Page 进行写入的。而重要的擦写（Erase）意味着，我们需要重写某个 Page 的话，我们可能需要给整个 Block 内容移除：</p><p><img src="https://image.mwish.me/blog-image/470B0E46-53DD-49A3-AC29-E8AD71AA3834.png" alt="470B0E46-53DD-49A3-AC29-E8AD71AA3834"></p><p>通常，Flash 的擦写次数是有上限的，而 SSD 会包含 FTL 层，来协调对 SSD 的写入。</p><p><img src="https://image.mwish.me/blog-image/9A5BDBB7-CDD3-4FDB-BACC-5AC2F30234AA.png" alt="9A5BDBB7-CDD3-4FDB-BACC-5AC2F30234AA"></p><p>对 SSD 的写入可能还会需要 GC，因为 Erase/Program 是不同粒度的，所以 SSD 可能是需要 GC 的。假设：</p><ol><li>前台没有空间供 SSD 写入</li><li>后台希望整理碎片，在有的 Block 中，可用的逻辑块很少了</li></ol><p>那么我们希望有一个 GC 来清理这些资源</p><p><img src="https://image.mwish.me/blog-image/D0E621E1-838A-4ADE-BB9D-88BD124EF3FD.png" alt="D0E621E1-838A-4ADE-BB9D-88BD124EF3FD"></p><p>上述图片演示了 GC 的过程。这中间需要有一部分额外空间来做 GC，比方说 SSD 提供 1TB 的空间，那么它需要有一定的内存来处理 NAND Flash 物理空间和逻辑空间的映射，同时，需要有一定空间来协助 GC，这部分空间叫做 over-provisioning (OP).</p><p>SSD 也可以在用户层配置更多的空间给 OP，这种配置能够让 SSD 有更多的空间做 GC，对于 random write 比较多的 SSD，实际上可以提供一定的性能优化，如下图：</p><p><img src="https://image.mwish.me/blog-image/5E1FF6C5E870DA80BB49B23B57F0A416.png" alt="5E1FF6C5E870DA80BB49B23B57F0A416"></p><p><img src="https://image.mwish.me/blog-image/BA93F665-D143-4773-98C9-35218854FEF1.png" alt="BA93F665-D143-4773-98C9-35218854FEF1"></p><p>以上是阅读后文之前需要理解的 SSD 知识。</p><h3 id="为什么为-SSD-设计缓存需要额外的数据结构"><a href="#为什么为-SSD-设计缓存需要额外的数据结构" class="headerlink" title="为什么为 SSD 设计缓存需要额外的数据结构"></a>为什么为 SSD 设计缓存需要额外的数据结构</h3><p>实际上，现有已经有比较多的 kv-store 了，包括著名的 RocksDB。主要的问题在于，Cache 中，如果不再引用某份数据，那么删除掉它是安全的。而 KV 存储引擎即使不保留多个版本，也一定会保留它。drop 一份数据的时候，甚至会 log 一个 tombstone，再慢慢清除存储的数据。</p><p>Netflix 使用 RocksDB 做小文件缓存，这使得它有大量的空间浪费，并且要开启较高的 OP。</p><h2 id="CacheLib"><a href="#CacheLib" class="headerlink" title="CacheLib"></a>CacheLib</h2><p>CacheLib 本身是 Facebook 以库的形式提供的缓存库。开发这个库主要是因为 Facebook 内部有很多需要用缓存的地方，包括 CDN、应用的 Look-Aside Cache、对 Storage System （比如图片和小对象）的 Cache。如下图：</p><p><img src="https://image.mwish.me/blog-image/DAD9DF7D-B6ED-48CE-AC8E-E5A806E381CE.png" alt="DAD9DF7D-B6ED-48CE-AC8E-E5A806E381CE"></p><p>过去这些团队都需要独立维护 Cache，也开源了像 memcached 一样的产品。但实际上这些团队相当于要造一套适用于自己的缓存。不同团队的缓存是不太一样的，论文里面展现了不同地方的使用场景：</p><ul><li>CDN，使用 DRAM 和 Flash 做 Cache</li><li>应用的 Look-Aside Cache，可能会运行一个比较大的 Memcache 集群，并且通过 RPC 来访问这些数据。</li><li>应用的 In-Process Cacahe. 这个和上面的 Look-Aside Cache 是一个相对的概念，因为对一些 app 来说，它自己需要缓存部分数据，比如 client session。</li><li>机器学习模型缓存</li><li>存储集群缓存。Facebook 使用大量的 HDD 作为缓存，部分时候可能希望前台能够缓存在机器的 SSD 中。</li><li>数据库的页缓存。这个需要和 DB 的逻辑强相关。</li></ul><p>在数据特征上，这些也呈现出很多不同：</p><ol><li>数据的冷/热是不同的，小部分数据<em>可能</em>承担了大部分流量。</li><li>数据的冷/热变更的很快</li><li>暴读的情况很多</li><li>需要缓存的对象涵盖了不同的大小范围</li></ol><p>关于冷热数据想必不用赘述。冷热变化可以见下图：</p><p><img src="https://image.mwish.me/blog-image/1A05F9DE-7B74-491C-816A-81F3A1A37635.png" alt="1A05F9DE-7B74-491C-816A-81F3A1A37635"></p><p>可以看到系统的冷热变化趋势。对象大小和暴读情况也如图：</p><p><img src="https://image.mwish.me/blog-image/0DFC5D36-0D63-4149-8CD4-332E3B0A2F79.png" alt="0DFC5D36-0D63-4149-8CD4-332E3B0A2F79"></p><p><img src="https://image.mwish.me/blog-image/D4234985-A56F-45BF-AE1B-931D56D2C999.png" alt="D4234985-A56F-45BF-AE1B-931D56D2C999"></p><p>相对来说这些东西需要写很多相同的缓存逻辑：换出策略，内存使用，处理 empty cache 等，所以 Facebook 造了一套通用的 CacheLib，用来节省团队造轮子的功夫。</p><p>同时，很重要的一点是对于 Flash 的使用。用 SSD/Flash 当缓存，相对来说能够提供较低的成本，和可以接受的性能。相对 DRAM，机器一般会提供更大的盘，同时，SSD 也会提供更低的成本和更可接受的性能。这套功能在 CacheLib 中叫做 HybridCache，CacheLib 允许指定存储设备。</p><p>目前 Facebook 的 CacheLib 使用率：</p><p><img src="https://image.mwish.me/blog-image/3ED5DCBC-9E46-4FA0-83D4-48BA6397DE57.png" alt="3ED5DCBC-9E46-4FA0-83D4-48BA6397DE57"></p><h3 id="Cache-Interface"><a href="#Cache-Interface" class="headerlink" title="Cache Interface"></a>Cache Interface</h3><p>CacheLib 对外提供的是 byte-addressable 的对象和 cache。它提供了一套线程安全的 api，来处理对应的逻辑：</p><p><img src="https://image.mwish.me/blog-image/25B03CAE-7B60-404A-B074-05D202590977.png" alt="25B03CAE-7B60-404A-B074-05D202590977"></p><p>此外，CacheLib 还给自定义的 Serialize/Deserialize 定义了接口，以便用户塞一些自定义结构体。</p><h3 id="Cache-Storage"><a href="#Cache-Storage" class="headerlink" title="Cache Storage"></a>Cache Storage</h3><p>CacheLib 将缓存分为了几部分：</p><ol><li>DRAM Cache</li><li>LOC (Large Object Cache)</li><li>SOC (Small Object Cache)</li></ol><p><img src="https://image.mwish.me/blog-image/7185D48C-6C32-4445-B318-E9117C0C5763.png" alt="7185D48C-6C32-4445-B318-E9117C0C5763"></p><p>申请的内存会出现在 DRAM cache 中，论文使用 chained hash 来存放 DRAM Cache，同时可以自己配置换出的策略。需要注意的是，这里给内存中的缓存可以配置 Pool，每个 Pool 可以自己设置换出策略等。感觉这相当于交给用户自己管理内存使用方式了。</p><p>这里使用了 slab classes 管理内存，这里 CacheLib 自己实现了一套节省空间的 slab allocator，然后对里面的并发进行了优化。</p><p><img src="https://image.mwish.me/blog-image/7B6C9AB9-0FE1-46EF-95AF-3BDF9DCB6EC5.png" alt="7B6C9AB9-0FE1-46EF-95AF-3BDF9DCB6EC5"></p><p>当对象从 DRAM 缓存中 evict 的时候，会按照一定的策略决定是换到 Flash 中还是 Expire。作为默认策略，CacheLib 会固定按照概率 $p$ 来决定是否从 DRAM 中接收数据。</p><p>Flash 上的存储区分了大小对象的存储，大对象是指不小于 2kB 的对象，小对象则自然指的是小于 2kB 的对象。因为 SSD 的特性，这两种对象需要有不同的处理方式。</p><h3 id="LOC-内存索引-SSD"><a href="#LOC-内存索引-SSD" class="headerlink" title="LOC: 内存索引 + SSD"></a>LOC: 内存索引 + SSD</h3><p>LOC 存储的都是 2kB 以上的对象. 作者认为，这些大对象让用户能够在内存中放置这些对象的 Index。具体的对象按照 4kb 的大小对齐。论文用了 4Bytes 的大小定位这部分的数据：4bytes 最大能表示 $2^{32}$  个数据，可以放 16T 的数据了。</p><p>LOC 的内存索引存储 <code>&lt;Key, Location&gt;</code>，LOC 会主动把 SSD 划分成不同的区域，根据这个来判断大小。然后 LOC 对象的地址会对齐 4kB，这大概是一个 SSD Page 的大小，这样能够保证：</p><ol><li>一个 SSD Page 不会存储过多的对象</li><li>地址对齐 4kB，减小地址对象的开销。</li></ol><p>同时，如果对象很大，那么它会连续跨多个页。需要把他们都读起来。</p><p>如果一个 cache read 读取有一个相同的 hash key，这里会把 Flash 中的元数据读起来。这里在元数据上需要存储对应的 key。然后把这个 key 跟用户请求的真实 key 比较，判断具体是否命中缓存。</p><p>这里还有一个 Erase 相关的优化。LOC 的 Erase 是以 Block 为单位的，它默认 16MB，但是是可配置的。这实际上相当于 抹去 SSD 的 Block，通过这种方式来增加写的顺序写。如果淘汰出的对象是一个比较热的对象，可能会重新加入 cache 中。</p><h3 id="SOC-Page-存储"><a href="#SOC-Page-存储" class="headerlink" title="SOC: Page 存储"></a>SOC: Page 存储</h3><p>SOC 存储很多小对象，如果像 LOC 一样存储它们的索引，系统整个 DRAM 开销会非常大。所以 SOC 使用了一个近似的索引来实现对应的逻辑。</p><p>SOC 把小对象划分成很多 sets，每个包含一个 4kB page，按照 FIFO 存储对象。每组有一个 8Bytes 的 bloom filter。这里把 key 查一下 Bloom Filter，如果不存在则返回不存在，否则读取整个 Page 并顺序扫描。</p><p><img src="https://image.mwish.me/blog-image/1C5A507951DF45CBC6DCF62B6D5A2AC4.png" alt="1C5A507951DF45CBC6DCF62B6D5A2AC4"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>CacheLib 论文感觉主要还是说这玩意的必要性，关于细节讲的比较少，内存部分描写比较细（但是这应该是一个很老的主题），Flash 部分 LOC 感觉写的细一点，SOC 根本不能细想。不过这篇文章确实介绍了，相对于 RocksDB，为什么需要 SSD 缓存。</p><p>论文绝大部分篇幅讲的是必要性和工程优化，可以看到 Facebook 确实抠的很细，但是我看了眼代码，感觉 Slab 这些优化都实现了，Flash 部分没看到这些东西存在…</p><h2 id="Kangaroo-Caching-Billions-of-Tiny-Objects-on-Flash"><a href="#Kangaroo-Caching-Billions-of-Tiny-Objects-on-Flash" class="headerlink" title="Kangaroo: Caching Billions of Tiny Objects on Flash"></a>Kangaroo: Caching Billions of Tiny Objects on Flash</h2><p>这篇是 CMU + Facebook + MSR/UW 一起写的，不知道是不是因为 Cache SSD 像一个香饽饽。但是这篇文章感觉比 CacheLib 这篇详实了很多，确实像个正经研究了。</p><p>Kangaroo 的落脚点在小对象优化上，论文考察了 SSD 的下面几个维度：</p><ul><li>写放大<ul><li>来自 SSD 的写放大</li><li>来自应用的写放大</li></ul></li><li>内存开销</li><li>SSD 空间开销</li></ul><p>然后采用了权衡的策略，并结合 SSD 的特点来选出了一个很优的结构。</p><p>论文认为，把 SSD 作为缓存有下列几种 Pattern:</p><ol><li>Log Structure + Index</li><li>Set-associative</li></ol><p>Log + Index 通常是，收到一个小对象的时候缓存下来，直到达到一个 Page（或者数个 Page） 的大小，然后顺序的 Log 这个 Page。考察这种方式的时候，我们会发现，它有着不错的前台写性能，但是 (1) 会需要比较大的内存索引 (2) 有可能需要 GC 等方式回收空间。论文作者着重强调了索引方面的问题。</p><p>Set-associative 以类似 CPU-Cache 的组相联的方式组织，这种方式将 SSD 分为几个部分，然后 <code>hash(key)</code> 找到对应的部分，查看 key 是否存在于其中。这种方式会有非常严重的写放大，因为可以看到，很多情况下，对它的写入都会变成随机写。</p><p><img src="https://image.mwish.me/blog-image/0F046C8B-4D21-4D87-907F-4F943CF45656.png" alt="0F046C8B-4D21-4D87-907F-4F943CF45656"></p><p>Kangaroo 选用了大部分 cache 空间用作 set-associative cache ，并称其为 <strong>KSet</strong>，然后拿一个小部分的缓存作为 Log + Index 的缓存 <strong>KLog</strong>，作为 KSet 的写入前台。KLog 每次把同一组的数据一起丢到 KSet 里，用 batch 的方式优化了 KSet 的写放大。</p><p>Kangaroo 的设计有几个 Key-Point:</p><ol><li>使用 <em>partitioned index</em>，来使 KLog-&gt;KSet 的数据处于同一个 KSet 的 Set</li><li>Kangaroo 可以 drop 掉 value，<strong>它不是 kv</strong>，只是一个缓存，KLog 里面的内容甚至可以不写入 KSet，这可以由某个策略来决定。Kangaroo 实现了 threshold admission，来决定是否要接纳 KLog 淘汰下来的值。</li><li>Kangaroo 提出了新的针对 KSet 的换出策略来进行优化</li></ol><h3 id="SSD-的写放大"><a href="#SSD-的写放大" class="headerlink" title="SSD 的写放大"></a>SSD 的写放大</h3><p>论文里将 SSD 的写放大分为了下面两种：</p><ul><li>Device-level write amplification (DLWA)：SSD Erase/GC 等带来的写放大。随机写会使 DLWA 恶化，从而需要配置更多的 OP。</li><li>Application-level write amplification (ALWA)：当应用重写自己的 Page 等内容的时候，例如 LSM-Tree Compaction。 </li></ul><p>实际上，CacheLib 的策略在 DLWA 和 ALWA 上都是很差劲的，因为它会造成非常多的随机写，和反复重写 Page。Kangaroo 可以靠 Grouping/Batching 来优化它。</p><h3 id="Log-structuredcaches-amp-Set-associative-flash-caches"><a href="#Log-structuredcaches-amp-Set-associative-flash-caches" class="headerlink" title="Log-structuredcaches &amp; Set-associative flash caches"></a>Log-structuredcaches &amp; Set-associative flash caches</h3><h3 id="Kangaroo-流程"><a href="#Kangaroo-流程" class="headerlink" title="Kangaroo 流程"></a>Kangaroo 流程</h3><p><img src="https://image.mwish.me/blog-image/D8DAFE57-3708-4971-8E01-CE5F57D41163.png" alt="D8DAFE57-3708-4971-8E01-CE5F57D41163"></p><h4 id="写入"><a href="#写入" class="headerlink" title="写入"></a>写入</h4><p>这里的内容首先会落到 DRAM cache 中，随着 DRAM cache evict，它会按照一定概率进入 KLog。写入 KLog 的时候，这里会往 KLog 中插入对应的对象，然后在 KLog Index 中插入对应的条目。KLog 大概占整个 Flash 存储空间的 5%。随着写入，记录可能会被 batch 淘汰到 KSet 中，然后写入对应的 Bloom Filter。</p><h4 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h4><ol><li>先从 DRAM Cache 中查询内容，如果存在则返回</li><li>从 KLog Index 中查询内容，如果查询到则进入 KLog 查找</li><li>如果不存在，则进入 KSet，从 Bloom Filter 找到对应的内容，如果存在则进入 KSet 寻找</li></ol><h3 id="KLog"><a href="#KLog" class="headerlink" title="KLog"></a>KLog</h3><p>KLog 有一个概率 $p$，前来的对象只有这个概率能进入 kangaroo。相比之前 CacheLib 的设计，由于 Batching 写入的优化，Kangaroo 大部分时候不会 discard 掉对象。</p><p>KLog 的目标是，降低整体的 ALWA，同时不增大内存的开销。它需要支持下面的操作：</p><ul><li><code>LOOKUP</code></li><li><code>INSERT</code></li><li><code>Enumerate-Set</code>: 使 KLog 寻找出所有映射到同一个 KSet 的对象。</li></ul><p><img src="https://image.mwish.me/blog-image/649629DA-4FBE-4ABE-9CE2-39BD17584712.png" alt="649629DA-4FBE-4ABE-9CE2-39BD17584712"></p><p>为了高效支持 <code>Enumerate-Set</code>，KLog 的内存 Index 被设计为 Bucket + Chain hashing。这里会让在同一个 KSet 的集合的对象落到同一个内存中的 Bucket。</p><p>这里 KLog Index 的结构可见于下面的 Table1，每个 Item 需要：</p><ol><li>offset, 标示在 KLog 的 Log 环上存储的位置</li><li>Tag，key hash 有关的值，实际上帮助我们推断最终这个条目会映射到哪一个 KSet 的 Page 上</li><li>Next-pointer: 指向 bucket 内的下一个 Item</li></ol><p><img src="https://image.mwish.me/blog-image/8B23F7BC-4387-4F5E-A8EB-63933FE258A7.png" alt="8B23F7BC-4387-4F5E-A8EB-63933FE258A7"></p><p>可以看到，在 size 上，论文对这几个必须的结构的大小做出了优化，使得它们占用了更小的内存空间。不过大概的思路还是一致的：</p><ol><li>Lookup: 找到对应的 bucket，然后忽略掉 invalid item，根据 <code>tag</code> 找到对应的 key。如果没找到，返回 Miss，否则根据 offset，在 Log 上寻找，然后验证整个 key 下盘上的 log 是一致的。KLog 在 Index 上更新 evict 相关的元数据。</li><li>Insert: 插入 Index，然后把对象插入 DRAM Buffer。Buffer 以单个/多个 Page 的一个 Segment 为粒度，保证它是连续的。等到写满 Buffer 的时候，Log 到存储上。</li><li>Enumerate-Set: 在同一个 bucket 里面，找到在同一个 Set 中的对象。</li></ol><p>此外，如图所示，这里按照 KSet 的布局，分成了不同的 <em>partition index</em>，每个 <em>partition index</em> 有独立的 DRAM 和 Flash 空间。这种结构希望能够将 KLog 和 KSet 结构整合更加紧密，同时，在结构设计上，作者可以用一定的 Hack 减少内存开销（见论文 4.2）。论文把单个 Item 压缩到了 48bits，给 Index 省了很大的 DRAM 空间。</p><h3 id="KLog-→-KSet"><a href="#KLog-→-KSet" class="headerlink" title="KLog → KSet"></a>KLog → KSet</h3><p>KLog 的写放大不是什么问题，我们回顾一下，它的前台几乎没有什么写放大，写的话小对象会填充完 Page 再写。ALWA 和 DLWA 都会很小。为了减小  KSet 的写放大，这里需要 batching 导入 KSet。同时，这里需要了解，KSet 是可以 Reject 写入的。</p><p>Kangaroo 有一个后台线程会保证每个 <em>partition index</em> 有一个空余的空间，供 Buffer Log 写入。KLog 会以 Segment 的形式来 evict，这里流程如下：</p><ol><li>对 Segment 中的每个对象，会调用 <code>Enumerate-Set</code> 来枚举出同一个 Set 的所有对象，并尝试写入 KSet。</li><li>如果 <code>Enumerate-Set</code> 对象没有到达 batching 写入阈值，那么 discard 掉这个 Segment 上的这些对象。如果某个 discard 的对象是比较热的对象，那么会重新插入 KLog 。</li></ol><p>系统在 (2) 上有一个阈值。这个阈值会影响 KSet 的 ALWA。系统认为，这个值应该保证，在大小上，KLog 是 KSet 的 5% 左右即可。阈值增大会降低 ALWA，但是会增加 cache-miss。</p><h3 id="KSet"><a href="#KSet" class="headerlink" title="KSet"></a>KSet</h3><p><img src="https://image.mwish.me/blog-image/7667364F-F381-4DAB-919F-2157A23B002F.png" alt="7667364F-F381-4DAB-919F-2157A23B002F"></p><p>KSet 的逻辑和 CacheLib 的逻辑是相同的，不同的是，这里额外在内存中维护了一个 RRIP bits。这个 RRIP bits 相当于用很少的 bits 维护了插入的优先级。</p><p>这里的逻辑比较像 MySQL 的缓存 replacement rule，它会在中间一个位置插入。相对于原本 CacheLib 的 LOC，这里相当于用 batching 写入 + Cache Replacement，优化了写放大和缓存命中率。</p><p>这一段优化主要在 RRIP 算法上，详细可以看论文的 4.4。</p><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>Kangaroo 这篇论文看上去科学了很多，用 Log-Struct 和 Set-associate 两种结构讲了一个比较合理的故事，并且既有一些量化的计算，也有一些实际的工程优化。相对来说，CacheLib 的论文还是大部分在吹自己的场景，只有一节含糊讲了下具体实现，这篇还是做了很扎实的讨论的。</p><p>CacheLib 主分支并没有合并 kangaroo 有关的代码，具体的线上可靠性还有待验证。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Database Recover System</title>
      <link href="/2021/08/07/Database-Recover-System/"/>
      <url>/2021/08/07/Database-Recover-System/</url>
      
        <content type="html"><![CDATA[<p>对于一个 DB 系统而言，大概要考虑这些错误：</p><ol><li>transaction failure<ol><li>Logical error: 例如 db 的资源不够，输入错误等问题</li><li>System error:  数据库系统进入了诸如死锁之类的状态</li></ol></li><li>System Crash: 硬件故障或者系统故障，可能导致持久存储上的数据损坏。（与这个相反，程序崩溃之后，不会影响持久数据的假设，成为 fail-stop assumption）。精心设计的系统即使出现逻辑 bug，也会有一些 <code>assert</code> 等方式，让系统不至于出现数据损坏，所以这个模型还是可信的。</li><li>Disk failure: 简单说就是盘坏了。</li></ol><p>今天这里不会介绍 HA 和 replica 相关的内容，因此，对于磁盘丢失数据我们略过不表。系统希望从崩溃的状态恢复的话，应该可以很粗糙的被分为两个阶段：</p><ol><li>系统正常运行的时候需要做的事情，用于在出现故障的时候，恢复系统的状态</li><li>系统出现故障后，恢复系统的状态。</li></ol><p>（系统的状态可以简单理解成 ACID 或者给用户提供的语义。）</p><h3 id="存储模型"><a href="#存储模型" class="headerlink" title="存储模型"></a>存储模型</h3><p>这个标题名称似乎有些让人困惑，但实际上，后续很多算法都需要依赖一个靠谱的存储层。对于单机 RDBMS 而言，它提供的语义可能类似 block. 并且，可以简单拆分成下面几项：</p><ol><li>volatile storage</li><li>non-volatile storage</li><li>stable storage</li></ol><p>(1) 类似于我们的 memory system, (2) 可以视作简单的盘。(3) 提供了一种数据很难丢失、损坏的语义。通常来说，需要靠 RAID/备份等方式来实现 (3) 这样稳定的存储/块存储语义。同时，写盘也可能出现问题，在写入存储的时候，可能有下列的 case:</p><ol><li>sucessful completion</li><li>total failure</li><li>partial failure</li></ol><p>(3) 实际上是很多问题的来源，为了解决这种 case，需要 CRC/double write 等不同方式。</p><p>下面这里抽象了一下写盘的语义。</p><p><img src="https://image.mwish.me/blog-image/B7CC2AA7-1F2E-4AF0-A477-C69B4143FE4D.png" alt="B7CC2AA7-1F2E-4AF0-A477-C69B4143FE4D"></p><h3 id="Recover-and-Atomicity"><a href="#Recover-and-Atomicity" class="headerlink" title="Recover and Atomicity"></a>Recover and Atomicity</h3><ul><li>Force: 事务完成之后，修改的 page 是否强制要求刷盘</li><li>Steal: 事务完成之前，能否把 Page 刷盘</li></ul><p><img src="https://image.mwish.me/blog-image/3237a0f02b383bd05a61a0f21696d722119.jpg" alt="3237a0f02b383bd05a61a0f21696d722119"></p><p>不妨看看上面的图，实际上做了一个很清晰的定量分析。等等，这是不是说，没有 log 也行呢？</p><p>实际上 BoltDB(虽然只是个 kv) 就提供了这样的能力，它不需要写 wal。本身依靠 cow 来实现这些逻辑：</p><ol><li>系统限制只有一个写事务</li><li>每次修改后，会在新的存储空间上做写入 Page</li><li>commit 的时候，强制刷盘，并且更新 meta，保证下次读到对应的内容</li></ol><p>实际上，它的 Recover 也简单，看一下 2个元数据块是否正常，两个都不正常就节哀了，一个不正常挑正常的，两个都正常挑事务 id 大的。</p><p>如果允许并发写的话，问题需要麻烦很多，早期的 sqlite 对这种模式提供了支持：</p><ol><li>事务会把修改前的 Page 写到 Journal File 空间上</li><li>恢复的时候，会用 Journal File 上的 Page 来提供恢复</li></ol><p>以上类似 cow 或者 shadow paging 的方式可以比较简单的实现一些事物的语义，同时，它们相对于 logging protocol 来说可能开销是更大的。它相当于 force + no steal：</p><p><img src="https://image.mwish.me/blog-image/B9C1A5D0-F0ED-40FF-9241-D0217C9E0F3D.png" alt="B9C1A5D0-F0ED-40FF-9241-D0217C9E0F3D"></p><h4 id="WAL-Protocol"><a href="#WAL-Protocol" class="headerlink" title="WAL Protocol"></a>WAL Protocol</h4><p>这里提供了物理日志和 wal 协议，这里，日志包含: <code>&lt; txn id, object id, Before Value (for undo), after value( for redo)&gt;</code>, 这里可以记作 <code>&lt;T_i, X_j, V_1, V_2&gt;</code> （我感觉这个是一个很简化的模型了，是不是还要处理 delete/insert 之类的）. 同时，这里需要和事务有关的信息, 比如: <code>&lt;Txn i begin&gt;</code> <code>&lt;Txn i Commit&gt;</code> <code>&lt;Txn i Abort&gt;</code>。 log 需要被写到 stable storage 中。</p><p>另一点要说的就是对 block 的写入，我们回到 steal/force 的 case:</p><ol><li>可能事务完成前就刷了写入过的盘，这个时候，假设事务 abort 了，显然，我们需要 <code>undo</code> 这些变更</li><li>可能事务完成后，没有写入 block，这个时候，假设事务 commit 了，显然，我们需要 redo 这些变更</li></ol><p>同时，需要考虑的还有 concurrency control 的语义：同一个 <code>object</code>, 被 txn1 写入之后，在 txn1 commit/abort 之前被 txn2 写入了应该怎么办呢？幸运的是，如果我们采用的是 strict 2PL 协议，这里并不会有这种情况。而 ts 协议大部分时候也避免了这种情况。当然，后面我们会提到，如果希望提前 release lock, 有什么方法能补救这个 case。</p><p><img src="https://image.mwish.me/blog-image/8F0DB468-C10C-494F-94EA-B07F6CB31D27.png" alt="8F0DB468-C10C-494F-94EA-B07F6CB31D27"></p><p>上述是一个对应的序列，那么，能够看到对应的 log:</p><p><img src="https://image.mwish.me/blog-image/7A403DB0-0619-47BE-B172-3A6CF821350C.png" alt="7A403DB0-0619-47BE-B172-3A6CF821350C"></p><p>假设在上述任何一个节点 system crash 了，我们都要走下面两个状态：</p><ol><li><code>redo(T_i)</code>: 这个过程在从前往后扫 wal 的时候发生，对于任何一个 start 的记录，它会把日志中的操作 replay 一遍。</li><li><code>undo(T_i)</code>: 这里不仅要 <code>undo</code> 对应的记录，也要写下对应的 undo 相关的恢复日志 (比如 <code>&lt;T_i, record, before value&gt;</code>，完成的时候也需要写 <code>&lt;T_i, abort&gt;</code>, 防止下次 recover 的时候，还需要恢复这样的状态。</li></ol><p>所以，这里有个简单的 recover 协议：</p><ol><li>T_i 在有 <code>start</code>, 但是没有 <code>commit</code>, 也没有 <code>abort</code> 的时候，需要被 undo</li><li>在事务有对应 <code>commit</code> 或者 <code>abort</code> 的时候需要 redo。<code>abort</code> 的时候为什么要 redo 呢？因为我们刚看到，abort 的时候需要把恢复对应的日志写下来，再 abort。</li></ol><h3 id="Checkpoints-ckpt"><a href="#Checkpoints-ckpt" class="headerlink" title="Checkpoints (ckpt)"></a>Checkpoints (ckpt)</h3><p>上面的内容暗示了日志的全量 scan, 实际上日志肯定要 GC 的，这里给出了一种方法：ckpt, 它暗示之前的 wal 都不重要了：</p><ol><li>把所有留在内存中的日志写到 storage 上</li><li>把所有的 dirty block 写到 storage 上</li><li>写下 <code>&lt;checkpoint &#123;active Txn1, active Txn2, ...&#125;&gt;</code> 日志，表示还活跃的 txn 有哪些。</li></ol><p>这些活跃事务之前的 txn 都已经在 block 中了。那么，恢复的时候，只要找到最近的一条 ckpt 日志，然后开始恢复即可。</p><p>当然，这在性能上带来了一些问题：把所有 dirty block 写到 storage 上，再写 ckpt 日志的时候，事务如果再进行更新并写 log，就会导致 ckpt 之前会有一些不在 disk 上的 log, 导致 ckpt 并没有这么有用。这里可以用 fuzzy checkpoint 来尝试解决这个问题。</p><h3 id="Recover-Processing"><a href="#Recover-Processing" class="headerlink" title="Recover Processing"></a>Recover Processing</h3><p>上述几个部分主要描述的是“系统正常工作的时候，如果希望后来系统是可以 Recover 的，需要做什么</p><h4 id="正常事务-abort-的回滚"><a href="#正常事务-abort-的回滚" class="headerlink" title="正常事务 abort 的回滚"></a>正常事务 abort 的回滚</h4><p>如果 <code>Ti</code> 需要被 rollback, 那么它会反向 scan 日志，对于每一条 <code>&lt;Ti, Xj, V1, V2&gt;</code> 的日志。逻辑大概是：</p><ol><li>Xj 被还原到 V1</li><li>写下一条 <code>&lt;Ti, Xj, V1&gt;</code> 的恢复日志。这条日志是不需要被 undo 的。这些日志被称为 compensation log records (CLRs).</li><li>一旦 <code>&lt;Ti, start&gt;</code> 的开始日志被反向 scan 找到，日志恢复结束，写一条 <code>&lt;Ti abort&gt;</code> 的日志。</li></ol><h4 id="System-Crash-后的恢复"><a href="#System-Crash-后的恢复" class="headerlink" title="System Crash 后的恢复"></a>System Crash 后的恢复</h4><ol><li>redo 阶段中，先需要找到最近的一个 ckpt，然后 replay redo logs</li><li>同时，这里应该需要维护一个需要被补充 abort 的事务状态表 undo-list。ckpt 有一个活跃状态列表，同时，事务 start 的时候，会被加到这个列表里，有事务对应的 commit 和 abort 的日志时，可以从这个列表中排出。</li><li>这个时候有一个 undo-list, 对着这个 undo-list 反向 scan, 进行正常事务 abort 的回滚操作，直到 undo-list 为空，即找到 undo-list 中最早 start 的事务的 log (感觉这表示这之前的 log 都可以 GC 掉)</li></ol><p><img src="https://image.mwish.me/blog-image/5730DEF8-A0F4-4034-8ADC-FCCD841C7709.png" alt="5730DEF8-A0F4-4034-8ADC-FCCD841C7709"></p><h3 id="Buffer-Pool-amp-GroupCommit-amp-WAL"><a href="#Buffer-Pool-amp-GroupCommit-amp-WAL" class="headerlink" title="Buffer Pool &amp; GroupCommit &amp; WAL"></a>Buffer Pool &amp; GroupCommit &amp; WAL</h3><p>下面是一些优化。写入的时候，可以写到 Buffer Pool 里面，然后把 Page Mark 成 dirty 的，按需求异步去写盘。某种意义上，这降低了写放大，但是也导致 BTree 有些逻辑比较难 tunning.</p><p>同时，wal 也可以 buffering, 但是这里需要注意的是，如果 wal 都做了 buffer, 需要有下面的约束：</p><ol><li>当且仅当 <code>&lt;Ti, Commit&gt;</code> 日志写进持久存储之后，Ti 才可被视作提交</li><li><code>&lt;Ti, Commit&gt;</code> 写进存储的时候，<code>Ti</code> 相关的所有日志必须已经顺序落盘</li><li>Block 在写入的时候，需要保证，这个 Block/Page 有关的日志全部被 flush 了。</li></ol><p>同时，显而易见，Commit 的时候，需要有落盘的开销。对于 SSD，这可能是 ~100us 的级别，对于 HDD，可能是 ~ms 的级别。这个时候，可以靠 Group Commit 来解决这个问题。这可能是增大单次写的 latency ，但是把写入的 IO 数量减少了，并均摊了写入的时间，优化了写入。</p><p>此外，事务可以 Batch 的来处理 insert/delete/update 请求，来作为优化。</p><h3 id="Lock-Release-and-Logical-Undo"><a href="#Lock-Release-and-Logical-Undo" class="headerlink" title="Lock Release and Logical Undo"></a>Lock Release and Logical Undo</h3><p>作为实现来说，对于 inc/dec 类的操作，简单做成: read + set，然后写物理日志是没问题的。但是，如果希望在这里增大并发的话，就会有一些奇怪的问题了。2PL 提到过，这里可能会有 cascading abort 的概念。</p><p>但是实际上，这里也可以用 logicial undo log records 来做一些优化。</p><p><img src="https://image.mwish.me/blog-image/680871EA-B3FF-4A6B-AA3F-27AD38EFE3B9.png" alt="680871EA-B3FF-4A6B-AA3F-27AD38EFE3B9"></p><p>如上图，这里把 inc/dec 做到了 log 里，用逻辑日志来做对应的操作。</p><p>在日志修改索引之前，txn 会创建 <code>&lt;Ti, Oj, operation-begin&gt;</code> 的日志记录。<code>Oj</code> 是对象的标示。</p><p>这里写的时候，实际上也需要写物理日志，标志 prev 和 new value。写完之后，需要写一条逻辑日志，表示更新的操作。</p><p><img src="https://image.mwish.me/blog-image/DDBA46660D2612F7B7B0E79ACA89B8C3.png" alt="DDBA46660D2612F7B7B0E79ACA89B8C3"></p><p>这里，rollback 和 recover 的时候，可以遵照逻辑日志的语义：</p><ol><li>不完整的（没有 operation-end 的逻辑日志）会被物理日志 resolve。<ol><li>没有 operation-end 可能表示对这个 tuple/对象 的锁定还没有释放，默认这种行为是串行的</li></ol></li><li>有 operation-end 的逻辑日志会用逻辑日志的信息回滚，并生成一个 operation-abort 的日志</li><li>跳过这个事务的日志，直到找到对应的 operation-begin</li><li>如果往前扫的途中，找到了一个 operation-abort, 那么他会跳过这个 Ti 对这个 object 所有的操作</li><li>直到结束</li></ol><h2 id="ARIES"><a href="#ARIES" class="headerlink" title="ARIES"></a>ARIES</h2><p>我们之前的描述中，recover 会 scan ckpt 以来所有的日志，然后给 block/page 来 replay 这些 redo 日志，再反向去 undo. 这些流程实际上可能还会把内存中所有 page 变成 dirty 的，同时，也带来了很低的效率。同时，ckpt 的过程相对来说也是低效的。</p><p>ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging 提出了 ARIES, 它相对来说提供了很快的 Recover，允许上层使用细粒度的锁等方式。</p><p>下面，假定这里用 Strict 2PL 的模式进行并发控制，并使用 steal + no-force 的方式控制并发。</p><p>下面是一些概念：</p><ol><li>LSN(log sequence number): 每个日志带有的序列号</li></ol><p>然后系统很多地方都会带有这个 LSN:</p><div class="table-container"><table><thead><tr><th style="text-align:center">name</th><th>where</th><th>definition</th></tr></thead><tbody><tr><td style="text-align:center">flushedLSN</td><td>Memory</td><td>磁盘上的日志中，最大的 log id (即 flush 过的最大日志的 id)</td></tr><tr><td style="text-align:center">pageLSN</td><td>per page (memory)</td><td>对这个 Page 最近的写入的 log id, 在内存中</td></tr><tr><td style="text-align:center">recLSN</td><td>per page (memory / disk)</td><td>这个 Page 上次 flush 的时候，最大的 log id, 在内存和盘上都有</td></tr><tr><td style="text-align:center">lastLSN</td><td>per transaction</td><td>事务最后写入的 LSN</td></tr><tr><td style="text-align:center">MasterRecord</td><td>disk</td><td>上个 ckpt 的 LSN</td></tr></tbody></table></div><p>然后同理，根据之前的 wal 协议，我们要保证：任何时候，任何 <code>pageLSN</code>  小于 <code>flushedLSN</code>。</p><h4 id="Commit"><a href="#Commit" class="headerlink" title="Commit"></a>Commit</h4><ol><li>写 Commit 日志</li><li>等待 Commit 和之前的所有日志被 flush 到盘上，并更新 flushedLSN. 内存中小于 flushedLSN 的记录可以被清除。</li><li>写一条 <code>TXN-END</code> 记录, 不要求立刻 flush</li></ol><h4 id="Abort"><a href="#Abort" class="headerlink" title="Abort"></a>Abort</h4><p>相对于我们之前的物理日志，这里要加上一些额外的字段：</p><ul><li><code>prevLSN</code> 同一个事务的上一条 LSN，这可以把一个事务的日志穿成一个单向链表</li></ul><p>abort 的时候，这里也要写 CLR，相对我们之前记录的 CLR，这里也增加了内容：</p><ul><li><code>undoNext</code> 指针，就是 undo 一条 CLR 只有，根据 <code>prevLSN</code> 的记录，找到的下一条要恢复的 redo 日志</li></ul><p><img src="https://image.mwish.me/blog-image/48E33312-9C7C-489B-986E-DE0726829AEC.png" alt="48E33312-9C7C-489B-986E-DE0726829AEC"></p><p>相对来说，这些记录能在 crash 的时候，提高恢复的速度。</p><p>crash 的时候，这里会：</p><ol><li>写一套 abort 的记录</li><li>写对应的 CLR, 然后沿着版本链 undo</li><li>写 <code>TXN-END</code></li></ol><h3 id="Fuzzy-Checkpoint"><a href="#Fuzzy-Checkpoint" class="headerlink" title="Fuzzy Checkpoint"></a>Fuzzy Checkpoint</h3><p>checkpoint 需要把所有的 dirty page 刷到存储中，这段时间都要 stop-all-txns, 然后要 flush the buffer。fuzzy checkpoint  可以提供一个模糊的 ckpt，这里需要记录事务和 Page 相关的内部状态，所以需要两个 Table:</p><ul><li>Active Transaction Table (ATT)<ul><li>txnId: txn id</li><li>status: 现在事务的状态，分为 <code>Running</code>, <code>Committing</code>, <code>Candidate for undo</code></li><li><code>lastLSN</code>: 事务上一次修改的 <code>LSN</code></li></ul></li><li>Dirty Page Table (DPT)<ul><li>记录了 page 和 <code>recLSN</code></li></ul></li></ul><p>这里相对来说，就不用 flush all, 而是说记录了哪些 Page 是 dirty 的。</p><p><img src="https://image.mwish.me/blog-image/E922642E-C55C-446D-824D-55CE92802225.png" alt="E922642E-C55C-446D-824D-55CE92802225"></p><p>这里 flush 的时候，知道 Page 是 dirty 的。可能需要前面一些的日志，来恢复这些 Txn, 当然这里 att 也能拿到 <code>lastLSN</code>, 来比较快的定位。</p><p>当然，这里也要求，写一条 <code>CHECKPOINT</code> 日志的时候，这中间把这条日志刷下去之前，还需要上锁和短暂的 stop，这里是想保证写入 <code>CHECKPOINT</code> 的时候，之前不会出现别的变更日志，让 <code>ATT</code> 和 <code>DPT</code> 的这里还有一种优化，让这个日志写两条：</p><ol><li><code>CHECKPOINT-BEGIN</code> : 逻辑上的 ckpt 实践</li><li><code>CHECKPOINT-END</code>: 包含 ATT + DPT</li></ol><p>这实际上就是把日志拆成了两条，然后延缓了这个状态。虽然这里也要有小小的 stall。</p><p><img src="https://image.mwish.me/blog-image/0FCE87D0-00D0-4ABE-824D-D917EFCD47B8.png" alt="0FCE87D0-00D0-4ABE-824D-D917EFCD47B8"></p><p>同时，当 <code>checkpoint</code> 写入完成的时候 <code>checkpoint-begin</code> 需要更新到 <code>MasterRecord</code>。这里相当于，<code>checkpoint-begin</code> 到 <code>checkpoint-end</code> 之间的事务，不会纪录到 ATT 中。</p><h4 id="Big-Picture"><a href="#Big-Picture" class="headerlink" title="Big Picture"></a>Big Picture</h4><p>在进入 Recover 之前，让我们对这些结构都有一个全局印象吧：</p><p><img src="https://image.mwish.me/blog-image/BEC1863C-DDBE-4E43-9C58-B8998B652C4D.png" alt="BEC1863C-DDBE-4E43-9C58-B8998B652C4D"></p><h4 id="Recover"><a href="#Recover" class="headerlink" title="Recover"></a>Recover</h4><p>这里 recover 分为三个阶段（还记得之前的 redo/undo 吗）：</p><ol><li>analysis</li><li>redo</li><li>undo</li></ol><p>analysis 阶段中：</p><ol><li>先找到 MasterRecord, 这里对应了一个存储里最新的 <code>BEGIN-CHECKPOINT</code>.</li><li>构建 ATT 和 DPT，这里 <code>CHECKPOINT-END</code> 可以帮助构建 ATT，别的状态刚进来是 UNDO</li><li>ATT 而言，对于剩下的日志：<ol><li>如果来了一个事务，把它状态设置成UNDO</li><li>如果事务提交了，设置成 COMMIT</li><li>如果找到了 <code>TXN-END</code>, 也要从 ATT 中移除。</li></ol></li><li>DPT 而言，对于剩下的写入：<ol><li>如果 Page 不再 DPT 中，把 P 增加到 DPT 中，然后初始化它的 <code>recLSN</code></li></ol></li></ol><p>在 analysis 阶段中，构建了完整的  ATT/DPT.</p><p>在 DPT 中，这里记录了 Page 的 recLSN, 这里找到最小的 recLSN, 然后开始对对应的 Page 来 replay:</p><ol><li>如果 Page 不在 DPT 中，跳过这条日志</li><li>如果 Page 的 LSN 不小于日志 LSN，跳过</li><li>否则，apply log, 并且设置内存中的  <code>pageLSN</code></li><li>redo 完之后，给对应的事务写上 TXN-END 记录，并且从 ATT 中移除</li></ol><p>UNDO 阶段中，这里可以用 lastLSN 来加速查找，并且写入 <code>CLR</code></p><p>ARIES 这边支持的 redo 是 Physiological REDO logging + Logical UNDO，用来提供相关的性能支持。Physiological REDO 可以进行，因为本身通过 Page 来定位，用 LSN 来让操作是幂等的。</p>]]></content>
      
      
      
        <tags>
            
            <tag> database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FAST&#39;16 WiscKey</title>
      <link href="/2021/08/01/FAST-16-WiscKey/"/>
      <url>/2021/08/01/FAST-16-WiscKey/</url>
      
        <content type="html"><![CDATA[<h1 id="FAST’16-WiscKey"><a href="#FAST’16-WiscKey" class="headerlink" title="FAST’16: WiscKey"></a>FAST’16: WiscKey</h1><p>WiscKey 是 LSM-Tree 上分离 Key-Value 的一种方案。作者的思路是：</p><ol><li>LSMTree 的 Compaction 有很大的写放大，实际上，Compaction 的时候，value 不那么会被用上，同时，由于写放大，它也没有办法很好利用 SSD 的性能。</li><li>解决方案是将 Value 从 LSM-Tree 中分离出来，同时，实际的场景中，key 的大小并不会很大。为了做到第二点，需要做的事情有：<ol><li>拆分出一个 vLog (value log) 组件，并将 value 落到 vLog 里面</li><li>需要一个 GC，来回收掉旧的 vLog</li><li>不再需要 wal，一切用 vLog 来 trade off</li><li>维持 consistency</li></ol></li></ol><p>当然，论文对 value log 的内容提出了指导性的设计，但是 Consistency 有关的部分其实是写得比较含糊的，感觉很多具体内容还是要看 badger 或者 Titan 之类的实现，才能了解的比较透彻。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>论文的出发点是有两点：</p><ol><li>Compaction 可能会带来非常大的写放大和性能损耗。其中，value 的 Compaction 会带来很大的写放大。写放大比例可能和 Compaction 模式有关。Tiered Compaction 每层会写放大一次，Leveled Compaction 可能会放大数次。这导致了对 SSD 的狂写放大，带来了性能损耗。</li><li>LSMTree 论文提出于 90 年代，那是一个 HDD 占主要地位的年代。HDD 的顺序写性能可能是随机写性能的百倍。LSM-Tree 相对来说，所有写入都是顺序写，这导致了很高的写性能。但是 SSD 没有必要这样去写 value，这回造成很高的写放大。同时，SSD 有很大的并行度，相对来说需要良好的设计来利用这些并行度。同时，SSD 暴写是有损耗的，很容易写坏设备。还有问题就是说，SSD 随机读/顺序读虽然还是有差距，但是相对 HDD 来差距会小很多。</li></ol><p>所以论文提供了最初的 idea:</p><blockquote><p>The central idea behind WiscKey is the separation of keys and values [42]; only keys are kept sorted in the LSM-tree, while values are stored separately in a log. In other words, we decou- ple key sorting and garbage collection in WiscKey while LevelDB bundles them together.</p></blockquote><p>这种 idea 带来了一些 challenge:</p><ol><li>Scan 的时候可能会有一些性能 loss，因为 value 没有任何 locality，如何解决这个问题。（Get 的时候也会有一点，不过这个相当于是一种 trade off 了，可以后文介绍）。WiscKey 靠 prefetch 和利用 SSD 并行度来解决这个问题</li><li>GC: WiscKey 的 GC 利用 vLog 上的顺序读写来优化性能，并希望自己的 GC 是轻量级的</li><li>Consistency: WiscKey 利用 vLog 和 vLog 记录的设计来做 consistency.</li></ol><p>下面是 benchmark 部分，这个就，听他吹一吹就行：</p><blockquote><p>With LevelDB’s own microbenchmark, WiscKey is 2.5×–111× faster than LevelDB for loading a database, depending on the size of the key-value pairs; for random lookups, WiscKey is 1.6×–14× faster than LevelDB. </p></blockquote><p>WiscKey 性能不总是比 LSM-Tree 好，在小 key 占多数的的 point get、range query 中，性能是下降的（当然，如果 vLog 值是顺序的，可能有好些的 locality, 但是不现实），不过，论文作者认为这些情况比较少发生：</p><blockquote><p>However, this workload does not reflect real-world use cases (which primarily use shorter range queries) and can be improved by log reorganization. </p></blockquote><h2 id="LevelDB-的读写放大和硬件利用"><a href="#LevelDB-的读写放大和硬件利用" class="headerlink" title="LevelDB 的读写放大和硬件利用"></a>LevelDB 的读写放大和硬件利用</h2><p><img src="https://image.mwish.me/blog-image/A0BE8E5C-F832-4E04-AAA5-695DE7CB1309.png" alt="A0BE8E5C-F832-4E04-AAA5-695DE7CB1309"></p><p>LevelDB 就不讲了，写放大和 LevelDB Compaction 有关。读放大其实相对来说 trick 一些，这里的分析方式如下：</p><blockquote><p>In the worst case, LevelDB needs to check eight files in L0, and one file for each of the remaining six levels: a total of 14 files. Sec- ond, to find a key-value pair within a SSTable file, LevelDB needs to read multiple metadata blocks within the file. Specifically, the amount of data actually read is given by (index block + bloom-filter blocks + data block). For example, to lookup a 1-KB key-value pair, LevelDB needs to read a 16-KB index block, a 4- KB bloom-filter block, and a 4-KB data block; in total, 24 KB. Therefore, considering the 14 SSTable files in the worst case, the read amplification of LevelDB is 24 × 14 = 336. Smaller key-value pairs will lead to an even higher read amplification.</p></blockquote><p>这里是算上了 index block 和 bloom fliter 的情况，最后读了一次 data block。这里提供了一个 1KB 的 key-value 的 pair, 然后点查 100000 次。</p><p><img src="https://image.mwish.me/blog-image/DA2A69DF-BC32-4112-B862-9E59B8893ADE.png" alt="DA2A69DF-BC32-4112-B862-9E59B8893ADE"></p><p>上面的图有点反直觉，不过实际上原因是说，随着数据集增大，LevelDB 的层数变深、SST 变多，读可能会需要访问越来越多的 SST 的 index blocks, 同时，这些 blocks 不一定都能 fit 在文件元信息的 cache 中，导致读性能的下降，读放大增大。写入很好理解，就不解释了。</p><p>（论文随后和 B+Tree 对比了一下，不过我感觉由于 BTree 的刷脏之类的逻辑，感觉读写放大都没这么好比较，就不贴了）</p><p>下面是硬件相关的内容，可以看到，sequential 相对来说很容易打满读带宽。而 rand access 需要并行 + 每次 issue 较大的块的话，相对来说也能把带宽打满。</p><p><img src="https://image.mwish.me/blog-image/07644C64-EB05-4306-AABE-09589B8D3066.png" alt="07644C64-EB05-4306-AABE-09589B8D3066"></p><p>作者认为，综上所述，compaction 和 random access 浪费了很多读相关的带宽，这点可以被好好利用。同时，即使不是 sequential access, 带宽也是能被打满的。这代表了后文的优化方向。</p><h2 id="WiscKey"><a href="#WiscKey" class="headerlink" title="WiscKey"></a>WiscKey</h2><p>WiscKey 提出了几个基本的设计思想和设计目标：</p><ol><li>WiscKey 分离了 key-value</li><li>为了高效 range-query, WiscKey 用并行随机读来最大化利用 SSD 的带宽。</li><li>WiscKey 利用 GC 等事务来优化 vLog</li><li>WiscKey 可能通过牺牲一致性的方式来优化写性能</li></ol><p>Design Goals:</p><ol><li>低写放大</li><li>低读放大</li><li>SSD 优化</li><li>兼容类似 LevelDB 这些语义，提供丰富的 api</li></ol><h3 id="Key-Value-分离"><a href="#Key-Value-分离" class="headerlink" title="Key-Value 分离"></a>Key-Value 分离</h3><p><img src="https://image.mwish.me/blog-image/052475CD-D553-457B-B931-552B6F1DB0D5.png" alt="052475CD-D553-457B-B931-552B6F1DB0D5"></p><blockquote><p>WiscKey is motivated by a simple revelation. Compaction only needs to sort keys, while values can be managed separately [42].</p></blockquote><p>实际上，这里的 sorting 只需要 key，不需要 value。由于大部分 workload 中，value 可能占的地位多一些，这样能让 SST 中，保存更多的对象，压缩更少的次数。Compaction 的时候，能减少 Compaction 相关的写放大。</p><p>这种模式也减小了读相关的放大。虽然在 WiscKey 中，读也会走到 vLog 上，不能利用 <code>&lt;key, value&gt;</code> 一起的局部性，但是能保证较小的 LSMTree Level，用这个来节省走一堆 index block 的读放大。这里可以有：</p><blockquote><p>For example, assuming 16-B keys and 1-KB values, if the size of the entire key-value dataset is 100 GB, then the size of the LSM-tree is only around 2 GB (assuming a 12-B cost for a value’s location and size), which can be easily cached in modern servers which have over 100-GB of memory.</p></blockquote><p>Figure4 给出了 WiscKey 的基本设计，需要注意的是，这个设计是没有考虑 GC 的，后面还得改呢=。=</p><p>LSM-tree 的 <code>addr</code> 差不多是 <code>(&lt;vLog-offset, value-size&gt;)</code> 这个格式。那么这个时候，逻辑大概如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">delete:</span><br><span class="line">delete in LSM-tree</span><br><span class="line"></span><br><span class="line">Insert:</span><br><span class="line">insert value log</span><br><span class="line">insert in LSM-tree</span><br><span class="line"></span><br><span class="line">get:</span><br><span class="line">get in LSM-tree</span><br><span class="line">get in value log by offset if key exists.</span><br></pre></td></tr></table></figure><h3 id="优化-Range-Query"><a href="#优化-Range-Query" class="headerlink" title="优化 Range Query"></a>优化 Range Query</h3><p>LevelDB 提供了 <code>iterator</code> ，这有一些对应的 api:</p><ol><li><code>Seek(key)</code></li><li><code>Next</code></li><li><code>Prev</code></li><li><code>Key</code></li><li><code>Value</code></li></ol><p>在 LevelDB 里面，这几个操作都是比较朴素的，Key Value 拿到 iterator 现有的东西，返回 Slice. Next 要么直接下一个，然后走下前缀压缩相关的逻辑，要么跳到 Index 上再找个 data block. 这里有个好处就是，range scan 再单个 SST 上还是有一定局部性的。反正 value 都存在一起。</p><p>WiscKey 这里降低了局部性。解决方案是，如果发现查询是一个 range 相关的查询，这里会提前拉出一堆 key 对应的 addr, 然后 issue 并行读。这里会有一批相关的线程来完成这些读相关的操作：</p><blockquote><p>The corresponding value addresses retrieved from the LSM-tree are inserted into a queue; multiple threads will fetch these addresses from the vLog concurrently in the background.</p></blockquote><h3 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h3><p><img src="https://image.mwish.me/blog-image/62A40683-41CB-4012-A3AD-5C0D272659CA.png" alt="62A40683-41CB-4012-A3AD-5C0D272659CA"></p><p>LevelDB 是怎么 GC 的呢？答案是 Compaction 的时候把不再需要的数据干掉。因为它的 key-value 是在一起的，所以这里是相对轻松的。</p><p>WiscKey Compaction 的时候没有动 vLog, 它需要根据 vLog 来做 GC。这个时候，它肯定需要走 LSM-tree 来查看 key 是不是不再需要的了，所以 vLog 要能够索引到 key. 如 Figure 5, 这里在 vLog 中编码了 key, 现在格式是：<code>(key size, value size, key, value)</code>.</p><p>vLog 这里提供了 <code>tail</code> 和 <code>head</code>. 当 GC 的时候，这里从 <code>tail</code> 拿几 MB 的 kv pair, 然后走 LSM-tree 查看数据可不可以被 GC。这里会把还需要用的数据放到 head 处，然后调整 tail 的位置。这里为了保证正确性，需要有这样的顺序：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 将有效的值 append 到 head 上</span><br><span class="line">2. fsync vLog file</span><br><span class="line">3. 把更新的值的地址加入到 LSM-tree</span><br><span class="line">4. 写入 tail 变更的信息</span><br><span class="line">5. 回收 tail</span><br></pre></td></tr></table></figure><p>其实 (3) 这个地方是有一致性问题的：有效数据你想怎么更新呢？感觉这里还挺麻烦的，没有 snapshot 的话倒是还好，如果考虑 LevelDB 的 multi-version 的话，感觉问题还不小…</p><p>WiscKey 可以配置 GC 触发的 pattern，比如定期触发之类的。同时，删除少的负载会很少触发 GC。</p><h3 id="Crash-Consistency"><a href="#Crash-Consistency" class="headerlink" title="Crash Consistency"></a>Crash Consistency</h3><p>还记得 vLog 是什么样子吗？<code>(key size, value size, key, value)</code>。有了这个，实际上就相当于 wal 了。（那这个和 LevelDB 区别是什么呢？实际上 LevelDB 一个 memtable 对应一个 Log file，而 WiscKey 把这个玩意抽开了）。这实际上就能保证 consistency。</p><p>当然，数据是可能有 corrupt 的。WiscKey 发现 log corrupt 的时候，可以在 LSMTree 中表示无该记录。</p><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><h4 id="Value-Log-Buffer"><a href="#Value-Log-Buffer" class="headerlink" title="Value-Log Buffer"></a>Value-Log Buffer</h4><p>这个就很简单，把 vLog 写到 buffer 里，写满了再刷，这个就，一致性/性能 trade-off 了。</p><h4 id="Optimizing-the-LSM-tree-Log"><a href="#Optimizing-the-LSM-tree-Log" class="headerlink" title="Optimizing the LSM-tree Log"></a>Optimizing the LSM-tree Log</h4><p>这里，我们刚刚说到，<code>tail</code> 会在 GC 的时候调整。这里的 head 是持久化的，那么我们考虑，recover 的时候，实际上只要从 <code>head</code> 开始，把它当 ckpt，往后扫 log 来恢复。</p><h3 id="Implemention"><a href="#Implemention" class="headerlink" title="Implemention"></a>Implemention</h3><p>vLog 可能有不同的访问模式，这里用 <code>posix_fadvise()</code> 来交给文件系统处理</p><p>同时，对于 Scan，WiscKey 维护了 32 个线程来处理。</p><blockquote><p>These threads sleep on a thread-safe queue, waiting for new value addresses to arrive. When prefetching is triggered, WiscKey inserts a fixed number of value addresses to the worker queue, and then wakes up all the sleeping threads. These threads will start reading values in parallel, caching them in the buffer cache automatically.</p></blockquote><p>这里用 <code>fallocate(2)</code> 来处理 disk 上的空间： <a href="https://man7.org/linux/man-pages/man2/fallocate.2.html">https://man7.org/linux/man-pages/man2/fallocate.2.html</a></p><h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p><img src="https://image.mwish.me/blog-image/AEE04BBB-1802-414A-8EF5-C8B9B17D6D78.png" alt="AEE04BBB-1802-414A-8EF5-C8B9B17D6D78"></p><p><img src="https://image.mwish.me/blog-image/25B3417B-F9AA-4B0F-BF21-706C3DFE2E3B.png" alt="25B3417B-F9AA-4B0F-BF21-706C3DFE2E3B"></p><p>可以看到，不知道出于什么原因，作者很逆天的把 WiscKey 写成了 WhisKey, 我搜了下，没找到原因。值得关注的其实还是 Figure 8 等一些 LevelDB 性能瓶颈出现的地方了。</p><h2 id="我的一些问题"><a href="#我的一些问题" class="headerlink" title="我的一些问题"></a>我的一些问题</h2><ol><li>GC 相关的写放大感觉是没有很好的衡量的，vLog GC 可能比较省写放大，但是能省多少读写放大呢，这个有很好的 tunning 吗？</li><li>Consistency 怎么能很好的保证呢？假如 GC 的时候，那我们要更新所有的 LSMTree 的 index，这可能暗示</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> database, storage </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VLDB&#39;17 Fast Scans on Key-Value Stores</title>
      <link href="/2021/07/27/VLDB-17-Fast-Scans-on-Key-Value-Stores/"/>
      <url>/2021/07/27/VLDB-17-Fast-Scans-on-Key-Value-Stores/</url>
      
        <content type="html"><![CDATA[<h1 id="VLDB’17-Fast-Scans-on-Key-Value-Stores"><a href="#VLDB’17-Fast-Scans-on-Key-Value-Stores" class="headerlink" title="VLDB’17 Fast Scans on Key-Value Stores"></a>VLDB’17 Fast Scans on Key-Value Stores</h1><p>尽管 KV 模型中，Scan 是一个非常常见的需求，但是大部分时候，Scan 其实效率是很不尽人意的。以 LevelDB 为例，它的 Scan 需要构建 <code>Iterator</code>, 然后把 Memtable, L0 层，其余层的 overlap 都可能读到对应的内容，并且可能需要合并相同 User Key 的数据。此外可能还需要 Manual Compaction 来维护 Scan 的效率。</p><p><em>Fast Scans on Key-Value Stores</em> 论文介绍了一个 kv-server 的模型, 它在尽量少降低 get/put 的效率的情况下，支持了高效的 Scan 查询。论文比较清晰地介绍了一下 kv-engine 的各种设计取舍，推导出了文章介绍的 TellStore 的系统实现。需要注意的是，这里 <code>Scan</code> 经常是一个全表扫的模型，而上层通过 range partition 来限制 scan 的范围。</p><h2 id="Abstract-and-Introduction"><a href="#Abstract-and-Introduction" class="headerlink" title="Abstract and Introduction"></a>Abstract and Introduction</h2><p>KV 模型和 KV-Server （下简称 KVS） 在今天市场正在扩散，原因归功于简单的模型和在这种模型下面不俗的性能：大部分时候，Get/Put 的性能是可预测且高效的，可以在常数时间内完成。但是大部分时候，KVS 的 Scan要么 没有对应接口，要么性能不佳：</p><p><img src="https://image.mwish.me/blog-image/F62997F2-3FF4-4582-A60F-FA4E9FA71F30.png" alt="F62997F2-3FF4-4582-A60F-FA4E9FA71F30"></p><p>论文实现了 TellStore, 即 benchmark 看上去很牛的那些。</p><p>论文认为，本质上，Scan 的高性能和 Get/Put 操作的高性能是冲突的，Scan 需要扫一定部分的数据：</p><ol><li>Scan 如果需要比较好的性能，需要很高的 spatial locality</li><li>Get/Put 如果需要很高的性能，需要 sparse index 来定位。</li><li>Version / GC 可能影响效率。而多 Version 的处理可能也会对 Scan 或者 Get/Put 性能造成影响。</li></ol><p>论文提出了 SQL-over-NoSQL 的架构，并且说明了这种架构下，如何高效同时支持 Get/Put/Scan。最后，论文介绍了它们实现的 TellStore。</p><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p><img src="https://image.mwish.me/blog-image/B78A7731-9C01-4BF1-9851-CBDE2029BD65.png" alt="B78A7731-9C01-4BF1-9851-CBDE2029BD65"></p><p>论文提供了一个 SQL-over-NoSQL 的架构，然后分为了几层，作者认为，这样的架构是弹性的，每一层可以单独的去扩展：</p><ol><li>Storage Layer: 存放分布式的 KV Store，这篇论文的重点</li><li>Processing Layer: 负责处理负载。这里处理事务和查询。同时实现了 MVCC 和 SI 的隔离级别。事务相关的内容由 Commit Manager 层处理。</li><li>Commit Manager: 维护 SI/MVCC。这里它只要给事务 Txn Timestamp, 并且管理事务的状态(active/committed/aborted), 作者认为，因为它功能比较简单，所以很少成为系统的瓶颈。</li></ol><p>而为了支持 SQL，Storage Layer 需要提供下列的语义：</p><ol><li>Scans: 数据可能会以 KV 的形式被组织在 Storage Layer 上。SQL 请求通常会批量 Scan 一个范围的 KV 来完成查询。同时 Storage Layer 也要能下推一些 Selections/Projections/Aggregate 之类的请求，来减少网络带宽开销和网络请求延时。</li><li>Versioning: 本身上层是 MVCC 的，这里需要 Storage Layer 支持多版本。不需要的版本需要被 GC 掉。</li><li>Batching &amp; Asynchronous Communication: 感觉这个就是很工程上和并发设计的问题了。OLTP 的简单查询应该被 Batch 发送到 Storage Layer。<em>这样来均摊多个并发事务的通信开销。</em> 同时，这些请求需要能够被异步处理，以不阻塞下个 Batch 的请求。</li></ol><p>下面需要介绍 KV 设计的 trade-off:</p><ol><li>format: 很多的分析型系统使用 columnar storage 来存储内容。Scan 如果形式上是 <code>sum(a)</code> 之类的请求，会在这上面大大受益。但是对于 Get/Put 而言，这样会导致 <code>Get(key)</code> 需要 materialize, <code>Set(key)</code> 则会写放大</li><li>versioning: 一堆版本，Scan 起来，如果它们贴一起，就得跳过一些不需要的版本的数据了，不贴一起就更麻烦了。</li><li>batching: 这个问题就很工程化了，是一个负载相关的问题。Scan 通常 CPU 开销比较重，而 Put/Get 属于比较轻的操作。放在一起并不明智。</li></ol><h2 id="Design-Space"><a href="#Design-Space" class="headerlink" title="Design Space"></a>Design Space</h2><h3 id="Where-to-Put-Updates"><a href="#Where-to-Put-Updates" class="headerlink" title="Where to Put Updates?"></a>Where to Put Updates?</h3><p>论文把更新的地方分成了三种： Update-in-place ，log-structure，delta-main.</p><ul><li>Update-in-place 即 就地更新，这个可以想到我们脑海中比较原始的 B-Tree. 这样的结构对定长的数据有着很好的性能，但是对变长/多版本数据而言通常意味着相对复杂一些的处理方法，同时，这里还有一定的并发问题，例如 B-Tree 的并发控制。</li><li>Log-structure Storage. 比较极端的，这里用 append log 来当作写数据。这个时候能够保证高效和没有空间上的碎片。纯日志结构的 put 是非常高效的，考虑类似 Bitcask 的 case, <code>Get</code> 的性能也可以做到很好，但是  <code>Scan</code> 可能相当复杂。LSM-Tree 是一种很好的常见妥协方案。</li><li>Delta-main: 数据写入的时候被组织在一个写优化的结构中，定期被合入一个读优化的结构。论文认为，这是就地更新和日志更新的 trade-off: 能尽量保证两者的优点。（我个人感觉这个应该会面临比较大的写放大？）</li></ul><h3 id="How-to-arrange-records"><a href="#How-to-arrange-records" class="headerlink" title="How to arrange records?"></a>How to arrange records?</h3><p>这就是经典的行存列存的问题了。简单来说方案大概有：</p><ol><li>Row-major: Get/Set 能够相对来说直接的完成目标，Scan 部分负载会有较差的局部性。</li><li>Column-major: Get/Set 可能需要物化/写放大，但是 Scan 可能受益。</li><li>PAX 类的行列混存: 试图在 1/2 中 trade-off。</li></ol><h3 id="How-to-handle-versions"><a href="#How-to-handle-versions" class="headerlink" title="How to handle versions?"></a>How to handle versions?</h3><p>MVCC 无论如何多版本，不同版本肯定是要物理存储的：</p><ol><li>不同版本物理上簇聚在一起。通常和就地更新一起用。</li><li>不同版本物理上不在一起，以链式来寻找版本。通常和 log-structure 一起用。它的局部性不好，但是这能简化 GC</li></ol><h3 id="When-to-do-Garbage-Collection"><a href="#When-to-do-Garbage-Collection" class="headerlink" title="When to do Garbage Collection?"></a>When to do Garbage Collection?</h3><ol><li>有线程/进程定期触发 GC</li><li>Scan 的时候，触发 GC</li></ol><p>2可能会增加 Scan 的时间，但是可能被 Scan 比较多的地方更容易被 GC。同时，它在 Scan 的时候 GC，也避免了 GC 之后，可能会出现额外的 cache miss.</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>作者推出了以下的图：</p><p><img src="https://image.mwish.me/blog-image/14B27788-9A82-4099-A238-1AA2A9335142.png" alt="14B27788-9A82-4099-A238-1AA2A9335142"></p><p><img src="https://image.mwish.me/blog-image/115FA5B8-DCEF-4B74-AF70-1C505FC509F5.png" alt="115FA5B8-DCEF-4B74-AF70-1C505FC509F5"></p><p>以上就是上面这几个维度的 KV 设计方案了，但是实际上可选的方案没有那么多，比方说 update-in-place 通常和 row-major 在一起，有很多方案实际上想想就不太合理。所以文章作者直接跳到结果了：</p><blockquote><p>The two most extreme variants are the variant based on log- structured with chained-versions in a row-major format and the variant using a delta-main structure with clustered-versions in a column-major format. The next two sections describe our imple- mentation of these variants in TellStore, called TellStore-Log and TellStore-Col. Section 6 gives implementation details of TellStore that are important for all TellStore variants.</p></blockquote><p>嗯，很合理…</p><p>下面将介绍 TellStore 的结构，这里介绍每个结构的时候，将会回答上面所有的问题。</p><h2 id="TellStore-Log"><a href="#TellStore-Log" class="headerlink" title="TellStore-Log"></a>TellStore-Log</h2><p><img src="https://image.mwish.me/blog-image/3E9D1EB8-CA83-41BD-898F-9F85B2B7F58F.png" alt="3E9D1EB8-CA83-41BD-898F-9F85B2B7F58F"></p><h3 id="Where-to-Put-Updates-1"><a href="#Where-to-Put-Updates-1" class="headerlink" title="Where to Put Updates?"></a>Where to Put Updates?</h3><p>这里为了写入快速，显然要写到 log buffer 里面，这里写入大致逻辑如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 拿到记录，写 log buffer</span><br><span class="line">2. 写 hash table</span><br><span class="line">3. 如果成功，当作写入成功，更新 log buffer header. 否则写入失败. 这回影响其中的 valid</span><br></pre></td></tr></table></figure><p>一旦上述 3 成功，日志就是 immutable 的。这使得 copy 和 recover 相对来说没有那么复杂。这里 1 可以是并发的，而 2 用来同步：对于冲突的写，写 hashtable 成功的数据.</p><p>同时，这里 hash table 实现是预先分配固定大小内存的。同时使用了开放寻址 + 线性探测的方式，以利用系统的局部性。</p><p>存储的 value 这里希望尽可能小，所以论文说就 24bytes: </p><blockquote><p>To keep memory usage small while allowing for a sufficiently sized table, the hash buckets only store the table ID, record key and pointer to the record (24 bytes).</p></blockquote><p>(所以这用的是 gcc4 的 cow string 吗，还是自己写了，囧…)</p><h3 id="How-to-Arrange-Records"><a href="#How-to-Arrange-Records" class="headerlink" title="How to Arrange Records?"></a>How to Arrange Records?</h3><p>行/列？显然是行存。</p><p>此外，作者不希望 Scan 的时候还需要查 hashtable, 所以数据自己能说明自己是否是 valid 的。此外，这里为每个 table 分配了一个 log 结构，这里加快了对 table scan 的效率。（可是没有所以结构咋查啊…）</p><h3 id="How-to-Handle-Versions"><a href="#How-to-Handle-Versions" class="headerlink" title="How to Handle Versions?"></a>How to Handle Versions?</h3><p>这里的版本如上图所示，采取链式方法串起来。新纪录需要指向旧纪录，同时 <code>validFrom</code> <code>validTo</code> 提供了对给定时间戳，允许的读范围。那么我们可以在更新一下 update</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. 拿到记录，写 log buffer</span><br><span class="line">2. 写 hash table</span><br><span class="line">3.1 如果写入失败. 这回影响其中的 valid = false</span><br><span class="line">3.2 成功，当作写入成功，更新 log buffer header. 如果有上一条记录，更新 validFrom 和上个记录的 validTo</span><br></pre></td></tr></table></figure><h3 id="When-to-do-Garbage-Collection-1"><a href="#When-to-do-Garbage-Collection-1" class="headerlink" title="When to do Garbage Collection?"></a>When to do Garbage Collection?</h3><p>这里每个 table 一个 log 结构的话，Scan 的时候， <code>validTo</code> 小于系统最小可能访问的 ts，就说明这条记录可以被 GC. 在 Scan 的时候，如果发现某个 Page (这里我想了下，感觉 log 可能是在 Page 里面存储的，有点类似 InnoDB?) 的可以被 GC 的 record 比例超过一定阈值，Page 就可以被标记为可 GC 的。这里需要把 Page 内 GC，然后调整 MVCC 关系的指针，这个操作代价很高，且 cache locality 很低。</p><h2 id="TellStore-Col"><a href="#TellStore-Col" class="headerlink" title="TellStore-Col"></a>TellStore-Col</h2><p>TellStore-Log 是一个高性能更新的结构。而论文实际上希望设计一个 Delta-main 结构，将 TellStore-Log 定期合并到一个高效 Scan 的结构中。</p><p><img src="https://image.mwish.me/blog-image/2F352388-C65C-42EE-8BD6-669142A4BE62.png" alt="2F352388-C65C-42EE-8BD6-669142A4BE62"></p><p>这里的逻辑大概是：</p><ol><li>一系列的 Main Page 作为系统的 main 存储</li><li>两个逻辑上的 log list 作为系统的 delta, 分别为 insert log 和 update log</li></ol><h3 id="Where-to-Put-Updates-2"><a href="#Where-to-Put-Updates-2" class="headerlink" title="Where to Put Updates?"></a>Where to Put Updates?</h3><ol><li>如果这个 key 不存在，那么丢到 insert-log 里面</li><li>如果这个 key 存在（在 insert-log 或者 main 中），丢到 update-log 里面。</li></ol><p>此外，还有个 <code>newest</code> 字段：</p><blockquote><p>Records in the main and insert-log both contain a mutable <em>newest</em> field containing a pointer to the most-recently written element with the same key. </p></blockquote><p>写入的时候，类似 TellStore-Log 的 newest 会作为同步处来处理。</p><h3 id="How-to-Arrange-Records-1"><a href="#How-to-Arrange-Records-1" class="headerlink" title="How to Arrange Records?"></a>How to Arrange Records?</h3><p>两个 delta 日志肯定行存，main 日志既可以行存也可以列存。TellStore-Col 是一个列存实现，然后用类似 PAX 的结构 <code>ColumnMap</code> 来存储信息：</p><p><img src="https://image.mwish.me/blog-image/368DD607-56BB-4AE3-B48D-2D37DA3F87D5.png" alt="368DD607-56BB-4AE3-B48D-2D37DA3F87D5"></p><ol><li>Meta Data 存储了一些必要的元信息</li><li>Fixed-Size Columns 可能根据 MetaData 确定有哪些内容，这里知道第一列在哪就可以很快定位“哪一个元素在哪”（似乎这里没有压缩逻辑？）</li><li>Var-size heap 和 var-size + meta columns 是提供给变长字段，例如 <code>string</code>  <code>BLOB</code> 的。“This heap is indexed by fixed-size metadata storing the 4-byte offset into the heap and its 4-byte prefix.”</li></ol><h3 id="How-to-Handle-Versions-1"><a href="#How-to-Handle-Versions-1" class="headerlink" title="How to Handle Versions?"></a>How to Handle Versions?</h3><p>main page 中的版本簇聚形式存储，从 lastest 到最旧的版本。这样，假设带着一个时间戳来读，那就需要一个找到对应的时间。不过因为是靠在一起的，所以局部性好一些。同时，它也有 <code>previous</code> 指针，指向 Update-Log 中的数据。</p><h3 id="When-to-do-Garbage-Collection-2"><a href="#When-to-do-Garbage-Collection-2" class="headerlink" title="When to do Garbage Collection?"></a>When to do Garbage Collection?</h3><p>这里 GC 功能要复杂些：它需要把 update-log 和 insert-log 合并到 main 里面（可能是以行存 —&gt; 列存的形式）。同时，这里形式类似 cow, 不会在 main page 原地更新，而是产生新的 page / reuse page.</p><p>这里 GC 由单独的线程处理（为什么不在 Scan 的时候处理呢？论文解释是这个工作量较大。TellStore-Log Scan 的时候需要扫全部记录，然后把没用的放前面即可。TellStore-Col 需要搞新 page + 合并 + 行转列，负载比较大）。</p><p>GC 发现某个记录需要被清除的时候会被触发。对于 main page 中的 key, 不同的版本可以从自己的临近数据和 update-log 中找到。然后可以从 insert-log 中找到新插入的数据，扫 update-log 拿到这些新的版本。<code>validTo</code> 过小的记录会被 discard 掉。完成后，log 记录、被 gc 的 main page 可以放入空闲 page 列表。</p><p>这里重申了一下为什么要 update-log:</p><ol><li>只要 scan insert-log, 就可以找到不在 main 中的数据。</li><li>同时这可能降低了 locality: 原本 scan 的时候，insert-update 一起，可能找到一个记录，就可以发现它是最新的。而新的 case 下 update 这里可能要回溯到 insert 上进行 random access. 这要求 update-log 被 GC/合并到 main 是非常频繁、能够保证 update-log 足够短。</li></ol><h2 id="Implemention"><a href="#Implemention" class="headerlink" title="Implemention"></a>Implemention</h2><p>这部分主要就是工程实现了。</p><p>网络上，这里实现采取了 boost.asio 的异步策略。同时，对 get/put 和 scan 的线程池做了切分：这里应该觉得 Scan 相对重一些，不能影响较轻的 Get/Put 查询。同时，还有线程负责 GC。</p><p>Scan 这里写的有点 hack, 有一个 scan thread 作为 coordinator，它会搜集所有 scan request，然后绑定到一个 shared scan 上，然后由一些线程去分 part 扫。感觉这里 Scan Request 多一些性能会比较好。</p><p>这里还用类似 Chord 的形式实现了个 DHT 。同时如果希望支持 Range，<code>Tell</code> 论文中提到了 Lock-Free Btree，它是在 processing layer 实现的，感觉到 storage layer 都是傻傻的全部 scan 然后 shared scan.</p><p>此外，这里因为 scan 的特性，还做了 codegen，这块我不是很了解，没细看。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>[CIDR 05] MonetDB/X100: Hyper-Pipelining Query Execution</title>
      <link href="/2021/07/05/MonetDB-X100-Hyper-Pipelining-Query-Execution/"/>
      <url>/2021/07/05/MonetDB-X100-Hyper-Pipelining-Query-Execution/</url>
      
        <content type="html"><![CDATA[<p>MonetDB/X100 是一篇 05 年的论文，也是分析型数据库中引用较多的一篇论文。它给 MonetDB 提供了一个高效的查询层，减小了 MonetDB 之前许多操作的开销。同时，贴合了当时的硬件的发展。目前，这篇论文的 Batch 等思路已经被比较大规模的使用了，同时，文章给出的手工编码代码的 baseline 也给 Hyper 等 Codegen 提供了启发。</p><p>同时，即使不了解数据库，学习过体系结构的朋友们也可以看看这篇论文的前几章。虽然论文写得比较早，但是对CPU 性能还是提供了一个比较好的视角。</p><p>除开 MonetDB/X100 之外，本笔记在第一段会介绍比较多 MonetDB 在提出 X100 之前的逻辑。</p><h2 id="MonetDB"><a href="#MonetDB" class="headerlink" title="MonetDB"></a>MonetDB</h2><p>MonetDB 最早基于 <em>内存映射文件</em> 来避免使用比较复杂的 buffer pool, 与传统的 RDBMS 不同:</p><ol><li>用 column at-a-time-algebra 取代 volcano 那类的 row at a time</li><li>minimize CPU cache misses rather than IOs</li><li>用类似 database cracking 的技术，来合理的生成 index</li><li>运行时去优化查询</li></ol><p>传统的数据库使用 tuple-at-a-time (比如一次 <code>Next</code> 拉一个 tuple), pull-based (上游有需要就走 <code>Next</code>), iterator 类似的 <code>next()</code> 拿下一条数据的形式。</p><p>MonetDB 最早支持对一批 column 进行同样的操作，通过编译器/手动实现优化，来增加对流水线的友好性，提高代码的 CPI.</p><p>Column-at-at-time 在最初是以 <strong>BAT</strong>(Binary Association Table) Algebra 的形式实现的，BAT 类似 <code>&lt;surrogate,value&gt;</code> ，前一个地址是虚拟的。读出来的数据、运算过程中的数据和结果都是以 BAT 的形式存储的。</p><p>BAT 运算也类似一种 IR，前端会把请求编译成 BAT Algebra, 给 backend，即执行 BAT Algebra 的部分执行。</p><p><img src="https://image.mwish.me/blog-image/D080EC21-89D4-4AF6-9494-2548832E6843.png" alt="D080EC21-89D4-4AF6-9494-2548832E6843"></p><p>BAT algebra 针对一个 column 的所有数据执行简单高效的操作。它的思路是：</p><blockquote><p>by making the algebra simple, the opportunities are created for implementations that execute the common case very fast.</p></blockquote><p>为了处理更新，MonetDB 要给每个 column 准备一个 pending updates set. 读取的时候，要 merge 两边的请求。</p><h2 id="CPU-amp-amp-DB"><a href="#CPU-amp-amp-DB" class="headerlink" title="CPU &amp;&amp; DB"></a>CPU &amp;&amp; DB</h2><p>在 MySQL 等 RDBMS 中，代码的 CPI 比较低。而 05 年的时候，CPU 也在进行着发展，可以看下面两张图：</p><p><img src="https://image.mwish.me/blog-image/00CB7129-27B1-45E4-BFEC-37320EBCF2DB.png" alt="00CB7129-27B1-45E4-BFEC-37320EBCF2DB"></p><p>上面这张图介绍了单核的频率影响</p><p><img src="https://image.mwish.me/blog-image/1C9DB6BB-314C-4831-AD23-0FD34C247A49.png" alt="1C9DB6BB-314C-4831-AD23-0FD34C247A49"></p><p>下面是 CPU 的性能。文章写于 05 年，可以看到当时的趋势。这篇文章聚焦在 Hyper-pipeline CPU 上，我看了下，感觉这个术语类似 superscalar。</p><p>文章认为，AP 型数据产品需要提升查询的性能，避免 CPI 低的情况。MonetDB 一定程度上优化了这一点，但是：</p><blockquote><p>However, its policy of full column materialization causes it to generate large data streams during query execution. </p></blockquote><p>上述内容中，我们还记得每次它扫一列，然后生成一个 BAT, 造成了很多额外开销。</p><p>所以这篇文章主要内容是：</p><blockquote><p>Therefore, we argue to combine the column-wise execution of MonetDB with the incremental materialization offered by Volcano-style pipelining.</p></blockquote><p>它提供了一个 X100 的 Query Engine。提供了 vectorized query processing model.</p><h3 id="可以提供的优化"><a href="#可以提供的优化" class="headerlink" title="可以提供的优化"></a>可以提供的优化</h3><p>现代 CPU 靠 Pipeline 来优化性能，而 Pipeline 可能会有各种 hazard。此外，if-else-then condition 可能会在分支预测上影响性能。2020 年，branch mispredict 大概需要 3ns. 这需要 flush pipeline. 此外，现代 CPU 依靠多级流水线来优化吞吐量。</p><blockquote><p>Translated to database systems, branches that are data-dependent, such as those found in a selection operator on data with a selectivity that is neither very high or very low, are impossible to predict and can significantly slow down query execution</p></blockquote><p>此外，这里还有 hyper-pipeline 等技术，能够使用多个 pipeline, 使 CPU &gt;= 1. 我个人感觉这篇文章的 <em>hyper-pipeline</em> 意思应该和现在 superscalar 差不多。</p><p>编译器一般会把能优化的代码尽量优化，一种有用的技术叫 <em>loop pipelining</em>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">F(A[0]),G(A[0]), F(A[1]),G(A[1]),.. F(A[n]),G(A[n])</span><br><span class="line">into:</span><br><span class="line">F(A[0]),F(A[1]),F(A[2]), G(A[0]),G(A[1]),G(A[2]), F(A[3]),..</span><br></pre></td></tr></table></figure><p>上述内容可以帮助 CPU 用 OoO 和 SIMD 等方式执行，提高并行度。此外，编译器还能试图优化 branch prediction:</p><p><img src="https://image.mwish.me/blog-image/E7C4ABDA-AFB3-4AD6-A7C6-78688BFFDA66.png" alt="E7C4ABDA-AFB3-4AD6-A7C6-78688BFFDA66"></p><p>还可以看到：<a href="https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array">https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array</a></p><p>最后一点与性能的最好的朋友和最大的敌人 cache 有关:</p><blockquote><p>and can significantly improve if cache-conscious data structures are used, such as cache-aligned B-trees [15, 7] or column-wise data layouts such as PAX [2] and DSM [8] (as in MonetDB).</p></blockquote><h3 id="TPC-H-测试"><a href="#TPC-H-测试" class="headerlink" title="TPC-H 测试"></a>TPC-H 测试</h3><p>在测试中，传统 DMBS 的 CPU IPC 只有 0.7 。而科学计算的 IPC 有 2. 论文选去了 TPC-H Query 1 作为了测试的 case.</p><p>TPC-H 数据基于 1GB 的数据仓库，可以根据 Scaling Factor (SF) 来更新这个大小。</p><p>传统 RDBMS 通常使用火山模型，同时要支持很多 flexible 的查询，这一点会大大影响性能：</p><blockquote><p>For instance, even a simple ScanSelect(R,b,P) only at query-time receives full knowledge of the format of the input relation R (number of columns, their types, and record offsets), the boolean selection expression b (which may be of any form), and a list of projection expressions P (each of arbitrary complexity) that define the output relation. In order to deal with all possible R,b, and P, DBMS implementors must in fact implement an expression interpreter that can handle expressions of arbitrary complexity.</p></blockquote><p><img src="https://image.mwish.me/blog-image/CC55337B-7F22-4CC3-9820-A8B1BF3CC58F.png" alt="CC55337B-7F22-4CC3-9820-A8B1BF3CC58F"></p><p>论文分析了 MySQL:</p><p><img src="https://image.mwish.me/blog-image/92B8BC80-EF8B-45F0-96AA-88E3CE62796C.png" alt="92B8BC80-EF8B-45F0-96AA-88E3CE62796C"></p><p>测试发现，大概很少量的工作在做实际的计算, 大部分 workload 都在 <code>rec_get_nth_field</code> 这种传来传去的东西上，还有 agg 的 hashset.</p><p>另外一项操作是 <code>::val</code> , 这个从具体的内存中捞出需要计算的 <code>int</code> 或者 <code>float</code>, 这个地方相对来说也比较费：</p><p>A simple arithmetic operation <code>+(double src1, double src2) : double</code> in RISC instructions would look like:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LOAD src1,reg1</span><br><span class="line">LOAD src2,reg2</span><br><span class="line">ADD reg1,reg2,reg3</span><br><span class="line">STOR dst,reg3</span><br></pre></td></tr></table></figure><p>MySQL 这个效率非常低。倒不是执行这几条指令会很痛，而是说，这里是可以更快的：</p><blockquote><p>The limiting factor in this code are the three load/store instructions, thus a MIPS processor can do one *(double,double) per 3 cycles. This is in sharp contrast to the MySQL cost of #ins/Instruction-Per- Cycle (IPC) = 38/0.8 = 49 cycles!</p></blockquote><p>利用上 loop-pipelining, SIMD 等技术，一起处理，能让这块性能大大提高。这一块的结论是：</p><ol><li><code>Item_func_plus::val</code> 应该被 loop-pipelining 的处理，和我们之前说的一样，这里可以利用上 SIMD, 循环展开等优化。</li><li>函数调用的开销应该被均摊。</li></ol><h4 id="TPC-H-测试-MonetDB-MIL"><a href="#TPC-H-测试-MonetDB-MIL" class="headerlink" title="TPC-H 测试 MonetDB/MIL"></a>TPC-H 测试 MonetDB/MIL</h4><p>MIL 就是我们之前提到的 BAT 运算。他提取固定形状的参数，产生固定形状的结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">join(BAT[tl,te] A, BAT[te,tr] B) : BAT[tl,tr]</span><br></pre></td></tr></table></figure><p>MIL 的 Join 可能需要 reverse 等操作，这个可以见图：</p><p><img src="https://image.mwish.me/blog-image/D6A29DE1-7ADF-4C86-B16F-8DB98E4303D1.png" alt="D6A29DE1-7ADF-4C86-B16F-8DB98E4303D1"></p><p>需要注意的是，Join 需要的 <code>reverse</code> 不会实际拷贝。（肯定没那么傻）</p><p><img src="https://image.mwish.me/blog-image/4EA0C11E-0B7A-4A2A-BB98-30757A34F1DD.png" alt="4EA0C11E-0B7A-4A2A-BB98-30757A34F1DD"></p><p>MonetDB 之前的计算 CPU 效果很好，但是 memory bandwidth 太大（因为全部一批处理 + 产生中间结果也是 BAT + mmap）。当数据规模很小的时候（SF = 0.001），bandwidth 可以很大，因为数据都可以 fit 在 cache 里。但是数据规模大的时候，Bandwidth 就受限于内存设备了，这会影响查询的效率。</p><p>当然，late materialization 可以一定程度上减少这个问题。用比较节省内存的表现形式，类似 c-store 中的 type 1-4, 只有需要的时候才 deserialize，能够提高这方面的性能。</p><p>此外，这里有很多个 <code>join</code>, 这些 <code>join</code> 是列的 <code>join</code>, 用来组成必要的行，可以看上面 figure 4.1。volcano + 行存，根本不需要执行这些 <code>join</code></p><blockquote><p>While in this paper we concentrate on CPU efficiency in main-memory scenarios, we point out that the “artificially” high bandwidths generated by MonetDB/MIL make it harder to scale the system to disk- based problems efficiently, simply because memory bandwidths tends to be much greater (and cheaper) than I/O bandwidth. </p></blockquote><p>这里提供了一个 硬编码的高效 UDF，作为程序的baseline，这里启发了 codegen 等方法：</p><p><img src="https://image.mwish.me/blog-image/39B4EAF7-A994-4E83-B920-4093A688BEA5.png" alt="39B4EAF7-A994-4E83-B920-4093A688BEA5"></p><h2 id="X100-A-Vectorized-Query-Processor"><a href="#X100-A-Vectorized-Query-Processor" class="headerlink" title="X100: A Vectorized Query Processor"></a>X100: A Vectorized Query Processor</h2><p><img src="https://image.mwish.me/blog-image/E871803A-131F-4472-9F0C-4FB849C33BD6.png" alt="E871803A-131F-4472-9F0C-4FB849C33BD6"></p><p>如上面的层次，X100 的目的是：</p><ol><li>高效 高 IPC 处理大量的数据。</li><li>能够扩展，支持 SQL frontend</li><li>支持更大规模的存储</li></ol><p>下面是相关的几个 part：</p><ol><li>Disk: 加入了 ColumnBM I/O 子系统，提供了一个水平分片的 I O访问接口和轻量的压缩。</li><li>RAM: 这里引入了 memory to cache 等逻辑，在 memory 里面，很多东西都用压缩的格式存储，来节省空间和 bandwidth</li><li>Cache: 这里用 vectorized processing model. 批量的处理数据，尽量能把这些东西丢在 cache 里。X100 会将大块的 BAT 内存切成这些 cache chunk, 在里面即使 random access 相对来说也比较友好。</li><li>X100 试图 batch 处理数据，即使是 agg 这样的算子，也尝试做成 vectorized 的，这里可能依赖简单的 codegen. （agg 困难的地方是输出形状和输入不一样。）</li></ol><p>最后的图可以跟上面的 figure5 看看。</p><h3 id="Query-Language"><a href="#Query-Language" class="headerlink" title="Query Language"></a>Query Language</h3><p>下面来看看具体的查询的执行：</p><p><img src="https://image.mwish.me/blog-image/5FA4A79B-BC44-482C-BDEC-662C76EE81DB.png" alt="5FA4A79B-BC44-482C-BDEC-662C76EE81DB"></p><p>这里会被推到：</p><p><img src="https://image.mwish.me/blog-image/096228AA-9952-4FCE-A634-A10B3376157A.png" alt="096228AA-9952-4FCE-A634-A10B3376157A"></p><ol><li>Scan 每次突出一个 vectorize batch 的数据</li><li>Select 筛选的时候，会产生一个 <em>selection-vector</em>，把过滤成功的填进区</li><li>Project 用来投影。这里不会修改 vectorize 的数据，而是以 <code>map</code> 原语类似的形式，拷到相同的位置中。</li><li>使用 Aggregate，这里因为 <code>(3)</code> 和 <code>(2)</code> 的筛选，<em>selection-vector</em> 也需要传上去。</li></ol><h3 id="X100-Algebra"><a href="#X100-Algebra" class="headerlink" title="X100 Algebra"></a>X100 Algebra</h3><p><img src="https://image.mwish.me/blog-image/D56A5DFE-98B6-468D-BDB8-9E7C74BA3301.png" alt="D56A5DFE-98B6-468D-BDB8-9E7C74BA3301"></p><p>这里 Dataflow 是不断产生 vectorize items 的对象，<code>Scan</code>  <code>Order</code> <code>TopN</code> 会产生一个 Dataflow,Project 会做转型，Aggr 会对 Group By 的对象去重，Array 会根据表达式产生一堆 N-dim array，用来把结果丢给 frontend system。</p><p>Aggr 和 Join 论文中提到了一点，不过有点老生常谈。就是怎么选算子的问题。</p><h3 id="Vectorized-Primitives"><a href="#Vectorized-Primitives" class="headerlink" title="Vectorized Primitives"></a>Vectorized Primitives</h3><p>过去，实现可能会比较 flexible, 比如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * AbstractExecutor implements the Volcano tuple-at-a-time iterator model.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AbstractExecutor</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Constructs a new AbstractExecutor.</span></span><br><span class="line"><span class="comment">   * @param exec_ctx the executor context that the executor runs with</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">AbstractExecutor</span><span class="params">(ExecutorContext *exec_ctx)</span> : exec_ctx_&#123;</span>exec_ctx&#125; &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Virtual destructor. */</span></span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">AbstractExecutor</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Initializes this executor.</span></span><br><span class="line"><span class="comment">   * @warning This function must be called before Next() is called!</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Init</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Produces the next tuple from this executor.</span></span><br><span class="line"><span class="comment">   * @param[out] tuple the next tuple produced by this executor</span></span><br><span class="line"><span class="comment">   * @param[out] rid the next tuple rid produced by this executor</span></span><br><span class="line"><span class="comment">   * @return true if a tuple was produced, false if there are no more tuples</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">bool</span> <span class="title">Next</span><span class="params">(Tuple *tuple, RID *rid)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** @return the schema of the tuples that this executor produces */</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">const</span> Schema *<span class="title">GetOutputSchema</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** @return the executor context in which this executor runs */</span></span><br><span class="line">  <span class="function">ExecutorContext *<span class="title">GetExecutorContext</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> exec_ctx_; &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">protected</span>:</span><br><span class="line">  ExecutorContext *exec_ctx_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个是从 15-445 lab 抄出来的. 就比较 flexible. MonetDB 相反，使用相对定制的接口：</p><blockquote><p>In a vertically fragmented data model, the execution primitives only know about the columns they operate on without having to know about the overall table layout (e.g. record offsets). When compiling X100, the C compiler sees that the X100 vectorized primitives operate on restricted (independent) arrays of fixed shape. </p></blockquote><p>MonetDB 需要手动编码很多接口，来保证实现的高效，比如：</p><p><img src="https://image.mwish.me/blog-image/EFB64D40-4E1C-44E6-8F06-27F13520317C.png" alt="EFB64D40-4E1C-44E6-8F06-27F13520317C"></p><p>（上面 <code>*</code> 表示一个 sequence）</p><p><img src="https://image.mwish.me/blog-image/CB2CEB26-698F-4F7A-95F7-7FD07BFA2069.png" alt="CB2CEB26-698F-4F7A-95F7-7FD07BFA2069"></p><p>（你看一个加法写四遍，这得模版大师来写一套了）</p><p>此外，这里还支持 <em>compound primitive signature</em> :</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(square(-(double*, double*)), double*)</span><br></pre></td></tr></table></figure><p>这种组合的 primitives 能够提供两倍的性能优化，原因应该和访存有关：</p><blockquote><p>The reason why compound primitives are more efficient is a better instruction mix. Like in the example with addition on the MIPS processor in Section 3.1, vectorized execution often becomes load/store bound, because for simple 2-ary calculations, each vectorized instruction requires loading two parameters and storing one result (1 work instruction, 3 memory instructions). Modern CPUs can typically only perform 1 or 2 load/store operations per cycle. In compound primitives, the results from one calculation are passed via a CPU register to the next calculation, with load/stores only occurring at the edges of the expression graph.</p></blockquote><h3 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h3><p><img src="https://image.mwish.me/blog-image/0334E642-F1AD-400F-97ED-BF59F09E1007.png" alt="0334E642-F1AD-400F-97ED-BF59F09E1007"></p><p>MonetDB 的 BAT 把相同的 column 存一起，而 ColumnBM 权衡了读写，把列存为大于 1MB 的 chunks.</p><p>它的更新操作如上图所属，把原本的视作不可变的对象，然后ColumnBM 实际上将所有 delta 列存储在一个块中，这等同于 PAX [2]。因此，这两种操作都只产生一个 I/O。更新只是删除后插入。更新使 delta 列增长，因此只要它们的大小超过总表大小的一个比较小的百分比，就应该重新组织数据存储（compaction?)，以便垂直存储再次更新并且清空 delta。</p><h2 id="TPC-H"><a href="#TPC-H" class="headerlink" title="TPC-H"></a>TPC-H</h2><p>再次跑 TPC-H 之后，X100 获得了没那么大的内存带宽和很好的性能，即使 SF=100，这里 RAM 开销也没那么大。Query 1 的 IPC 提升了很多：</p><blockquote><p>A first observation is that X100 manages to run all primitives at a very low number of CPU cycles per tuple even relatively complex primitives like aggregation run in 6 cycles per tuple. Notice that a multiplication (map mul *) is handled in 2.2 cycles per tuple, which is way better than the 49 cycles per tuple achieved by MySQL (see Section 3.1).</p></blockquote><p>测试还给出了 vector size 的影响：</p><p><img src="https://image.mwish.me/blog-image/F409BB1E-BA05-44B0-BBC8-B60C234EC993.png" alt="F409BB1E-BA05-44B0-BBC8-B60C234EC993"></p><p>这里，比较明显的事，vector size 能在 cache 里面放下的时候，性能是提升的，当放不下的时候，开始访存，性能裂化。比较极端的情况就是回到 MonetDB/MIL 的情景。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li>CIDR’05: MonetDB/X100: Hyper-Pipelining Query Execution</li><li><strong>The Design and Implementation of Modern Column-Oriented Database Systems</strong></li><li><strong>Computer Organization and Design</strong></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>VLDB05: C-Store: A Column-oriented DBMS</title>
      <link href="/2021/07/02/C-Store-A-Column-oriented-DBMS/"/>
      <url>/2021/07/02/C-Store-A-Column-oriented-DBMS/</url>
      
        <content type="html"><![CDATA[<p>这篇文章是 C-Store 的一片阅读笔记，重点介绍的还是它存储数据的 schema. 并发这段我没看很细，就比较简短力图不出错的介绍了一下。写笔记这周在 oncall, 有点神智不清。如果哪有问题可以 评论或者 mail anmmscs_maple@qq.com 以指正。</p><hr><p>C-Store 是一篇比较早的论文。它描述了一个读优化的 RDBMS，支持 SQL。它的设计目标是：</p><ol><li>基于 column，而不是 row，来存储数据。</li><li>对数据在存储上，甚至在内存上做合理的 encoding，提高存储和查询的效率。</li><li>并非按照 <code>&lt;table, [Indexes]&gt;</code> 这种模型来存储，而是按照列的 Projections 来存储</li><li>实现了 Transaction、高可用、Snapshot Isolation</li><li>用 bitmap 索引来优化了 C-Store 场景下的 B+Tree。</li></ol><p>传统的 DBMS，因为希望有着良好的写入性能，通常会以行存的形式存储逻辑上的行。而数据仓库等系统，则通常会进行 bulk load 导入一批数据，然后进行长期的读。在这些场景中，将单列存储在一起，有机会获得更好的查询性能。</p><p>发表论文的时候，传统的 DBMS 会将列按原本的格式乖乖一个个存储，并 padding 到 byte/word 的粒度。这一点让 CPU 不用做 codec。但当时 CPU 正在变得越来越快，而存储 bandwidth 上升量没有这么快，所以需要权衡这种开销。论文提出存储的时候减少 bandwitdh 的方式：</p><ol><li>把数据以一种更紧凑的格式存储，不用 padding 到 bits。例如 varint/只存需要的bits等形式。</li><li><code>densepack</code> 把上述格式在内存中连续存储 <code>(?) 这里我怀疑没读懂它意思</code></li></ol><p>同时，这也要求我们尽量能够让 query executor 支持处理这种压缩过的数据。</p><p>DBMS 可能会有 table heap, primary index, secondary index. 这些结构并非 read-optimized 的。在后者的场景下，bitmap indexes, cross table indexes, materialized views 有更好的性能。基于以上原因，C-Store 存储 <code>set&#123;[一些columns]&#125;</code>, 其中，每个集合被称作 <code>projections</code>，组内按照同样的 attribute 排列。同一个列可能被存储在多个 projections 中，为了防止重复存储导致的空间过度放大，这里会采用多种上述说的存储格式的优化。</p><p>C-Store 的运行环境在设想中类似 MapReduce 论文中的环境，部署在一个巨大的刀片机集群上，同时不会共享存储。C-Store 并不靠 <code>Walmart</code> 一样的 replica 来保证 HA。它利用 <code>projections</code> 层面的列重复性来保证 HA。可以给 C-Store 一定的配置，来保证能容忍 <code>k</code> 台机器故障（即 <em>K-safe</em>）.</p><p><img src="https://image.mwish.me/blog-image/3E942EE4-E2D5-4815-95F3-32F88EC14E1D.png" alt="3E942EE4-E2D5-4815-95F3-32F88EC14E1D"></p><p>即使是 datawarehouse 类的系统，或者 CRM，也需要事务和简单的更新，来修正不正确的记录。（比如对账？）. 对于 column store 而言，所有 column 都按照某个逻辑顺序排序，同时插入按照某种情况单向插入，可以获得很好的写入性能，但是读取性能又不会好。所以这里有上述的 WS 和 RS，和可以 Tuple Mover。需要注意的是，这里 WS 也是 column oriented 的。</p><p>在这里，写入会被写到 WS 中，删除需要 mark 在 RS 中。Tuple Mover 类似 LSM-Tree，定期把数据 bulk load 到 RS 中。读取的时候，系统会选择一个小于最近一个 commit 的时间戳 <code>T</code>，用它来构造 snapshot。通过这种模式来 historical mode read。</p><p>最后，这里需要构建一个 column oriented 相关的 query optimizer 和 query executor。</p><p>论文认为自己的创新在于：</p><ol><li>WS/RS</li><li>多个不同排序的 projections</li><li>高度压缩/提供多种编码方式的的 columns</li><li>列存优化的 query optimizer 和 query executor。</li><li>基于 projections 的 HA 和 <em>K-safety</em></li><li>用 SI 来避免读取的时候走 2PC</li></ol><h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><p>C-Store 支持标准的关系模型。也就是说，它在 <em>逻辑上</em> 存储的数据和 MySQL, PostgreSQL 这些并没有什么区别。但是实际上，它需要支持转化为对应的 projections </p><p>举例说，下面一张 RDBMS 的表，和 DEPT 的表关联着：</p><p><img src="https://image.mwish.me/blog-image/AA9BF703-1BF7-4475-9927-9E5A8F8BE77E.png" alt="AA9BF703-1BF7-4475-9927-9E5A8F8BE77E"></p><p>在 C-Store 中，存储逻辑类似：</p><p><img src="https://image.mwish.me/blog-image/66F6751C-D06B-454E-8A37-0FEB4A267053.png" alt="66F6751C-D06B-454E-8A37-0FEB4A267053"></p><p>在每个 projection 中，如果有 k 列，那么会有 <code>k</code> 个存储单列的数据结构。它们按照其中的一列 <code>sort key</code> 来排序。</p><p>每个 <em>projection</em> 都会水平分片到至少一个 <code>segments</code> 里面。C-Store 的 partition 是基于 sort key 来进行 partition的。每个 segment 都会有个  <em>segment identifier</em>, Sid. 这个数字要求大于0.</p><p>当需要处理 SQL 的时候，请求会处理相关的 projections. 但同时，c-store 需要把几个 sort key 不同的 projections 组合成要返回的数据，这实际上依赖一个类似 join 的功能。c-store 依靠 storage keys 和 join indices 来支持这些操作：</p><ol><li>storage keys 是针对 segment 而言的，这个被称作 SK. 在 RS 的同个 segment 中，不会实际存储 SK, 他们就是 1, 2, 3… 这样按顺序排列。（然后你也别问我为啥不是0开始的）。在 WS 中，他们需要维护这个，这和 WS 的结构和逻辑有关。</li><li>Join Indices 是一个额外的索引，用于把 projection X 的 <code>&lt;SegmentID, SortKey&gt;</code> 按顺序映射到另一个 projections 中，这个结构维护是比较昂贵的。</li></ol><p><img src="https://image.mwish.me/blog-image/B0B9222B-14B2-4942-B6E7-8A5AB111D108.png" alt="B0B9222B-14B2-4942-B6E7-8A5AB111D108"></p><blockquote><p>In practice, we expect to store each column in several projections, thereby allowing us to maintain relatively few join indices. This is because join indexes are very expensive to store and maintain in the presence of updates, since each modification to a projection requires every join index that points into or out of it to be updated as well.</p></blockquote><p>C-Store 通过上述的把一列存储多份，然后实现了恢复机制，来做到 <em>k-safety</em>. 这也需要定义的 schema 的支持。</p><h2 id="RS"><a href="#RS" class="headerlink" title="RS"></a>RS</h2><p>RS 部分是一个读优化的列存储，论文主要介绍了它的存储优化和 Join Indexes, 论文分成了几部分讨论数据的 codec, 实际上未来还有一些更好的方法，但是文章给出的方法还是比较有代表性的：</p><p><strong>Type 1</strong>:有序的且大部分值相同的序列</p><p>这种序列用 <code>(v, f, n)</code> 来表示</p><blockquote><p><em>f</em> is the position in the column where <em>v</em> first appears, and <em>n</em> is the number of times <em>v</em> appears in the column.</p></blockquote><p>为了支持 query, c-store 对这个结构支持了 B树索引，加快了对这个内容的查找。</p><p><strong>Type 2:</strong> 无序且大部分值相同的序列</p><p>这种序列用 <em>(v, b)</em> 来编码，<strong>v</strong> 是可能的值，<strong>b</strong> 是是这个值的数的 bitset:</p><blockquote><p>For example, given a column of integers 0,0,1,1,2,1,0,2,1, we can Type 2-encode this as three pairs: (0, 110000100), (1, 001101001), and (2,000010010).</p></blockquote><p>这里也实现了 <code>&lt;position, value&gt;</code> 的 B+Tree 查找结构。</p><p><strong>Type 3</strong>: 有序且值较少相同的序列</p><p>采用 Delta 的形式进行编码（我感觉这里有点怪，因为 delta 本身应该和压缩没关系，感觉像是用了 delta + varint 啥的…）</p><p><strong>Type 4</strong>: 无序，且值较少相同的序列</p><p>这里没提具体怎么做，就提了一下目前是啥都不做，但是在探索了：</p><blockquote><p>If there are a large number of values, then it probably makes sense to leave the values unencoded. However, we are still investigating possible compression techniques for this situation. A densepack B-tree can still be used for the indexing.</p></blockquote><h3 id="Join-Indexes"><a href="#Join-Indexes" class="headerlink" title="Join Indexes"></a>Join Indexes</h3><blockquote><p>As noted earlier, a join index is a collection of (sid, storage_key) pairs. Each of these two fields can be stored as normal columns.</p></blockquote><p>这个就和之前提的差不多，看上面那个figure 应该就明白了</p><h2 id="WS"><a href="#WS" class="headerlink" title="WS"></a>WS</h2><p>为了避免把优化器搞得太复杂，这里 WS 也用了 projection 和列存的模式，和 RS 有相同的 projections 和 join indexes.</p><p>这里的 SK 和 RS 中的 SK 不同，每个逻辑 tuple 都有相同的 SK, 然后需要存储这个字段。SK 要比 RS 中所有的 SK 都大。（实际上这个地方需要 tuple mover 的协助）。</p><p>RS 以 <code>(segment id, SK)</code> 标志一个对象，实际上 WS 于 RS 有相同的逻辑 segment. 这里认为 WS 的大小相对 RS 来说非常小，所以没有对内容来进行压缩优化。</p><p>下面就是 WS 实际的结构，WS 每个列都被表示为 <code>(v, sk)</code> 。此外，还有一个 <code>(s, sk)</code> 的 B-Tree 结构，s 是 sortkey, sk 是 WS 列的位置。实际上这相当于 append only 的 heap tuple 加一个 index.</p><p>然后再回到 Join Indexes, 每个 Projection 分为 segment in RS + segment in WS. Join Index 存储了驱动表(sender) 到目标表 (receiver )的记录。</p><h2 id="Storage-Management"><a href="#Storage-Management" class="headerlink" title="Storage Management"></a>Storage Management</h2><p>C-Store 又一个 storage allocator, 它会动态调整 Segment 的分区，或者申请 Segment. 这里，假设 RS 要调整分区，那实际上对应的 WS 和与 RS 相关的 Join Indexes 也需要对应的调整。</p><h2 id="Update-and-Transactions"><a href="#Update-and-Transactions" class="headerlink" title="Update and Transactions"></a>Update and Transactions</h2><p>这一部分感觉逻辑还是比较难的，C-Store 提出了一个修改过的 2PC，然后用 epoch 相关的协议，来实现 Snapshot Isolation. </p><p>Update 更新的时候，需要创建 Storage Key, 这里 Tuple Mover 和 WS 维护，保证这个 Storage Key 一定大于 RS 中的任意 key。这里在 BerkeleyDB 上构建了 WS，并要求使用一个比较大的 Buffer Pool, 来保证较高的写性能。这里，C-Store 只希望有写相关的事务，它通常用 snapshot isolation 的模式来读取，所以系统不需要设置 read lock.</p><p>系统把 Snapshot Isolation 可以读的，即不会和写入干涉的时间戳称为 <em>high water mark</em> (HWM). 同时，系统不希望支持 time-traverse, 所以系统设置了一个 <em>low water mark</em> (LWM) 来做一个时间的低水位。在 LWM - HWM 中的东西是可读的。LWN 之前的删除可以尝试被 GC 掉。</p><p><img src="https://image.mwish.me/blog-image/DCDDC52E-CE55-4C3B-8589-7885222CC63A.png" alt="DCDDC52E-CE55-4C3B-8589-7885222CC63A"></p><p>这一段的逻辑感觉是比较杂的，写入的时候，这里有个中央时间管理器 TA，它会定期前进，当事务都完成的时候，它会做一个发号，然后让系统走到下一个 epoch，然后推高 HWM（我感觉 LWM 也可以由读事务结束和 lastmove 来推高）. 为了处理时间回卷的逻辑，这里设置了一个 Wrapping: 保留最低时间戳，防止不正确的回卷。</p><p>对于并发来说，只读事务会走 LWM-HWM 间的 SI，读写事务走 2PL，遵循 NO-FORCE + Steal 语义。系统不会做 REDO, 一旦丢失数据，会走从 Projections 中 Recover 的逻辑。同样的，系统的 2PC 也没有 Prepare.</p><p><img src="https://image.mwish.me/blog-image/86FCE6D9-D08E-46E9-8D26-68A0AF1102AE.png" alt="86FCE6D9-D08E-46E9-8D26-68A0AF1102AE"></p><p>系统的 Recover 如上所述。</p><h2 id="Tuple-Mover"><a href="#Tuple-Mover" class="headerlink" title="Tuple Mover"></a>Tuple Mover</h2><p>Tuple Mover 需要做的是逻辑上的合并操作。根据 LWM HWM 来决定保留什么样的数据，然后做合并，再更新。</p>]]></content>
      
      
      
        <tags>
            
            <tag> database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LevelDB: Write Path</title>
      <link href="/2021/06/18/LevelDB-Write-Path/"/>
      <url>/2021/06/18/LevelDB-Write-Path/</url>
      
        <content type="html"><![CDATA[<h1 id="LevelDB-WriteBatch"><a href="#LevelDB-WriteBatch" class="headerlink" title="LevelDB WriteBatch"></a>LevelDB WriteBatch</h1><p>这篇文章意料之内的写得很乱。感觉不太适合刚看代码的来读，看代码有困惑的地方可以来这里互相印证一下。</p><h2 id="最简单的写路径-写-Memtable"><a href="#最简单的写路径-写-Memtable" class="headerlink" title="最简单的写路径: 写 Memtable"></a>最简单的写路径: 写 Memtable</h2><p><a href="https://zhuanlan.zhihu.com/p/143309915">https://zhuanlan.zhihu.com/p/143309915</a></p><p>可以参考上面这篇 blog. LevelDB 会尝试写入 memtable. 这里比较重要的链路是：</p><ol><li><code>DBImpl::Put</code> / <code>DBImpl::Delete</code> 实现了 <code>DB</code> 对外的接口, 它们会把请求整理到一个 <code>leveldb::WriteBatch</code> 对象中. <code>batch</code> 可以 <code>Put</code>, <code>Delete</code>, 操作会被放到 <code>batch</code> 中的一个 <code>std::string</code> 中.  WriteBatch 开头是一个 <code>kHeader</code> 长度的 header, 包含 8-byte 的 seq-number 和 4-byte 的 count. 随后是记录列表, 每条记录包含一个 <code>char</code> 和 <code>length</code> + <code>content</code> 的内容。</li><li><code>DBImpl::Write</code>  的时候, 会确定一下是不是 <code>sync</code> 写。一个 batch 内全是 sync, 这个 batch 会选出一个 leader 来写入数据。<ol><li>写入数据是单线程写的，一般链路上会拿到 <code>DBImpl::mutex_</code> . </li><li>调用 <code>MakeRoomForWrite</code>, 确保写入空间是充足的。<ol><li>如果 L0 文件超过 8 个文件，到达了 soft limit, 它会释放 mutex_ 并 sleep 1ms. 等待 Compaction 成功</li><li>在可能的 sleep 后，如果 <code>mem_</code> 内存充足 (判定的方式是 Arena 的内存占用小于某个阈值)，它会直接返回，开启后续流程。</li><li><code>imm_</code> 不是 null 的，基本上就说明后台有 compaction，需要等待 <code>imm_</code> 被压缩</li><li>看看是否是 L0 文件到达上限，到达了就停止写</li><li>走到这里说明，imm<em> is nullptr, 文件可能大于 soft_limit, 一定小于 hard limit，同时, mem</em> 内存是不够的，需要切新的文件，然后把旧的文件放到 <code>imm_</code> 中。这里操作比较细，需要：<ol><li><code>Versions::NextNewFileId</code> 拿到系统的下一个文件 id, 作为 log 文件的 id, 让系统创建一个新的文件作为新的 log 文件.</li><li><code>imm_</code> 指向 <code>mem_</code>, 这里不会更新 <code>ref_count</code>.</li><li>创建一个新 <code>mem_</code>, 并把日志指向新创建的文件，对他 <code>Ref()</code> 一下，增加 ref count</li><li>调度 <code>MaybeScheduleCompaction</code> , 正常情况会在 2.2.2 里面成功退出.</li></ol></li></ol></li><li>拿到 <code>Versions::LastSequence</code> ，作为这次的 log_id. 因为写 log 的线程只有一个，所以这个是写入安全的。这里会放锁然后尝试顺序写 log.</li><li>写入成功后，插入 mem. 这里没有带 <code>mutex_</code>, 但是只有单个线程去插入。<code>!w.done</code> 的时候，写者会 <code>Wait</code>，所以不会有别的线程来写入，但是这里可以插入到写入的队列中。写完之后放锁。</li><li>写完之后 notify waiting 的记录。</li></ol></li></ol><p>写入就这样轻松快乐的完成了。</p><h3 id="内存操作：和读取的关系"><a href="#内存操作：和读取的关系" class="headerlink" title="内存操作：和读取的关系"></a>内存操作：和读取的关系</h3><p>我们之前说了 <code>LastSequence</code> ，读取的时候，如果没有快照，会 grab lock，然后拿到 <code>VersionSet::LastSequence</code>. 这个时候，只有写日志会推高这个 Sequence, 用这个来读取是安全的，不会读到新写入的数据。</p><p>同时，这个地方读会给 <code>mem_</code> 和 <code>imm_</code> 来做 <code>Ref</code>, 这个时候，内存是最后一个读者带着 <code>mutex_</code> 来释放的。</p><h2 id="Memtable-Compaction"><a href="#Memtable-Compaction" class="headerlink" title="Memtable Compaction"></a>Memtable Compaction</h2><p><code>DBImpl::MaybeScheduleCompaction</code> 是可能调度 Compaction 的函数，在必要的时候，处理 Compaction.</p><p>调用它的地方有：</p><ol><li>手动 <code>CompactRange</code> 的时候，在 <code>TEST_CompactRange</code></li><li><code>Get</code> / ReadSample 的时候，看看有没有触发 Seek Compaction</li><li>写入产生 <code>imm_</code> 的时候</li><li>每次 Compaction 完后，再次尝试看看有没有 Compaction</li></ol><p>Compaction 的条件有：</p><ol><li><code>imm_</code> 不为 nullptr</li><li>有 ManualCompaction</li><li><code>VersionSet::NeedsCompaction</code></li></ol><p>Compaction 有下面几种类型和优先级:</p><ol><li>CompactMemTable: 优先级最高</li><li>ManualCompaction: 优先级次高</li><li>Size Compaction: 优先级比 SeekCompaction 高</li><li>SeekCompaction</li></ol><p>我们简单介绍一下 Compaction 的大概的逻辑：</p><h3 id="Memtable-Compaction-1"><a href="#Memtable-Compaction-1" class="headerlink" title="Memtable Compaction"></a>Memtable Compaction</h3><ol><li><code>DBImpl::MaybeScheduleCompaction</code>: <code>env_-&gt;Schedule(&amp;DBImpl::BGWork, this);</code> , 触发 Compaction</li><li><code>BackgroundCall()</code> , 持有 <code>mutex_</code></li></ol><p>以 <code>CompactMemTable</code> 为例，讲一下基本的 Compaction 流程：</p><ol><li>拿到 <code>VersionSet::current</code>, 作为 Compaction 的 base. 在 Compaction 期间，不会有别的 Compaction 进来。然后 <code>Ref()</code> 它一下（我感觉其实没啥意思…）</li><li>进入 <code>DBImpl::WriteLevel0Table</code> 创建一个 <code>FileMeta</code> 然后 <code>VersionSet::NewFileNumber()</code>, 拿到新 SST 的文件 id, 把它放到 <code>pending_outputs_</code> 里面。<ol><li>释放锁</li><li>创建 <code>TableBuilder</code>，然后从 iterator 中读取数据</li><li>如果成功，Sync 并关闭文件，否则，删除 SST 然后返回</li><li>把新文件丢到 table cache 中。</li><li>重新持有锁</li></ol></li><li><code>pending_outputs_</code> 移除新 SST</li><li>调用 <code>Version::PickLevelForMemTableOutput</code> 获得文件写入的层数。这里注意，memtable compaction 不一定会直接下到 L0 层，可能直接第二层了。</li><li>VersionEdit 记录新创建文件的信息，包括 key 范围和在哪层。</li><li>Unref base (我一下没看出有啥用)</li><li>edit 再记录一下 log file number, 这里注意，只有 memory compaction 会推高它，原因后面介绍。</li><li>准备写元数据，注意<code>VersionSet::Finalize</code> 的时候，这里会更新 compaction score, 用来处理可能的 size compaction.</li><li>LogAndApply 会更新一些别的信息，然后写 MANIFEST, 更新 Version 和元信息。这里还会处理 Version 链表里 Ref 之类的东西</li><li>Compaction 完后，Unref <code>imm_</code> (还记得不，前面写内存的时候，我们提到了，Compaction 的时候，<code>mem_</code> 会被 <code>Ref</code> 一下，<code>mem_</code> 变 <code>imm_</code> 的时候没有 <code>Unref</code>, 这个时候 <code>Unref</code> 啦)。</li><li>调用 <code>RemoveObsoleteFiles</code>, 这个函数 在 db 初始化和文件打开的时候调用，清楚掉旧的文件。<ol><li>日志文件: prev_log_number 是一个废弃的字段. log_number 会被内存 compaction 推高，大于它才会被回收.</li><li>SST(.sst, .ldb) 文件: 不是 pending<em>outputs</em> 且不存在于 VersionSet 所有版本引用的文件中的文件。. (还记得我们的 <code>pending_outputs_</code> 吗，刚刚几行提到的)</li></ol></li><li>都写完就结束啦</li></ol><h3 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h3><p>Memtable Compaction 应该是最简单的 Compaction 了。下面讲讲剩下的。这些 Compaction 往往涉及从某层的某个 memtable 开始，然后扩大范围，最后 Compaction.</p><p>再回到 <code>DBImpl::BackgroundCompaction</code>:</p><ol><li><code>VersionSet::PickCompaction</code> 来挑选 Compaction，它会选出对应的 Seek Compaction 和 Range Compaction. 还记得我们在上面 <code>8</code> 提到的 Compaction Score 吗？Size Compaction 就是靠这个 Score 来选出 Compaction 的 <strong>level</strong> 和 <strong>起点 SST</strong> 的。<ol><li>Compaction 会计算出一个 Compaction Score, score 最大的是下一个 size compaction 的目标。</li><li>这里还有个 <code>compaction_pointer_</code> 这个是轮转的。上次这一层 Compaction 到哪，下次就从这个 <code>pointer</code> 开始了</li></ol></li><li>如果是 Level0 到下层的 Compaction，这里需要把 L0 中，key 重复的一起 Compaction 掉。<ol><li>这里调用了 <code>Version::GetOverlappingInputs</code>, 这个函数做的很粗糙，对 L0 就不停扩大 L0 范围。感觉很不优雅</li></ol></li><li><code>VersionSet::SetupOtherInputs</code> 处理本层和下一层的其余输入 SST：<ol><li><code>AddBoundaryInputs</code> 再次添加<strong>来源层</strong>的 inputs。这是说，对于 SST (实际上 L0 层应该不会出现这个问题），写入比 <strong>起点 SST</strong> 早的文件捞出来一起 Compaction 掉，否则就会出现同一个 key，上层比下层新的 case.</li><li>根据目标层的所有 SST，拿到它最小的、最大的 <code>InternalKey</code>. 然后再调用 <code>Version::GetOverlappingInputs</code> 去 <strong>下一层</strong> (可能不是目标层哦)，找到范围对应的 SST。然后再和 3.1 一样走一次 <code>AddBoundaryInputs</code>.</li><li>现在，<strong>来源层</strong> 和 <strong>来源层 + 1</strong> 的 SST 文件数量没有超过 <code>ExpandedCompactionByteSizeLimit(options_)</code> 的话，还可以从来源层再捞一把和下层的边界有交集的数据…</li><li>把 <strong>来源层 + 2</strong> 范围重合的文件也计算一遍。</li><li>给 <strong>来源层</strong> 和 <strong>来源层 + 1</strong> 设置 Compaction Pointer （记得 1.2 不）</li></ol></li><li>如果来源层 + 1 没有重叠，来源层只有一个文件，可以 <code>Compaction::IsTrivialMove</code> 看出来, 然后直接推到下层。</li><li>(4) 不成功的情况下，调用 <code>DBImpl::DoCompactionWork</code> 来 Compaction. 他可能输出多个 SST，所以搞了个 <code>DBImpl::CompactionState</code> 来维护状态。<ol><li>找到 <code>DBImpl::snapshots_</code>, 拿到最老读者的 seq id. 这个 seq id 之前的记录是不能删除的。</li><li>如果有 <code>imm_</code> ，放锁，然后优先 Compact Memtable. 这是为了不影响正常写入</li><li>如果这次写的 SST 太大了，先输出，然后换个 SST 写</li><li>下面是正式写数据的流程，这里要决定数据是不是要保留。大致逻辑是，需要不影响 Compaction 的正确性。总的来说，这个删除的策略感觉是非常保守的。</li></ol></li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Handle key/value, add to state, etc.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// 每次保留一个 current_user_key. 遇到第二次</span></span><br><span class="line"><span class="type">bool</span> drop = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">if</span> (!<span class="built_in">ParseInternalKey</span>(key, &amp;ikey)) &#123;</span><br><span class="line">  <span class="comment">// Do not hide error keys</span></span><br><span class="line">  current_user_key.<span class="built_in">clear</span>();</span><br><span class="line">  has_current_user_key = <span class="literal">false</span>;</span><br><span class="line">  last_sequence_for_key = kMaxSequenceNumber;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (!has_current_user_key ||</span><br><span class="line">      <span class="built_in">user_comparator</span>()-&gt;<span class="built_in">Compare</span>(ikey.user_key, <span class="built_in">Slice</span>(current_user_key)) !=</span><br><span class="line">          <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// First occurrence of this user key</span></span><br><span class="line">    current_user_key.<span class="built_in">assign</span>(ikey.user_key.<span class="built_in">data</span>(), ikey.user_key.<span class="built_in">size</span>());</span><br><span class="line">    has_current_user_key = <span class="literal">true</span>;</span><br><span class="line">    last_sequence_for_key = kMaxSequenceNumber;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// key 保留情况处理.</span></span><br><span class="line">  <span class="keyword">if</span> (last_sequence_for_key &lt;= compact-&gt;smallest_snapshot) &#123;</span><br><span class="line">    <span class="comment">// Hidden by an newer entry for same user key</span></span><br><span class="line">    drop = <span class="literal">true</span>;  <span class="comment">// (A)</span></span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ikey.type == kTypeDeletion &amp;&amp;</span><br><span class="line">             ikey.sequence &lt;= compact-&gt;smallest_snapshot &amp;&amp;</span><br><span class="line">             compact-&gt;compaction-&gt;<span class="built_in">IsBaseLevelForKey</span>(ikey.user_key)) &#123;</span><br><span class="line">    <span class="comment">// Note(mwish): `IsBaseLevelForKey` 这个函数也太讨巧了，感觉不太好用...</span></span><br><span class="line">    <span class="comment">// 终于知道为什么要 Seek Compaction 了.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// For this user key:</span></span><br><span class="line">    <span class="comment">// (1) there is no data in higher levels</span></span><br><span class="line">    <span class="comment">// (2) data in lower levels will have larger sequence numbers</span></span><br><span class="line">    <span class="comment">// (3) data in layers that are being compacted here and have</span></span><br><span class="line">    <span class="comment">//     smaller sequence numbers will be dropped in the next</span></span><br><span class="line">    <span class="comment">//     few iterations of this loop (by rule (A) above).</span></span><br><span class="line">    <span class="comment">// Therefore this deletion marker is obsolete and can be dropped.</span></span><br><span class="line">    drop = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  last_sequence_for_key = ikey.sequence;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Compaction-和读"><a href="#Compaction-和读" class="headerlink" title="Compaction 和读"></a>Compaction 和读</h3><p>读取的逻辑在：<a href="https://zhuanlan.zhihu.com/p/372152739">https://zhuanlan.zhihu.com/p/372152739</a> 这里介绍过一些。</p><p>Memtable 和 LogSequence 已经介绍过了，这里介绍 SST 相关的。Compaction 不会直接删除文件，但是会 <code>RemoveObsoleteFiles</code>。对于读而言，如果哪个 snapshot 和 version 正在被读取，是不会被删掉的。</p><p>那我们考虑一个问题。有一个巨早拿到的 Snapshot, 过了很久之后被读取。这个时候拿到的 <code>Version</code> 是 <code>current</code>. 这个地方，怎么保证被删掉的文件数据还能读呢？这个是靠 Compaction 的时候，读到的 log_id 保证的。假如我们有一个很早的 snapshot, 它的 SST 会被删除，但是相关的记录是不会被删除的。</p><hr><ul><li>LevelDB Log: WAL of LSMTree C0  <a href="https://zhuanlan.zhihu.com/p/145178907">https://zhuanlan.zhihu.com/p/145178907</a></li><li>LevelDB Put: How it Batch <a href="https://zhuanlan.zhihu.com/p/143309915">https://zhuanlan.zhihu.com/p/143309915</a></li><li>LevelDB Memtable <a href="https://zhuanlan.zhihu.com/p/145403978">https://zhuanlan.zhihu.com/p/145403978</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Note on System Design Interview: Part2</title>
      <link href="/2021/05/24/Note-on-System-Design-Interview-Part2/"/>
      <url>/2021/05/24/Note-on-System-Design-Interview-Part2/</url>
      
        <content type="html"><![CDATA[<h3 id="Notification-System"><a href="#Notification-System" class="headerlink" title="Notification System"></a>Notification System</h3><p>这里应该还可以包括 chrome notification:</p><p><img src="https://image.mwish.me/blog-image/A7653474-34AE-4C7E-8E99-3638D3995E23.png" alt="A7653474-34AE-4C7E-8E99-3638D3995E23"></p><p>这里的要点是：</p><ol><li>有一个软实时更新的系统，不要求实时发送，不过也最好不要把推送给用户的内容晚了太多</li><li>能够 scale, 并推给不同类型的端，比如 iOS, iPad 等</li></ol><p>这里应该要设置一对多的 user: device 表，作为用户存储信息的表，然后可以准备一个 cache.</p><p>有这个信息后，如果收到一条消息，可能要慢慢把消息丢给 user 的各个 device 或者一些 device, 这里可以用 mq 来解耦这个过程：</p><p><img src="https://image.mwish.me/blog-image/FADB51E3-4EC9-42B0-8B4F-BADE93037F33.png" alt="FADB51E3-4EC9-42B0-8B4F-BADE93037F33"></p><p>这里 worker group 需要 talk from queue, 然后开始消费。这里因为消息不能丢，所以也要持久化处理情况：</p><p><img src="https://image.mwish.me/blog-image/07544A0D-700E-4A9D-9CA3-77AADD3D70F4.png" alt="07544A0D-700E-4A9D-9CA3-77AADD3D70F4"></p><p>当然，这里还要注意 rate limit, retry 和 queue 状态的监控。</p><h3 id="News-Feed-System"><a href="#News-Feed-System" class="headerlink" title="News Feed System"></a>News Feed System</h3><blockquote><p>News feed is the constantly updating list of stories in the middle of your home page. News Feed includes status updates, photos, videos, links, app activity, and likes from people, pages, and groups that you follow on Facebook</p></blockquote><p>又叫喂猪系统。</p><p>这里提供了几个 api:</p><ol><li>Post service (包含 post cache): 正常发文/读文章的服务。</li><li>Fanout service: push new content to friends’ news feed. Newsfeed data is stored in the cache for fast retrieval. (感觉还是要写到 SQL/NoSQL 里面的，得防止丢数据)</li><li>Notification service: 我们上一节吹逼做的那个</li></ol><p>用户发文的时候，可能要读扩散写扩散搞到 feed system 里面。给关注自己的人推消息。话说这个 ddia 应该讲了。这里可以只存 <code>&lt;post_id, user_id &gt;</code>, 然后找到 db 里头。</p><p><img src="https://image.mwish.me/blog-image/6F30A791-DB86-4267-A099-C0A3134C3158.png" alt="6F30A791-DB86-4267-A099-C0A3134C3158"></p><p>上述是写入的 pipeline. 查询的话就是把大 v 的文章和自己 feed 里面的 merge 一下就行：</p><p><img src="https://image.mwish.me/blog-image/9AE9A19F-6B93-442D-B83E-7CABE3FD9028.png" alt="9AE9A19F-6B93-442D-B83E-7CABE3FD9028"></p><p>话说这里还列了 cache type, 其实挺有意义的：</p><p><img src="https://image.mwish.me/blog-image/50343781-12BD-409F-ACAB-9100CBC61263.png" alt="50343781-12BD-409F-ACAB-9100CBC61263"></p><p>还可以参考：</p><ol><li><a href="https://www.zhihu.com/question/20690652">https://www.zhihu.com/question/20690652</a></li><li><a href="https://developer.aliyun.com/article/224132">https://developer.aliyun.com/article/224132</a></li><li><a href="https://www.facebook.com/help/327131014036297/">https://www.facebook.com/help/327131014036297/</a></li></ol><h3 id="Chat-System"><a href="#Chat-System" class="headerlink" title="Chat System"></a>Chat System</h3><p>Chat System 的要点是：</p><ol><li>可能需要保持状态、长连接（这里使用了 ws 实现）</li><li>网络不好的时候，避免频繁的状态变化</li><li>对话肯定要持久化，但是不同的用户可以连接在不同的机器上</li><li>也有些东西不需要长连接</li></ol><p>这里登陆之类的使用了无状态的 api, 然后用 ws 维护连接。登录状态用心跳包维护，避免过度 reset。</p><p>人与人聊天，人与组聊天使用序列的 id, 这个因为可以 sharding 所以代价不高。一条消息，先持久化存储，然后 fanout 给对话对象（或者 notification system）</p><p><img src="https://image.mwish.me/blog-image/8C0B2A00-B661-4CF9-9C37-F633AE934756.png" alt="8C0B2A00-B661-4CF9-9C37-F633AE934756"></p><p>这里端需要维护自己的 <code>max_seq_id</code>, 然后重新登录的时候，能够拉出一批数据。</p><p>而群聊可以用推模式或者拉模式来实现。对于小群推就推了，否则也可以拉。</p><p>登录推送(QQ 微信没有，steam 有)可以 fanout 类似的逻辑来维护</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Note on System Design Interview</title>
      <link href="/2021/05/22/Note-on-System-Design-Interview/"/>
      <url>/2021/05/22/Note-on-System-Design-Interview/</url>
      
        <content type="html"><![CDATA[<p>System Design Interview 介绍了 system design 的一些面试题，也介绍了分布式系统上的一些 building blocks. 这本书介绍了一下这些内容。</p><p>这本书逻辑上大概分为两部分：</p><ol><li>介绍分布式应用的 building blocks</li><li>介绍一些分布式系统常用组件的实现方式。</li><li>介绍一些大型 web 应用的架构。</li></ol><h2 id="Part1-building-blocks"><a href="#Part1-building-blocks" class="headerlink" title="Part1 building blocks"></a>Part1 building blocks</h2><p>这里的客户端/user 一般指的是 web 或者是移动端的 app. 这些通过 dns 来拿到服务器的 ip, 然后访问服务器。</p><p>同时，数据存储通常会丢到某个 db 上。按需求选择 MySQL MongoDB 这些选型。</p><p>说句实话一般网络 app 这些东西就够了。但是大型应用这样就等死吧。</p><h3 id="Load-balancer"><a href="#Load-balancer" class="headerlink" title="Load balancer"></a>Load balancer</h3><p>一般需要负载均衡来处理一些问题，nginx, haproxy, envoy 都有这些功能。</p><p>（这里注意一下有个 L4/L7 负载均衡的区别）</p><h3 id="Database-application"><a href="#Database-application" class="headerlink" title="Database application"></a>Database application</h3><p>无论是 master/slave 然后挂个什么方式，可以做 db 的主从备份、在业务测切分 db。</p><p>当然也可以用分布式的 db, 不过有的时候你还是要 manage 一些数据分布之类的问题的：</p><p><img src="https://image.mwish.me/blog-image/223BD7B0-1EE7-402E-9F6C-EDD9EA0A8C7B.png" alt="223BD7B0-1EE7-402E-9F6C-EDD9EA0A8C7B"></p><h3 id="cache"><a href="#cache" class="headerlink" title="cache"></a>cache</h3><p>没有需求上缓存属于折磨自己：<a href="https://www.zhihu.com/question/383926405">https://www.zhihu.com/question/383926405</a></p><p>但是有需求的话，缓存能够起飞。</p><p>缓存的架构也很复杂，我之前读过一篇 fb 的论文：</p><ol><li><a href="https://zhuanlan.zhihu.com/p/194347153">https://zhuanlan.zhihu.com/p/194347153</a></li><li><a href="https://zhuanlan.zhihu.com/p/310697650">https://zhuanlan.zhihu.com/p/310697650</a></li></ol><p>然后还要区分下 write through cache/write aside cache.</p><p>这本书提了一下使用 cache 需要提前设计的几件事：</p><ol><li>Eviction policy</li><li>mitigating failure</li><li>consistency</li><li>Expiration policy</li><li>Decide when to use cache</li></ol><h3 id="CDN"><a href="#CDN" class="headerlink" title="CDN"></a>CDN</h3><p>CDN 从一个类似 amazon s3 的服务拉内容（当然，直播的话会更复杂）</p><ol><li>cost (真实…)</li><li>cache expiry</li><li>CDN fallback: CDN 挂了怎么办</li><li>Invalidating files</li></ol><h3 id="Stateful-Stateless"><a href="#Stateful-Stateless" class="headerlink" title="Stateful/Stateless"></a>Stateful/Stateless</h3><p>Stateless 的通常可以直接起飞，快乐扩容，但是很多时候也需要访问 stateful 的 db 这类的资源，访问 shared storage 这类。</p><h3 id="Data-Centers"><a href="#Data-Centers" class="headerlink" title="Data Centers"></a>Data Centers</h3><p>很多时候，业务部署都需要多个 DC，一个地方机房过热，可能受灾就有多机器全挂了。</p><p>DC 需要考虑流量调度、数据同步、测试，但也给了系统更好的稳定性。</p><p>对于基础组建而言，多数据中心同步还是一个很麻烦的问题，因为 latency 高，流量贵。</p><h3 id="Message-queue"><a href="#Message-queue" class="headerlink" title="Message queue"></a>Message queue</h3><p>对业务而言，mq 意味着某种形式的解耦。用户可能希望希望：</p><ol><li>丢就丢了，随便你怎么处理</li><li>希望 exactly once 之类的语义。</li></ol><h3 id="Logging-metrics-automation"><a href="#Logging-metrics-automation" class="headerlink" title="Logging, metrics, automation"></a>Logging, metrics, automation</h3><p>查过问题懂得都懂。虽然我不是很懂 logging…</p><h3 id="wrap-up"><a href="#wrap-up" class="headerlink" title="wrap up"></a>wrap up</h3><p><img src="https://image.mwish.me/blog-image/38114998F5B912A9F3097D35DCCBDC4A.png" alt="38114998F5B912A9F3097D35DCCBDC4A"></p><h3 id="量级估计"><a href="#量级估计" class="headerlink" title="量级估计"></a>量级估计</h3><p>这个可以参考 every number programmers should know, 又一个每年都会更新的网站，可以找找看。</p><p>然后知道 MB GB PB 有多大（我需要天天算这个哈哈哈）</p><p><img src="https://image.mwish.me/blog-image/9C0CB68D373EF6E629488FD1969F8809.png" alt="9C0CB68D373EF6E629488FD1969F8809"></p><p>这里还有对 QPS 和 Peek QPS 的估算（实际上我感觉真实情况还是要看统计数据什么的）</p><h2 id="Part2-组件和实现"><a href="#Part2-组件和实现" class="headerlink" title="Part2 组件和实现"></a>Part2 组件和实现</h2><h3 id="Rate-Limiter"><a href="#Rate-Limiter" class="headerlink" title="Rate Limiter"></a>Rate Limiter</h3><p>为了不发现暴写就等死，可以做一些组件上的限流。</p><p>此外，业务本身也会自己估一个 QPS，这个虽然比较粗略，但是也能做一个基本的限制。限流在这方面可以给自己系统一个很好的保障。</p><p>这个可以以客户端的形式提供，也可以做成一个 api gateway，在 QPS 过高的时候返回一个 HTTP 429。</p><p>RateLimit 有下面的算法</p><ul><li>Token bucket</li><li>Leaking bucket</li><li>Fixed window counter</li><li>Sliding window log</li><li>Sliding window counter</li></ul><p>我这里搓了一个简单的单机 <code>leaky_bucket.rs</code> : <a href="https://github.com/mapleFU/md-snippets/blob/master/components/ratelimiter/src/leaky_bucket.rs#L36">https://github.com/mapleFU/md-snippets/blob/master/components/ratelimiter/src/leaky_bucket.rs#L36</a></p><p>参考了：<a href="https://github.com/uber-go/ratelimit/blob/main/limiter_atomic.go">https://github.com/uber-go/ratelimit/blob/main/limiter_atomic.go</a></p><p>实际的数据可以存储在 Redis 这样的地方，让这个组件能够 scale. 同时，为了处理 Redis 这方面的并发操作，可以使用 lua script 或者 sorted sets data structure。</p><h3 id="Consisteny-Hashing"><a href="#Consisteny-Hashing" class="headerlink" title="Consisteny Hashing"></a>Consisteny Hashing</h3><p>这节内容没啥讲的，基本和 Dynamo 那篇论文差不多。和 Chord 这篇论文的不一样. 这个是应该假定有 proxy 的</p><p>consistent hashing 我推荐再看看 Jump Consistent Hashing, MagLev. 这两个都是 Google 提出来的。</p><p><a href="https://writings.sh/post/consistent-hashing-algorithms-part-2-consistent-hash-ring">https://writings.sh/post/consistent-hashing-algorithms-part-2-consistent-hash-ring</a></p><p>上面这篇博客是我找到的最好的相关博客。</p><h3 id="Key-Value-Storage"><a href="#Key-Value-Storage" class="headerlink" title="Key-Value Storage"></a>Key-Value Storage</h3><p>这篇也基本是 Dynamo. 我觉得有兴趣可以看看 Spanner </p><p><img src="https://image.mwish.me/blog-image/B6E41610-821B-41E0-BE81-092E3179B667.png" alt="B6E41610-821B-41E0-BE81-092E3179B667"></p><p>这个 cheatsheet 倒是挺有意思的，看完 dynamo 论文可以回头看一眼。</p><h3 id="Unique-ID-Generator"><a href="#Unique-ID-Generator" class="headerlink" title="Unique ID Generator"></a>Unique ID Generator</h3><p>这个其实也看对 Unique ID 的需求的：</p><ol><li>是否要强有序？或者比较弱的有序？</li><li>你的 id 需要多少位？</li></ol><p>下面有几种方式：</p><p>一：走 DB, 然后 db 可能可以多个 master. 比方说有 k 台机器，然后每台机器递增，然后对外提供就是：如果来自第一台就是 1, 1+k, 1 + 2k… 如此类推。</p><p>这种方式在多 DC 的环境下不太好处理，同时服务器增加的时候，不是很好处理。</p><p>然后其实也可以参考美团的 leaf: <a href="https://tech.meituan.com/2019/03/07/open-source-project-leaf.html">https://tech.meituan.com/2019/03/07/open-source-project-leaf.html</a></p><p>二：UUID</p><blockquote><p>A UUID is another easy way to obtain unique IDs. UUID is a 128-bit number used to identify information in computer systems. </p></blockquote><p>UUID 有几种不同的生成方法，比如 UUID V1 V2 V3 V4. 通常我们可以用 v4 来高一些随机生成</p><p>当然，uuid 也可以根据别的一些信息来生成。</p><p>三：Ticket Server</p><p>用 Etcd 之类的方式来发号，这个比较类似 PingCAP 的 PD 了。</p><p>四：twitter snowflake</p><p>这个是根据机器 ID 和时间来发号的。注意这个时间应该采用递增的时间，而不允许回退。</p><p>我写了个简单的实现：<a href="https://github.com/mapleFU/md-snippets/tree/master/components/snowflake">https://github.com/mapleFU/md-snippets/tree/master/components/snowflake</a></p><h3 id="URL-Shortener"><a href="#URL-Shortener" class="headerlink" title="URL Shortener"></a>URL Shortener</h3><p>URL Shortener 通常有要求是：</p><ol><li>不能重复。</li><li>human readable</li></ol><p>这个内容也可以生成验证码。然后存到 db 里面，因为要做去重。这里 db 可以糊一层 cache，但是感觉 bloom 不太好搞，因为 down 掉了感觉恢复起来不晓得咋搞。</p><p>这里我也搓了一遍（不过就只有算法，DB 交互只写了个接口）：<a href="https://github.com/mapleFU/md-snippets/tree/master/components/url_shortener">https://github.com/mapleFU/md-snippets/tree/master/components/url_shortener</a></p><h2 id="Part3-Systems"><a href="#Part3-Systems" class="headerlink" title="Part3: Systems"></a>Part3: Systems</h2><h3 id="Web-Crawler"><a href="#Web-Crawler" class="headerlink" title="Web Crawler"></a>Web Crawler</h3><p>Web crawler 需要：</p><ol><li>给定一些 Seed, 然后从这些网页开始拉</li><li>能够拉取 robot.txt 遵纪守法；然后要有一定反爬能力</li><li>需要能够解析网页，找到对应的信息</li><li>按照 BFS/DFS 的策略，从已经爬到的链接里拿到后面的目标</li><li>防止无限递归的网址/反爬策略把自己搞傻了</li><li>对网络的访问不要过于频繁，要限流</li><li>要能够合理处理 timeout</li><li>但同时，需要有分布式的爬取能力</li></ol><p><img src="https://image.mwish.me/blog-image/806C279E-1089-4799-A21F-BA71B70FC7F6.png" alt="806C279E-1089-4799-A21F-BA71B70FC7F6"><img src="/Users/bytedance/Downloads/0624F981-1F6A-4549-A007-81CACA2D4AEE.png" alt="0624F981-1F6A-4549-A007-81CACA2D4AEE"></p><p>这里我觉得这个架构还是有点像 Scrapy 的，看了一下 scrapy：</p><p><img src="https://image.mwish.me/blog-image/scrapy_architecture_02.png" alt="scrapy_architecture_02"></p><p>这里有一些中间件，就是上图的 extension model. </p><p>Scheduler 可能可以有一个 Redis 后端，用来调度下一个应该抓的 URL, 然后这个发给 downloader, 走逻辑下载，再回到 engine, 丢给 spiders 的中间件做一些扩展处理，最后把内容丢给 item pipeline.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LevelDB: Read path</title>
      <link href="/2021/05/13/LevelDB-Read-path/"/>
      <url>/2021/05/13/LevelDB-Read-path/</url>
      
        <content type="html"><![CDATA[<p>鉴于网上讲 LevelDB 代码的文章没有一万也有一千了，本文肯定比他们还烂。所以这篇文章就简单讲讲 LevelDB 的读流程。</p><p>我们对这个的事先印象是：</p><ol><li>用户 <code>Get</code> 一个 key</li><li>从 memtable 里面找这个 <code>key</code> . memtable 里面，key 在写入的时候，被 <code>WriteBatch::Put</code> 变成了 <code>&lt;写类型, key 长度, key 内容, value 长度, value 内容&gt;</code> 的字符串，然后在 <code>MemTableInserter::Put</code> 和 <code>Memtable::Add</code> 里面变成了 <code>&lt;sequence, type, key 长度, key 内容&gt;</code> <code>&lt;value 长度, value 内容&gt;</code> 的 <code>InternalKey</code> 和 <code>value</code></li><li>如果在正在写入的 memtable 和 immutable memtable 都没有，那么它回到 SST 里面去查找。</li></ol><p>此外，读可以拿到 iterator 和 snapshot, 并且用 iterator 和 snapshot 来读：</p><p>leveldb 可以拿到 iterator 读，也可以拿到 snapshot 去读，注意这里还是有生命周期：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">leveldb::Iterator* it = db-&gt;<span class="built_in">NewIterator</span>(leveldb::<span class="built_in">ReadOptions</span>());</span><br><span class="line"><span class="keyword">for</span> (it-&gt;<span class="built_in">SeekToFirst</span>(); it-&gt;<span class="built_in">Valid</span>(); it-&gt;<span class="built_in">Next</span>()) &#123;</span><br><span class="line">  cout &lt;&lt; it-&gt;<span class="built_in">key</span>().<span class="built_in">ToString</span>() &lt;&lt; <span class="string">&quot;: &quot;</span>  &lt;&lt; it-&gt;<span class="built_in">value</span>().<span class="built_in">ToString</span>() &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">assert</span>(it-&gt;<span class="built_in">status</span>().<span class="built_in">ok</span>());  <span class="comment">// Check for any errors found during the scan</span></span><br><span class="line"><span class="keyword">delete</span> it;</span><br></pre></td></tr></table></figure><p>和 snapshot</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">leveldb::ReadOptions options;</span><br><span class="line">options.snapshot = db-&gt;<span class="built_in">GetSnapshot</span>();</span><br><span class="line">... apply some updates to db ...</span><br><span class="line">leveldb::Iterator* iter = db-&gt;<span class="built_in">NewIterator</span>(options);</span><br><span class="line">... read <span class="keyword">using</span> iter to view the state when the snapshot was created ...</span><br><span class="line"><span class="keyword">delete</span> iter;</span><br><span class="line">db-&gt;<span class="built_in">ReleaseSnapshot</span>(options.snapshot);</span><br></pre></td></tr></table></figure><p>LevelDB 内部大量使用 <code>slice</code> 类型，表示“没有所有权的字符串”。这个有点类似 <code>std::string_view</code>, 不过功能弱不少。</p><p>那么，我们今天要给上面的流程填充一些细节：</p><ol><li>读文件相关的 system api</li><li>LevelDB 对 SST 相关的读处理：<ol><li>SST 文件的读取</li><li>Block Cache / mmap</li><li>Iterator 类型</li></ol></li><li>LevelDB 读相关的内容回收</li></ol><h3 id="System-API-amp-amp-env"><a href="#System-API-amp-amp-env" class="headerlink" title="System API &amp;&amp; env"></a>System API &amp;&amp; env</h3><p>env 定义在文件的 <code>util/env.h</code> 和 <code>util/env_&#123;平台&#125;.cc</code> 下面, 定义了这个平台默认的行为。和文件相关的内容全部封装在这个接口里。</p><p>这里定义了：</p><p> <code>RandomAccessFile</code> 随机读的文件，用 <code>pread</code> 或者 <code>mmap</code> 来实现。提供一个带 <code>offset</code> 和 <code>size</code> 的 read 接口；需要注意的是，这里使用了 Limit, 限制数量为 1000 的 <code>mmap</code> 的 <code>RandomAccessFile</code> （这个配置参数是可以修改的）。作者认为：</p><ol><li>mmap 本身可以在 random access 的情况下优化读（感觉这是因为 LevelDB 本身 Block Cache 使用的 LRU 策略比较简单）</li><li>Mmap 本身限制在了 1000 个：作者认为这样可以优化性能。我看了一下相关的讨论，作者认为 leveldb 本身存储的是小文件，而 compaction 过多导致系统 <code>RSS</code> 会变得巨大。所以作者把这个量限制在了 1000 个</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A file abstraction for randomly reading the contents of a file.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LEVELDB_EXPORT</span> RandomAccessFile &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">RandomAccessFile</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">RandomAccessFile</span>(<span class="type">const</span> RandomAccessFile&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  RandomAccessFile&amp; <span class="keyword">operator</span>=(<span class="type">const</span> RandomAccessFile&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">RandomAccessFile</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Read up to &quot;n&quot; bytes from the file starting at &quot;offset&quot;.</span></span><br><span class="line">  <span class="comment">// &quot;scratch[0..n-1]&quot; may be written by this routine.  Sets &quot;*result&quot;</span></span><br><span class="line">  <span class="comment">// to the data that was read (including if fewer than &quot;n&quot; bytes were</span></span><br><span class="line">  <span class="comment">// successfully read).  May set &quot;*result&quot; to point at data in</span></span><br><span class="line">  <span class="comment">// &quot;scratch[0..n-1]&quot;, so &quot;scratch[0..n-1]&quot; must be live when</span></span><br><span class="line">  <span class="comment">// &quot;*result&quot; is used.  If an error was encountered, returns a non-OK</span></span><br><span class="line">  <span class="comment">// status.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Safe for concurrent use by multiple threads.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Status <span class="title">Read</span><span class="params">(<span class="type">uint64_t</span> offset, <span class="type">size_t</span> n, Slice* result,</span></span></span><br><span class="line"><span class="params"><span class="function">                      <span class="type">char</span>* scratch)</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>LevelDB 调用 <code>NewRandomAccessFile</code> 的时候，会先尝试走 <code>PosixMmapReadableFile</code> ，没有就 fallback 到 <code>PosixRandomAccessFile</code>.</p><p>LevelDB 给整个需要的链路都加入了 <code>Env*</code>, 来支持各个平台系统方面的调用</p><h3 id="Block-Read"><a href="#Block-Read" class="headerlink" title="Block Read"></a>Block Read</h3><p>LevelDB 的数据是以 SST 组织的，SST 内切分成了不同的 block, 以便提供 Index/CRC/缓存。Block Size 和性能有比较大的关系。LevelDB 文档里面提示：</p><ol><li>Scan 居多的话，那么 Block Size 可以设置小一点。</li><li>Point Get 居多的话，Block Size 可以设大一点。</li></ol><p>RocksDB 文档也有对应内容。</p><p>LevelDB 用户可以配置 BlockCache, 而且一定有(不用配置) TableCache. 关于 LevelDB 的 Cache, 可以简单看看：</p><p><a href="https://zhuanlan.zhihu.com/p/363382898">https://zhuanlan.zhihu.com/p/363382898</a></p><p>前者是 Block 内容的缓存，后者是 SST 的元信息的缓存。简单的说，可以通过后者索引到前者。</p><p>Block cache: <code>options.block_cache</code> 设置读文件的时候用的 block cache, 当执行一些不希望用到 block cache 的操作的时候，可以使用 <code>options.fill_cache = false</code> 的配置。</p><p>那么回到程序中，具体读取文件的时候，程序会从 <code>TableCache::Get</code> 来从元信息定位到 Block 相关的内容。然后调用 <code>Table::BlockReader</code> 和 <code>ReadBlock</code>. 在 ReadBlock 的时候，程序对上述的 <code>mmap</code> 和 用<code>pread</code>的文件作出了区分：</p><ol><li>如果没有提供 <code>block_cache</code>, 那么不会存 block cache, 但是 <code>mmap</code> 仍然可能使用</li><li>如果提供了 <code>block_cache</code>:<ol><li>如果是 <code>mmap</code> 的文件，不会走 Block cache</li><li>否则把内容缓存到 block cache 里，使用的 charge 是 compression 之前的 size.</li></ol></li></ol><h3 id="Iterators"><a href="#Iterators" class="headerlink" title="Iterators"></a>Iterators</h3><p><code>Iterator</code> 接口定义在 <code>include/leveldb/iterator.h</code>, 是 LevelDB 里面一个很包罗万象的类型。跟 Iterator 相关的类型有：</p><ol><li><code>DBIter</code>, 这个接口提供的 <code>key()</code> <code>value()</code> 都是 user 的 key, value, 提供给上层用户使用。</li><li><code>MemTableIterator</code>: 给 <code>MemTable::Table::Iterator</code> 封装了一层，后者的 <code>key()</code> 包含了 <code>InternalKey</code> 和 <code>value</code> , 这个 <code>MemTableIterator</code> 对外提供 <code>InternalKey</code> 和 <code>value</code></li><li><code>Block::Iter</code>: 这个类型是给单个 <code>data block</code>  和 <code>index block</code>准备的（leveldb 还有一些存放别的元信息的 block）: 会走上一节我们提到的 <code>ReadBlock</code> 相关的接口，从 Block 里面读取 <code>InternalKey</code> 和 <code>value</code><ol><li>这里 Data Block 存放数据，index block 存放对 data block 的索引。</li></ol></li></ol><p><img src="static/2021-05-14/C32EA624-79EA-43BD-8E24-1D018E3212A3.png" alt="C32EA624-79EA-43BD-8E24-1D018E3212A3"></p><p>如果说上面三个 <code>Iterator</code> 还比较清晰，那我们可以看看下面的一个奇怪的 Iterator:</p><ol><li><code>Version::LevelFileNumIterator</code>: 这个迭代器很奇怪（你马上就知道为什么了），它丢出的信息是 Iterator 的元信息(不是用户的 <code>key</code>, <code>value</code>, 而是 “文件的 &lt;最大key&gt;” 和 <code>&lt;(文件号, 文件大小)&gt;</code></li></ol><p>下面，是时候组织起这些 Iterator 了：</p><p><code>TwoLevelIterator</code> : 重点来了，难得来了！<code>TwoLevelIterator</code> 提供了一种“两级” 的抽象：一个提供索引，一个提供数据。提供数据的结束之后，提供索引的去找下一项，具体使用的地方有两个：</p><ol><li><code>Table::NewIterator</code>: Table 创建的是 TwoLevelIterator, 首先是 IndexBlock 的 iterator, 然后是对应的 block reader. 实际上这里就是拿到 index 信息，然后能够读到 block 的信息。</li><li>读某一层的数据。index_iter 是单层文件元信息的迭代器 <code>Version::LevelFileNumIterator</code>，BlockFunction 是 (1) 中的整合。见 <code>Version::NewConcatenatingIterator</code>.</li></ol><p>怎么样，是不是连起来了～</p><p>再来一个：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Iterator* <span class="title">NewMergingIterator</span><span class="params">(<span class="type">const</span> Comparator* comparator, Iterator** children,</span></span></span><br><span class="line"><span class="params"><span class="function">                             <span class="type">int</span> n)</span></span>;</span><br></pre></td></tr></table></figure><p>这个地方会创建一个 <code>MergingIterator</code>, 合并所有的 Iterator, 找到 <code>key</code> 最小的一个。需要注意的是，目前使用的时候，这里 <code>key</code> 最小指的还是 <code>InternalKey</code>.</p><p>此外，还要注意 <code>RegisterCleanup</code>, 这个函数是 <code>Iterator</code> 清理自身资源用的。</p><h3 id="Version-amp-amp-snapshot"><a href="#Version-amp-amp-snapshot" class="headerlink" title="Version &amp;&amp; snapshot"></a>Version &amp;&amp; snapshot</h3><p>我们上面提供了各种各样的 <code>Iterator</code>, 这下我们读的时候可有工具了。但是这里需要注意的是，读的时候还可以选择一个 snapshot, 然后，还需要考虑读的时候，中途发生了 compaction 要怎么处理。</p><p>LevelDB 提供了一个 <code>sequence_id</code> 来指定顺序。它定义的是读相对于写的偏序, 他存储在 <code>VersionSet</code> 里：</p><ol><li>写会推高 <code>last_sequence_</code>, 而且是一次性推高很多，等同于写入的 batch</li><li>读会拿到 <code>last_sequence_</code> , 并根据这个值来决定自己读到什么。</li></ol><p>实际上，即使不外部创建 Snapshot, 内部也会拿到一个最近的 sequence id, 来决定这个时候的行为。</p><p>LevelDB 拿到了这个 <code>sequence_id</code> 之后, 需要接下来决定自己要读什么。然后它会找到最新的 <code>Version</code>. <code>Version</code> 是 LevelDB 中 SST 文件布局的一个版本，有任何的 compaction 发生，都会生成新的 Version。那么为什么它每次都会找到新的 Version, 而不是根据 snapshot 来找版本链呢？（其实这个地方我还没仔细考虑过，记个 TODO….）</p><p>拿到 Version 之后，单个 Version 里面，内容是不变的。Version 可以提供每层的 <code>Iterator</code>, 拿到这些就可以构建 <code>MergingIterator</code> 去读啦~</p><h3 id="资源回收"><a href="#资源回收" class="headerlink" title="资源回收"></a>资源回收</h3><p>实际上，LevelDB 大部分采用了读者来回收内存的模式，同时使用了很多引用计数。这些引用计数通常都不是线程安全的。</p><p>很多类提供了 <code>Ref()</code> <code>Unref()</code> 的方法。感觉 LevelDB 最好提供个侵入式智能指针（虽然它没有）。</p><p>那么在读的时候，<code>Version</code>, <code>Memtable</code> 对象会被 <code>Ref()</code> 一下。然后，有的时候是手动<code>Unref</code>, 有的时候，是给 <code>Iterator</code> 使用了 <code>RegisterCleanup</code>，让它们在正确的时间 <code>Unref</code>. </p><h3 id="对-Compaction-的影响"><a href="#对-Compaction-的影响" class="headerlink" title="对 Compaction 的影响"></a>对 Compaction 的影响</h3><p>读行为会启发式的导致 seek compaction. 这个可以看到 <code>DBIter</code> 和  <code>Stats</code>相关的代码，有两种更新方式：</p><ol><li>点查的时候，如果这层 SST 没找到对应的内容（同时 bloom filter 也没有回避这次读），而下层有，则记录</li><li>seek 的时候，会有一个采样算法，记录</li></ol><p>当记录到达一定值的时候，leveldb 认为应该错峰的去 compaction，这个叫 Seek Compaction.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Notes on &lt;LSM-based Storage Techniques: A Survey&gt;: Part 2</title>
      <link href="/2021/04/23/Notes-on-LSM-based-Storage-Techniques-A-Survey-Part-2/"/>
      <url>/2021/04/23/Notes-on-LSM-based-Storage-Techniques-A-Survey-Part-2/</url>
      
        <content type="html"><![CDATA[<h2 id="LSM-Tree-improvements"><a href="#LSM-Tree-improvements" class="headerlink" title="LSM-Tree improvements"></a>LSM-Tree improvements</h2><p>尽管现在 LSM-Tree 被用到了多种 NoSQL 中，但是原始的 LSM-Tree 仍然有下面的缺点：</p><ol><li>写放大：LSM-Tree 能比 in-place update 提供更好的写性能，但是 LSM-Tree 的 compaction 会造成不小的写放大。如我们之前分析的, Leveled Compaction 每层每个 key 需要写 T 次。而多层又会乘以另一个系数。这种写放大不仅会限制写性能，也会很快速的把 SSD 盘写坏</li><li>Compaction 操作：LSM-Tree 有很重的逻辑都和 compaction 有关，所以要非常谨慎的实现 compaction 操作。此外，compaction 可能会造成 Write Stall，或者是查询的时候，因为产生了不在 cache 中的新文件，对新文件有 cache miss.</li><li>硬件：原始的 LSM-Tree 是以 HDD 为 C0 外其他组件存储来实现的，它的顺序写入比随机写入快很多。现在我们进入了大内存、SSD/NVME、NVM 的时代。为了适应这些新的存储，LSM-Tree 需要对应的改进</li><li>特殊的 workloads: 可能有一些特殊的负载，可以需要特殊的 LSM-Tree，提供能好的性能，比如 append 占绝大多数的 （mq 中），或者 key-value 小的，能全部装在 memory 中的… 对于这些可以设置特殊的结构</li><li>secondary indexing: 对于 LSM-Tree，大部分基本实现提供了一个简单的 k/v 接口. 如果我们把这个 模型视作 <code>&lt;key, Tuple&gt;</code>，那么访问的时候，如果查询非 key 的某个 tuple 中的元素，则需要额外支持。一些 LSM-Tree 变种对这种负载提供了很好的支持。</li></ol><p><img src="https://image.mwish.me/blog-image/96B112B9-F87D-4394-B9DA-2DCEE57FA832.png" alt="96B112B9-F87D-4394-B9DA-2DCEE57FA832"></p><p>以上一张图是论文对这个优化系谱的描述，这里只介绍 1-3。下面我们将一个个介绍这些优化。需要注意的是，由于笔者能力所限，这些介绍可能会有纰漏或者错误。欢迎读者指正。</p><h2 id="减小写放大"><a href="#减小写放大" class="headerlink" title="减小写放大"></a>减小写放大</h2><p>大多数减小写放大的内容和 tiered compaction 相关。需要用到我们之前介绍的 vertical grouping 或者 horizontal grouping:</p><p><img src="https://image.mwish.me/blog-image/1EF1AB80-7796-489F-966C-B25AA382E4B0.png" alt="1EF1AB80-7796-489F-966C-B25AA382E4B0"></p><p>利用这种 grouping，权衡一定的读写放大。</p><h4 id="WriteBuffer-Tree"><a href="#WriteBuffer-Tree" class="headerlink" title="WriteBuffer Tree"></a>WriteBuffer Tree</h4><p>[1] WriteBuffer Tree 可以被当成 vertical grouping + tiered compaction 的变种。它出自 <strong>Design of a Write-Optimized Data Store</strong> 。</p><p>看看 WB-Tree 论文的介绍：</p><blockquote><p>WB Tree, an <em>unordered</em> key-value store optimized for high insert performance while maintaining fast random read access.</p></blockquote><p>所以需要注意，它是不支持 range 的。</p><p><img src="https://image.mwish.me/blog-image/F6DB6302-6E3D-46F1-AB11-88FB775CE17B.png" alt="F6DB6302-6E3D-46F1-AB11-88FB775CE17B"></p><p>如上图所描述，它利用 hash-partition, 让每个 group 存储差不多的数据量，然后用 B-Tree 类似的结构，组织这个树。</p><p>当一个 non-leaf node 满的时候，它会执行 spill: compaction 然后写到 children 里。这里是 append 进去的，所以写开销相对小。</p><p>当一个 Leaf node 满的时候，它会执行 split, 分裂到两个叶子结点中。</p><h4 id="LWC-Tree"><a href="#LWC-Tree" class="headerlink" title="LWC-Tree"></a>LWC-Tree</h4><p>LWC-Tree 可以参考这个 slide : <a href="https://www.storageconference.us/2017/Presentations/CompactionTreeToReduceIOamplification-slides.pdf">https://www.storageconference.us/2017/Presentations/CompactionTreeToReduceIOamplification-slides.pdf</a></p><p><img src="https://image.mwish.me/blog-image/D6068B0F-81E4-4B4B-8FCF-5A889C0C9DFD.png" alt="D6068B0F-81E4-4B4B-8FCF-5A889C0C9DFD"></p><p>这里，把 compaction 变成了 light-weight compaction。作为添加到 sstable 中。</p><p>这种方法的困难是，需要能够处理 metadata. 因为 SSTable 的 index block 可没那么聪明。所以这里设计了一个对应的 DTable.</p><h4 id="PebblesDB"><a href="#PebblesDB" class="headerlink" title="PebblesDB"></a>PebblesDB</h4><p>PebblesDB 认为写放大的根本原因是，多次 rewrite data to the same level. 所以他认为，需要维护每个 level 的没有交集的文件。</p><p><img src="https://image.mwish.me/blog-image/CB1BCC0F-B0CE-4A2E-88EF-7547A45D9626.png" alt="CB1BCC0F-B0CE-4A2E-88EF-7547A45D9626"></p><p>它使用 Guard 来切分这些文件。</p><h4 id="dCompaction"><a href="#dCompaction" class="headerlink" title="dCompaction"></a>dCompaction</h4><p>dCompaction 维护了虚拟的 SSTable:</p><blockquote><p>A virtual merge operation produces a virtual SSTable that sim- ply points to the input SSTables without performing actual merges. However, since a virtual SSTable points to multiple SSTables with overlapping ranges, query performance will degrade.</p></blockquote><p>实际上我觉得这相当于一个懒惰的 merge ，这样会降低 query 的效率。所以根据 query 的次数触发 compaction。</p><p>上面这些方法都部份类似 tiered compaction + vertical grouping。</p><h4 id="merge-skiping"><a href="#merge-skiping" class="headerlink" title="merge skiping"></a>merge skiping</h4><p>skip-tree 的设想是，一个 level 0 在 compaction 的时候，直接到达没有 overlapping 的最大层。</p><p><img src="https://image.mwish.me/blog-image/A68631B2-AA26-4161-A2E3-15E02FB81A8A.png" alt="A68631B2-AA26-4161-A2E3-15E02FB81A8A"></p><p>如果 merge 的时候，某个 key 在下面层都没有，那么久 skip 到最下层，每层有个 mutable buffer. 会写到这个 mutable buffer 里面。为了减小日志开销，这里只会 log merge 的 key, 让 replay wal 的时候，能够找到原来 SSTable 中的 key, value。</p><p>这种方法目前并没有怎么采用，因为管理 mutable buffer 和 merge 过于复杂。同时，相关的性能很难分析。</p><h4 id="Exploiting-Data-Skew"><a href="#Exploiting-Data-Skew" class="headerlink" title="Exploiting Data Skew"></a>Exploiting Data Skew</h4><p>TRIAD 在有 hot key 被频繁更新的时候，可以减小相关的写开销。它的基本 idea 是把 hot-key 做成某种 in-memory db 的结构。</p><h4 id="减小写放大：总结"><a href="#减小写放大：总结" class="headerlink" title="减小写放大：总结"></a>减小写放大：总结</h4><p>以上的写放大优化，大部分生成自己能够显著提升 LSM-T 的写性能。但是这些结果通常比较难评估，同时 RocksDB/LevelDB 默认还是采用了比较朴素的策略。此外，他们对空间放大从来也没有那么在意。</p><h2 id="优化-merge"><a href="#优化-merge" class="headerlink" title="优化 merge"></a>优化 merge</h2><p>merge 相关的优化包括改善 merge 性能、减小 buffer cache miss、避免 write stall</p><h3 id="改善-merge-性能"><a href="#改善-merge-性能" class="headerlink" title="改善 merge 性能"></a>改善 merge 性能</h3><p>VT-Tree 做了一种优化：merge 的时候，如果一个 sstable 和别的 merge 目标没有重复空间，那么下层直接指向上层对应的内容。</p><p><img src="https://image.mwish.me/blog-image/3CDAF69E-CF33-4ACA-9BDE-272976222B84.png" alt="3CDAF69E-CF33-4ACA-9BDE-272976222B84"></p><p>这里优化了 compaction 的性能，但是造成了碎片化。VT-Tree 添加了一个 stitching 阈值 K, 超过这个阈值的时候，相关的内容会被黏合到一起。</p><p>此外，这里 merge 的时候，因为 bloom filter 不能合起来，所以采用了 quotient filters。这种类型比较难实现，但是功能强大，能够合并起来。</p><p>此外，还有将 compaction 的过程 pipeline 的设计：</p><p><img src="https://image.mwish.me/blog-image/48930BF5-699D-4828-8EE3-166508520720.png" alt="48930BF5-699D-4828-8EE3-166508520720"></p><p>这里把 compaction 分成三个部分：read — write — sort. 这里认为 read/write 是 重IO 的，作者认为可以将这几部分流水线处理。</p><h3 id="减小-cache-miss"><a href="#减小-cache-miss" class="headerlink" title="减小 cache miss"></a>减小 cache miss</h3><p>产生新的 component 的时候，相关的内容可能因为没在内存里，产生大量 cache miss.</p><p>有一种方法是，产生新的 component 的时候，可以 warmup 相关的内容。慢慢从旧的 component 灰度到新的内容中。用这种方式均摊暴涨的 cache miss。</p><p>LSbM-Tree 提供了另一种方法，上层 merge 的时候，直接把对应缓存的内容推到下一层，等它们被 LRU 之类的算法换出。不过：</p><blockquote><p>However, this approach is mainly effective for skewed workloads where only a small range of keys are frequently accessed. It can in- troduce extra overhead for queries accessing cold data that are not cached, especially for range queries since they can- not benefit from Bloom filters.</p></blockquote><p><img src="https://image.mwish.me/blog-image/A2A366A4-FF93-4081-8D98-BF398A9B84F4.png" alt="A2A366A4-FF93-4081-8D98-BF398A9B84F4"></p><h3 id="minimize-write-stalls"><a href="#minimize-write-stalls" class="headerlink" title="minimize write stalls"></a>minimize write stalls</h3><p>bLSM 为了 unpartioned Leveled compaction 而设计，它给 LSM-Tree 每层添加了额外的调度组件。当需要 compaction 的时候，它等待上一层往自己这层 compaction 完，在进行操作。这最终限制了写入的速度和 SSD 写入的数量。</p><p>当然，作者批评 bLSM-Tree 没有考虑这个等待相关的 queuing latency.</p><h2 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h2><p>原始的 LSM-Tree 是以 HDD 为 C0 外其他组件存储来实现的，它的顺序写入比随机写入快很多。现在我们进入了大内存、SSD/NVME、NVM 的时代。为了适应这些新的存储，LSM-Tree 需要对应的改进，来针对上述这些介质提供好的性能、高效的操作。</p><h3 id="big-memory"><a href="#big-memory" class="headerlink" title="big-memory"></a>big-memory</h3><p><em>FloDB: Unlocking Memory inPersistent Key-Value Stores</em> 这篇论文提出了 FloDB.</p><p>作者认为，对于大的内存 components, LevelDB/RocksDB 这些效果并不好，于是它使用了 HashTable 来做一个写入层。</p><p><img src="https://image.mwish.me/blog-image/B26ED72F-FEF4-4C9A-AC39-4F2C0B79BF67.png" alt="B26ED72F-FEF4-4C9A-AC39-4F2C0B79BF67"></p><p><img src="https://image.mwish.me/blog-image/A98B25C8-6411-4AB0-AC12-3E65AE287120.png" alt="A98B25C8-6411-4AB0-AC12-3E65AE287120"></p><p>作者认为这样能提高 大 memory components 的写入性能。</p><h3 id="Multi-Core"><a href="#Multi-Core" class="headerlink" title="Multi-Core"></a>Multi-Core</h3><p>Scaling  Concurrent  Log-Structured  Data  Stores 提出了 cLSM:</p><p><img src="https://image.mwish.me/blog-image/AC15DF930A30DEDD727688E0EA0A71EF.png" alt="AC15DF930A30DEDD727688E0EA0A71EF"></p><p>cLSM 提供了一种 Non-blocking synchronization，不过我简单看了下，感觉现在 LevelDB, RocksDB 都差不多是这样…如果我感觉不对可以提醒我。</p><h3 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h3><p>与传统的盘不同，SSD的随机读写相对来说速度不俗。</p><p>FD-Tree 用类似 LSM-Tree 的方式来减小 SSD 的 random write. 它插入了不少 fence pointer</p><p><img src="https://image.mwish.me/blog-image/57B0315D-C919-43C8-9D09-19C22D415D35.png" alt="57B0315D-C919-43C8-9D09-19C22D415D35"></p><p><img src="https://image.mwish.me/blog-image/fdtree-arch.png" alt="fdtree-arch"></p><p>FD-Tree 算是 BTree LSMTree 的缝合怪，论文这里提到他是因为这里用 fence pointer 代替 BF。</p><p>当然，这里提升了查询效率，但是差不到的东西还是要从头查到尾。所以现在的很多结构还是用 Bloom Filter.</p><hr><p>MaSM: Efficient Online Updates in Data Warehouses 提出了 warehouse 相关的 WaSM</p><p><img src="https://image.mwish.me/blog-image/DDA34F12-12AA-4A5B-A61A-D6F7FF7463A4.png" alt="DDA34F12-12AA-4A5B-A61A-D6F7FF7463A4"></p><p>这里相当于维护一个写结构，然后 main data 放在满的 HDD 上，做读结构。Buffer 做 tiered compaction，最后丢到  main 上。</p><hr><p>SSD 支持很快的 random read, 所以，分离 key-value 成了改善写性能的好办法。WiscKey 就是这么做的。</p><p><img src="https://image.mwish.me/blog-image/9A4D85C2-28F8-4D8E-81DD-F796644282C1.png" alt="9A4D85C2-28F8-4D8E-81DD-F796644282C1"></p><p>在 WiscKey 中，LSM-Tree 只维护了 <code>&lt;key, 索引&gt;</code>, value 被 append 到另外的地方。</p><p>WiscKey 会有专门的任务来 GC, 它会走三步：</p><ol><li>从 WAL 尾部开始，查看这个 entry 存不存在</li><li>写 valid entries</li><li>移除掉尾部的数据</li></ol><blockquote><p>In WiscKey, garbage-collection is performed in three steps. First, WiscKey scans the log tail and validates each entry by performing point lookups against the LSM-tree to find out whether the location of each key has changed or not. Second, valid entries, whose locations have not changed, are then appended to the log and their locations are updated in the LSM-tree as well. Finally, the log tail is truncated to reclaim the storage space.</p></blockquote><p>这个 GC 已经成为了新的瓶颈。而 HashKV 通过添加了一层 hash partition, 来减小了这样的开销。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LSM-based Storage Techniques: A Survey</title>
      <link href="/2021/04/21/LSM-based-Storage-Techniques-A-Survey-Part1/"/>
      <url>/2021/04/21/LSM-based-Storage-Techniques-A-Survey-Part1/</url>
      
        <content type="html"><![CDATA[<p>如今，LSM-Tree 正在渐渐被大众所接受。或许是从 BigTable 开始，NoSQL 的存储引擎从 DB 教科书上占一大节的 B+Tree，慢慢转向了 LSM-Tree。BigTable, Dynamo, HBase, Cassandra, LevelDB, RocksDB 和 AsterixDB 都使用了 LSMTree 作为存储引擎。</p><p>这篇论文简单介绍了 LSM-Tree，然后对 读/写/空间相关的内容，对原始论文的 LSMTree 做了分析。同时介绍了 LSM-Tree 相关的的优化。</p><p>LSM-Tree 设想是，把所有的、很可能是 <em>随机写</em> 的写入变更存储在内存中，然后转化成顺序写 flush 到磁盘上。LSM-Tree 有下列优点：</p><ol><li>优秀的写性能</li><li>不俗的空间利用率</li><li>比较容易实现的 concurrency control 和 recovery （这在 B-Tree 中比较复杂，设计 btree concurrency control，甚至可能把事务相关的信息嵌入整个 Btree）</li></ol><p>LSM-Tree 目前有各种修改，可以适应各种 workload，比如 RocksDB，在它的 FAST21 论文中涉及：</p><blockquote><p> real-time data processing , graph processing, stream processing, and OLTP workloads.</p></blockquote><h2 id="LSM-Tree-Basics"><a href="#LSM-Tree-Basics" class="headerlink" title="LSM-Tree Basics"></a>LSM-Tree Basics</h2><p><img src="https://image.mwish.me/blog-image/C272EA0D-4077-4696-BE9D-F09734F2C5A3.png" alt="C272EA0D-4077-4696-BE9D-F09734F2C5A3"></p><p>索引结构有两种更新方式：</p><ol><li>In-place update: 就地更新，对写入不是很友好，通常可能只保持需要的版本(论文里说最新的版本，不过我感觉实际上更多是“需要的版本”)，对读和通常比较友好。</li><li>Out-of-place update: 对写入比较友好。</li></ol><p>1976 年提出的 <code>Different files</code> 是一个比较早期的 out-of-space 更新，维护了一个 <code>diff file</code> 和一个 <code>main file</code>，而 pg 也会把写都记录到一个 sequnce-log 里面，由 <code>vacuum cleaner</code> 进行 GC。类似的思路也被利用到了 LFS 文件系统上。</p><p>以上结构大概是维护 log/维护 delta 和 main, 他们的问题是：</p><ol><li>low query performance: query 需要根据之前所有的 log 来做出决策</li><li>low space utilization: 不需要的内容 (obsolete records) 没有被删除，导致不小的空间放大。</li></ol><p><img src="https://image.mwish.me/blog-image/A5D820DF-48C2-40D1-AD32-15FE3C6B228E.png" alt="A5D820DF-48C2-40D1-AD32-15FE3C6B228E"></p><p>最早的 LSM-Tree 在 1996 年提出，如上图。它提供了很高的写性能与不差的读性能。</p><p>LSM-Tree 有多个 components，$C<em>0$ 驻留在内存中，其余部分在磁盘上。$C_i$ 状态是 full 的时候，会有一个 rolling merge 进程，把 $C_i$ 的 leaf 刷到 $C</em>{i + 1}$ 中 。这个有一点点类似 LevelDB 的 leveling merge，不过：</p><blockquote><p>However, as we shall see later, the originally proposed rolling merge process is not used by to- day’s LSM-based storage systems due to its implementation complexity. </p></blockquote><p>需要注意的是，对于 $T<em>i = | C</em>{i + 1} | / | C_i|$ 而言，保持一样的比例，会使得 LSM-Tree 写性能有所优化。</p><p>差不多同一个时候，<em>Jagadish et al.</em> 提出了一个多层的结构，当 L 层满的时候，会把本层全部内容下刷到 L + 1 层。在如今的 LSM-Tree 中，这种行为被称为 tiering merge policy，即 tiered compaction。</p><h3 id="今日的-LSM-Tree"><a href="#今日的-LSM-Tree" class="headerlink" title="今日的 LSM-Tree"></a>今日的 LSM-Tree</h3><p>目前的 LSM-Tree 写入的时候，会写一条记录，删除的时候，标志一个 tombstone （类似 leveldb 的 type）。今天的 LSM-Treee 会利用不可变的结构，来简化 concurrency control 和 recovery：merge 的时候，原来的内容不会变更，这与之前提过的 rolling merge 是不同的。</p><p>在当今 LSM-Tree 实现中，内存结构通常使用并发的数据结构，比如 SkipList(这种结构比较容易实现 concurrency ordered map) 或者 B+Tree. 在磁盘的结构则使用 SSTable 或者 B+Tree。这里介绍一下 SSTable，它包含多个 data block 和一个 index block, index block 包含了 range 的元信息和 data block 的信息。(可见 BigTable 论文)。</p><p>对于 LSM-Tree 的查询有两种：<em>point lookup query</em> 和 <em>range query</em> ，前者从写入时间的 新-旧，一个个结构找，直到找到对应的内容或者 miss, range query 则需要一个类似 priority queue 的内容，来吐出对应的 key。以上可见，对于写入增加 —&gt; 磁盘结构变大、层数变多，这里查找的性能是会下降的。Compaction 会以写来优化读和空间放大，目前有两种常见的 Compaction:</p><ol><li>tiered compaction</li><li>leveled compaction</li></ol><p><img src="https://image.mwish.me/blog-image/39BF2B48-BCF3-4DD1-9A39-C0FB3D042FEF.png" alt="39BF2B48-BCF3-4DD1-9A39-C0FB3D042FEF"></p><p>在介绍 compaction 之前，我们可以先介绍一下 sorted run: 每一层中，单个逻辑有序且不与其他重复的结构，比如 <code>0-100</code>, 会被视作一个 sorted run，这篇论文的用词是 component。</p><p>Leveling merge policy 会从 <code>i</code> 层单个 sorted run 中向 <code>i + 1</code> 层合并，成为 1 个 sorted run. 在 i 层的 key 平均要被 compaction 多次，才会 compaction 到下一层。</p><p>tiered compaction 则如下图所示，每一层会有可能不止一个 sorted run, 但只会合并一次：</p><p><img src="https://image.mwish.me/blog-image/compaction-1.png" alt="compaction-1"></p><p>简单的说，leveled compaction 对读和空间放大有好处，tiered compaction 写放大比较少</p><h3 id="常见优化"><a href="#常见优化" class="headerlink" title="常见优化"></a>常见优化</h3><h4 id="用-bloom-filter-优化读"><a href="#用-bloom-filter-优化读" class="headerlink" title="用 bloom filter 优化读"></a>用 bloom filter 优化读</h4><p>BF 优化读是一个很好的策略，这里就不再介绍 BF 了，但同时，需要注意的是，合并的时候可能要重新计算 BF，因为可能有些 tombstone 的数据，合并就给你不要了，所以 BF 这里有问题。</p><p>这里 Bloom Filter 很多时候只需要对应到磁盘上，所以经常是静态的（即不需要预先知道 key 的数量，来增插删改）。</p><p>此外，也有用 Cuckoo Filter 之类的方式，来在对应的需求下替换 BF.</p><h3 id="partition"><a href="#partition" class="headerlink" title="partition"></a>partition</h3><p>上面的 $C_i$ 不仅是逻辑的一层，也是物理的一整块结构。原始的 LSM-Tree rolling merge 只会把一部分叶子结点 merge 到一层。</p><p><img src="https://image.mwish.me/blog-image/4ED4867F-2630-407D-9753-555D24D0D5C2.png" alt="4ED4867F-2630-407D-9753-555D24D0D5C2"></p><p>这里，LSM-Tree 可以把每一层 sorted run 分为多个 SSTable, 例如 LevelDB 默认使用 2M 左右的 SSTable.</p><p>这样的操作有下列的好处：</p><blockquote><p>First, partitioning breaks a large com- ponent merge operation into multiple smaller ones, bound- ing the processing time of each merge operation as well as the temporary disk space needed to create new components. Moreover, partitioning can optimize for workloads with se- quentially created keys or skewed updates by only merging components with overlapping key ranges</p></blockquote><p>上述是 Leveled compaction 的 partition，tiered compaction 需要一别的方式设计：</p><p>这里提供了一些方案：</p><p><img src="https://image.mwish.me/blog-image/F3B0E1FA-89CD-4FFF-8D3A-0A33D1E0A811.png" alt="F3B0E1FA-89CD-4FFF-8D3A-0A33D1E0A811"></p><p>（我总觉得很缝合）</p><h3 id="Concurrency-Control-and-Recovery"><a href="#Concurrency-Control-and-Recovery" class="headerlink" title="Concurrency Control and Recovery"></a>Concurrency Control and Recovery</h3><p>虽然有很多不可变结构，但是处理上述问题，也要与 compaction 的流交互在一起。</p><p>内存中的结构可以写到一个 no-steal 的 buffer 里，然后只需要写 WAL (当作 redo log), 就可以保证恢复。</p><p><img src="https://image.mwish.me/blog-image/922cb3ed1d64d4f5e3a12b95cdf5d25ff24.jpg" alt="922cb3ed1d64d4f5e3a12b95cdf5d25ff24"></p><p>对于磁盘结构而言，可以实现成 Multi-version 的，这里对应的 component（包括内存结构和 SST）可以实现一个 rc, 当可以删除且没有读者的时候，可以把数据清除。</p><p>上述内容是 concurrency control. 对于 recover 而言，有两种方式：</p><ul><li>类似 boltdb, 如果每层只有一个 partition, 每层选取 id 最大的版本或者 wall-clock 最大的数据</li><li>类似 leveldb, 维护一个 manifest 元信息列表。</li></ul><h3 id="Cost-analysis-and-RUM-conjecture"><a href="#Cost-analysis-and-RUM-conjecture" class="headerlink" title="Cost analysis and RUM conjecture"></a>Cost analysis and RUM conjecture</h3><p><img src="https://image.mwish.me/blog-image/AB77AD96-5AB8-4C6B-BA76-5D5015E949B2.png" alt="AB77AD96-5AB8-4C6B-BA76-5D5015E949B2"></p><p>LSM-Tree 有着如上的基本的复杂度，注意：</p><ol><li>写入是考虑每层的 compaction 次数，来计算出来的</li><li>点查这里是考虑了 Bloom filter</li></ol><p>这里感兴趣还可以看看 RUM：</p><p><img src="https://image.mwish.me/blog-image/3-Figure1-1.png" alt="3-Figure1-1"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Notes on C++ Copy Elision</title>
      <link href="/2021/04/12/Notes-on-C-Copy-Elision/"/>
      <url>/2021/04/12/Notes-on-C-Copy-Elision/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Omits copy and move (since C++11) constructors, resulting in zero-copy pass-by-value semantics.</p></blockquote><p>以上是 copy elision 的解释。</p><p>下面列举一些代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">get_F1</span><span class="params">(S&amp; s)</span> </span>&#123;</span><br><span class="line">    s.i = <span class="number">8</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">S* <span class="title">get_F2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    S* ps = <span class="keyword">new</span> S; <span class="comment">// 2. default ctor 2</span></span><br><span class="line">    ps-&gt;i = <span class="number">8</span>;</span><br><span class="line">    <span class="keyword">return</span> ps;     <span class="comment">// should be freed later</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>和</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">T <span class="title">get_object</span><span class="params">(args...)</span> </span>&#123;</span><br><span class="line">T t;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="keyword">return</span> std::<span class="built_in">move</span>(t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至少一般我们被教育过，不要 <code>return std::move(t)</code>, 同时我们知道，返回某个 <code>S</code> 类型的量，可能会有 Copy Elision 的优化，帮助我们就地在外部构造这个值 (<code>constructing the automatic object directly into the exception object.</code>)</p><h3 id="Value-Category-and-Guaranteed-Copy-Elision"><a href="#Value-Category-and-Guaranteed-Copy-Elision" class="headerlink" title="Value Category and Guaranteed Copy Elision"></a>Value Category and Guaranteed Copy Elision</h3><p>C++11 定义了 Value Categories. C++ 中，每个 expression 都有一个 value category</p><p>我们考虑仅定义 <code>lvalue</code> 和 <code>rvalue</code>. 字面量 <code>2</code> 肯定是 <code>rvalue</code>, 而 <code>lvalue</code> 被视作 <code>localizable value</code>, 那么，简单句几个例子:</p><ul><li><code>v</code> 是一个 <code>std::vector</code>, <code>v.front()</code> 是一个 lvalue</li><li><code>*p</code> 是一个 lvalue</li><li>甚至一个字符串字面量都是一个不可更改值的 lvalue.</li></ul><p>而 <code>nullptr</code>, <code>&#39;a&#39;</code>, <code>7</code>  这些被视作 <code>rvalue</code>. </p><p><code>lvalue</code> 可以被转成 <code>rvalue</code> ，所以 <code>y = x</code> 是可以的，当然 <code>7 = 8</code> 就不行啦。</p><p>上面只是一个非常模糊的说明，C++11 定义了下面的内容：</p><p><img src="https://image.mwish.me/blog-image/BE725B3AB0EF7D38B52D06B194606D7D.png" alt="BE725B3AB0EF7D38B52D06B194606D7D"></p><p>而 <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0135r0.html">Guaranteed copy elision through simplified value categories</a> 定义了新的 value category, 随后又了如下变更：<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0135r1.html">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0135r1.html</a></p><p>这意味着，如果你有一个</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">T <span class="title">f</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">T</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">T x = <span class="built_in">f</span>(); <span class="comment">// 1</span></span><br><span class="line">T x2 = <span class="built_in">T</span>(<span class="built_in">T</span>(<span class="built_in">f</span>())); <span class="comment">// 2</span></span><br></pre></td></tr></table></figure><p>这里需要根据 <code>f()</code> 的上下文推断，<code>T()</code> 是个 prvalue, 那么 C++ 17 会强制 1 仅调用一次  T 的构造函数</p><p>然后，再看 2:</p><blockquote><p><strong>If the initializer expression is a prvalue and the cv-unqualified version of the source type is the same class as the class of the destination, the initializer expression is used to initialize the destination object. [</strong> <em>Example**</em>:<strong> <code>T x = T(T(T()));</code> </strong>calls the<strong> <code>T</code> </strong>default constructor to initialize<strong> <code>x</code></strong>. ]**</p></blockquote><p>所以这里构造函数也只会走一次。</p><p><em>以上内容在 C++17 之后是强制的。</em></p><h3 id="NRVO"><a href="#NRVO" class="headerlink" title="NRVO"></a>NRVO</h3><p>我们再考虑 NRVO：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">T <span class="title">get_object</span><span class="params">(args...)</span> </span>&#123;</span><br><span class="line">T t;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="keyword">return</span> std::<span class="built_in">move</span>(t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们贴两个图：</p><p><img src="https://image.mwish.me/blog-image/CFF34BB9BC32A9B1EA0A3C8660C537B0.png" alt="CFF34BB9BC32A9B1EA0A3C8660C537B0"></p><p><img src="https://image.mwish.me/blog-image/628BAC04ED66DC742323A690115292E2.png" alt="628BAC04ED66DC742323A690115292E2"></p><p>这里描述了 NRVO 和 NRVO 失败的情况。可以看到，对于一个 <code>HardToCopyAndEasyToMove</code> 的结构，即使不 <code>return std::move(..)</code>, 编译器也能正确的优化</p><h3 id="遇上-scoped-guard"><a href="#遇上-scoped-guard" class="headerlink" title="遇上 scoped_guard"></a>遇上 scoped_guard</h3><p>如果你想在参数返回之前，做一些检查，在 <code>go</code> 里面，你没准这么写了：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> s Status <span class="comment">// when init s.ok() == true</span></span><br><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">if</span> s.ok() &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="keyword">return</span> s</span><br></pre></td></tr></table></figure><p>不谈代码好不好，这里逻辑上是可以的，因为 Go 万物都是 Copy。</p><p>当你想在 C++ 里面实现这些东西的时候，比如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Status s; <span class="comment">// when moved, it will be ok</span></span><br><span class="line">std::scoped_guard defer_fn; <span class="comment">// check s</span></span><br><span class="line">...</span><br><span class="line">  </span><br><span class="line"><span class="keyword">return</span> s;</span><br></pre></td></tr></table></figure><p>如果这里走了 move, 那我们有 evaluation order: <a href="https://en.cppreference.com/w/cpp/language/eval_order">https://en.cppreference.com/w/cpp/language/eval_order</a></p><p><img src="https://image.mwish.me/blog-image/BA42F5DB-AE8A-49C9-8FF4-946D1A2BCB2B.png" alt="BA42F5DB-AE8A-49C9-8FF4-946D1A2BCB2B"></p><p>我们可以看到，这里可能先发生 move, 再来 check s, move 之后 s 可能就不能满足用户的预期了。</p><h3 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h3><p>其实我也不懂 C++，有什么地方写错了，请立刻通知我，我会第一时间查证和改正。</p><p>查阅的时候，虽然感觉 C++ 规则很复杂，但是大部分时候，即使不熟悉这些细节，正常写代码也能保证高效率。正如没有受过法律的正常人，也很少会犯法。</p><p>好了，搞完了，接着打逆转裁判了。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://zh.cppreference.com/w/cpp/language/value_category">value category</a></li><li><a href="https://en.cppreference.com/w/cpp/language/copy_elision">copy elision</a></li><li>Guaranteed copy elision through simplified value categories  <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0135r0.html">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0135r0.html</a></li><li>C++ Templates 2nd</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LRU, 更多的 LRU</title>
      <link href="/2021/04/08/LevelDB-utils-LRU/"/>
      <url>/2021/04/08/LevelDB-utils-LRU/</url>
      
        <content type="html"><![CDATA[<p>面试的时候面试官经常会让你搓个 LRU，boost 这里有个 case:</p><p><a href="https://www.boost.org/doc/libs/1_67_0/boost/compute/detail/lru_cache.hpp">https://www.boost.org/doc/libs/1_67_0/boost/compute/detail/lru_cache.hpp</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// a cache which evicts the least recently used item when it is full</span></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">Key</span>, <span class="keyword">class</span> <span class="title class_">Value</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">lru_cache</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">typedef</span> Key key_type;</span><br><span class="line">    <span class="keyword">typedef</span> Value value_type;</span><br><span class="line">    <span class="keyword">typedef</span> std::list&lt;key_type&gt; list_type;</span><br><span class="line">    <span class="keyword">typedef</span> std::map&lt;</span><br><span class="line">                key_type,</span><br><span class="line">                std::pair&lt;value_type, <span class="keyword">typename</span> list_type::iterator&gt;</span><br><span class="line">            &gt; map_type;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">lru_cache</span>(<span class="type">size_t</span> capacity)</span><br><span class="line">        : <span class="built_in">m_capacity</span>(capacity)</span><br><span class="line">    &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ~<span class="built_in">lru_cache</span>()</span><br><span class="line">    &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">size_t</span> <span class="title">size</span><span class="params">()</span> <span class="type">const</span>；</span></span><br><span class="line"><span class="function">    <span class="type">size_t</span> <span class="title">capacity</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">empty</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">contains</span><span class="params">(<span class="type">const</span> key_type &amp;key)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">insert</span><span class="params">(<span class="type">const</span> key_type &amp;key, <span class="type">const</span> value_type &amp;value)</span></span>;</span><br><span class="line">    <span class="function">boost::optional&lt;value_type&gt; <span class="title">get</span><span class="params">(<span class="type">const</span> key_type &amp;key)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">clear</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">evict</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    map_type m_map;</span><br><span class="line">    list_type m_list;</span><br><span class="line">    <span class="type">size_t</span> m_capacity;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这玩意短小又精悍:</p><ol><li><code>list_type</code> 存储了 <code>key</code> 的 LRU 链表，插入在最前方插入/把中间某个 key 丢到最前面</li><li><code>m_map</code> 存储了 <code>map[key -&gt; (list_iter, value)]</code></li></ol><p>这个相对来说应该是很好理解的。但是这玩意也掩盖了 LRU 的复杂性:</p><ol><li>假设我们 evict, 那么我们要逐出一个元素，然后根据 key 查一下 <code>m_map</code>，complexity 是 O(1) 的，但是仍然需要访问 <code>m_map</code></li><li>如果并发的话，hash 肯定要上一把大锁</li></ol><p>实际上上面两点都有一定的问题。然后对于 LRU 的调用者，还有个“内部”，“外部”的问题，可以参考一下 CMU 15-445 Lab-1 的接口：</p><ul><li>使用的时候可能会把 LRU 某个取出来，作为活跃的、正在使用的对象，使用完之后再丢进 LRU 里头</li></ul><h2 id="LevelDB-LRU"><a href="#LevelDB-LRU" class="headerlink" title="LevelDB LRU"></a>LevelDB LRU</h2><p>LevelDB 实现了侵入式的 LRU, 同时分为了多个 shard。这分别针对了我们上面说的复杂性 (1) 和 (2), 先看看接口：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">LEVELDB_EXPORT Cache* <span class="title">NewLRUCache</span><span class="params">(<span class="type">size_t</span> capacity)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LEVELDB_EXPORT</span> Cache &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">Cache</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">Cache</span>(<span class="type">const</span> Cache&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  Cache&amp; <span class="keyword">operator</span>=(<span class="type">const</span> Cache&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Destroys all existing entries by calling the &quot;deleter&quot;</span></span><br><span class="line">  <span class="comment">// function that was passed to the constructor.</span></span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">Cache</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Opaque handle to an entry stored in the cache.</span></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">Handle</span> &#123;&#125;;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Insert a mapping from key-&gt;value into the cache and assign it</span></span><br><span class="line">  <span class="comment">// the specified charge against the total cache capacity.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Returns a handle that corresponds to the mapping.  The caller</span></span><br><span class="line">  <span class="comment">// must call this-&gt;Release(handle) when the returned mapping is no</span></span><br><span class="line">  <span class="comment">// longer needed.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// When the inserted entry is no longer needed, the key and</span></span><br><span class="line">  <span class="comment">// value will be passed to &quot;deleter&quot;.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Handle* <span class="title">Insert</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">void</span>* value, <span class="type">size_t</span> charge,</span></span></span><br><span class="line"><span class="params"><span class="function">                         <span class="type">void</span> (*deleter)(<span class="type">const</span> Slice&amp; key, <span class="type">void</span>* value))</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If the cache has no mapping for &quot;key&quot;, returns nullptr.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Else return a handle that corresponds to the mapping.  The caller</span></span><br><span class="line">  <span class="comment">// must call this-&gt;Release(handle) when the returned mapping is no</span></span><br><span class="line">  <span class="comment">// longer needed.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> Handle* <span class="title">Lookup</span><span class="params">(<span class="type">const</span> Slice&amp; key)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Release a mapping returned by a previous Lookup().</span></span><br><span class="line">  <span class="comment">// REQUIRES: handle must not have been released yet.</span></span><br><span class="line">  <span class="comment">// REQUIRES: handle must have been returned by a method on *this.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Release</span><span class="params">(Handle* handle)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Return the value encapsulated in a handle returned by a</span></span><br><span class="line">  <span class="comment">// successful Lookup().</span></span><br><span class="line">  <span class="comment">// REQUIRES: handle must not have been released yet.</span></span><br><span class="line">  <span class="comment">// REQUIRES: handle must have been returned by a method on *this.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span>* <span class="title">Value</span><span class="params">(Handle* handle)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If the cache contains entry for key, erase it.  Note that the</span></span><br><span class="line">  <span class="comment">// underlying entry will be kept around until all existing handles</span></span><br><span class="line">  <span class="comment">// to it have been released.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Erase</span><span class="params">(<span class="type">const</span> Slice&amp; key)</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Return a new numeric id.  May be used by multiple clients who are</span></span><br><span class="line">  <span class="comment">// sharing the same cache to partition the key space.  Typically the</span></span><br><span class="line">  <span class="comment">// client will allocate a new id at startup and prepend the id to</span></span><br><span class="line">  <span class="comment">// its cache keys.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">uint64_t</span> <span class="title">NewId</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Remove all cache entries that are not actively in use.  Memory-constrained</span></span><br><span class="line">  <span class="comment">// applications may wish to call this method to reduce memory usage.</span></span><br><span class="line">  <span class="comment">// Default implementation of Prune() does nothing.  Subclasses are strongly</span></span><br><span class="line">  <span class="comment">// encouraged to override the default implementation.  A future release of</span></span><br><span class="line">  <span class="comment">// leveldb may change Prune() to a pure abstract method.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Prune</span><span class="params">()</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Return an estimate of the combined charges of all elements stored in the</span></span><br><span class="line">  <span class="comment">// cache.</span></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">size_t</span> <span class="title">TotalCharge</span><span class="params">()</span> <span class="type">const</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">LRU_Remove</span><span class="params">(Handle* e)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">LRU_Append</span><span class="params">(Handle* e)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Unref</span><span class="params">(Handle* e)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">Rep</span>;</span><br><span class="line">  Rep* rep_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>先做个阅读理解：</p><ol><li><code>struct Handle</code>  是一个没有定义任何成员的类型，<code>Cache::Handle*</code> 其实被我们当成一个特殊的地址处理，可以参考 <code>LRUHandle</code> 的定义. 可以看到，第一个成员是 value. 我们在 <code>LRUCache</code> 返回的时候用 <code>reinterpret_cast&lt;Cache::Handle&gt;(lru_hanle_ptr)</code>, 然后对应地址最前面就是 <code>value</code>。当然这个也可以通过 <code>Cache::Value</code> 访问</li><li><code>Lookup</code> 发生的时候，LRUCache 的元素会被标记 <code>ref</code>, <code>Release</code> 的时候，会被标记为 <code>Unref</code>. </li><li><code>Insert</code> 带 Deleter 这个比较正常，charge 相对来说不好理解一些，可以和 Shard 一起理解，每个 shard 不是按<code>Handle</code> 个数算的，而是按 <code>charge</code> 算的。然后 block cache (<code>options.block_cache</code> 配置，存储 table 相关的 content ) 里面，每个 <code>block</code> 单位是一个 block 的 size, TableCache （对 SST 文件的句柄 cache）里面，charge 对应是 1.</li><li><code>NewID</code> 这个玩意实际上和实现的逻辑有关，在 block cache 里，<code>key</code> 被编码成 64bit 的 cache id (per table) 和 64bit 的 block 偏移量，所以需要每个 block cache 能生成出 一个 unique id.</li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">LRUHandle</span> &#123;</span><br><span class="line">  <span class="type">void</span>* value;</span><br><span class="line">  <span class="built_in">void</span> (*deleter)(<span class="type">const</span> Slice&amp;, <span class="type">void</span>* value);</span><br><span class="line">  LRUHandle* next_hash;</span><br><span class="line">  LRUHandle* next;</span><br><span class="line">  LRUHandle* prev;</span><br><span class="line">  <span class="comment">// charge 是一个统计量，在 block_cache 中，这个统计量是 size().</span></span><br><span class="line">  <span class="comment">// 在 TableCache 中，这个统计量是1.</span></span><br><span class="line">  <span class="comment">// 注：TableCache 和 block 不是同一个对象。</span></span><br><span class="line">  <span class="type">size_t</span> charge;  <span class="comment">// TODO(opt): Only allow uint32_t?</span></span><br><span class="line">  <span class="type">size_t</span> key_length;</span><br><span class="line">  <span class="type">bool</span> in_cache;     <span class="comment">// Whether entry is in the cache.</span></span><br><span class="line">  <span class="type">uint32_t</span> refs;     <span class="comment">// References, including cache reference, if present.</span></span><br><span class="line">  <span class="type">uint32_t</span> hash;     <span class="comment">// Hash of key(); used for fast sharding and comparisons</span></span><br><span class="line">  <span class="type">char</span> key_data[<span class="number">1</span>];  <span class="comment">// Beginning of key</span></span><br><span class="line"></span><br><span class="line">  <span class="function">Slice <span class="title">key</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="comment">// next_ is only equal to this if the LRU handle is the list head of an</span></span><br><span class="line">    <span class="comment">// empty list. List heads never have meaningful keys.</span></span><br><span class="line">    <span class="built_in">assert</span>(next != <span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">Slice</span>(key_data, key_length);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>我们来瞅瞅具体的 LRUCache 结构体：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LRUCache</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">LRUCache</span>();</span><br><span class="line">  ~<span class="built_in">LRUCache</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Separate from constructor so caller can easily make an array of LRUCache</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">SetCapacity</span><span class="params">(<span class="type">size_t</span> capacity)</span> </span>&#123; capacity_ = capacity; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Like Cache methods, but with an extra &quot;hash&quot; parameter.</span></span><br><span class="line">  <span class="function">Cache::Handle* <span class="title">Insert</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">uint32_t</span> hash, <span class="type">void</span>* value,</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="type">size_t</span> charge,</span></span></span><br><span class="line"><span class="params"><span class="function">                        <span class="type">void</span> (*deleter)(<span class="type">const</span> Slice&amp; key, <span class="type">void</span>* value))</span></span>;</span><br><span class="line">  <span class="function">Cache::Handle* <span class="title">Lookup</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">uint32_t</span> hash)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Release</span><span class="params">(Cache::Handle* handle)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Erase</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">uint32_t</span> hash)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Prune</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="comment">// charge 属于用户逻辑了。</span></span><br><span class="line">  <span class="function"><span class="type">size_t</span> <span class="title">TotalCharge</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="function">MutexLock <span class="title">l</span><span class="params">(&amp;mutex_)</span></span>;</span><br><span class="line">    <span class="keyword">return</span> usage_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">LRU_Remove</span><span class="params">(LRUHandle* e)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">LRU_Append</span><span class="params">(LRUHandle* list, LRUHandle* e)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Ref</span><span class="params">(LRUHandle* e)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Unref</span><span class="params">(LRUHandle* e)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">FinishErase</span><span class="params">(LRUHandle* e)</span> <span class="title">EXCLUSIVE_LOCKS_REQUIRED</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Initialized before use.</span></span><br><span class="line">  <span class="type">size_t</span> capacity_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// mutex_ protects the following state.</span></span><br><span class="line">  <span class="keyword">mutable</span> port::Mutex mutex_;</span><br><span class="line">  <span class="function"><span class="type">size_t</span> usage_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Dummy head of LRU list.</span></span><br><span class="line">  <span class="comment">// lru.prev is newest entry, lru.next is oldest entry.</span></span><br><span class="line">  <span class="comment">// Entries have refs==1 and in_cache==true.</span></span><br><span class="line">  <span class="function">LRUHandle lru_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Dummy head of in-use list.</span></span><br><span class="line">  <span class="comment">// Entries are in use by clients, and have refs &gt;= 2 and in_cache==true.</span></span><br><span class="line">  <span class="function">LRUHandle in_use_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">HandleTable table_ <span class="title">GUARDED_BY</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">LRUCache::<span class="built_in">LRUCache</span>() : <span class="built_in">capacity_</span>(<span class="number">0</span>), <span class="built_in">usage_</span>(<span class="number">0</span>) &#123;</span><br><span class="line">  <span class="comment">// Make empty circular linked lists.</span></span><br><span class="line">  lru_.next = &amp;lru_;</span><br><span class="line">  lru_.prev = &amp;lru_;</span><br><span class="line">  in_use_.next = &amp;in_use_;</span><br><span class="line">  in_use_.prev = &amp;in_use_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><code>LRUCache</code> 包含两大部分，<code>in_use_</code> （客户端正在使用的双向链表）和 <code>lru_</code> （ LRU 逻辑），这里和 LRUHandle 的逻辑有相关，LRUHandle 上有 <code>ref_</code>, 表示引用计数。<code>lru_</code> 也相当于我们之前 boost 那里的 <code>m_list_</code></li></ol><p>不过 <code>LRUHandle</code> 上还有个迷之字段 <code>next_hash</code>, 然后 HandleTable 又是什么样的呢？这就是今天的坑点了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">HandleTable</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">HandleTable</span>() : <span class="built_in">length_</span>(<span class="number">0</span>), <span class="built_in">elems_</span>(<span class="number">0</span>), <span class="built_in">list_</span>(<span class="literal">nullptr</span>) &#123; <span class="built_in">Resize</span>(); &#125;</span><br><span class="line">  ~<span class="built_in">HandleTable</span>() &#123; <span class="keyword">delete</span>[] list_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">LRUHandle* <span class="title">Lookup</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">uint32_t</span> hash)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> *<span class="built_in">FindPointer</span>(key, hash);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">LRUHandle* <span class="title">Insert</span><span class="params">(LRUHandle* h)</span> </span>&#123;</span><br><span class="line">    LRUHandle** ptr = <span class="built_in">FindPointer</span>(h-&gt;<span class="built_in">key</span>(), h-&gt;hash);</span><br><span class="line">    LRUHandle* old = *ptr;</span><br><span class="line">    h-&gt;next_hash = (old == <span class="literal">nullptr</span> ? <span class="literal">nullptr</span> : old-&gt;next_hash);</span><br><span class="line">    *ptr = h;</span><br><span class="line">    <span class="keyword">if</span> (old == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">      ++elems_;</span><br><span class="line">      <span class="keyword">if</span> (elems_ &gt; length_) &#123;</span><br><span class="line">        <span class="comment">// Since each cache entry is fairly large, we aim for a small</span></span><br><span class="line">        <span class="comment">// average linked list length (&lt;= 1).</span></span><br><span class="line">        <span class="built_in">Resize</span>();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> old;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">LRUHandle* <span class="title">Remove</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">uint32_t</span> hash)</span> </span>&#123;</span><br><span class="line">    LRUHandle** ptr = <span class="built_in">FindPointer</span>(key, hash);</span><br><span class="line">    LRUHandle* result = *ptr;</span><br><span class="line">    <span class="keyword">if</span> (result != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">      *ptr = result-&gt;next_hash;</span><br><span class="line">      --elems_;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// The table consists of an array of buckets where each bucket is</span></span><br><span class="line">  <span class="comment">// a linked list of cache entries that hash into the bucket.</span></span><br><span class="line">  <span class="type">uint32_t</span> length_;</span><br><span class="line">  <span class="type">uint32_t</span> elems_;</span><br><span class="line">  LRUHandle** list_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Return a pointer to slot that points to a cache entry that</span></span><br><span class="line">  <span class="comment">// matches key/hash.  If there is no such cache entry, return a</span></span><br><span class="line">  <span class="comment">// pointer to the trailing slot in the corresponding linked list.</span></span><br><span class="line">  <span class="function">LRUHandle** <span class="title">FindPointer</span><span class="params">(<span class="type">const</span> Slice&amp; key, <span class="type">uint32_t</span> hash)</span> </span>&#123;</span><br><span class="line">    LRUHandle** ptr = &amp;list_[hash &amp; (length_ - <span class="number">1</span>)];</span><br><span class="line">    <span class="keyword">while</span> (*ptr != <span class="literal">nullptr</span> &amp;&amp; ((*ptr)-&gt;hash != hash || key != (*ptr)-&gt;<span class="built_in">key</span>())) &#123;</span><br><span class="line">      ptr = &amp;(*ptr)-&gt;next_hash;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ptr;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Resize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">uint32_t</span> new_length = <span class="number">4</span>;</span><br><span class="line">    <span class="keyword">while</span> (new_length &lt; elems_) &#123;</span><br><span class="line">      new_length *= <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    LRUHandle** new_list = <span class="keyword">new</span> LRUHandle*[new_length];</span><br><span class="line">    <span class="built_in">memset</span>(new_list, <span class="number">0</span>, <span class="built_in">sizeof</span>(new_list[<span class="number">0</span>]) * new_length);</span><br><span class="line">    <span class="type">uint32_t</span> count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">uint32_t</span> i = <span class="number">0</span>; i &lt; length_; i++) &#123;</span><br><span class="line">      LRUHandle* h = list_[i];</span><br><span class="line">      <span class="keyword">while</span> (h != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        LRUHandle* next = h-&gt;next_hash;</span><br><span class="line">        <span class="type">uint32_t</span> hash = h-&gt;hash;</span><br><span class="line">        LRUHandle** ptr = &amp;new_list[hash &amp; (new_length - <span class="number">1</span>)];</span><br><span class="line">        h-&gt;next_hash = *ptr;</span><br><span class="line">        *ptr = h;</span><br><span class="line">        h = next;</span><br><span class="line">        count++;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">assert</span>(elems_ == count);</span><br><span class="line">    <span class="keyword">delete</span>[] list_;</span><br><span class="line">    list_ = new_list;</span><br><span class="line">    length_ = new_length;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>别看这个结构很复杂，实际上就是个链式 hash. 开辟了一个数组，然后用 <code>next_hash</code> 表示链，这个类似 absl 的 <code>flat_hash_set</code>, 而 set 的成员则是 <code>LRUHandle</code>, 那么这个时候，evict 的时候，可以直接通过 <code>hash</code> 和查表来定位。</p><p>相对 boost 的实现来说，这里可以算绕了个大圈子，但是 Google 表示这里有 5% 的性能收益（boost 可能受限于 hash table 的结构, 有空间上的开销和局部性上的开销）。</p><p>那么，还有一个问题是，为什么 <code>LRUHandle</code> 只存有 <code>next_hash</code>, 没有 <code>prev_hash</code>? 如果有 <code>prev_hash</code>, 那么 Erase 的时候甚至不需要查表。这里可以看看 <code>Insert</code> 代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">LRUHandle* <span class="title">Insert</span><span class="params">(LRUHandle* h)</span> </span>&#123;</span><br><span class="line">  LRUHandle** ptr = <span class="built_in">FindPointer</span>(h-&gt;<span class="built_in">key</span>(), h-&gt;hash);</span><br><span class="line">  LRUHandle* old = *ptr;</span><br><span class="line">  h-&gt;next_hash = (old == <span class="literal">nullptr</span> ? <span class="literal">nullptr</span> : old-&gt;next_hash);</span><br><span class="line">  *ptr = h;</span><br><span class="line">  <span class="keyword">if</span> (old == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">    ++elems_;</span><br><span class="line">    <span class="keyword">if</span> (elems_ &gt; length_) &#123;</span><br><span class="line">      <span class="comment">// Since each cache entry is fairly large, we aim for a small</span></span><br><span class="line">      <span class="comment">// average linked list length (&lt;= 1).</span></span><br><span class="line">      <span class="built_in">Resize</span>();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> old;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 这里大概要求 <code>next_hash</code> 链表不会很长, 然后不加上这个来节省空间。</p><h2 id="RocksDB-LRU"><a href="#RocksDB-LRU" class="headerlink" title="RocksDB LRU"></a>RocksDB LRU</h2><p>RocksDB 的 LRU 大致支持类似 LevelDB 的 LRU, 但是它支持类似 2-LRU，会在一定条件下，把 LRU 丢到高优队列中：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">enum</span> <span class="title class_">Flags</span> : <span class="type">uint8_t</span> &#123;</span><br><span class="line">    <span class="comment">// Whether this entry is referenced by the hash table.</span></span><br><span class="line">    IN_CACHE = (<span class="number">1</span> &lt;&lt; <span class="number">0</span>),</span><br><span class="line">    <span class="comment">// Whether this entry is high priority entry.</span></span><br><span class="line">    IS_HIGH_PRI = (<span class="number">1</span> &lt;&lt; <span class="number">1</span>),</span><br><span class="line">    <span class="comment">// Whether this entry is in high-pri pool.</span></span><br><span class="line">    IN_HIGH_PRI_POOL = (<span class="number">1</span> &lt;&lt; <span class="number">2</span>),</span><br><span class="line">    <span class="comment">// Whether this entry has had any lookups (hits).</span></span><br><span class="line">    HAS_HIT = (<span class="number">1</span> &lt;&lt; <span class="number">3</span>),</span><br><span class="line">  &#125;;</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">LRUCacheShard::LRU_Insert</span><span class="params">(LRUHandle* e)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">assert</span>(e-&gt;next == <span class="literal">nullptr</span>);</span><br><span class="line">  <span class="built_in">assert</span>(e-&gt;prev == <span class="literal">nullptr</span>);</span><br><span class="line">  <span class="type">size_t</span> total_charge = e-&gt;<span class="built_in">CalcTotalCharge</span>(metadata_charge_policy_);</span><br><span class="line">  <span class="keyword">if</span> (high_pri_pool_ratio_ &gt; <span class="number">0</span> &amp;&amp; (e-&gt;<span class="built_in">IsHighPri</span>() || e-&gt;<span class="built_in">HasHit</span>())) &#123;</span><br><span class="line">    <span class="comment">// Inset &quot;e&quot; to head of LRU list.</span></span><br><span class="line">    e-&gt;next = &amp;lru_;</span><br><span class="line">    e-&gt;prev = lru_.prev;</span><br><span class="line">    e-&gt;prev-&gt;next = e;</span><br><span class="line">    e-&gt;next-&gt;prev = e;</span><br><span class="line">    e-&gt;<span class="built_in">SetInHighPriPool</span>(<span class="literal">true</span>);</span><br><span class="line">    high_pri_pool_usage_ += total_charge;</span><br><span class="line">    <span class="built_in">MaintainPoolSize</span>();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// Insert &quot;e&quot; to the head of low-pri pool. Note that when</span></span><br><span class="line">    <span class="comment">// high_pri_pool_ratio is 0, head of low-pri pool is also head of LRU list.</span></span><br><span class="line">    e-&gt;next = lru_low_pri_-&gt;next;</span><br><span class="line">    e-&gt;prev = lru_low_pri_;</span><br><span class="line">    e-&gt;prev-&gt;next = e;</span><br><span class="line">    e-&gt;next-&gt;prev = e;</span><br><span class="line">    e-&gt;<span class="built_in">SetInHighPriPool</span>(<span class="literal">false</span>);</span><br><span class="line">    lru_low_pri_ = e;</span><br><span class="line">  &#125;</span><br><span class="line">  lru_usage_ += total_charge;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="近似-LRU-和其他方法"><a href="#近似-LRU-和其他方法" class="headerlink" title="近似 LRU 和其他方法"></a>近似 LRU 和其他方法</h2><p>可以看到，这里的 LRU 是带锁实现的。HashTable + doubly linked list 让它的并发变得比较麻烦。这里可以参考一下一些近似的 LRU 算法，在算法本身的性能上有相对好一些的开销：</p><ol><li>redis 的 LRU<ol><li>这里的 LRU 感觉一点都不 LRU，只是产生一个 LRU 时间，采样 key, 然后处理掉“ Least Recent Used” 的数据，是一个与概率的结合，本身靠采样 + 随机性实现</li></ol></li><li>RocksDB 的 clock 算法<ol><li>这里 clock 本身相对 LRU 来说好并行很多，RocksDB 这里用了 <code>tbb</code> 中的库来实现。</li></ol></li></ol><p>此外，也有 <a href="https://en.wikipedia.org/wiki/Adaptive_replacement_cache">Adaptive replacement cache</a> 这样的策略，或者 LFU 这样的策略。可以配合 bench 和 pprof ，配合自己的需求使用。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Linux-API:mmap&amp;flock</title>
      <link href="/2021/03/10/Linux-API-mmap-flock/"/>
      <url>/2021/03/10/Linux-API-mmap-flock/</url>
      
        <content type="html"><![CDATA[<h2 id="Linux-API-introduction-to-mmap-2-and-flock-2"><a href="#Linux-API-introduction-to-mmap-2-and-flock-2" class="headerlink" title="Linux API: introduction to mmap(2) and flock(2)"></a>Linux API: introduction to mmap(2) and flock(2)</h2><h2 id="mmap"><a href="#mmap" class="headerlink" title="mmap"></a>mmap</h2><p><code>mmap(2)</code> 比较折磨人，它的接口如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;sys/mman.h&gt;</span><br><span class="line"></span><br><span class="line">void *mmap(void *addr, size_t length, int prot, int flags,</span><br><span class="line">           int fd, off_t offset);</span><br><span class="line">int munmap(void *addr, size_t length);</span><br></pre></td></tr></table></figure><p>mmap 有两种 mapping:</p><ol><li>file mapping</li><li>anonymous mapping</li></ol><p>对于 1，<code>fd</code> 在 <code>mmap</code> 后可以 <code>close</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">After the mmap() call has returned, the file descriptor, fd, can</span><br><span class="line">be closed immediately without invalidating the mapping.</span><br></pre></td></tr></table></figure><p><code>mmap</code> 的 <code>prot</code> 有下列的语义：</p><ol><li><code>PROT_EXEC</code>: Pages may be executed.</li><li><code>PROT_READ</code>: Pages may be read.</li><li><code>PROT_WRITE</code>: Pages may be written.</li><li><code>PROT_NONE</code>:Pages may not be accessed.</li></ol><p>mmap 的逻辑和 os 的 <code>page cache</code> 强相关，上述语义可能作用在 page 上，必要的时候给你个 <code>SIGSEGV</code></p><p><code>rwx</code> 三个选项都理解，<code>PROT_NONE</code> 可能用于做 Guard Page: <a href="https://stackoverflow.com/questions/12916603/what-s-the-purpose-of-mmap-memory-protection-prot-none">https://stackoverflow.com/questions/12916603/what-s-the-purpose-of-mmap-memory-protection-prot-none</a></p><p>同时，<code>flags</code> 也有许多选项，除了 <code>MAP_NONBLOCK</code> <code>MAP_LOCKED</code> 这些，需要留意 <code>MAP_SHARED</code> 和 <code>MAP_PRIVATE</code> , 使用可以见下表。</p><p><img src="https://image.mwish.me/blog-image/0E0F6E12-FAB6-434A-8177-68F7CFE39FB2.png" alt="0E0F6E12-FAB6-434A-8177-68F7CFE39FB2"></p><p>上述也会影响 <code>fork</code> 的时候父子进程的 <code>mmap</code> 行为（可以回到一下之前对 <code>fork</code> 的吐槽）</p><h3 id="文件映射"><a href="#文件映射" class="headerlink" title="文件映射"></a>文件映射</h3><p><code>mmap</code> 的时候，文件会被按照 <code>offset</code> 和 <code>length</code> 映射到内存中，如图：</p><p><img src="https://image.mwish.me/blog-image/0FCE129310878CAB48CB0E6D47DC8169.png" alt="0FCE129310878CAB48CB0E6D47DC8169"></p><p>这种 mapping 可能是 on-demand 的，即 <code>mmap</code> 之后不把 page 加载，需要的时候再访问。</p><p>对于 <code>MAP_PRIVATE</code>, 它可以：</p><ul><li>被用在 <code>PROT_READ | PROT_EXEC</code> , 运行程序，这样不会修改程序的数据</li><li>共享一个只读的 <code>.text</code></li></ul><p>而共享的文件则如下图所示：</p><p><img src="https://image.mwish.me/blog-image/6CFC2E40-CF95-4C33-B6F9-D6836D857F80.png" alt="6CFC2E40-CF95-4C33-B6F9-D6836D857F80"></p><p>这种 memory mapping IO 会有特点：文件和 kernel 的 buffer 是由 os 自动 manage 的，同时，内核和用户进程不再和 write 一样，先写用户 buffer, 再写 kernel buffer.</p><p>当需要强制 flush 的时候，可以走 <code>msync(2)</code> 来强制刷盘</p><p>mmap 的映射可能比文件本身还大，未来的内存可能需要 <code>ftruncate</code> 处理：</p><p><img src="https://image.mwish.me/blog-image/D3EA25A8-9FBE-4215-8CCF-408BAF69183C.png" alt="D3EA25A8-9FBE-4215-8CCF-408BAF69183C"></p><h3 id="匿名映射"><a href="#匿名映射" class="headerlink" title="匿名映射"></a>匿名映射</h3><p>数据会被初始化为 0</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">MAP_ANONYMOUS</span><br><span class="line">       The mapping is not backed by any file; its contents are</span><br><span class="line">       initialized to zero.  The fd argument is ignored; however,</span><br><span class="line">       some implementations require fd to be -1 if MAP_ANONYMOUS</span><br><span class="line">       (or MAP_ANON) is specified, and portable applications</span><br><span class="line">       should ensure this.  The offset argument should be zero.</span><br><span class="line">       The use of MAP_ANONYMOUS in conjunction with MAP_SHARED is</span><br><span class="line">       supported on Linux only since kernel 2.4.</span><br></pre></td></tr></table></figure><h3 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h3><p><code>mprotect(2)</code> 切换进程页的访问权限</p><p><code>mlock</code> 会讲内存 Page 驻留在物理内存中，不会swap 出去</p><h3 id="madvise-2"><a href="#madvise-2" class="headerlink" title="madvise(2)"></a>madvise(2)</h3><p>用户改内核的代码和调度是不现实的，但是很多时候用户比内核自己清楚需要调度成啥样。</p><p><code>madvise(2)</code> 相当于提供上述相关的信息，“建议”内核做相关的操作。详见：<a href="https://www.man7.org/linux/man-pages/man2/madvise.2.html">https://www.man7.org/linux/man-pages/man2/madvise.2.html</a></p><h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><p>BoltDB 的读取使用了 <code>mmap</code>. 内存空间是小于磁盘的，而 bolt 没有自己写 BufferPool, 而是用了 mmap, 可以看看代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// mmap memory maps a DB&#x27;s data file.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">mmap</span><span class="params">(db *DB, sz <span class="type">int</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line"><span class="comment">// Map the data file to memory.</span></span><br><span class="line">b, err := syscall.Mmap(<span class="type">int</span>(db.file.Fd()), <span class="number">0</span>, sz, syscall.PROT_READ, syscall.MAP_SHARED|db.MmapFlags)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Advise the kernel that the mmap is accessed randomly.</span></span><br><span class="line"><span class="keyword">if</span> err := madvise(b, syscall.MADV_RANDOM); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> fmt.Errorf(<span class="string">&quot;madvise: %s&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Save the original byte slice and convert to a byte array pointer.</span></span><br><span class="line">db.dataref = b</span><br><span class="line">db.data = (*[maxMapSize]<span class="type">byte</span>)(unsafe.Pointer(&amp;b[<span class="number">0</span>]))</span><br><span class="line">db.datasz = sz</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>DB::mmap</code> 具体走到 <code>bolt_unix.go</code> 下的 <code>mmap</code>, 这里用 <code>madvise</code> + <code>MADV_RANDOM</code> 来表达访问的模式，同时把这次数据存储到 <code>db</code> 上</p><p><code>dataref</code> 防止 <code>syscall.Mmap</code> 的结果被回收，具体访问的数据被丢到 <code>data</code> 上。</p><p><code>munmap</code> 是一个反向操作：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// munmap unmaps a DB&#x27;s data file from memory.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">munmap</span><span class="params">(db *DB)</span></span> <span class="type">error</span> &#123;</span><br><span class="line"><span class="comment">// Ignore the unmap if we have no mapped data.</span></span><br><span class="line"><span class="keyword">if</span> db.dataref == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Unmap using the original byte slice.</span></span><br><span class="line">err := syscall.Munmap(db.dataref)</span><br><span class="line">db.dataref = <span class="literal">nil</span></span><br><span class="line">db.data = <span class="literal">nil</span></span><br><span class="line">db.datasz = <span class="number">0</span></span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="flock"><a href="#flock" class="headerlink" title="flock"></a>flock</h2><p><a href="https://man7.org/linux/man-pages//man2/flock.2.html">https://man7.org/linux/man-pages//man2/flock.2.html</a></p><p><code>flock(2)</code> 源自 BSD，<code>flock</code> 可以指定 <code>LOCK_SH</code> 和 <code>LOCK_EX</code>, 表示共享/互斥，也可以 <code>LOCK_UN</code> 解锁</p><p>本身调用 <code>flock</code> 会阻塞进程，不希望阻塞可以带上 <code>LOCK_UB</code> flag</p><p><code>flock</code> 本身和 <code>fd</code> 是绑定的，也就是说，<code>dup</code> 产生的 fd 和 <code>fork</code> 子进程 产生的 fd 是同一把锁，这意味着，对它们的 <code>LOCK_UN</code> 处理需要额外注意。</p><p><img src="https://image.mwish.me/blog-image/46EDACEC-B756-477A-877C-302378852132.png" alt="46EDACEC-B756-477A-877C-302378852132"></p><p>可以参考一下代码的 <code>flock</code> 和 <code>funlock</code>, 内容在 <code>bolt_unix.go</code>:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">flock</span><span class="params">(db *DB, mode os.FileMode, exclusive <span class="type">bool</span>, timeout time.Duration)</span></span> <span class="type">error</span> &#123;</span><br><span class="line"><span class="keyword">var</span> t time.Time</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="comment">// If we&#x27;re beyond our timeout then return an error.</span></span><br><span class="line"><span class="comment">// This can only occur after we&#x27;ve attempted a flock once.</span></span><br><span class="line"><span class="keyword">if</span> t.IsZero() &#123;</span><br><span class="line">t = time.Now()</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> timeout &gt; <span class="number">0</span> &amp;&amp; time.Since(t) &gt; timeout &#123;</span><br><span class="line"><span class="keyword">return</span> ErrTimeout</span><br><span class="line">&#125;</span><br><span class="line">flag := syscall.LOCK_SH</span><br><span class="line"><span class="keyword">if</span> exclusive &#123;</span><br><span class="line">flag = syscall.LOCK_EX</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Otherwise attempt to obtain an exclusive lock.</span></span><br><span class="line">err := syscall.Flock(<span class="type">int</span>(db.file.Fd()), flag|syscall.LOCK_NB)</span><br><span class="line"><span class="keyword">if</span> err == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> err != syscall.EWOULDBLOCK &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Wait for a bit and try again.</span></span><br><span class="line">time.Sleep(<span class="number">50</span> * time.Millisecond)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// funlock releases an advisory lock on a file descriptor.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">funlock</span><span class="params">(db *DB)</span></span> <span class="type">error</span> &#123;</span><br><span class="line"><span class="keyword">return</span> syscall.Flock(<span class="type">int</span>(db.file.Fd()), syscall.LOCK_UN)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的 <code>funlock</code> 比较朴素，<code>flock</code> 采取了 <code>LOCK_NB</code> 和一个 retry 尝试结合，超过 timeout 后，程序会自动退出。</p><p><code>flock</code> 只能以文件为粒度上锁，需要更细的控制需要使用 <code>fcntl</code> 。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/71517406">https://zhuanlan.zhihu.com/p/71517406</a></li><li><a href="https://man7.org/linux/man-pages/man2/mmap.2.html">https://man7.org/linux/man-pages/man2/mmap.2.html</a></li><li>BoltDB: <a href="https://github.com/boltdb/bolt">https://github.com/boltdb/bolt</a></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Notes on Query Optimization</title>
      <link href="/2021/02/08/Notes-on-Query-Cost-Estimation/"/>
      <url>/2021/02/08/Notes-on-Query-Cost-Estimation/</url>
      
        <content type="html"><![CDATA[<p>上一节我们介绍了 executor, 这节是优化器的入门。用户的 SQL 可以用某种关系代数的表达式表示。同时，我们可以利用关系代数推出某种等价性，两个关系表达式在所有可能的 db 集合都会产生相同元素集，那么这两个表达式是 等价(equivalent) 的。</p><p>上面我翻译的有点垃圾，贴下原文：</p><blockquote><p>Two relational-algebra expressions are said to be <strong>equivalent</strong> if, on every legal data- base instance, the two expressions generate the same set of tuples. (Recall that a legal database instance is one that satisfies all the integrity constraints specified in the data- base schema.) </p><p>Note that the order of the tuples is irrelevant; the two expressions may generate the tuples in different orders, but would be considered equivalent as long as the set of tuples is the same.</p></blockquote><p>DB 优化的过程需要：</p><ol><li>生成与给定 expression 逻辑等价的表达式</li><li>产生不同的查询计划</li><li>估计每个 Plan 的开销，选择代价最小的</li></ol><p>完成 (1) 需要有一些等价规则：</p><blockquote><p>To implement the first step, the query optimizer must generate expressions equiv- alent to a given expression. It does so by means of <em>equivalence rules</em> that specify how to transform an expression into a logically equivalent one.</p></blockquote><p>随即我们获得2，然后根据一些固定规则或者统计信息来进行优化。</p><p>Equivalent Rules 建议阅读原书，感觉我怎么讲都是把它们图贴一遍…总的来说，这些 rules 有下列的含义：</p><ul><li>关系代数有一些等价规则，我们希望，部分规则适用以后，产生等价于原始关系的结果，但产生较少中间关系</li><li>A set of equivalence rules is said to be <strong>minimal</strong> if no rule can be derived from any combination of the others. </li></ul><p>此外，一些 Join 相关的，也能根据索引、公共属性等 Rules 来处理。</p><p><img src="https://image.mwish.me/blog-image/F86C9C0C-6F5F-4EB7-ACC7-9DD1DFA17AF9.png" alt="F86C9C0C-6F5F-4EB7-ACC7-9DD1DFA17AF9"></p><p>上面的 <code>genAllEquivalent(E)</code> , 对于给定的 Expression <code>E</code> , 生成所有的等价表达式, 中间的部分阶段可以被称为 transformation。</p><p>等等，上面你肯定觉得太废了，实际上，我们可以减少开销：</p><ul><li>E 和 E’ 可以在内存中共享一些表达式，感觉类似 COW-Tree 那样</li><li>如果 Optimizer 在这个阶段分析 cost, 那么它能够减少很多不必要的生成。</li></ul><blockquote><p>Some query optimizers use equivalence rules in a heuristic manner. With such an approach, if the left-hand side of an equivalence rule matches a subtree in a query plan, the subtree is rewritten to match the right-hand side of the rule. This process is repeated till the query plan cannot be further rewritten. Rules must be carefully chosen such that the cost decreases when a rule is applied, and rewriting must eventually terminate. Although this approach can be implemented to execute quite fast, there is no guarantee that it will find the optimal plan.</p></blockquote><p>上述描述的是 RBO 的概念，</p><blockquote><p>Yet other query optimizers focus on join order selection, which is often a key factor in query cost. We discuss algorithms for join-order optimization in Section 16.4.1.</p></blockquote><h2 id="Estimating-Statictics"><a href="#Estimating-Statictics" class="headerlink" title="Estimating Statictics"></a>Estimating Statictics</h2><p>一个操作的代价依赖于统计信息，例如：</p><ul><li>走不走某个索引？如果你要查的数据少的话，走索引能大大优化性能，但是你本身查询数据大，又要回表，那你就相当于白走一趟。</li><li>走哪个索引？我们现在有很多索引，你要挑选可能比较少的一个来走。</li><li>Join 的顺序，我们怎么 Join 才能代价比较小</li></ul><p>同时，我们不能先验知道所有数据，比如用户传了一个 <code>a &gt; 5 &amp;&amp; a &lt; 10</code>, 那对应的行应该有多少呢？这个问题可能影响上述的决策。</p><p>数据库系统的 Catalog 可能包含下列信息：</p><ul><li>$n_r$ , 包含 r 的 tuple 数目</li><li>$b_r$, r 相关的 tuple 数目</li><li>$l_r$ ，关系 r 中每个 tuple 包含的 bytes</li><li>$f_r$, 一个磁盘块能容纳 r 中 tuple 的个数</li><li>$V(A, r)$, 关系 r 中属性 A 的非重复值个数。</li></ul><p>索引相关的，比如 B+Tree 的信息，或者有没有索引，可能也可以维护在 Catalog 中。</p><p>此外，db 可以维护一个 histogram:</p><p><img src="https://image.mwish.me/blog-image/3CDD7A79-37C8-4B1E-8CA5-2B55F8E8587B.png" alt="3CDD7A79-37C8-4B1E-8CA5-2B55F8E8587B"></p><p>通过直方图，来表示细粒度区间的取值。否则，db 可能会只保存最大值和最小值，然后假设数据分布是均匀的。</p><p>那么，我们有以上信息之后，可以做一些基本的估计：</p><ul><li>$\sigma_{A=v}(r)$  均匀分布的情况下，可选有 $n_r / V(A, r)$ 个 tuple, 如果有直方图的话，可以在直方图对应取值定位。</li><li>$\sigma_{A&lt;v}(r)$ 等同理</li><li>Conjunction/Disjunction 中，假设个条件独立，有下列计算方式：<br><img src="https://image.mwish.me/blog-image/513E6593-9478-41F7-A551-5315F009DA2F.png" alt="513E6593-9478-41F7-A551-5315F009DA2F"><br><img src="https://image.mwish.me/blog-image/304D1058-66C2-45B4-8A84-5AE5AF25CFA5.png" alt="304D1058-66C2-45B4-8A84-5AE5AF25CFA5"></li></ul><p>特别地指出，有一些特殊的高频值，可以被特殊的单独记录到一个高频值集合中。然后这些值的估计可以走这个单独的几何，来防止这些特殊值影响统计。</p><h3 id="Join-size-Estimation"><a href="#Join-size-Estimation" class="headerlink" title="Join size Estimation"></a>Join size Estimation</h3><ul><li>笛卡尔积大小就是 * 一下得了，反而最简单，$r \times s$ 就可以了，产生结果每个 tuple 大小 $l_r + l_s$</li></ul><p>估计自然连接的大小会复杂很多：</p><ul><li>$R \cap S = \emptyset $ ，退化为笛卡尔积的计算方式</li><li>如果 join 的是 R 的 key, 那元素至多不会多于 S。这个可以用 $V(A, s)$ 来做一个估计：<ul><li>对一个 R 中的 tuple t，可能会与 $n_s / V(A, s)$ 的产生连接</li><li>所以总共 $(n_r * n_s) / V(A, s)$ 组</li><li>但是上面是在各个概率相等的情况下出现的，实际上可能需要更复杂的区间统计。同时另一种算法会给出  $(n_r * n_s) / V(A, r)$, 一般取小的</li></ul></li></ul><h3 id="其他估计"><a href="#其他估计" class="headerlink" title="其他估计"></a>其他估计</h3><p><img src="https://image.mwish.me/blog-image/FCC0B444-CCC3-4E26-9767-2A887566FBBB.png" alt="FCC0B444-CCC3-4E26-9767-2A887566FBBB"></p><h3 id="查询结果的分析"><a href="#查询结果的分析" class="headerlink" title="查询结果的分析"></a>查询结果的分析</h3><p>假如我们需要 $V(A, \sigma_{\theta}(r))$, 那我们要对他内部分析：</p><ol><li>可以取它为 A 等于单个值，或者 A 等于一个集合</li><li>可以乘以一个系数 $V(A, r) * s$, s 为系数</li><li>可以用一些更精确的概率来分析</li></ol><p>假如我们要估计 Join 的结果：</p><p><img src="https://image.mwish.me/blog-image/68AFA23D-75CC-4247-9468-5E944A08F7CF.png" alt="68AFA23D-75CC-4247-9468-5E944A08F7CF"></p><p>简单来说，看 Join 条件是独立的，跟A有关，跟B有关，还是都有关，然后根据概率来估计</p><h2 id="信息收集"><a href="#信息收集" class="headerlink" title="信息收集"></a>信息收集</h2><p>如果每个 Update 都收集统计信息就太废了。一来系统有 HLL 这些模糊方式，和采样，二来系统可以在一段时间后手动 analyze 或者自动重建统计信息。</p><p>MySQL 的 InnoDB 中，有一个 <code>innodb_table_stats</code> 表，大概内容如下：</p><p>它的配置可以参考：<a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-performance-optimizer-statistics.html">https://dev.mysql.com/doc/refman/5.7/en/innodb-performance-optimizer-statistics.html</a></p><p>大概信息如：</p><div class="table-container"><table><thead><tr><th style="text-align:left">Field</th><th style="text-align:left">Type</th><th style="text-align:left">Null</th><th style="text-align:left">Key</th><th style="text-align:left">Default</th><th style="text-align:left">Description</th></tr></thead><tbody><tr><td style="text-align:left"><code>database_name</code></td><td style="text-align:left"><code>varchar(64)</code></td><td style="text-align:left">NO</td><td style="text-align:left">PRI</td><td style="text-align:left"><code>NULL</code></td><td style="text-align:left">Database name.</td></tr><tr><td style="text-align:left"><code>table_name</code></td><td style="text-align:left"><code>varchar(64)</code></td><td style="text-align:left">NO</td><td style="text-align:left">PRI</td><td style="text-align:left"><code>NULL</code></td><td style="text-align:left">Table, partition or subpartition name.</td></tr><tr><td style="text-align:left"><code>last_update</code></td><td style="text-align:left"><code>timestamp</code></td><td style="text-align:left">NO</td><td style="text-align:left"></td><td style="text-align:left"><code>current_timestamp()</code></td><td style="text-align:left">Time that this row was last updated.</td></tr><tr><td style="text-align:left"><code>n_rows</code></td><td style="text-align:left"><code>bigint(20) unsigned</code></td><td style="text-align:left">NO</td><td style="text-align:left"></td><td style="text-align:left"><code>NULL</code></td><td style="text-align:left">Number of rows in the table.</td></tr><tr><td style="text-align:left"><code>clustered_index_size</code></td><td style="text-align:left"><code>bigint(20) unsigned</code></td><td style="text-align:left">NO</td><td style="text-align:left"></td><td style="text-align:left"><code>NULL</code></td><td style="text-align:left">Size, in pages, of the primary index.</td></tr><tr><td style="text-align:left"><code>sum_of_other_index_sizes</code></td><td style="text-align:left"><code>bigint(20) unsigned</code></td><td style="text-align:left">NO</td><td style="text-align:left"></td><td style="text-align:left"><code>NULL</code></td><td style="text-align:left">Size, in pages, of non-primary indexes.</td></tr></tbody></table></div>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Notes-on-Query-Execution:part1</title>
      <link href="/2021/02/08/Notes-on-Query-Execution/"/>
      <url>/2021/02/08/Notes-on-Query-Execution/</url>
      
        <content type="html"><![CDATA[<p>SQL 是用户使用的，数据库会把 SQL 转换成某种内部表示，类似于扩展的关系代数。</p><p>关于词法、语法解析的部分，比较幸运的是，很多书都介绍了怎么处理 SQL:</p><ul><li><a href="https://book.douban.com/subject/6109479/">https://book.douban.com/subject/6109479/</a></li><li><a href="https://book.douban.com/subject/27082372/">https://book.douban.com/subject/27082372/</a></li></ul><p><img src="https://image.mwish.me/blog-image/A23D3A76-BC84-4873-A2C1-74DA42F1F795.png" alt="A23D3A76-BC84-4873-A2C1-74DA42F1F795"></p><p>Query-evaluation Engine 处理给定的 Plan, 执行这个 Plan, 然后把结果返回给查询。</p><h2 id="查询的代价"><a href="#查询的代价" class="headerlink" title="查询的代价"></a>查询的代价</h2><p><a href="https://colin-scott.github.io/personal_website/research/interactive_latency.html">https://colin-scott.github.io/personal_website/research/interactive_latency.html</a></p><p>上面是每年的 Latency Numbers Every Programmer Should Know</p><p>2020 年：</p><ol><li>Main memory reference: 100ns</li><li>SSD random read: 16000ns</li><li>1,000,000 bytes sequentially from SSD: 49, 000ns</li><li>Disk seek: 2ms</li><li>1,000,000 bytes sequentially from dosl: 825, 000 ns</li></ol><p>书上作者举的是2018年的例子，HDD Seek + 传送数据可以以10ms为单位，SSD则快得多，经常处在亚0.1 ms 级。（结合我这边生产，感觉基本没有用 HDD 的了…不晓得存储会不会这么搞）</p><p>此外，有些东西会让这些统计变得更复杂：</p><ol><li>无论用 <code>mmap</code> 还是手写 buffer pool，读写的很大一部分势必在内存中</li><li>如果系统有多个 disk, 那么并行访问多个 disk 可能能比在一个 disk 上 IO 快很多</li></ol><p>下面介绍了 Postgres 的策略：</p><blockquote><p>In addition, although we assume that data must be read from disk initially, it is possible that a block that is accessed is already present in the in-memory buffer. Again, for simplicity, we ignore this effect; as a result, the actual disk-access cost during the execution of a plan may be less than the estimated cost. To account (at least partially) for buffer residence, PostgreSQL uses the following “hack”: the cost of a random page read is assumed to be 1/10th of the actual random page read cost, to model the situation that 90% of reads are found to be resident in cache.</p></blockquote><h2 id="Selection"><a href="#Selection" class="headerlink" title="Selection"></a>Selection</h2><p>下面介绍一下 B+Tree 的一些参数：</p><ol><li>$h_i$ B+Tree 的高度。</li><li>$t_s$ : block-access time (disk seek time plus rotational latency) ， 对于 SSD，2018 年大约是 90 microseconds；对于 HDD,2018 年大概是 4ms</li><li>$t_T$ 单个 block 数据传输的时间，对于 SSD，有 10 microseconds for a 4-kilobyte block. 对于 HDD，这个速度慢得多</li></ol><p>（2021年还有人用 HDD 做 DB 吗？这也太慢了，氪金就是力量诶）</p><p>那么，开销大概是：</p><p><img src="https://image.mwish.me/blog-image/CC050B3A-1569-42B4-9924-18A91D72DAD9.png" alt="CC050B3A-1569-42B4-9924-18A91D72DAD9"></p><p>给出一个 A2 的参考 Cluster Index Equality on Key: $(h_i + 1) * (t_T + t_s)$ . 在 cluster index找到就可以，路径都需要读到。</p><p>A3 则是因为大概要找到 left-most page，然后执行 A1 类似的逻辑。以此类推。</p><p>有上述内容，我们大概可以知道 MySQL 里面查询、回表之类的代价估计了。</p><p>不过上述 cluster index 和 secondary index 就涉及到了索引选择的问题。如果满足要求的数据很多，那就直接走 cluster index 了，否则数据少的话走 secondary index 优化，岂不美哉。</p><p>Postgres 实现了 bitmap index scan, 走 index 挑出需要 scan 的 block, 再决定具体的行为。可以看：<a href="https://dba.stackexchange.com/questions/119386/understanding-bitmap-heap-scan-and-bitmap-index-scan">https://dba.stackexchange.com/questions/119386/understanding-bitmap-heap-scan-and-bitmap-index-scan</a></p><h3 id="Conjunction-Disjunction-Negation"><a href="#Conjunction-Disjunction-Negation" class="headerlink" title="Conjunction/Disjunction/Negation"></a>Conjunction/Disjunction/Negation</h3><p>这…表面上懂的都懂，但这里涉及一个问题：假如有多于一个索引，索引选择怎么办</p><blockquote><p>To reduce the cost, we choose a θ<em>i</em> and one of algorithms A1 through A6 for which the combination results in the least cost for σθ<em>i</em> (<em>r</em>). The cost of algorithm A7 is given by the cost of the chosen algorithm.</p></blockquote><p>一种方式如上述 A7，根据 cost 选择一个代价最低的索引</p><p>另一种方式 A8 是走 <strong>composite index</strong>（中文似乎叫联合索引）。</p><p>A9 需要有对应的 UID 来做 tuple 标示，它会走多个索引，然后取相同的 uid。</p><p>Disjunction 需要所有的路径都可以走 index, 否则退化成 Linear Scan.</p><h2 id="Sorting"><a href="#Sorting" class="headerlink" title="Sorting"></a>Sorting</h2><p>(我感觉排序这种在面试里面出现过一万遍了，然后数据结构书一般都讲了外排序吧…)</p><p>$M$ 系统可以提供给 sort 的 block 数目</p><p>$b_b$ 被定义为 N-way Merge 阶段可以处理的 block 数目</p><p>$b_r$ 为这个 relation 的 block 数量</p><p><img src="https://image.mwish.me/blog-image/2B0B9940-9714-42AD-989A-5CAE288F3F97.png" alt="2B0B9940-9714-42AD-989A-5CAE288F3F97"></p><ol><li>第一次产生了 $b_r$ 的 block 输出，IO 大致为 $b_r / M$</li><li>每一次能够处理 $M / b_b$ 次</li><li>产生了上述结果</li></ol><p>可以看看 TiDB 的外部排序：<a href="https://github.com/pingcap/tidb/issues/12431">https://github.com/pingcap/tidb/issues/12431</a></p><h2 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h2><p>首先贴一下书上给的模型吧：</p><p><img src="https://image.mwish.me/blog-image/BE84D5FA-B143-4EA3-9AE8-5EE764779368.png" alt="BE84D5FA-B143-4EA3-9AE8-5EE764779368"></p><p>（想起了我们说唱大学，因为数据库没什么考的，所以要把书上给的 Schema 背下来，然后默写 SQL，真的傻逼）</p><h3 id="Nested-loop-join-Block-Nested-loop-join"><a href="#Nested-loop-join-Block-Nested-loop-join" class="headerlink" title="Nested-loop join / Block Nested-loop join"></a>Nested-loop join / Block Nested-loop join</h3><p>真的有人在用吗…</p><p>简单说：Nest-loop Join 就是搞两个循环来 Join; Block Nest-loop Join 就是针对关系的 block 搞两个循环，内层走 nest-loop join.</p><p>不过值得注意的是，外层的 tuple 只会 Scan 一遍，内层的会 Scan 很多遍。理智告诉我们应该把内层的放小一点。</p><p>实际上，考虑到类似的场景，例如 broadcast join: <a href="https://jaceklaskowski.gitbooks.io/mastering-spark-sql/content/spark-sql-joins-broadcast.html">https://jaceklaskowski.gitbooks.io/mastering-spark-sql/content/spark-sql-joins-broadcast.html</a> 其实思路也差不多</p><p><img src="https://image.mwish.me/blog-image/65D7BD6A-CD41-4656-8A08-A0C4A33FDBA4.png" alt="65D7BD6A-CD41-4656-8A08-A0C4A33FDBA4"></p><p>上述方法能够减少内层 IO ，因为我们一次性读取了多个外层 block, 减少了循环的次数。</p><h3 id="Indexed-Nested-loop-Join"><a href="#Indexed-Nested-loop-Join" class="headerlink" title="Indexed Nested-loop Join"></a>Indexed Nested-loop Join</h3><p><img src="https://image.mwish.me/blog-image/B4BF6308-9A34-43D2-9B7E-6133055B1E96.png" alt="B4BF6308-9A34-43D2-9B7E-6133055B1E96"></p><blockquote><p>Although the number of block transfers has been reduced, the seek cost has actually increased, increasing the total cost since a seek is considerably more expensive than a block transfer. However, if we had a selection on the <em>student</em> relation that reduces the number of rows significantly, indexed nested-loop join could be significantly faster than block nested-loop join.</p></blockquote><p>其实看上去有优势，但是并没有好多少。</p><h3 id="Sort-Merge-Join"><a href="#Sort-Merge-Join" class="headerlink" title="Sort-Merge Join"></a>Sort-Merge Join</h3><p>这个去掉了 loop 的形式，采取 sort ，然后在有序的区间内作 equal 的操作。</p><p>Merge 的操作是 $M + N$, sort 的操作如之前所叙述。此外，在 worst case 中，如果两个关系中所有的 join key 都一样，那么 Merge 的操作会退化到 $M * N$</p><p>此外，有一种 <strong>Hybrid merge-join</strong> 的算法, 如果关系 A 走在 cluster index 或者已经有排序，关系 B 可以走 secondary index。那么可以 A 和 B merge, 再去 B 做类似 index bitmap scan 的操作。为什么需要这样呢？如果两边都是 secondary index 才能 Join 的话，可能会有莫名其妙的 IO 代价放大。</p><h3 id="Hash-Join"><a href="#Hash-Join" class="headerlink" title="Hash Join"></a>Hash Join</h3><p>先看看书上的形式化定义：</p><p><img src="https://image.mwish.me/blog-image/467B05FF-55E6-4952-8DBA-B7B9006131AD.png" alt="467B05FF-55E6-4952-8DBA-B7B9006131AD"></p><p>(实际上这里用的是 grace hash join)</p><p><img src="https://image.mwish.me/blog-image/B37A2209-60C4-455D-8C49-9E3E1051290A.png" alt="B37A2209-60C4-455D-8C49-9E3E1051290A"></p><p>这里分为 build phase 和 probe phase。如果 s 能装在内存中，那就直接在内存中哈希，然后扫 r。</p><p>否则给 s 和 r 构建 hash index, 然后每个相同的 hash 做 nested loop join 的操作。</p><p>这里问题是：</p><p>Skew/Overflow: 数据可能倾斜，这里可以避免产生过大的 block, 或者递归走 hash build</p><p>关于 hash join, 这里有一些性能分析：</p><p>对于 grace hash join, 每个 block 要：</p><ol><li>读取一遍，然后哈希写入一遍，这是一个 pass</li><li>再读取一遍，做 nested loop join, 这是一个 pass</li></ol><p>此外，哈希会造成 $n_h$ 的冗余 block 开销，所以，这里的开销是：</p><p>$3(b_r + b_s) + 4n_h$</p><p>在递归的情况下，我们要利用到因子 $M$ 得到：</p><p><img src="https://image.mwish.me/blog-image/7CF38D96-CEAE-4BAC-9F35-811B82023EBA.png" alt="7CF38D96-CEAE-4BAC-9F35-811B82023EBA"></p><p>15-445 指出，一般来说 hash join 有着比较好的效率，不过已排序/要排序的数据，可以使用 sort join</p><p>如果内层关系很小，且外层可以走索引，那 Index Nested Loop Join 会不错，否则可以试试 Hash Join，这个应该需要根据统计信息来判定。</p><h4 id="Hybrid-Hash-Join"><a href="#Hybrid-Hash-Join" class="headerlink" title="Hybrid Hash Join"></a>Hybrid Hash Join</h4><p>hybrid hash join 做了内存足够的时候，执行上的优化，这里考虑的场景是「内存比较大，但是整个 Hash Join 也不是完全放得下」的场景。之前考虑过 s 全部构件在内存或者写到盘上的情况的情况，感觉 hybrid hash join 构建了一个半 on-disk hash，来优化这个操作。我们构造一个 $s_0$, 它包含:</p><ul><li>先将一个关系切分成 t 在内存中，k - t 在盘上，然后哈希</li><li>另一个关系 load 起来 t 份和之前的关系直接处理，剩下的部分再走盘上哈希的流程。</li></ul><p>以此来优化。</p><h3 id="杂项：优化"><a href="#杂项：优化" class="headerlink" title="杂项：优化"></a>杂项：优化</h3><p>使用 bloom filter 来优化 Join</p><h2 id="其他运算"><a href="#其他运算" class="headerlink" title="其他运算"></a>其他运算</h2><h3 id="Duplicate-Elimination"><a href="#Duplicate-Elimination" class="headerlink" title="Duplicate Elimination"></a>Duplicate Elimination</h3><ul><li>使用 hashing 或者 sorting 去重</li><li>有些 DB 有 HLL 之类的模糊手段</li></ul><h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><p>大体是构建 hash map 甚至 on-disk hash, 然后 probe.</p><h3 id="Aggregation"><a href="#Aggregation" class="headerlink" title="Aggregation"></a>Aggregation</h3><p>感觉是一个另类的统计，我实现的时候构建过一个统计的 hash, 统计完之后遍历取信息。这里有不同的方案：</p><ol><li>在构造过程中（类似流式的）取信息</li><li>走 Hashing 来构造</li></ol><p>正常情况下，能不 swap 到盘上还是不 swap 到盘上吧，但是算子之间肯定还是有区别的。</p><h2 id="查询执行"><a href="#查询执行" class="headerlink" title="查询执行"></a>查询执行</h2><p>15-445 应该介绍过 DB 的查询执行。比较传统的执行方式是 volcano 模型，这个模型和当时的硬件结构是有关的。同时，我们也知道 vectorize 和 codegen 等模型。我们可以在 <code>MonetDB/X100</code> 和  Efficiently Compiling Efficient Query Plans for Modern Hardware 这两篇论文找到对应的答案。</p><p>这里表达式执行可以分为：</p><ol><li>物化执行（materialized evaluation）：中间关系的结果需要被物化</li><li>流水线执行（pipeline evaluation）：可以减少临时文件（物化输出）的数量，将结果能直接输出给下一个表达式。这种方式能够消除读写中间输出的代价。其中，也能够这样区分对应的输出方式<ol><li>需求驱动：由 top 的算子来发送 <code>next</code> 或者 <code>next_batch</code> 这样的请求，驱动下层的算子来取对应的数据。可以看作是 pull 的模型</li><li>生产者驱动：底层的算子产生 tuple，然后输出给上层的算子。可以看作是 push 的模型</li></ol></li></ol><p>在查询中，可以流水化的边被称为 pipelined edge, 需要物化的（比如 Hash Join）被称为 blocking edge. 一般来说，不同的 pipeline edge 组成的子树可以并发执行，blocking 的可能需要物化。</p><p>这里还介绍了一下 streaming 上的查询执行，感觉可以看：<a href="https://www.skyzh.dev/posts/articles/2022-01-15-store-of-streaming-states/">https://www.skyzh.dev/posts/articles/2022-01-15-store-of-streaming-states/</a></p><p>此外，有些 cache 亲和的查询执行策略，这里是让划分的 block 能 fit 在 L1/L2/L3 cache 中，从而加速查询。</p><p>这里还介绍了查询编译和 columnar 执行，不过就提了两行。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Distributed System: Master</title>
      <link href="/2020/12/29/Distributed-System-Master/"/>
      <url>/2020/12/29/Distributed-System-Master/</url>
      
        <content type="html"><![CDATA[<p>上一篇文章中，我们介绍了 CPU 的 cache coherent 机制和两种实现方式的基础内容，同时介绍了分布式系统的 Lease 机制。这篇文章我们将回顾一下用到 Lease 的系统，同时介绍一下分布式系统的主节点操作：这也同时会涉及 ZooKeeper, Redis 和分布式锁相关的内容。</p><h2 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h2><p>我们在介绍 Lease 的时候，引入了假设：Clock Drift 在一定范围内。我们会看到今天介绍的内容中，仍然有一部分系统是依赖这个假设的。</p><p>尽管 <code>gettimeofday</code> 调用是线程安全的，但是分布式系统的时间永远有种种问题。</p><p>可以简单阅读： <a href="https://tldp.org/LDP/sag/html/keeping-time.html">https://tldp.org/LDP/sag/html/keeping-time.html</a></p><p>为了理解这个问题，不妨看一看 rCore 产生 timer interrupt 的代码（这个是教学用的，可能实际的会复杂一些）：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// 设置下一次时钟中断的时间</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">set_timer</span>(time: <span class="type">usize</span>) &#123;</span><br><span class="line">    <span class="title function_ invoke__">sbi_call</span>(SBI_SET_TIMER, time, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// 时钟中断的间隔，单位是 CPU 指令</span></span><br><span class="line"><span class="keyword">static</span> INTERVAL: <span class="type">usize</span> = <span class="number">100000</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// 设置下一次时钟中断</span></span><br><span class="line"><span class="comment">/// </span></span><br><span class="line"><span class="comment">/// 获取当前时间，加上中断间隔，通过 SBI 调用预约下一次中断</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">set_next_timeout</span>() &#123;</span><br><span class="line">    <span class="title function_ invoke__">set_timer</span>(time::<span class="title function_ invoke__">read</span>() + INTERVAL);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// 触发时钟中断计数</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">static</span> <span class="keyword">mut</span> TICKS: <span class="type">usize</span> = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// 每一次时钟中断时调用</span></span><br><span class="line"><span class="comment">/// </span></span><br><span class="line"><span class="comment">/// 设置下一次时钟中断，同时计数 +1</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">tick</span>() &#123;</span><br><span class="line">    <span class="title function_ invoke__">set_next_timeout</span>();</span><br><span class="line">    <span class="keyword">unsafe</span> &#123;</span><br><span class="line">        TICKS += <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> TICKS % <span class="number">100</span> == <span class="number">0</span> &#123;</span><br><span class="line">            <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125; tick&quot;</span>, TICKS);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>硬件有一个 Monotonic 的时钟，在启动之后能够拿到自己的 <code>tick</code> 。但是，可能是没有什么表意的。</li><li>我们也有 <code>gettimeofday</code> 这样的调用，我们可以知道时区之类的信息，但是由于种种原因，我们的时间很可能是不准的。假设开启了 NTP, 我们甚至有可能进行短暂的回退。</li></ul><p>上面的内容在语言的库层面也有支持，比如 C++ 的 <code>chrono</code> , 你可以简略阅读 cppreference，或者阅读这里：<a href="https://www.modernescpp.com/index.php/the-three-clocks">https://www.modernescpp.com/index.php/the-three-clocks</a></p><p>所以，简单来说，依赖什么时钟，怎么依赖时钟，都是一个问题。</p><h2 id="Lease-和-主操作"><a href="#Lease-和-主操作" class="headerlink" title="Lease 和 主操作"></a>Lease 和 主操作</h2><p>回到 Lease, 虽然这个词语义可能不一样，比如在 memcache 里面，对 Read Miss 它会发放 Lease，以便合理的访问 DB, 保证 (1) 一致性 (2) 防止暴读打挂 DB。拜 sharding 所赐，这个 Lease 维护的时间序简单一些。同时，因为是 cache，所以丢失也无关紧要。</p><p>而我们上一篇文章介绍的 Lease，大致流程如下：</p><blockquote><ul><li>写入：client 需要向一个逻辑上的单点（我们在 Redis 里面会看到这个）发送 Lease Request, 拿到对应的 lease 之后，才能在 lease 期间写资源</li><li>另外一个写入需要写时，server 会尝试 invalid 之前 grant 的 lease，然后再 grant lease</li><li>如果 invalid 联系不上（比如发生网络分区），这里会等待到 grant 的 lease 时间结束。</li></ul></blockquote><p>在上述这段中，如果你感受不到什么问题的话，其实才是问题所在：</p><ol><li>你依赖了一个额外的同步 Server，你做的操作和它不一定有关系。同时它是一个物理单点的话，挂掉就不好了。</li><li>写入操作需要保证是“只有一个拿到 Lease 的在操作“，这并不自然。</li></ol><h3 id="基础的-Raft-和-term"><a href="#基础的-Raft-和-term" class="headerlink" title="基础的 Raft 和 term"></a>基础的 Raft 和 term</h3><p>当我们需要 HA 的时候，这方面我们可能需要 Paxos 这样的 Consensus。这样，某种程度上，我们可以把一个单点变成逻辑上的 HA 的集合。我们来简单回到 Raft，来看看<strong>最简单的</strong> Raft 是怎么做主节点的操作的：</p><ol><li>半数以上（包括自己）投票产生 Leader, 而Leader 对应一个 <code>term</code></li><li>如果新 Leader 选举出来了，同时旧 Leader 还存在。那么它在集群内部的请求是无法生效的，因为它的 <code>term</code> 小于现有半数机器的 <code>term</code></li></ol><p>这里没有依赖物理时钟，而是依赖了单调递增的一个逻辑值 <code>term</code>，来进行操作。</p><h3 id="Session-amp-amp-Lease"><a href="#Session-amp-amp-Lease" class="headerlink" title="Session &amp;&amp; Lease"></a>Session &amp;&amp; Lease</h3><p>回到我们的 Lease, 比如 ZooKeeper 维护了一个 Session Timeout, 在这里，可以参考一下 ZooKeeper 的论文 4.4 节：</p><blockquote><p>在我们的实现中，设置 timeout 是为了使 leader 在 follower 放弃他们之前意识到他们不再是 leader，因此它们就不会发布空事务。</p><p>为了检测客户端 session 的 failure, ZooKeeper 使用了 timeout。如果在 timeout 时间内，没有其他服务器收到一个 client session 对应的消息，即判定为 failure。如果客户端足够频繁地发送请求，则无需发送任何其他消息。 否则，客户端会在活动不足时发送心跳消息。 如果客户端无法与服务器通信以发送请求或心跳，则它将连接到其他ZooKeeper服务器以重新建立其会话。 为了防止会话超时，ZooKeeper客户端库在会话闲置了<code>s/3</code> ms后发送了心跳信号，如果在<em><code>2s/3</code></em> ms内未收到服务器的消息，则切换到新服务器，其中<em>s</em>是 session timeout（以毫秒为单位）。</p></blockquote><p>（顺便安利一下我翻译的：<a href="https://github.com/mapleFU/zookeeper_paper_cn#44-client-server-interactions">https://github.com/mapleFU/zookeeper_paper_cn#44-client-server-interactions</a> ，可能有的地方翻译的不太好，欢迎 PR）</p><p>上述保证允许 ZooKeeper 的 client 能够比较好的使用。用 <code>s</code> 的 <code>1/3</code> 和 <code>2/3</code> 隐式依赖 clock drift 不会太大。</p><p>Raft 的 Lease Read 也做了 Lease 相关的优化。简单的 Raft 读一般需要 Leader 证明 “自己仍然是 Leader”，获取一个 Read Index，等提交越过这个 Read Index 之后返回。而 Lease Read 则是一个简单的推理：在一次 heartbeat 和 election timeout 相关的一段时间内，自己仍然是 Leader 。这个在博士论文中有介绍：</p><p><img src="https://image.mwish.me/blog-image/A436F352-391E-4CEB-8DC6-415AFF87FDE7.png" alt="A436F352-391E-4CEB-8DC6-415AFF87FDE7"></p><p>这个也可以参考 TiKV 的实现相关的讨论：<a href="https://zhuanlan.zhihu.com/p/25367435">https://zhuanlan.zhihu.com/p/25367435</a></p><h3 id="Corner-Case-与主节点操作"><a href="#Corner-Case-与主节点操作" class="headerlink" title="Corner Case 与主节点操作"></a>Corner Case 与主节点操作</h3><p>在上面工具的帮助下，你可能认为没有问题了，当然，这是不现实的～</p><p>DDIA 的作者在它的博客上写过一篇 how to do distributed locking <a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html</a> ，提到了下面的时序问题：</p><p><img src="https://image.mwish.me/blog-image/unsafe-lock.png" alt="unsafe-lock"></p><p>本质上，这是因为 Storage 并非 lock service, 这导致操作出现不一致：在 Lock Service 里，我们有独立的 Lock, 但是在外部操作视角，这并不是独立的。这导致我们之前的约束再次出现问题！</p><p>这两篇文章提到了 ZooKeeper 相关的解决方案：</p><ol><li><a href="https://fpj.systems/2016/02/10/note-on-fencing-and-distributed-locks/">https://fpj.systems/2016/02/10/note-on-fencing-and-distributed-locks/</a></li><li><a href="https://zhuanlan.zhihu.com/p/299272034">https://zhuanlan.zhihu.com/p/299272034</a></li></ol><p>（我更推荐你阅读后者，虽然其实不止要读一遍）</p><p>这里是在说，发送操作的时候，如果获取到主的权限，可以产生一个 Term，发送操作的时候带上这个 Term，如果 Term 不合理的话，下层允许拒绝掉这个操作。</p><p>此外，HDFS 中，允许你使用 IO Fencing: 当一个新的节点成为 Leader 的时候，你能够 ssh 到旧的 leader 上，来 kill 掉它，防止出现时序问题。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li>Hardware/Software Clocks <a href="https://tldp.org/LDP/sag/html/hw-sw-clocks.html">https://tldp.org/LDP/sag/html/hw-sw-clocks.html</a></li><li>Modern Cpp: The There Clocks <a href="https://www.modernescpp.com/index.php/the-three-clocks">https://www.modernescpp.com/index.php/the-three-clocks</a></li><li>TiKV 读优化：<a href="https://zhuanlan.zhihu.com/p/25367435">https://zhuanlan.zhihu.com/p/25367435</a></li><li><a href="https://fpj.systems/2016/02/10/note-on-fencing-and-distributed-locks/">https://fpj.systems/2016/02/10/note-on-fencing-and-distributed-locks/</a></li><li><a href="https://zhuanlan.zhihu.com/p/299272034">https://zhuanlan.zhihu.com/p/299272034</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Cache Consistency in CPU and Distributed System: Part2</title>
      <link href="/2020/12/12/Cache-Consistency-in-CPU-and-Distributed-Sysem-Part2/"/>
      <url>/2020/12/12/Cache-Consistency-in-CPU-and-Distributed-Sysem-Part2/</url>
      
        <content type="html"><![CDATA[<h3 id="Redlock"><a href="#Redlock" class="headerlink" title="Redlock"></a>Redlock</h3><p>Redlock 的最佳了解链接在：<a href="https://redis.io/topics/distlock">https://redis.io/topics/distlock</a></p><p>这里比较详细的描写了 Redis 的 Redlock 的算法流程。但是顺便一提，看完建议看看这个: <a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html</a></p><h3 id="Raft-Lease"><a href="#Raft-Lease" class="headerlink" title="Raft Lease"></a>Raft Lease</h3><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html</a></li><li><a href="https://redis.io/topics/distlock">https://redis.io/topics/distlock</a></li><li></li><li><a href="https://zhuanlan.zhihu.com/p/299272034">https://zhuanlan.zhihu.com/p/299272034</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> system, distributed </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cache Consistency in CPU and Distributed System</title>
      <link href="/2020/12/12/Cache-Consistency-in-CPU-and-Distributed-System/"/>
      <url>/2020/12/12/Cache-Consistency-in-CPU-and-Distributed-System/</url>
      
        <content type="html"><![CDATA[<p>CPU 和内存之间，我们有两种东西：</p><ul><li>memory consistency: 什么应该读到写入的什么东西。</li><li>cache coherence: <a href="https://zhuanlan.zhihu.com/p/272348686">https://zhuanlan.zhihu.com/p/272348686</a></li></ul><p>这一节的内容会比较长，我们会介绍：</p><ul><li>如何在 CPU 中维护上面的一致性：我们将介绍 snooping-based （国内翻译类似基于监听的协议）和 directory（基于目录的协议）。</li><li>如何在分布式系统中维护一致性：我们将介绍这与计算机系统中有什么不同，然后介绍 Lease 机制。</li></ul><h2 id="Preview"><a href="#Preview" class="headerlink" title="Preview"></a>Preview</h2><p>我们在之前内容聊到过 cacheline/cacheblock 的基本概念：</p><p><a href="https://zhuanlan.zhihu.com/p/271020814">https://zhuanlan.zhihu.com/p/271020814</a></p><p><img src="https://image.mwish.me/blog-image/D0BB5BAB-3486-4EC9-BF8E-D470DAF87BE3.png" alt="D0BB5BAB-3486-4EC9-BF8E-D470DAF87BE3"></p><p>我们还有一些 design 上的区别：</p><blockquote><ol><li><p>Write-through：写入的时候需要更新cache 和 memory</p></li><li><p>Write-back:</p></li><li><ol><li>写入的时候更新 cache block</li><li>添加一个 dirty flag</li><li>OS 在 IO 之前 flush cache</li></ol></li></ol><p>write-through 也有 write allocate 等策略。write allocate 是指：如果目标内存不在 cache 中，是否要把它捞上来。</p></blockquote><h2 id="Snooping-cache-coherence"><a href="#Snooping-cache-coherence" class="headerlink" title="Snooping cache-coherence"></a>Snooping cache-coherence</h2><p>Idea: 所有与 coherence 相关的活动，会被广播给各个 cache-controller. Cache controller 舰艇这些操作，来维持 memory coherence。</p><p>那么我们可以想到一个最朴素的实现：</p><blockquote><p>在 write-through + cache line 为粒度的场景下</p><p>任何一次写，在完成的时候，都会 Invalid 掉所有的 cache。所以别的 P 下一次读都会 cache miss</p></blockquote><p>那么，我们可以维护一个如下图的状态机器，cache 有两种逻辑状态：</p><p><img src="https://image.mwish.me/blog-image/7350CB1E-748C-42CC-9803-D26D06523C98.png" alt="7350CB1E-748C-42CC-9803-D26D06523C98"></p><p>这里对 bus 有需求：</p><ul><li>所有的 write txn 被所有的 cache controller 以同种顺序观察到。</li></ul><p>同时可以有下面的假设：</p><p><img src="https://image.mwish.me/blog-image/DA90A8BF-2444-4257-B217-74A0025DFC6A.png" alt="DA90A8BF-2444-4257-B217-74A0025DFC6A"></p><p>当然，以上是 write-through 的场景。相对 write-back 来说，write-through 只是优化了读，同时，这样的缺点是：每次写都要写内存，需要很高的 bandwidth. write-back 大大减少了这种场景，但是，在 write-back 的情况下，实现 cache coherence 会复杂得多。</p><p>现在，我们需要区分 dirty/clean, exclusive 和 shared. 这个需要靠 cacheline 的 <code>valid</code> 标记来区分。</p><ul><li>Exclusive: 被写入之后，变成独占的，只有写入者的是有效的</li><li>Owner: 别的 cache 需要 load 的时候，不能从 memory 读，因为 memory 的数据是 stale 的。需要从写入的唯一一份 cache 中读。</li></ul><p>那么，我们有下面的 ideas：</p><blockquote><ul><li>exclusive 状态的 cache 可以不通知别的进程，就可以完成修改</li><li>P 只能写 exclusive 的 cache, 所以它写之前需要广播</li><li>当 P 收到别的 P 的写请求时，他必须 Invalid 自己的 cache</li></ul></blockquote><h4 id="MSI"><a href="#MSI" class="headerlink" title="MSI"></a>MSI</h4><p>Key tasks:</p><ul><li>确保在写入时是 Exclusive 的</li><li>能够读到最近写入的 cacheline, 即使不在内存中</li></ul><p>同时，有三个 cache line 状态：</p><ul><li>M: Modified</li><li>I: Invalid</li><li>S: Shared</li></ul><p>有两种来自 local P 的操作：</p><ul><li>PrRd: 处理器读</li><li>PrWr: 处理器写</li></ul><p>三种来自 remote cache 的操作：</p><ul><li>BusRd：当某个处理器的高速缓存的读操作出现未命中，它会向总线发送一个BusRd请求，并预期能够收到该缓存块的数据。</li><li>BusRdX：当某个处理器的高速缓存的写操作出现未命中，它会向总线发送一个BusRdX请求，预期能够收到该缓存块的数据，并且使其他处理器中对应相同地址的缓存块无效。</li><li>Flush：该请求表明一个缓存块正在被写回内存。</li></ul><p><img src="https://image.mwish.me/blog-image/4487FEFE-0B95-49B4-B54A-FA49AB0D8836.png" alt="4487FEFE-0B95-49B4-B54A-FA49AB0D8836"></p><p>MSI 对于 coherence 的满足性：</p><ul><li>写是 total order 的，如果状态不是 M 本处理器的写会 Invalid 所有的 cache；如果本身是 M, 没有被读占有，那么本身写按照 order 进行。任何一个读需要把 M 变成 S。</li></ul><p>现代化的系统使用的MSI协议的变种以减少保持缓存一致性所需要的通信量。MESI协议增加了一个Exclusive（独占）状态，以减少对于只存在于一个高速缓存的块的写操作造成的通信。MOSI协议增加了一个Owned（持有）状态，以减少对于被其他缓存读取过的高速缓存的块的写回操作造成的通信。MOESI协议同时做了这两件事情。</p><p><img src="https://image.mwish.me/blog-image/B914D377-13F5-4E3B-BE58-089149C98CA6.png" alt="B914D377-13F5-4E3B-BE58-089149C98CA6"></p><h4 id="Multi-level-Cache"><a href="#Multi-level-Cache" class="headerlink" title="Multi-level Cache"></a>Multi-level Cache</h4><p>现在的处理器都是有多级缓存的，这暗示要引入额外的复杂度：包含关系。</p><p>因为 L1 某种意义上是 L2 的子集，所以即使 L1 不修改 L2，协议上仍然要在 L2 上作修改。</p><p><img src="https://image.mwish.me/blog-image/2C8CC59F-687A-4AA7-8FF9-5EA96DBD152E.png" alt="2C8CC59F-687A-4AA7-8FF9-5EA96DBD152E"></p><h2 id="Directory-Based-cache-coherence"><a href="#Directory-Based-cache-coherence" class="headerlink" title="Directory-Based cache-coherence"></a>Directory-Based cache-coherence</h2><p>在 SMP 中，我们有如上的视图。但是，我们可能会为了降低 latency, 增大内存访问的带宽而使用 NUMA 架构：</p><p><img src="https://image.mwish.me/blog-image/FA197163-9E91-427B-9D4B-4F99632A2157.png" alt="FA197163-9E91-427B-9D4B-4F99632A2157"></p><p>Snoop 协议肯定还能用，但是要把修改通过 interconnect 告诉别的 P 和 cache controller…</p><p>一种可选的方案是，使用 directory 来存放 cacheline 对应的状态。而 cacheline 也会从 directory 中寻找需要的信息。</p><p><img src="https://image.mwish.me/blog-image/0C173BDB-774B-4CDB-BBC5-224246586921.png" alt="0C173BDB-774B-4CDB-BBC5-224246586921"></p><p>directory 协议维护了一个 directory, 来表示每一个 Line 的状态。请求不需要过每一个 Processor, 而是通过 memory 所对应的 directory, 来完成一致性的维护。</p><h2 id="没有-interconnect-的系统"><a href="#没有-interconnect-的系统" class="headerlink" title="没有 interconnect 的系统"></a>没有 interconnect 的系统</h2><h3 id="Lease-Basics"><a href="#Lease-Basics" class="headerlink" title="Lease: Basics"></a>Lease: Basics</h3><p>我们上述内容中看到，为了维护 write serialization 以及更大的 cache coherence, 需要依赖一点：</p><ul><li>interconnect 是可靠的</li><li>它能够帮我们 total order 的广播写</li></ul><p>在分布式系统中，我们很难依赖第一点假设，实际上，异步系统的共识甚至是没有下限的，详见 FLP。对于第二点，实现全序广播是相当昂贵的，我们可能熟悉一些基于复制状态机的协议。</p><p>89 年的 Leases: An Efficient Fault-Tolerant Mechanism for Distributed File Cache Consistency 提出了 Lease 机制，这是我们在今天的分布式系统里面非常常见的协议。当然，这个原 paper 只介绍了 write-through 的场景。我们试图介绍基本之后，之后会讲讲各种地方的 Lease 使用和问题。</p><blockquote><ul><li>“A lease is a contract that gives its holder specified rights over property for a limited period of time.”</li><li>“ A lease grants to its holder <strong>control over writes</strong> to the covered datum <strong>during the term of the lease</strong>, such that the server must obtain the approval of the leaseholder before the datum may be written.” </li></ul></blockquote><p><img src="https://image.mwish.me/blog-image/25A8DE4A-BD8F-46B3-BA18-34A15C4D21D8.png" alt="25A8DE4A-BD8F-46B3-BA18-34A15C4D21D8"></p><ul><li>写入：client 需要向一个逻辑上的单点（我们在 Redis 里面会看到这个）发送 Lease Request, 拿到对应的 lease 之后，才能在 lease 期间写资源</li><li>另外一个写入需要写时，server 会尝试 invalid 之前 grant 的 lease，然后再 grant lease</li><li>如果 invalid 联系不上（比如发生网络分区），这里会等待到 grant 的 lease 时间结束。</li></ul><p>这里隐含了时间这个要求。实际上分布式系统的时间只是一个偏序概念。这里只能假定大家 system clock 的运行偏差在一定范围内。</p>]]></content>
      
      
      
        <tags>
            
            <tag> system, distributed </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>来得太早的 2020 年年鉴</title>
      <link href="/2020/12/05/%E6%9D%A5%E5%BE%97%E5%A4%AA%E6%97%A9%E7%9A%84-2020-%E5%B9%B4%E5%B9%B4%E9%89%B4/"/>
      <url>/2020/12/05/%E6%9D%A5%E5%BE%97%E5%A4%AA%E6%97%A9%E7%9A%84-2020-%E5%B9%B4%E5%B9%B4%E9%89%B4/</url>
      
        <content type="html"><![CDATA[<p>主要还是想讲讲自己 2020 年看过的动画。</p><p>年初在公司实习，周末和晚上可以看看动画片。在年会之前，补完了《电波女与青春男》的动画。这部我高中看了2集就没看下去了，年初看的时候却觉得意外的很青春。</p><p>随后周末和bgm的上海网友一起去看了京紫的动画，然后顺手拿了色纸。其实我不指望京紫有多好看。但是出于对京都动画的尊敬，还是带着期待去看了，结果觉得竟然还不错。看完电影聊天的时候听 uks 黑屁了半天细田守。</p><p><img src="https://image.mwish.me/blog-image/817D0680-4E78-4122-86AC-3995A978271C.png" alt="817D0680-4E78-4122-86AC-3995A978271C"></p><p>年会的时候其实蛮痛苦的，感觉氛围融入不进去，北京的菜又巨几把难吃。不过庆幸的是，我一个人很安静地看完了《在细雨中呼喊》。我太喜欢这本书的时间线了。年会公司朋友都在庆祝的时候，就我他妈在看书，还是挺微妙的。</p><p><img src="https://image.mwish.me/blog-image/AFEBDB31-641B-44F9-9F1B-069881E23EC7.png" alt="AFEBDB31-641B-44F9-9F1B-069881E23EC7"></p><p>然后，本来想开完年会就回家的，不过因为没有赶上自己买的高铁，往后 delay 了三个小时，意外获得机会去北京吃了吃街头卤煮，逛了逛北京兵器博物馆，买了个煎饼果子。感觉有点微妙的畅爽。</p><p>那个时候，我没有料到自己下半年会在北京度过，真的没有。我也没有想到会有疫情。这不可预料的一年以孙家不可预测的命运一起，在我的面前展开了。</p><p>假期大概有14天？其实放假之前就不咋忙了，在家里帮家里人做事啥的。然后补完了空境的剧场版啃完了，准确说未来福音我没看。最喜欢的是矛盾螺旋。</p><p>那会儿在家里把《Heart Catch Precure》 啃完了。算是自己第一部有意识去补的子供动画。虽然我被变身bank搞得还挺烦的，但是当两次 \<Heart goes on\> 响起的时候，我还是流泪了。</p><p><img src="https://image.mwish.me/blog-image/A9CB8180-97DE-4334-9626-A1E33308910E.png" alt="A9CB8180-97DE-4334-9626-A1E33308910E"></p><p>过年的时候因为疫情原因，大家一切从简。我找我表哥一起看群友推荐的动画，《星界的纹章》。确实是很悠闲浪漫的动画，如果不是我当时比较焦躁，可能对它会有更高的评价。不过这片子看完得在两星期后了。2月9号左右，俺就开始接着上班了。</p><p><img src="https://image.mwish.me/blog-image/A4E3A564-83FE-4C81-B837-DB0AE22DA108.png" alt="A4E3A564-83FE-4C81-B837-DB0AE22DA108"></p><p>然后俺准备再看一遍卡夫卡的城堡，之前把吴晓东的《从卡夫卡到昆德拉》里面卡夫卡那几节看了一下，再看的时候，感触深了一些，但是还是感觉很错乱。</p><p>忙公司的事情和毕设把我搞的焦头烂额，2月底到3月只有周末的时间有空了，开始的时候不忙，看完了《<a href="http://bgm.tv/subject/40003">福星小子2 绮丽梦中人</a> 》，后来忙起来了，俺就只把《少战》补完了。期间还追了下《ID:INVADED》和映像研，不过都搞得我有点失望。</p><p>四月份五月份都在忙找工作和工作。焦虑之余，把《Hello World》啃了，就感觉野崎麻豆真的不行…想起之前马小褂翻译的作画讲座，把《神是中学生》补了。这应该是我今年个人最喜欢的动画了。</p><p><img src="https://image.mwish.me/blog-image/2795599D-417F-4B7A-912D-23CBA4C96612.png" alt="2795599D-417F-4B7A-912D-23CBA4C96612"></p><p><img src="https://image.mwish.me/blog-image/1C29D5C2-30D4-4042-BB80-DF59DC8C9996.png" alt="1C29D5C2-30D4-4042-BB80-DF59DC8C9996"></p><p>4月底，找到了几个保底的工作，然后能回学校了。心情好起来了，跟家里人关系也融洽了。给我妈下了一整套《请回答 1988》，发现我爸妈都是片子主角那个时代的人，虽然彼时韩国比国内江西富裕不少，但是九十年代的共同记忆还是有的。我也看得比较开心。此外还和家里人一起看了宫崎骏的《卡里奥斯特罗城》。感觉虽然这部很不鲁邦，但是是真的很浪漫。此外还把 \<Flip Flappers\> 补了。Cp 活动上我向押山清高要签名的时候说我很喜欢丫丫卡，但实际上我还没看完——事实证明，看完了我还是很喜欢。</p><p>找到保底工作之后，也把《罪与罚》啃了。一开始还不习惯俄国人的几个名称，所以买了本实体书看名称表。最近发现对着表看卡拉马佐夫兄弟已经没啥压力了，果然，看小说也是要学习的啊…</p><p>5月底，回到同济，在去上海的高铁上看完了《许三观卖血记》。这大概是我今年最快乐的一个月了。每天骑车去附近家乐福买点生活用品，去上海动物园之类的地方逛逛，摸鱼做做毕设。这段时间也把工作定下来了。也感谢给我支持的网友，我永远感谢你。</p><p>回学校这段时间，因为工作定下来了，所以焦虑少了不少，在学校一遍减肥，一边补完了《索拉里斯星》、《伊里野的天空、UFO之夏》、《悉达多》和《银河铁道之夜》。动画也看了不少，把《幽灵公主》补完了（应该是我个人最喜欢的宫崎骏电影了），然后补完了 CLANNAD After Story（这部我觉得看得越早越好，补了很多现实主义作品再来看麻枝准的浪漫，我能感受到他传达的情感，但是总感觉怪怪的）。</p><p><img src="https://image.mwish.me/blog-image/A10054C1-F3A2-41A4-A885-A97A74129C36.png" alt="A10054C1-F3A2-41A4-A885-A97A74129C36"></p><p>在学校最后几天，把《章北海传》看完了，然后错过了学院的典礼，最后去学校的毕业典礼，突然很伤感，怎么就这么结束了，一点实感都没有啊…</p><p><img src="https://image.mwish.me/blog-image/E78C22E6-5372-45CB-B72D-DDDA89FD5AC1.png" alt="E78C22E6-5372-45CB-B72D-DDDA89FD5AC1"></p><p>在漫长的告别，再回家休整几天后，前往北京。在上班之前看完了 Macross Delta。然后开始北京的正式工生活。在北京这几天，把千本樱文库的斩首循环啃完了，七月底 把哈佛的《公正：该如何做是好》看完了，然后8月补了塞林格的《弗兰妮和祖伊》（塞林格算是最对我胃口的作家了）和一无所有。动画就把《风之谷》给补了。</p><p>然后从8月一直忙到国庆，期间只有一段放松的，就是大学舍友来北京出差，那会儿和他一起看了信条：</p><p><img src="https://image.mwish.me/blog-image/633F9F50-FB96-437D-9119-969259B7E5AC.png" alt="633F9F50-FB96-437D-9119-969259B7E5AC"></p><p>国庆第一天看完了《放学后的昴星团》，虽然这部作品是个广告片，演出完全跟不上，但是结尾那种浪漫绝对是有G社魂的，那种回到原点，然后漫漫长眠的浪漫。这不是不懂SF的人能够拍出来的：</p><p><img src="https://image.mwish.me/blog-image/303EB6C3-7CA6-46E9-8301-77A0898529F8.png" alt="303EB6C3-7CA6-46E9-8301-77A0898529F8"></p><p>回上海和大学同学约饭，去他们家瞎玩，然后把姜子牙看了，说实话我觉得这片子还不错，虽然网上骂声不小，但是我觉得还行…</p><p><img src="https://image.mwish.me/blog-image/CECAA6C8-A458-4D67-9606-1B86976DDD2A.png" alt="CECAA6C8-A458-4D67-9606-1B86976DDD2A"></p><p>然后去 WF 玩了一趟爽，回家肝了4天，把 Xenoblade 重制版打通了，已经把《敵との対峙》这首歌刻在灵魂里了。关于这部作品没啥说的，知乎上有个很棒的回答，把我想说的都说了。顺便把 Re0 小说看到最近更新。（当时觉得还能写很久，没想到一下第六章就完结了）。</p><p>10月照样忙碌，每天写完代码回来看看《世界尽头与冷酷仙境》。顺便把《Soma Bringer》通关了，终于知道 DC 哥哥头像是什么了…</p><p>11月一直忙到现在，看了一半《<a href="https://book.douban.com/subject/3438303/">抬高房梁，木匠们；西摩：小传</a>》，然后看了一半《欧洲现代史》，起因是发现很多欧洲的书都看不懂…11月底看完了《花与爱丽丝杀人事件》，真的看得很开心。然后这个月还补完了《美伦X》的漫画，算是《童年的终结》燃向致敬了。虽然我不喜欢克拉克，但是我还是蛮喜欢这部的…</p><p>12月了，2020就要结束了，不过想想，今年到年底的目标就只有《在这个世界的角落》和《大人帝国》了。或许目标还会变呢…</p><p>记动荡的一年。</p>]]></content>
      
      
      
        <tags>
            
            <tag> acgn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Notes: brpc DoublyBufferedData</title>
      <link href="/2020/12/05/Notes-brpc-DoublyBuffer/"/>
      <url>/2020/12/05/Notes-brpc-DoublyBuffer/</url>
      
        <content type="html"><![CDATA[<p><code>DoublyBufferedData</code> 逻辑上是一个这样的数据结构：</p><ol><li>持有两份数据，读同时读一份，写的话写另一份. 它自己分为</li><li>并发读几乎是没有什么开销的，写/更新会有开销。</li></ol><p>看代码注释吧：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">// This data structure makes Read() almost lock-free by making Modify()</span><br><span class="line">// *much* slower. It&#x27;s very suitable for implementing LoadBalancers which</span><br><span class="line">// have a lot of concurrent read-only ops from many threads and occasional</span><br><span class="line">// modifications of data. As a side effect, this data structure can store</span><br><span class="line">// a thread-local data for user.</span><br><span class="line">//</span><br><span class="line">// Read(): begin with a thread-local mutex locked then read the foreground</span><br><span class="line">// instance which will not be changed before the mutex is unlocked. Since the</span><br><span class="line">// mutex is only locked by Modify() with an empty critical section, the</span><br><span class="line">// function is almost lock-free.</span><br><span class="line">//</span><br><span class="line">// Modify(): Modify background instance which is not used by any Read(), flip</span><br><span class="line">// foreground and background, lock thread-local mutexes one by one to make</span><br><span class="line">// sure all existing Read() finish and later Read() see new foreground,</span><br><span class="line">// then modify background(foreground before flip) again.</span><br></pre></td></tr></table></figure><p>同时，需要注意的是，这个 <code>class</code> 实现的时候利用了 TLS，所以使用的时候实际上可以自定义 TLS。</p><p>先看这个 <code>class</code> 对外提供的接口：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> TLS = Void&gt;</span><br><span class="line"><span class="keyword">class</span> DoublyBufferedData &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">class</span> ScopedPtr &#123;</span><br><span class="line">    <span class="keyword">friend</span> <span class="keyword">class</span> DoublyBufferedData;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">ScopedPtr</span>() : _data(<span class="literal">NULL</span>), _w(<span class="literal">NULL</span>) &#123;&#125;</span><br><span class="line">        ~<span class="built_in">ScopedPtr</span>() &#123;</span><br><span class="line">            <span class="keyword">if</span> (_w) &#123;</span><br><span class="line">                _w-&gt;<span class="built_in">EndRead</span>();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="type">const</span> T* <span class="title">get</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> _data; &#125;</span><br><span class="line">        <span class="type">const</span> T&amp; <span class="keyword">operator</span>*() <span class="type">const</span> &#123; <span class="keyword">return</span> *_data; &#125;</span><br><span class="line">        <span class="type">const</span> T* <span class="keyword">operator</span>-&gt;() <span class="type">const</span> &#123; <span class="keyword">return</span> _data; &#125;</span><br><span class="line">        <span class="function">TLS&amp; <span class="title">tls</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> _w-&gt;<span class="built_in">user_tls</span>(); &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="built_in">DISALLOW_COPY_AND_ASSIGN</span>(ScopedPtr);</span><br><span class="line">        <span class="type">const</span> T* _data;</span><br><span class="line">        Wrapper* _w;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">DoublyBufferedData</span>();</span><br><span class="line">    ~<span class="built_in">DoublyBufferedData</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Put foreground instance into ptr. The instance will not be changed until</span></span><br><span class="line">    <span class="comment">// ptr is destructed.</span></span><br><span class="line">    <span class="comment">// This function is not blocked by Read() and Modify() in other threads.</span></span><br><span class="line">    <span class="comment">// Returns 0 on success, -1 otherwise.</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">Read</span><span class="params">(ScopedPtr* ptr)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Modify background and foreground instances. fn(T&amp;, ...) will be called</span></span><br><span class="line">    <span class="comment">// twice. Modify() from different threads are exclusive from each other.</span></span><br><span class="line">    <span class="comment">// <span class="doctag">NOTE:</span> Call same series of fn to different equivalent instances should</span></span><br><span class="line">    <span class="comment">// result in equivalent instances, otherwise foreground and background</span></span><br><span class="line">    <span class="comment">// instance will be inconsistent.</span></span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Fn&gt; <span class="function"><span class="type">size_t</span> <span class="title">Modify</span><span class="params">(Fn&amp; fn)</span></span>;</span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Fn, <span class="keyword">typename</span> Arg1&gt; <span class="function"><span class="type">size_t</span> <span class="title">Modify</span><span class="params">(Fn&amp; fn, <span class="type">const</span> Arg1&amp;)</span></span>;</span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Fn, <span class="keyword">typename</span> Arg1, <span class="keyword">typename</span> Arg2&gt;</span><br><span class="line">    <span class="function"><span class="type">size_t</span> <span class="title">Modify</span><span class="params">(Fn&amp; fn, <span class="type">const</span> Arg1&amp;, <span class="type">const</span> Arg2&amp;)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// fn(T&amp; background, const T&amp; foreground, ...) will be called to background</span></span><br><span class="line">    <span class="comment">// and foreground instances respectively.</span></span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Fn&gt; <span class="function"><span class="type">size_t</span> <span class="title">ModifyWithForeground</span><span class="params">(Fn&amp; fn)</span></span>;</span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Fn, <span class="keyword">typename</span> Arg1&gt;</span><br><span class="line">    <span class="function"><span class="type">size_t</span> <span class="title">ModifyWithForeground</span><span class="params">(Fn&amp; fn, <span class="type">const</span> Arg1&amp;)</span></span>;</span><br><span class="line">    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> Fn, <span class="keyword">typename</span> Arg1, <span class="keyword">typename</span> Arg2&gt;</span><br><span class="line">    <span class="function"><span class="type">size_t</span> <span class="title">ModifyWithForeground</span><span class="params">(Fn&amp; fn, <span class="type">const</span> Arg1&amp;, <span class="type">const</span> Arg2&amp;)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 <code>Fn</code> 是更新函数，这个我们暂且不表。可以看到，这里提供了 <code>Read</code> 和 <code>Modify</code></p><p>需要注意的是，<code>Read</code> 是侵入式的，需要一个 <code>ScopedPtr</code> 来管理读相关的 Ownership。<code>ScopedPtr</code> 同时支持 <code>tls</code>, 这是 thread local 相关的自定义语义。</p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> TLS = Void&gt;</span><br><span class="line"><span class="keyword">class</span> DoublyBufferedData &#123;</span><br><span class="line">    <span class="keyword">class</span> Wrapper;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">ScopedPtr</span> &#123;</span><br><span class="line">    <span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">DoublyBufferedData</span>;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">ScopedPtr</span>() : _data(<span class="literal">NULL</span>), _w(<span class="literal">NULL</span>) &#123;&#125;</span><br><span class="line">        ~<span class="built_in">ScopedPtr</span>() &#123;</span><br><span class="line">            <span class="keyword">if</span> (_w) &#123;</span><br><span class="line">                _w-&gt;<span class="built_in">EndRead</span>();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="type">const</span> T* <span class="title">get</span><span class="params">()</span> <span class="type">const</span> </span>&#123; <span class="keyword">return</span> _data; &#125;</span><br><span class="line">        <span class="type">const</span> T&amp; <span class="keyword">operator</span>*() <span class="type">const</span> &#123; <span class="keyword">return</span> *_data; &#125;</span><br><span class="line">        <span class="type">const</span> T* <span class="keyword">operator</span>-&gt;() <span class="type">const</span> &#123; <span class="keyword">return</span> _data; &#125;</span><br><span class="line">        <span class="function">TLS&amp; <span class="title">tls</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> _w-&gt;<span class="built_in">user_tls</span>(); &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="built_in">DISALLOW_COPY_AND_ASSIGN</span>(ScopedPtr);</span><br><span class="line">        <span class="type">const</span> T* _data;</span><br><span class="line">        Wrapper* _w;</span><br><span class="line">    &#125;;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="function"><span class="type">const</span> T* <span class="title">UnsafeRead</span><span class="params">()</span> <span class="type">const</span></span></span><br><span class="line"><span class="function">    </span>&#123; <span class="keyword">return</span> _data + _index.<span class="built_in">load</span>(butil::memory_order_acquire); &#125;</span><br><span class="line">    <span class="function">Wrapper* <span class="title">AddWrapper</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">RemoveWrapper</span><span class="params">(Wrapper*)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Foreground and background void.</span></span><br><span class="line">    T _data[<span class="number">2</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Index of foreground instance.</span></span><br><span class="line">    butil::atomic&lt;<span class="type">int</span>&gt; _index;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Key to access thread-local wrappers.</span></span><br><span class="line">    <span class="type">bool</span> _created_key;</span><br><span class="line">    <span class="type">pthread_key_t</span> _wrapper_key;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// All thread-local instances.</span></span><br><span class="line">    std::vector&lt;Wrapper*&gt; _wrappers;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Sequence access to _wrappers.</span></span><br><span class="line">    <span class="type">pthread_mutex_t</span> _wrappers_mutex;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Sequence modifications.</span></span><br><span class="line">    <span class="type">pthread_mutex_t</span> _modify_mutex;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>关于 <code>pthread_key_t</code> 和相关的，可以看看 Linux 系统编程手册 31节。它包含一些简单的生命周期管理的策略，线程会自动 destruct 数据。</p><p><img src="https://image.mwish.me/blog-image/E38A4C61-DEEF-4C87-ADDF-9961485FC7BB.png" alt="E38A4C61-DEEF-4C87-ADDF-9961485FC7BB"></p><p>然后可以注意到这个 wrapper 类型：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> TLS&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DoublyBufferedDataWrapperBase</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">TLS&amp; <span class="title">user_tls</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> _user_tls; &#125;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">    TLS _user_tls;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DoublyBufferedDataWrapperBase</span>&lt;T, Void&gt; &#123;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 单个线程从 Wrapper 里面读是线程安全的。</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> TLS&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DoublyBufferedData</span>&lt;T, TLS&gt;::Wrapper</span><br><span class="line">    : <span class="keyword">public</span> DoublyBufferedDataWrapperBase&lt;T, TLS&gt; &#123;</span><br><span class="line"><span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">DoublyBufferedData</span>;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">Wrapper</span><span class="params">(DoublyBufferedData* c)</span> : _control(c) &#123;</span></span><br><span class="line">        <span class="built_in">pthread_mutex_init</span>(&amp;_mutex, <span class="literal">NULL</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ~<span class="built_in">Wrapper</span>() &#123;</span><br><span class="line">        <span class="keyword">if</span> (_control != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            _control-&gt;<span class="built_in">RemoveWrapper</span>(<span class="keyword">this</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">pthread_mutex_destroy</span>(&amp;_mutex);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// _mutex will be locked by the calling pthread and DoublyBufferedData.</span></span><br><span class="line">    <span class="comment">// Most of the time, no modifications are done, so the mutex is</span></span><br><span class="line">    <span class="comment">// uncontended and fast.</span></span><br><span class="line">    <span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">BeginRead</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">pthread_mutex_lock</span>(&amp;_mutex);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">EndRead</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">pthread_mutex_unlock</span>(&amp;_mutex);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">WaitReadDone</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">BAIDU_SCOPED_LOCK</span>(_mutex);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    DoublyBufferedData* _control;</span><br><span class="line">    <span class="type">pthread_mutex_t</span> _mutex;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这个 wrapper 是一个 TLS 相关的结构，它本身是会被存放在 <code>DoublyBufferedData</code> 的 TLS 相关内容中。而且它只有读相关的权限。他在内部有一个 <code>_control</code>, 控制的是具体读取 <code>DoublyBufferedData</code> 的数据。不过话说回来，<code>BeginRead</code> <code>EndRead</code> 甚至析构函数都比较好理解(<code>RemoveWrapper</code> 一会儿讲)，但是这个 <code>WaitReadDone()</code> 让人有些费解: 我们先看看它代码吧</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NOTE(gejun): c++11 deduces additional reference to the type.</span></span><br><span class="line"><span class="keyword">namespace</span> butil &#123;</span><br><span class="line"><span class="keyword">namespace</span> detail &#123;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line">std::lock_guard&lt;<span class="keyword">typename</span> std::remove_reference&lt;T&gt;::type&gt; <span class="built_in">get_lock_guard</span>();</span><br><span class="line">&#125;  <span class="comment">// namespace detail</span></span><br><span class="line">&#125;  <span class="comment">// namespace butil</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BAIDU_SCOPED_LOCK(ref_of_lock)                                  \</span></span><br><span class="line"><span class="meta">    decltype(::butil::detail::get_lock_guard<span class="string">&lt;decltype(ref_of_lock)&gt;</span>()) \</span></span><br><span class="line"><span class="meta">    BAIDU_CONCAT(scoped_locker_dummy_at_line_, __LINE__)(ref_of_lock)</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;&gt; <span class="keyword">class</span> <span class="title class_">lock_guard</span>&lt;<span class="type">pthread_mutex_t</span>&gt; &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">lock_guard</span><span class="params">(<span class="type">pthread_mutex_t</span> &amp; mutex)</span> : _pmutex(&amp;mutex) &#123;</span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> !defined(NDEBUG)</span></span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> rc = <span class="built_in">pthread_mutex_lock</span>(_pmutex);</span><br><span class="line">        <span class="keyword">if</span> (rc) &#123;</span><br><span class="line">            <span class="built_in">LOG</span>(FATAL) &lt;&lt; <span class="string">&quot;Fail to lock pthread_mutex_t=&quot;</span> &lt;&lt; _pmutex &lt;&lt; <span class="string">&quot;, &quot;</span> &lt;&lt; <span class="built_in">berror</span>(rc);</span><br><span class="line">            _pmutex = <span class="literal">NULL</span>;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">        <span class="built_in">pthread_mutex_lock</span>(_pmutex);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">// NDEBUG</span></span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    ~<span class="built_in">lock_guard</span>() &#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> NDEBUG</span></span><br><span class="line">        <span class="keyword">if</span> (_pmutex) &#123;</span><br><span class="line">            <span class="built_in">pthread_mutex_unlock</span>(_pmutex);</span><br><span class="line">        &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">        <span class="built_in">pthread_mutex_unlock</span>(_pmutex);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">DISALLOW_COPY_AND_ASSIGN</span>(lock_guard);</span><br><span class="line">    <span class="type">pthread_mutex_t</span>* _pmutex;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>这里它自己实现了一套 <code>lock_guard</code>, 然后局部 lock 了…等等，这个就是一个 <code>scoped_lock</code>, 那它怎么样 fence 呢？我们得看看 <code>Read</code> 和 <code>Modify</code> 了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> TLS&gt;</span><br><span class="line"><span class="type">int</span> DoublyBufferedData&lt;T, TLS&gt;::<span class="built_in">Read</span>(</span><br><span class="line">    <span class="keyword">typename</span> DoublyBufferedData&lt;T, TLS&gt;::ScopedPtr* ptr) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">BAIDU_UNLIKELY</span>(!_created_key)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    Wrapper* w = <span class="built_in">static_cast</span>&lt;Wrapper*&gt;(<span class="built_in">pthread_getspecific</span>(_wrapper_key));</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">BAIDU_LIKELY</span>(w != <span class="literal">NULL</span>)) &#123;</span><br><span class="line">        w-&gt;<span class="built_in">BeginRead</span>();</span><br><span class="line">        ptr-&gt;_data = <span class="built_in">UnsafeRead</span>();</span><br><span class="line">        ptr-&gt;_w = w;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    w = <span class="built_in">AddWrapper</span>();</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">BAIDU_LIKELY</span>(w != <span class="literal">NULL</span>)) &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">int</span> rc = <span class="built_in">pthread_setspecific</span>(_wrapper_key, w);</span><br><span class="line">        <span class="keyword">if</span> (rc == <span class="number">0</span>) &#123;</span><br><span class="line">            w-&gt;<span class="built_in">BeginRead</span>();</span><br><span class="line">            ptr-&gt;_data = <span class="built_in">UnsafeRead</span>();</span><br><span class="line">            ptr-&gt;_w = w;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>获得 TLS 的 Wrapper, 否则尝试添加一个对应的 Wrapper</li><li>读的时候，开启 <code>w-&gt;BeginRead</code> ，然后构造一个 <code>ScopedPtr</code> 对象，它在外部析构的时候会调用 <code>EndRead</code></li></ul><p><code>UnsafeRead</code> 逻辑如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">const</span> T* <span class="title">UnsafeRead</span><span class="params">()</span> <span class="type">const</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="keyword">return</span> _data + _index.<span class="built_in">load</span>(butil::memory_order_acquire); &#125;</span><br></pre></td></tr></table></figure><p>注意这里是 <code>acquire</code>，我们下文会提到。</p><p>而 <code>AddWrapper</code> 的逻辑也很清晰，它的逻辑受到 <code>_wrappers_mutex</code> 保护。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Called when thread initializes thread-local wrapper.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> TLS&gt;</span><br><span class="line"><span class="keyword">typename</span> DoublyBufferedData&lt;T, TLS&gt;::Wrapper*</span><br><span class="line">DoublyBufferedData&lt;T, TLS&gt;::<span class="built_in">AddWrapper</span>() &#123;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;Wrapper&gt; <span class="title">w</span><span class="params">(<span class="keyword">new</span> (std::nothrow) Wrapper(<span class="keyword">this</span>))</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> == w) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="built_in">BAIDU_SCOPED_LOCK</span>(_wrappers_mutex);</span><br><span class="line">        _wrappers.<span class="built_in">push_back</span>(w.<span class="built_in">get</span>());</span><br><span class="line">    &#125; <span class="built_in">catch</span> (std::exception&amp; e) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> w.<span class="built_in">release</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Called when thread quits.</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> TLS&gt;</span><br><span class="line"><span class="type">void</span> DoublyBufferedData&lt;T, TLS&gt;::<span class="built_in">RemoveWrapper</span>(</span><br><span class="line">    <span class="keyword">typename</span> DoublyBufferedData&lt;T, TLS&gt;::Wrapper* w) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> == w) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">BAIDU_SCOPED_LOCK</span>(_wrappers_mutex);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; _wrappers.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">        <span class="keyword">if</span> (_wrappers[i] == w) &#123;</span><br><span class="line">            _wrappers[i] = _wrappers.<span class="built_in">back</span>();</span><br><span class="line">            _wrappers.<span class="built_in">pop_back</span>();</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>目前都没什么问题，但是我们得看看写是怎么实现的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> TLS&gt;</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Fn&gt;</span><br><span class="line"><span class="type">size_t</span> DoublyBufferedData&lt;T, TLS&gt;::<span class="built_in">Modify</span>(Fn&amp; fn) &#123;</span><br><span class="line">    <span class="comment">// _modify_mutex sequences modifications. Using a separate mutex rather</span></span><br><span class="line">    <span class="comment">// than _wrappers_mutex is to avoid blocking threads calling</span></span><br><span class="line">    <span class="comment">// AddWrapper() or RemoveWrapper() too long. Most of the time, modifications</span></span><br><span class="line">    <span class="comment">// are done by one thread, contention should be negligible.</span></span><br><span class="line">    <span class="built_in">BAIDU_SCOPED_LOCK</span>(_modify_mutex);</span><br><span class="line">    <span class="type">int</span> bg_index = !_index.<span class="built_in">load</span>(butil::memory_order_relaxed);</span><br><span class="line">    <span class="comment">// background instance is not accessed by other threads, being safe to</span></span><br><span class="line">    <span class="comment">// modify.</span></span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> ret = <span class="built_in">fn</span>(_data[bg_index]);</span><br><span class="line">    <span class="keyword">if</span> (!ret) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Publish, flip background and foreground.</span></span><br><span class="line">    <span class="comment">// The release fence matches with the acquire fence in UnsafeRead() to</span></span><br><span class="line">    <span class="comment">// make readers which just begin to read the new foreground instance see</span></span><br><span class="line">    <span class="comment">// all changes made in fn.</span></span><br><span class="line">    _index.<span class="built_in">store</span>(bg_index, butil::memory_order_release);</span><br><span class="line">    bg_index = !bg_index;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Wait until all threads finishes current reading. When they begin next</span></span><br><span class="line">    <span class="comment">// read, they should see updated _index.</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">BAIDU_SCOPED_LOCK</span>(_wrappers_mutex);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; _wrappers.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">            _wrappers[i]-&gt;<span class="built_in">WaitReadDone</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> ret2 = <span class="built_in">fn</span>(_data[bg_index]);</span><br><span class="line">    <span class="built_in">CHECK_EQ</span>(ret2, ret) &lt;&lt; <span class="string">&quot;index=&quot;</span> &lt;&lt; _index.<span class="built_in">load</span>(butil::memory_order_relaxed);</span><br><span class="line">    <span class="keyword">return</span> ret2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><p>写会 grab <code>_modify_mutex</code></p></li><li><p>拿到需要修改的 <code>index</code>, 因为 <code>_index</code> 只有 <code>0</code> <code>1</code></p></li><li><p><code>fn(_data[bg_index])</code> 修改。这个时候</p><ol><li>只有一个 modify，这是 <code>_modify_mutex</code> 保证的</li><li>读不会读到 <code>_data[bg_index]</code> .这个保证得整体逻辑一起看</li></ol></li><li><p>写入 <code>_index</code>, 这个时候读之前改过的是安全的</p><ol><li>Q: 为什么需要 release ?</li><li>A: seq_cst 肯定是可以的，如果是 <code>relaxed</code> 的话，没有 <code>fence</code> 的话，<code>UnsafeRead</code> 会读到混写的数据。这里期望写不阻塞读。</li></ol></li><li><p><code>BAIDU_SCOPED_LOCK</code> 来 grab <code>_wrappers_mutex</code>, 这里保证不会 <code>AddWrappers</code> 或者 <code>RemoveWrappers</code>, 每个分配出去的 <code>Wrappers</code> 出去下面两种状态之一：</p><ol><li>分配出去了，持有了自己的 <code>mutex_</code>，再进行 <code>UnsafeRead</code></li><li>么有分配出去，也没有 <code>UnsafeRead</code></li></ol><p>所以上 <code>_wrappers_mutex</code> 后再 <code>WaitReadDone</code> 之后，状态是安全的. </p></li><li><p>修改原来的数据，返回。</p></li></ol><p>上述感觉 <code>5</code> 里面有一些隐含的风险，假设一个线程拿了两个 <code>ScopedPtr</code>, 然后 Block 在第二个上，第一个死都不释放，那么程序就…感觉这个是不是其实改成可重入锁安全一些？</p><h2 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h2><p>读了一遍，终于知道这个玩意怎么 work 了。但是我感觉我设计不出这么巧妙的东西，有什么参考材料吗，囧…</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Thrift IDL</title>
      <link href="/2020/12/04/Thrift-IDL/"/>
      <url>/2020/12/04/Thrift-IDL/</url>
      
        <content type="html"><![CDATA[<p>最近在复习 DDIA, 本来打算把一些序列化相关的内容写一篇很长的文章，预期内容从可读的 json 到 thrift/pb 到 avro, 再到 MySQL 的 Row format，到 Apache Arrow。结果最近被自己写的 bug 坑到想死，然后今天13机兵又到了…那我们从简吧，写完了赶紧打游戏。</p><p>Thrift 是一个提供了代码生成、服务端的库，允许你在上面编程：</p><p><img src="https://image.mwish.me/blog-image/Apache_Thrift_architecture.png" alt="Apache_Thrift_architecture"></p><p>Facebook 内部有各种语言编写的系统，而 thrift 需要为所有的语言进行服务。他需要实现 C/S 协议，实现对应的应用层的传输，然后给用户一层透明的编写的抽象。</p><p>抽象很重要的一部分是 IDL. 相对于 JSON 来说，thrift 给我们提供了编写 idl 的能力，我们可以以此来生成特定语言的 stub 代码。但是一个很重要的事情是：</p><ul><li>假设我使用的是 JSON + REST 我可以通过 REST 的 <code>/v</code> 来标注对应的版本，同时小的版本修改，我们可以在服务端嵌入对应的逻辑，比如我们变更了一个字段的类型，或者添加了一个字段，我们只要在服务端处理了对应的逻辑即可。</li></ul><p>而 Thrift 相对来说是不可读的：我们编写可读的 idl, 生成我们自己都懒得看的静态的 idl 代码，然后我们在 idl 代码上瞎搞。相对于 Json 那种谁看了都明白的结构，thrift 可能优化了空间，但是我们要面对一些问题：</p><ul><li>他生成的 binary 是怎么样的（其实不那么重要，但是理解这个才能理解下面重要的东西）</li><li><strong>变更的时候，怎么样修改 idl 是合理的</strong></li></ul><p>第一个问题本身没那么重要，但是他对理解“怎么样修改 idl 是合理的”很重要。实际上，对于这点，我们可以看到，thrift 会支持：</p><ol><li><em>Types</em></li><li><em>Versioning</em></li></ol><h2 id="Types-in-Thrift"><a href="#Types-in-Thrift" class="headerlink" title="Types in Thrift"></a>Types in Thrift</h2><p><a href="https://thrift.apache.org/docs/types.html">https://thrift.apache.org/docs/types.html</a></p><h3 id="Base-types"><a href="#Base-types" class="headerlink" title="Base types"></a>Base types</h3><p>Thrift 支持：</p><ul><li><code>bool</code>A boolean value, true or false</li><li><code>byte</code> A signed byte</li><li><code>i16</code> A 16-bit signed integer</li><li><code>i32</code> A 32-bit signed integer</li><li><code>i64</code> A 64-bit signed integer</li><li><code>double</code> A 64-bit floating point number</li><li><code>string</code> An encoding-agnostic text or binary string</li></ul><p>这里需要注意：</p><ol><li>不支持 <code>float</code>, 因为部分语言没有。</li><li>不支持 <code>unsigned</code>, 如果需要 <code>unsigned</code>, 你得 cast 了。</li></ol><p>需要说明的时候，在传输的时候，他是按网络序传输的。同时，我们之前谈大小端的时候说到 <code>double</code> 的问题。这里在传输的时候，会把 <code>double</code> 给 <code>reinterpret_cast</code> 成 <code>i64</code>, 然后按网络序发送。</p><p>而 <code>bool</code> 会被按 <code>i8</code> 传输。<code>string</code> 会被组织成 <code>prefix_length</code> + <code>data</code> 的形式。</p><h4 id="containers"><a href="#containers" class="headerlink" title="containers"></a>containers</h4><p>同时，除了上面的基础类型, 它还支持容器，对应 <code>list</code>  <code>set</code> 和 <code>map</code> . 这些类型要求是 iterable 的。</p><h4 id="structs"><a href="#structs" class="headerlink" title="structs"></a>structs</h4><p>表示结构，需要</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Example</span> &#123;</span> </span><br><span class="line"><span class="number">1</span>:i32 number=<span class="number">10</span>, </span><br><span class="line"><span class="number">2</span>:i64 bigNumber,  </span><br><span class="line"><span class="number">3</span>:<span class="type">double</span> decimals,</span><br><span class="line"><span class="number">4</span>:<span class="built_in">string</span> name=<span class="string">&quot;thrifty&quot;</span> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你甚至可以设置 default 值，同时，可以显式设置 tag。</p><p>Thrift 还支持了 message 和 service，但是今天略过不表。</p><h2 id="Interface"><a href="#Interface" class="headerlink" title="Interface"></a>Interface</h2><p>内存结构和二进制表示是分开的，实际上，thrift 甚至可以指定 JSON，xml。不过我们今天就介绍他的 IDL，所以别的不表。</p><p>在生成的时候我们有如下接口：</p><p><img src="https://image.mwish.me/blog-image/F7DF206F-44D2-4486-AF34-71DFB47E8821.png" alt="F7DF206F-44D2-4486-AF34-71DFB47E8821"></p><p>我相信没耐心看完…有几个重要的是：</p><ol><li><code>read</code> 对应的复合类型的 <code>readBegin</code> + <code>readEnd</code></li><li><code>write</code>对应的复合类型的 <code>readBegin</code> + <code>readEnd</code></li><li><code>write</code> 对应的 <code>writeFieldStop</code> </li></ol><blockquote><p>The procedure for reading a struct is to readFieldBegin() until the stop field is encountered, and then to readStructEnd(). The generated code relies upon this call sequence to ensure that everything written by a protocol encoder can be read by a matching protocol decoder.</p></blockquote><p>上述的内容会在代码中被生成，然后按照类型被写入。</p><p>这个同时跟 idl 中的 <code>optional</code>  <code>required</code> 和 default 是挂钩的，可以看看这个 SO：</p><p><a href="https://stackoverflow.com/questions/34100425/apache-thrift-when-use-optional-before-a-list-c-server-seems-not-to-return">https://stackoverflow.com/questions/34100425/apache-thrift-when-use-optional-before-a-list-c-server-seems-not-to-return</a></p><p>这里显示，idl 生成的代码，写入的时候、读取的时候会生成字段，而<code>optional</code> 会影响对应的写入。</p><h3 id="Binary"><a href="#Binary" class="headerlink" title="Binary"></a>Binary</h3><p>binary 可以详见 Compact 和 Binary 的文档：</p><ul><li><a href="https://github.com/apache/thrift/blob/master/doc/specs/thrift-binary-protocol.md">https://github.com/apache/thrift/blob/master/doc/specs/thrift-binary-protocol.md</a></li><li><a href="https://github.com/apache/thrift/blob/master/doc/specs/thrift-compact-protocol.md">https://github.com/apache/thrift/blob/master/doc/specs/thrift-compact-protocol.md</a></li></ul><p>我们介绍 binary:</p><p><img src="https://image.mwish.me/blog-image/2B9FDC8D-470E-4F5E-8E55-F1B7FE54BCC2.png" alt="2B9FDC8D-470E-4F5E-8E55-F1B7FE54BCC2"></p><p><img src="https://image.mwish.me/blog-image/50C3BFC4-24E5-4C9B-9466-69A9981B1E62.png" alt="50C3BFC4-24E5-4C9B-9466-69A9981B1E62"></p><p>实际上，你会知道一点：</p><ol><li>Stop field 能 explicit 的表示结束，而且别的编码不会影响他的正确性</li><li>这里没有 name，只有 field id</li><li>field 可能是乱序的</li></ol><p>那么我们实际上知道，field id 是不能乱设的！我们也可以读读 spec 里面的: <a href="https://github.com/apache/thrift/blob/master/doc/specs/SequenceNumbers.md">https://github.com/apache/thrift/blob/master/doc/specs/SequenceNumbers.md</a></p><h2 id="编程-amp-Version"><a href="#编程-amp-Version" class="headerlink" title="编程 &amp; Version"></a>编程 &amp; Version</h2><p><img src="https://image.mwish.me/blog-image/88075741-4060-4010-B4EF-0B9F9CDD53F8.png" alt="88075741-4060-4010-B4EF-0B9F9CDD53F8"></p><p>以 C++ 为例，用户实际上除了数据，还能看到一个 <code>__isset</code> ，这个字段是 <code>public</code> 的。这个被用来识别版本：</p><ul><li>不认识的 tag 字段被丢弃</li><li>有的字段设置 <code>__isset</code></li></ul><p>上述功能可以实现版本。具体可以看 whitepaper 5.3 的 case analysis:</p><p><img src="https://image.mwish.me/blog-image/0CB17CF3-7E2C-4DA2-A825-BAF31A220D10.png" alt="0CB17CF3-7E2C-4DA2-A825-BAF31A220D10"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Long Tail Key &amp;&amp; Memcache in FB</title>
      <link href="/2020/11/23/Long-Tail-Key-Memcache-in-FB/"/>
      <url>/2020/11/23/Long-Tail-Key-Memcache-in-FB/</url>
      
        <content type="html"><![CDATA[<p>之前这篇文章大体介绍了一下 memcache 的架构： <a href="https://zhuanlan.zhihu.com/p/194347153">https://zhuanlan.zhihu.com/p/194347153</a></p><p>上述一些在这篇文章中会用到的概念有：</p><ul><li>Memcache Pool: 按照 key 切分成为不同的 Pool, 适配不同的 key 和 key 不同的读写频率。同时，把冷热-高低代价的数据放在不同的池子里，然后 tunning, 来保证系统效率。</li><li>Lease 机制：用 Lease 来控制一致性</li><li>In a Region: Replication<ul><li><code>frontend cluster</code> 即一组 服务器和memcached。多组 frontend cluster 存储到底层的 storage 上。</li><li>在 Region 层面，也有 Region Pool, 这是一种资源共享。Region 中 frontend 请求不一，但对应存储层是一样的。对于某类数据：即数量少访问贵的，可以被移到一个共享的池子中。</li></ul></li></ul><p>阅读 FB 分割的时候最好理解上述文章的对应内容。同时，这篇文章建模的时候大量使用了 <code>user</code> 这个词，可能某种程度上，fb 资源是以 user 做某些方式 sharding 的，不过文章也解释了，对资源的请求有和用户火热程度相似的分布。</p><p>了解了架构之后，实际上数据会有上面说的，分布的问题：</p><p><img src="https://image.mwish.me/blog-image/7EC471A1-D7FF-4F7A-B46E-36AD9005BDD4.png" alt="7EC471A1-D7FF-4F7A-B46E-36AD9005BDD4"></p><ul><li>90% 的请求是少于访问32次的，很多人至多有 100 个朋友，并且只和他们发消息/看他们相关的内容。</li><li>部分火热的用户/资源访问频率很高。</li></ul><p>FB 希望：</p><ul><li>一个 region pool 内的热数据能尽量在多个对应 <code>frontend cluster</code> 缓存中</li><li>冷数据全部占用 RAM 的话会是一笔巨大的开销，可以把他们分配在不常访问/访问代价稍高的地方。</li></ul><p>论文把 memcache 集群分为了 frontend cluster 独立的 L1 cache 和共享的 L2 cache，这类似 CPU 的架构，不同于 CPU，由于访问时间/penalty 的增加，可以用一些别的可能复杂一些、更好预测的缓存算法，取代一些可以做到硬件里的 LRU/类LRU 策略，来减小 penalty。</p><p>当然，就我个人感受来看，memcache 应该是 fb 一个通用系统，所以感觉它的算法会做的 common 一些，而不是根据某些业务的请求做一些激进的优化。</p><h2 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h2><blockquote><p>Each key-value pair has a key ID, which is a string. A normalized version of key-id is defined as a normalized key. For example, key ID <code>photos:foobar:&#123;12345&#125;:c&#123;1&#125;</code> has <code>photos:foobar:&#123;N&#125;:c&#123;N&#125;</code> as its normalized key where N stands for an integer value. For this particular example, ‘12345’ is a user ID and the second N = 1 is for version number. A key family is a set for all cache key-value pairs which have the same normalized key.</p></blockquote><p>同时，key 被组织称 key family, 来：</p><ul><li>分配给专用的 memcached pool</li><li>添加 TTL</li><li>整个 key family 迁移</li></ul><blockquote><p>The prefix of normalized key is used to detect which pool the key belongs to. For example, all keys starting with prefix ‘photo’ go to the photo tier which has its dedicated Memcached machines.</p></blockquote><p>论文定义了 <em>work set size</em>，指的是在给定的时间窗口内每个单独的 <code>&lt;key, value&gt;</code>  被访问过的 bytes 和。</p><p><img src="https://image.mwish.me/blog-image/1A0F8742-DA4A-4553-BD23-4DE00ABE8677.png" alt="1A0F8742-DA4A-4553-BD23-4DE00ABE8677"></p><p>同时，这里引入了一个计算放大的量，duplicate factor:</p><p><img src="https://image.mwish.me/blog-image/9D3D2F2D-714D-4094-9200-C11FB4209073.png" alt="9D3D2F2D-714D-4094-9200-C11FB4209073"></p><p>对于一个 key family，它可能被分配到一个 region pool，对应到一个到多个 frontend cluster。<code>wss</code> 表示单个 cluster 的访问的 size, duplication factor 反映在整个集群中的放大比例。region 在这一层逻辑中，可以被看作在 L2 的空间内存里。</p><p>这个值在逻辑上与 key family 对应的 user, 即 key family 实际上对应的请求者数量是相关的：</p><blockquote><p>When a key family is shared across more unique users, it has a higher probability of being accessed from more frontend clusters.</p></blockquote><p>现在目标是，对于某个给定的 key family, 能够把热点请求在 frontend 集群中，作为对应的 L1 cache，不那么热的就不要在 frontend 集群，丢在 L2 Cache 甚至数据库里。</p><h3 id="Key-based-Sampling"><a href="#Key-based-Sampling" class="headerlink" title="Key-based Sampling"></a>Key-based Sampling</h3><p>通过控制采样率来控制采样。</p><blockquote><p>Because keys are not sampled by user requests, key-based sampling can capture all cache accesses including ones not associated with user activities. </p></blockquote><p>这里以 key 为单位，通过以下方式完成采样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hash(key_id) % sample_rate == 0</span><br></pre></td></tr></table></figure><blockquote><p> Because keys are not sampled by user requests, key-based sampling can capture all cache accesses including ones not associated with user activities. </p></blockquote><p>这里要说明的是，fb 请求逻辑可能会这样，比如加载页面，要一个请求加载几百张图片。这里采取的模式是应用简单的 k-v 抽象。</p><p>它的采样算法很简单，<code>hash(key_id) % sample_rate == 0</code> 就算命中…简单吧！</p><p>（我当时看的时候大骂：就这？LRU不来个？LFU不来个？）</p><h3 id="Promotion-Algorithm"><a href="#Promotion-Algorithm" class="headerlink" title="Promotion Algorithm"></a>Promotion Algorithm</h3><p><img src="https://image.mwish.me/blog-image/E39FD911-059D-4E34-9557-96EFA756E441.png" alt="E39FD911-059D-4E34-9557-96EFA756E441"></p><p><img src="https://image.mwish.me/blog-image/639562CE-3D6E-4DF8-BDF5-1106D46DB6A2.png" alt="639562CE-3D6E-4DF8-BDF5-1106D46DB6A2"></p><p>这就真的如上图所述了…我感觉反而没什么好说的。不过现在要在两层 cache 维护 lease, 感觉上原本是一个 miss 请求发一个 lease, 现在感觉两层分别做 lease 应该也可以？然后 promote 独立进行。不知道是不是。</p><p>这里重点是 <code>5</code> 的采样方法，和第一次 miss 加载到 L2 的不会尝试被 promote 到 L1。</p><h3 id="概率模型"><a href="#概率模型" class="headerlink" title="概率模型"></a>概率模型</h3><p><img src="https://image.mwish.me/blog-image/8BCEF769-8A07-4B65-AF7B-8129D14903AA.png" alt="8BCEF769-8A07-4B65-AF7B-8129D14903AA"></p><p>结论：</p><p><img src="https://image.mwish.me/blog-image/46485508-C9A4-4DFB-BB25-F2E19D8499BC.png" alt="46485508-C9A4-4DFB-BB25-F2E19D8499BC"></p><p>文章 4-5 节介绍了这个算法的优化效果，看上去还是不错的。原理感觉和 CPU Cache 多级原理是一样的（不过冷热分割和 cache 结合起来倒是很有意思）</p><h2 id="Redis-HotKey"><a href="#Redis-HotKey" class="headerlink" title="Redis HotKey"></a>Redis HotKey</h2><p>我们介绍了 FB 的采样方法，现在我们讲讲国内用的多的 Redis。</p><p>阿里云 Redis 实现了 <code>hotkeys</code> ，可以帮我们实现热 key 查找： <a href="https://www.alibabacloud.com/help/doc-detail/101108.htm">https://www.alibabacloud.com/help/doc-detail/101108.htm</a></p><p>相关的 issue 可以找到：</p><ul><li><a href="https://github.com/redis/redis/issues/4473">https://github.com/redis/redis/issues/4473</a></li></ul><p>（还是杭州阿里的大佬做的，orz）</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Logarithmically increment a counter. The greater is the current counter value</span></span><br><span class="line"><span class="comment"> * the less likely is that it gets really implemented. Saturate it at 255. */</span></span><br><span class="line"><span class="type">uint8_t</span> <span class="title function_">LFULogIncr</span><span class="params">(<span class="type">uint8_t</span> counter)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (counter == <span class="number">255</span>) <span class="keyword">return</span> <span class="number">255</span>;</span><br><span class="line">    <span class="type">double</span> r = (<span class="type">double</span>)rand()/RAND_MAX;</span><br><span class="line">    <span class="type">double</span> baseval = counter - LFU_INIT_VAL;</span><br><span class="line">    <span class="keyword">if</span> (baseval &lt; <span class="number">0</span>) baseval = <span class="number">0</span>;</span><br><span class="line">    <span class="type">double</span> p = <span class="number">1.0</span>/(baseval*server.lfu_log_factor+<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">if</span> (r &lt; p) counter++;</span><br><span class="line">    <span class="keyword">return</span> counter;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>它依赖概率增加 <code>counter</code>, 同时有一个 <code>baseval</code>. 之前使用的是 <code>hash(key_id) % sample_rate == 0</code> 来决定是不是，现在用 <code>double p = 1.0/(baseval*server.lfu_log_factor+1)</code> 来代替<code>sample_rate</code>, 以增加 counter 来增加采样。</p><p>在 issue 里也提到了，因为是一个 counter, 所以要面对 key 之前常访问，现在少访问的情况，所以要有一个 <code>last_access_time</code> 和 counter:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* If the object decrement time is reached decrement the LFU counter but</span></span><br><span class="line"><span class="comment"> * do not update LFU fields of the object, we update the access time</span></span><br><span class="line"><span class="comment"> * and counter in an explicit way when the object is really accessed.</span></span><br><span class="line"><span class="comment"> * And we will times halve the counter according to the times of</span></span><br><span class="line"><span class="comment"> * elapsed time than server.lfu_decay_time.</span></span><br><span class="line"><span class="comment"> * Return the object frequency counter.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * This function is used in order to scan the dataset for the best object</span></span><br><span class="line"><span class="comment"> * to fit: as we check for the candidate, we incrementally decrement the</span></span><br><span class="line"><span class="comment"> * counter of the scanned objects if needed. */</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span> <span class="title function_">LFUDecrAndReturn</span><span class="params">(robj *o)</span> &#123;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> ldt = o-&gt;lru &gt;&gt; <span class="number">8</span>;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> counter = o-&gt;lru &amp; <span class="number">255</span>;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> num_periods = server.lfu_decay_time ? LFUTimeElapsed(ldt) / server.lfu_decay_time : <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (num_periods)</span><br><span class="line">        counter = (num_periods &gt; counter) ? <span class="number">0</span> : counter - num_periods;</span><br><span class="line">    <span class="keyword">return</span> counter;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>MVCC &amp; SI: 协议</title>
      <link href="/2020/11/17/MVCC-SI/"/>
      <url>/2020/11/17/MVCC-SI/</url>
      
        <content type="html"><![CDATA[<p><img src="https://image.mwish.me/blog-image/98F9A3FE-E697-417F-8A84-0987DDEEEFF0.png" alt="98F9A3FE-E697-417F-8A84-0987DDEEEFF0"></p><p>MVCC 是现代商业数据库非常常用的机制，MySQL InnoDB, Postgres, WiredTiger 都使用了 MVCC，适用范围可见上图，但是 MVCC 本身也引入了问题：</p><ol><li>MVCC 如何实现协议？</li><li>在存储、GC 等方面，MVCC 需要一些 trade off</li></ol><p>Snapshot Isolation 是个更令人脑壳痛的东西，你会发现很多 DB 实现的就是 SI，但是这些 DB 本身其实没有实现 Generalized SQL definition 里面的 SI，实现的可能只是 <code>monotonic atomic view</code>。</p><p>这两个事情在一起比较让人头晕，下面会讲 MVTS，MV2PL 和 SI。</p><p>这里仅仅介绍协议，暂时不介绍 MVCC 的存储和 GC，这几个坑还挺大的。</p><h2 id="MVCC-协议"><a href="#MVCC-协议" class="headerlink" title="MVCC: 协议"></a>MVCC: 协议</h2><p>MVCC 的目的是：</p><p><strong>Writers do not block readers. Readers do not block writers.</strong></p><p>（当然，实际上我感觉还是取决于实现。TS 协议其实都可以 block 呢）</p><p>MVCC 需要大量引入 timestamp 的概念，reader 以 timestamp 来读，并决定自己能读到什么。</p><p>在逻辑视图上，MVCC record 需要引入额外的记录：</p><ol><li>begin</li><li>end</li></ol><p>这两个表示对象的生命周期，也决定了读者来读什么。写入的时候，写者会创建一条记录，给 end 标记上自己的对应的 ts。读者根据自己的 ts 来决定“应该读到什么”。</p><p>实际上 MVCC 和 SI 可能关系比较大，经常用于实现 SI，但是 ts 用来决定读并不代表只能 SI。它可以实现 RC 和 Serializable。但同时，这个协议也会影响具体实现后隔离的表现。</p><p>MVCC 有下面一些 trade-off:</p><ul><li>Concurrency Control Protocol </li><li>Version Storage</li><li>Garbage Collection</li><li>Index Management</li><li>Foreign Key</li></ul><h3 id="MVTS"><a href="#MVTS" class="headerlink" title="MVTS"></a>MVTS</h3><p>MVTS 协议源于 1979 年，是最早的 MVCC 协议。</p><p>TS 协议中，每个事务在开始的时候都会定下一个 commit-ts. 记作 $TS(T_i)$, 同时, 以 commit-ts 为标准，来限制 Tuple 读写，如果不能满足需求，就会被 abort. 同时，tuple 有 read-ts 和 write-ts, 表示单条记录读写。</p><p><img src="https://image.mwish.me/blog-image/6EC5DFC5-AC8C-4565-A9DA-59AA31CF6BD3.png" alt="6EC5DFC5-AC8C-4565-A9DA-59AA31CF6BD3"></p><p>MVTS 中：</p><p>end-ts 相当于之前的 write-ts, read-ts 相当于这个版本对应的最大 read-ts</p><h4 id="写入"><a href="#写入" class="headerlink" title="写入"></a>写入</h4><p>一个事务写入时，如果：</p><ol><li>另一个事务在更新这条记录，有一个最新的正在写入的版本</li><li>已存在的最高版本的 record begin_ts 大于自身</li><li>已存在的最高版本的 record begin_ts 小于自身，但 read-ts 大于自身</li></ol><p>它都会 abort。</p><p>事务写入 tuple 的时候，会在上述的 <code>txn-id</code> 字段设置成自己，相当于 grab 写锁。</p><p>如果 tuple Q 最高版本 <code>k</code> 满足 <code>TS(T) == W-TS(Q_k)</code>, 那么说明是本事务写入，可以放心写。</p><p>如果上述条件都不满足，它会创建一个新的版本，把之前的 end-ts 设置成 <code>TS(T)</code>，然后创建一条新的纪录，把 end-ts 设置成无限，begin-ts 设置成 <code>TS(T)</code>.</p><h4 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h4><ol><li>$T_i$ 读取时，数据库找到 <code>[begin-ts, end-ts]</code> 包含 $TS(T_i)$ 的记录，即事务读到它之前最近的请求</li><li>如果上面有 <code>T_id</code> 的写锁，那么abort或者 wait</li></ol><h4 id="Relaxed"><a href="#Relaxed" class="headerlink" title="Relaxed"></a>Relaxed</h4><p>数据库系统实现里面模型比上面的 relax 一些，读取的时候，如果大于最大的 ts, 那直接读最大的记录。这样读永远不会 abort, 感觉这样实现比较有问题= =</p><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ol><li>仍然需要一定的更改，才能让 MVTS 是 Recoverable 的</li><li>很多时候读取要更新 ts, 可能会放大磁盘写</li></ol><h3 id="MV2PL"><a href="#MV2PL" class="headerlink" title="MV2PL"></a>MV2PL</h3><p><img src="https://image.mwish.me/blog-image/6993165C-819A-4BA7-8B63-DE5F8AFFC552.png" alt="6993165C-819A-4BA7-8B63-DE5F8AFFC552"></p><p>TS 的时间戳来自事务开始时分配的 commit-ts, MVTS 沿用了这个 ts。2PL 的 Commit 时间被当成是全局唯一的时间，准确说是释放第一个锁锁的时间。在 Rigirous 2PL 协议下，可以当成它们等效。</p><p>MV2PL 维护了一个全局单调递增的 ts-counter。事务 Commit 的时候，会把这个 counter 递增，同时赋予自己这个 counter。实际上，MV2PL 使用的不是 timestamp，而是“事务提交的 counter”。</p><h4 id="读取-只读事务"><a href="#读取-只读事务" class="headerlink" title="读取: 只读事务"></a>读取: 只读事务</h4><p>只读事务在读取时，对于只读事务，事务 <code>TS = ts-counter</code>, 然后用这个 ts-counter 去读。</p><p>已知：事务获取 ts-counter 时，之前所有的事务都已经提交。</p><p>即：读取的时候，没有 blocking, 没有 abort。事务记录是完整的。</p><h4 id="读写事务"><a href="#读写事务" class="headerlink" title="读写事务"></a>读写事务</h4><p>读写事务读取时，获得 S-Lock, 读取最新版本，写入时，先对现在的最新，写入后的次新上一个 X-Lock，然后再写一个新版本。然后设置新版本的 <code>end-ts</code> 为无穷，当 Commit 阶段时，事务获得一个 CommitTS, 然后把自己的 ts 对应成这个 commit-ts, 然后设置自己修改所有内容的<code>begin-ts</code> 为自身，设置次新版本 <code>end-ts</code> 为自身，</p><p>实际上，在这里事务的外部时间顺序被削弱了，read 可能可以慢于写。但是时间和事务的 order 被不同的 <code>ts-counter</code> 給 fence 开了。</p><p><img src="https://image.mwish.me/blog-image/16D1F158-2844-4A7E-9DAD-060F95C86CE6.png" alt="16D1F158-2844-4A7E-9DAD-060F95C86CE6"></p><p>在论文  <strong>Fast Serializable Multi-Version Concurrency Control for Main-Memory Database Systems</strong> 中，对于这点提出了证明。</p><p>此外，MV2PL 冲突处理，有如下 comments:</p><blockquote><p>The key difference among 2PL protocols is in how they handle deadlocks. Previous research has shown that the <em>no-wait</em> policy [9] is the most scalable deadlock prevention technique [48]. With this, the DBMS immediately aborts a transaction if it is unable to acquire a lock on a tuple (as opposed to waiting to see whether the lock is released). Since transactions never wait, the DBMS does not have to employ a background thread to detect and break deadlocks.</p></blockquote><h2 id="Snapshot-Isolation"><a href="#Snapshot-Isolation" class="headerlink" title="Snapshot Isolation"></a>Snapshot Isolation</h2><p>Snapshot Isolation 是一种特殊的并发控制方案，已在包括 Oracle，PostgreSQL 和SQL Server在内的商业和开源系统中得到广泛认可。</p><p>实现上，SI 通常依赖 MVCC，但是 MVCC 却不止能实现 SI。</p><ol><li>事务在开始的时候，拿到一个 Snapshot，就是开始时刻事务对应的<strong>一致性</strong>的视图。</li><li>事务在自己的 space 中进行修改。</li><li>事务 Commit 的时候，需要验证和别的事务是否有冲突</li><li>事务<strong>原子性</strong>的 Commit, 一旦 Commit ，要么对别的所有 Snapshot 不可见，要么一下子全部可见。</li></ol><p>那么，采用多版本实现的时候，我们通常需要：</p><ol><li>$StartTS(T_i)$, is the time at which transaction $T_i$ started. </li><li>The second timestamp, $CommitTS(T_i)$ is the time when the transaction $T_i$ requested validation.</li></ol><p>事务读取时，不会看到其后的任何写。</p><blockquote><p>注: MySQL 的 RR 下，有两种读，一种读一致性 Snapshot, 一种全局。实际上 SELECT + SELECT for Update 混用，实际表现会略显混乱.</p></blockquote><p>对于更新事务而言，需要 Commit 之前，要 validate 自身是否是合理合法的。首先，需要了解的是，SI 已经有了 PL-2 的级别，能够防止 G0 G1. 在 SI 的情况下，加入实现的时候，有两个事务，更新了同一条记录，然后提交，可能会造成“某个事务的更新被丢失”，即 lost update。在一些满足 <code>LWW</code>, 即“最近写入为准”的系统中，这是可以的，但是这样可能会违反事务的一致性约束。所以也要避免它。</p><p>可能的情况有：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">StartTS(Tj) ≤ StartTS(Ti) ≤ CommitTS(Tj), or</span><br><span class="line">StartTS(Ti) ≤ StartTS(Tj) ≤ CommitTS(Ti).</span><br></pre></td></tr></table></figure><p>有两种策略：</p><ol><li><strong>first committer wins</strong></li><li><strong>first updater wins</strong></li></ol><p>这些策略按照实现而定具体应该选用什么。</p><h3 id="SSI"><a href="#SSI" class="headerlink" title="SSI"></a>SSI</h3><p>Postgres 实现了 SSI，这个和 Generalized SQL 那篇论文强相关。PG 靠防止 anti dependency 成环，abort 掉可能成环的事务，来实现了 SSI 的调度。同时做了对只读事务的优化。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><strong>An Empirical Evaluation of In-Memory Multi-Version Concurrency Control</strong></li><li><strong>Fast Serializable Multi-Version Concurrency Control for Main-Memory Database Systems</strong> </li><li><a href="https://zhuanlan.zhihu.com/p/54979396">https://zhuanlan.zhihu.com/p/54979396</a></li><li>数据库系统概念，第七版。</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>事务: 并发控制协议: 2PL &amp;&amp; TS</title>
      <link href="/2020/11/15/transaction-concurrency-control/"/>
      <url>/2020/11/15/transaction-concurrency-control/</url>
      
        <content type="html"><![CDATA[<p>并发控制是事务的重要成分，他们会决定事务的调度、处理、abort 顺序。</p><p>事务的并发控制可以大致分为：</p><ul><li>乐观的并发控制<ul><li>OCC </li><li>TS</li></ul></li><li>悲观的并发控制<ul><li>2PL</li></ul></li></ul><p>乐观的并发控制假设冲突比较少的情况发生，出现冲突就会选择事务 abort；悲观的并发控制则是假设事务冲突经常发生，会避免冲突。</p><h2 id="2PL"><a href="#2PL" class="headerlink" title="2PL"></a>2PL</h2><p>首先 2PL 的 Lock 和“读写锁” “自旋锁”这些同步操作不是一回事，后者在 DB 层被称为 Latch。</p><p>基础的锁可以简单分为：</p><ul><li>S-LOCK：Shared Lock，读获取 S-Lock</li><li>X-Lock: Exclusive Lock，写获取 X-Lock</li></ul><p>2PL 分为两个阶段：</p><ol><li>Growing：仅获取锁或者拒绝获取锁的请求</li><li>Shrinking：只允许释放锁</li></ol><h3 id="正确性证明"><a href="#正确性证明" class="headerlink" title="正确性证明"></a>正确性证明</h3><p>数据库系统概念对这个有一个很棒的证明，用的是归纳法：<a href="http://www.mathcs.emory.edu/~cheung/Courses/554/Syllabus/7-serializability/2PL.html">http://www.mathcs.emory.edu/~cheung/Courses/554/Syllabus/7-serializability/2PL.html</a></p><p>（大意是 1个事务中，已经是串行的。然后 n 个事务中，假设 n-1 个事务是串行的，满足 2PL 条件下，无法找到一种调度，让他满足非串行化调度）</p><p><a href="https://zhuanlan.zhihu.com/p/59535337">https://zhuanlan.zhihu.com/p/59535337</a> 这篇文章也给了一个反证法来证明。大意也如上，不过用了成环的角度来描述。</p><p>此外，关于 2PL 的 order, 还有一个很有趣的概念：2PL 可以当成提出第一个解锁请求的时候，瞬时执行的。这个在下面有一个反证法证明（在 claim 那）：<a href="http://www.mathcs.emory.edu/~cheung/Courses/554/Syllabus/7-serializability/2PL.html">http://www.mathcs.emory.edu/~cheung/Courses/554/Syllabus/7-serializability/2PL.html</a></p><h3 id="2PL-的麻烦"><a href="#2PL-的麻烦" class="headerlink" title="2PL 的麻烦"></a>2PL 的麻烦</h3><h4 id="CASCADING-ABORTS"><a href="#CASCADING-ABORTS" class="headerlink" title="CASCADING ABORTS"></a>CASCADING ABORTS</h4><p><img src="https://image.mwish.me/blog-image/1895A50B-B8EC-4C4A-8D81-F8034A2F9BF9.png" alt="1895A50B-B8EC-4C4A-8D81-F8034A2F9BF9"></p><p>上述调度发生的时候，T1 unlock 了，T2 获取锁读 T1，然后 T1 abort 了，为了防止 G1a，T2 也应该 abort。</p><p>那么这个时候，依赖 T2 写入的也都会 abort ，哈，雪崩！</p><p>为了防止这种现象，会有 strict 2PL:</p><blockquote><p>A schedule is <strong>strict</strong> if a value written by a txn is not read or overwritten by other txns until that txn finishes.</p></blockquote><p>在 S2PL 下，不仅能防止上述 cascading abort, 还能靠存储原来的值来恢复 abort。</p><p>此外，还有另一种模式：</p><blockquote><p>Another variant of two-phase locking is the <strong>rigorous two-phase locking protocol</strong>, which requires that all locks be held until the transaction commits. We can easily verify that, with rigorous two-phase locking, transactions can be serialized in the order in which they commit.</p></blockquote><h4 id="Upgrade-Lock"><a href="#Upgrade-Lock" class="headerlink" title="Upgrade Lock"></a>Upgrade Lock</h4><p>如果 txn 先读 object a, 再写 object a。那么它需要进行 upgrade, 把 S-LOCK 变成 X-LOCK。</p><p>升级只能在 growing phase 中进行。</p><h4 id="Deadlock"><a href="#Deadlock" class="headerlink" title="Deadlock"></a>Deadlock</h4><p>在实现上，通常2PL会引入 LockTable 来记录锁的信息。同时向 LockTable 申请锁定。所以与 OS 不一样，数据库可以高度介入这些行为。</p><p>有两种处理死锁的方案：deadlock detection 和 deadlock prevention。</p><h5 id="Deadlock-Prevention"><a href="#Deadlock-Prevention" class="headerlink" title="Deadlock Prevention"></a>Deadlock Prevention</h5><p>deadlock prevention 可以用某种方式，比如开始的时间，来控制优先级。有了优先级，当事务申请 Lock，同时这个 object 上已经有 lock 的时候，有两种策略：wait-die 和 wound-wait，这些策略本身暗示了一个事务序号或者时间戳的存在：</p><ul><li>wait-die: 如果请求的事务有更高的优先级，那么等待，否则会 abort</li><li>wound-wait: 如果请求的事务有更高的优先级，那么 abort 掉持锁的事务，否则会等待事务完成。</li></ul><p>这两种方式让事务抢占锁的时候，有了一个单调的 total order。所以本身是 work 的。同时，为了避免冲突，被 abort 的事务会要求一定程度上用原有的优先级。</p><p>还有一种混合的策略是锁超时，一定时间事务没有推进下去之后，会被判定为超时。</p><h5 id="Deadlock-Detection"><a href="#Deadlock-Detection" class="headerlink" title="Deadlock Detection"></a>Deadlock Detection</h5><p>deadlock detection 通常采取 wait-for graph 的形式来实现，它构建一个 DAG，然后在申请锁的时候，构建 Transaction 的 direct 依赖。unlock 的时候，释放相关的依赖。当 wait-for graph 出现环的时候，说明有冲突. 需要挑选一个 victim 事务 abort 掉。</p><p>当然，这个 wait-for graph 也可以在定时或者其他的时机构建，比如在定期检查的时候构建。</p><p>Abort 事务本身也是有讲究的，这里可能会在 wait-for graph 里面成环，我们需要 abort 掉环中的一个事务。</p><ol><li>事务执行了多久，还需要执行多久</li><li>回滚时牵涉的事务</li><li>这个事务是否重复了很多遍，再 abort 就饿死了。</li></ol><h4 id="LockTable"><a href="#LockTable" class="headerlink" title="LockTable"></a>LockTable</h4><p>综上，上述的内容需要一个 LockTable 来实现。这里采取了一个 HashTable + Chain 的结构：</p><p><img src="https://image.mwish.me/blog-image/70612C78-F305-444C-8918-B7FEC410BF55.png" alt="70612C78-F305-444C-8918-B7FEC410BF55"></p><ul><li>当有 LOCK 请求时，请求排队处理；共享的请求可能被同时 grant</li><li>有 unlock 请求时，释放元素，并且处理下一个</li><li>有 abort 请求时，clear，并进行恢复工作。</li></ul><h3 id="Multiple-Granularity-amp-amp-intention-locks"><a href="#Multiple-Granularity-amp-amp-intention-locks" class="headerlink" title="Multiple Granularity &amp;&amp; intention locks"></a>Multiple Granularity &amp;&amp; intention locks</h3><p>关系型数据库有不同的层次：</p><ul><li>Database</li><li>table</li><li>Page</li><li>Tuple/Row</li><li>Column</li></ul><p>当 Txn 申请 Lock 的时候，DBMS 会面临分配的层次问题：</p><ul><li>层次低的话，分配更多低层次锁，允许更高的并行度，但是 LockTable 会面临更大的时空开销（主要是内存/CPU）。</li><li>分配高层次锁，可能的并行度会降低，但是 LockTable 面临的时空开销减小。</li></ul><p>同时，实现者在 LockTable 维护 Lock 的时候，会发现，协调不同层次的锁是困难的，而且从 Root 开始锁定开销过大，因此有了 intention locks.</p><ul><li>IS: Intention-Shared，希望更细粒度的获得 shared lock</li><li>IX: Intention-Exclusive: 希望获得更细粒度的 exclusive lock</li><li>SIX: S + IX</li></ul><p><img src="https://image.mwish.me/blog-image/C7506976-D338-406A-BCDF-94246279E1DD.png" alt="C7506976-D338-406A-BCDF-94246279E1DD"></p><p>这个应该横坐标是 holding lock, 纵着的是过来的请求。事务给下层上 S/X 锁，父节点必须有对应的锁或者意向锁。</p><p>发现行锁过多可能会进行锁的升级(escalation) ，来更新父级别的锁. 不过 InnoDB 没有，因为它自称自己上锁很便宜（虽然被何登成老师吐槽过 orz）：<a href="https://dev.mysql.com/doc/refman/5.6/en/innodb-transaction-model.html">https://dev.mysql.com/doc/refman/5.6/en/innodb-transaction-model.html</a></p><h4 id="Predicate"><a href="#Predicate" class="headerlink" title="Predicate"></a>Predicate</h4><p>S2PL 很大程度上能防止 G0 G1 G2-Item 了，但是无法保证 G2 不发生，所以需要处理 predicate。这里可以：</p><ol><li>整个 Lock 住信息：添加一个 information object, 读会对他上 S-LOCK，写会 X-LOCK，导致产生冲突。这种方式的缺点是并行能力太差，需要把整个对应的 index 锁住。</li><li>采用 index-locking：读/写之前对对应 B+tree index 的 leaf node 锁定，更新的时候锁定 index 的 <code>(old)</code> <code>(new)</code></li><li>predicate-locking: 对 Predicate 上锁，比较复杂、性能低下而一般不采用。</li></ol><p>MySQL 采用了 next-key locking 的实现，来解决 predicate 和 phantom 的问题。为什么是 Next-Key Locking? 这个策略貌似是上世纪 ARIES/KVL 搞出来的，将谓词锁转化为记录的锁，这种方式相对来说直观又节省空间。</p><h4 id="插入和删除"><a href="#插入和删除" class="headerlink" title="插入和删除"></a>插入和删除</h4><p>插入本身需要注意锁相关的信息。比方说插入的时候本身要对记录上锁，删除的时候也要注意上锁。MySQL 会有插入意向锁，具体可见隐式锁相关的描述：<a href="http://mysql.taobao.org/monthly/2020/09/06/">http://mysql.taobao.org/monthly/2020/09/06/</a> 。</p><h4 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h4><p>更低级的一致性，比如二级一致性(degree-two consistency)可以靠提前释放读锁之类的方式来实现. 有一种方式被称为游标一致性，这里会在 cursor 读期间上读锁，读完之后释放。</p><p>increment lock 是一种特殊的锁。为了保证在某些 inc/dec 操作上的高效而使用:</p><p><img src="https://image.mwish.me/blog-image/D2AC199C-DD0C-47B8-9BBD-2B67BD4357FD.png" alt="D2AC199C-DD0C-47B8-9BBD-2B67BD4357FD"></p><h2 id="TS"><a href="#TS" class="headerlink" title="TS"></a>TS</h2><p>对于 2PL 而言，如果要定序，事务本身会在第一个 lock 释放的时候作为 commit 时间。2PL 本身有这个依赖，其实就简单实现一下是不需要 commit_ts start_ts 的。</p><p>Basic-TS 协议则不然，它会在事务开始的时候，给事务一个 TS，对于事务 T，记作 <code>TS(T)</code>，而 ts 是尽量单调递增的（可以是系统时间或者是一个 counter），某种意义上，这给了所有事务一个 total order。</p><p>那么，我们在事务开始的时候就获得了“如果 commit 应该有的 ts”, 所以，实现上会需要每个 object 的读/写 时间，来完成相关的验证，一旦发现违背了隔离级别的需求，就要进行一定的恢复处理：</p><p>To implement this scheme, we associate with each data item <em>Q</em> two timestamp values:</p><ol><li><strong>W-timestamp</strong>(<em>Q</em>) denotes the largest timestamp of any transaction that executed write(<em>Q</em>) successfully.</li><li><strong>R-timestamp</strong>(<em>Q</em>) denotes the largest timestamp of any transaction that executed read(<em>Q</em>) successfully.</li></ol><p>然后，有一些对应的读写规则：</p><p><img src="https://image.mwish.me/blog-image/A863B4B2-7871-4E03-8D5C-1B2EC2F46CAB.png" alt="A863B4B2-7871-4E03-8D5C-1B2EC2F46CAB"></p><p>上面比较复杂，不过简单说大概思路就是：</p><ol><li>欲写 <code>X</code>，不可以写 <code>TS(T) &lt; W-TS(X)</code> 的数据，不能被定序的后来写入的事务写了。</li><li>欲写 <code>X</code>，不可以写 <code>TS(T) &lt; R-TS(X)</code> 的数据，不能被定序的后来写入的事务读了。</li><li>欲读 , 不能读到定序的事务之后的写入。</li></ol><p>我们下面来考虑 Recoverable 和 Cascadeless:</p><p>TS 协议本身不是 recoverable 的，需要一定的更改，有下面这些参考方案：</p><ol><li>Recoverability and cascadelessness can be ensured by performing all writes together at the end of the transaction. The writes must be atomic in the following sense: While the writes are in progress, no transaction is permitted to access any of the data items that have been written.</li><li>Recoverability and cascadelessness can also be guaranteed by using a limited form of locking, whereby reads of uncommitted items are postponed until the transaction that updated the item commits.</li><li>Recoverability alone can be ensured by tracking uncommitted writes and allowing a transaction <em>T**i</em> to commit only after the commit of any transaction that wrote a value that <em>T**i</em> read. Commit dependencies, outlined in Section 18.1.5, can be used for this purpose.</li></ol><p>TS 不会产生死锁，因为有冲突都 abort 了。但是 Basic-TS 有一些 performance 上的问题：</p><ol><li>本身不是 recoverable 的，需要一定的更改。</li><li>更新 timestamp 开销比较大。</li><li>长时间运行的事务碰见冲突概率比较大，可能会饿死。</li></ol><p>关于 ts 协议有一些批评，就是即使读也要更新相关的数据，造成额外的写开销。</p><h3 id="Thomas-Write-Rule"><a href="#Thomas-Write-Rule" class="headerlink" title="Thomas-Write Rule"></a>Thomas-Write Rule</h3><p>回顾一下规则：欲写 <code>X</code>，不可以写 <code>TS(T) &lt; R-TS(X)</code> 的数据，不能被定序的后来写入的事务读了。</p><p>Thomas-Write Rule 允许你跳过这个规则，因为你可以视作“写入被后来的覆盖了”。</p><h2 id="OCC-基于检查的方法"><a href="#OCC-基于检查的方法" class="headerlink" title="OCC: 基于检查的方法"></a>OCC: 基于检查的方法</h2><p>对于一个事务而言，如果大部分事务是只读事务，冲突较少，那么应该减轻各种处理的开销。OCC 大致分为三个阶段：</p><ol><li>Read Phase: 读对象，把对象 copy 到事务内写</li><li>Validation Phase: txn commit 的时候, 检查事务是否和别的事务产生冲突</li><li>Write Phase: 把记录写入</li></ol><p>我们引入几个时间点（不一定要分配时间戳）来帮助理解这个流程：</p><ol><li><code>StartTs(T)</code>: 事务开始执行的时间</li><li><code>ValidationTS(T)</code>:  完成 Read Phase, 开始进入 <code>StartTs</code> 的时间戳</li><li><code>FinishTs(T)</code>: 完成写阶段的时间戳</li></ol><p>这里可以尝试在 Validation Phase 中分配时间戳，然后 trace 读写的对应时间戳：</p><ol><li>两个事务没有冲突，且 <code>TS(Tk) &lt; TS(Ti)</code>, 当且仅当：<ol><li><code>FinishTS(Tk) &lt; StarTs(Ti)</code>. 这点是显而易见的</li><li><code>ValidationTS(Ti) &gt; FinishTS(Tk)</code> 且 <code>WriteSet(Tk)</code> 和 <code>ReadSet(Ti)</code> 没有相交</li></ol></li></ol><p>这个方法是 Cascadeless 的，因为 Write 阶段之后才能读到正确数据。</p><p>CMU 15-445 描述了一个 validation 的基本策略，他的大致逻辑如下：</p><ol><li>检查与 StartTS 至 ValidationTS 间的提交事务有无冲突，即验证是否读取了 FinishTS 事务的写集合</li><li>发现进入 ValidationTS 的事务中，更旧的事务的时候，进行下列验证：<ol><li>验证阶段的时候（准确说是开始写的时候），对方已完成写。那新事务的读集和旧事务写集不冲突即可。</li><li>验证阶段的时候，对方没完成写，那要求旧事务的写集不和新事务的读写集冲突。</li></ol></li></ol><p>进入 ValidationTS 的时候，TS 是递增的。如果用 StartTS 作事务的时间戳，本身协议上是满足序列化的，但是问题在于验证的时间戳可能不是递增的，这个情况下可能出现：</p><ol><li>两个事务差不多时候开始，<code>TS(i) &lt; TS(j)</code></li><li><code>j</code> 比 <code>i</code> 更早进入验证阶段</li></ol><p>这个时候肯定就有问题了，所以倾向于在 Validation 阶段分配。</p><h2 id="性能评估"><a href="#性能评估" class="headerlink" title="性能评估"></a>性能评估</h2><p>这里不考虑 MVCC 的部分，对他们的性能进行评估. <code>&lt;Staring into the Abyss: An Evaluation of Concurrency Control with One Thousand Cores&gt;</code> 给了一个评估，但我不是很信任它的结果，感觉作者对 scalable counter 没啥经验。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>2PL 部分：</p><ul><li>InnoDB 的 Locking <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html">https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html</a></li><li>InnoDB存储引擎(第2版) <a href="https://book.douban.com/subject/24708143/">https://book.douban.com/subject/24708143/</a></li><li>CMU 15-445</li><li>数据库系统概念(第七版)</li></ul><p>TS 部分：</p><ul><li>CMU 15-445</li><li>数据库系统概念(第七版)</li></ul><p>OCC 部分：</p><ul><li>CMU 15-445</li><li>Microsoft Hekaton</li><li>数据库系统概念(第七版)</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>事务:协议和隔离</title>
      <link href="/2020/11/14/%E4%BA%8B%E5%8A%A1-%E5%8D%8F%E8%AE%AE%E5%92%8C%E9%9A%94%E7%A6%BB/"/>
      <url>/2020/11/14/%E4%BA%8B%E5%8A%A1-%E5%8D%8F%E8%AE%AE%E5%92%8C%E9%9A%94%E7%A6%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="事务：隔离级别和协议"><a href="#事务：隔离级别和协议" class="headerlink" title="事务：隔离级别和协议"></a>事务：隔离级别和协议</h1><p>应用程序员会依赖事务这么一种抽象：事务。它提供了 ACID 的抽象，A 可以理解为多行数据读/写的原子性；C 据说是用来凑数的；I 表示事务中间有某种互相隔离；D 表示事务是持久的。对于应用程序员而言，抽象是隔离级别。关于这点，可以简单这么理解：<strong>隔离级别越高，冲突越剧烈，可能的性能会更差</strong>。而我们也可以牺牲一些保证，来提供性能</p><p>对应用程序员而言，需要理解的是隔离级别，甚至数据库更上层的建模、缓存。ANSI-92 中给出了一定的隔离级别的定义，但是对乐观的事务而言，我们仍然需要理解一些不同的标准。我们下面会介绍一些隔离级别，这里援引了 DDIA 的定义：</p><ol><li>Read Committed: <ol><li>（最基础的隔离级别，很多时候</li><li>从 DB 读的时候，只能看到已经提交的数据，没有脏读</li><li>写入的时候，不会覆盖掉未写入的数据，没有脏写</li><li>可能的实现：行级别的 Lock，或者是 MVCC/COW 等机制</li></ol></li><li>Repeatable Read: 没有 read skew</li><li>Snapshot Isolation: 从一个一致性的视图中读取<ol><li>没有read skew</li><li>可能会有 write skew</li></ol></li><li>Serializable: 所有事务的调度是可串行化的</li></ol><p>我们还有一些现象，代表某种程度上对事务的 break：</p><ol><li>Dirty reads: 看到了未提交的数据</li><li>Dirty write: 不能覆盖另一个事务的尚未提交的一部分</li><li>Read skew/unrepeatable read: 两次读同一个 record 可能读到不同的值</li><li>write skew: 可以将写入偏差视为丢失更新问题的一般化。如果两个事务读取相同的对象，然后更新其中 一些对象（不同的事务可能更新不同的对象），则可能发生写入偏差。在多个事务更新同一<br>个对象的特殊情况下，就会发生脏写或丢失更新（取决于时机）。在 PG MySQL/InnoDB 等的 RR 级别下，都无法避免 Write Skew</li><li>phantom read：DDIA 认为这是导致写入偏差的根源，SELECT 查询到符合条件的 columns，然后按照条件操作一个 subset。这个时候，一个事务中的写入导致了另一个事务查询结果被改变。 </li></ol><p>其实上面这些我整理的还是挺乱的，有空的可以回顾一下 DDIA…但是上面这些虽然乱，但是对应的内容其实是不难懂的。难就难在显示可能有点区别：</p><ul><li>DDIA 的定义倾向于 2PL + MVCC 相关，但是实际上会有不同的实现。别看实现都会尽量实现标准，但是在数据库领域，某个地方的实现能决定太多的行为了。</li><li>有很多数据库采取乐观的并发控制，他们的表现会不会不太一样？</li><li>有部分数据库实现上采取 SI 代替 RR，这会不会导致定义上有什么问题？</li><li>如何理解 MySQL，PG 这类的隔离级别？</li><li>“写后读” 这些定义和上述有什么关系？</li></ul><p>我们尽量以不介绍实现的情况下来讲讲，但是下面内容可能不可避免的要求你对 2PL MVCC SI 有着最基础的理解。在数据库领域，某个地方的实现能决定整个链路的行为。</p><h2 id="ANSI-92-Phenomena"><a href="#ANSI-92-Phenomena" class="headerlink" title="ANSI-92 Phenomena"></a>ANSI-92 Phenomena</h2><p><img src="https://image.mwish.me/blog-image/8A4D7051-23D4-43B1-9E29-90FC938CD97A.png" alt="8A4D7051-23D4-43B1-9E29-90FC938CD97A"></p><p><img src="https://image.mwish.me/blog-image/6B34260B-EF80-4FA3-AC86-94F2B91FD159.png" alt="6B34260B-EF80-4FA3-AC86-94F2B91FD159"></p><p>1/2 表示事务 ID，c a 表示 COMMIT ABORT，那么我们可以很好的把上面的四个 P 对应到 DDIA 的定义中。这个需要放到单对象 + Lock 的环境下理解：</p><ol><li>P0: 对单对象的覆盖写入，即脏写，导致仅 COMMIT 的时候数据库的状态为 Txn2 的写入。</li><li>P1 对单对象的脏读。如果 TXN1 abort 了，那么显然很危险。</li><li>P2: 写修改了读, 类似不可重复读的修改。</li><li>P3: Phantom Read，对于某个 Predicate 的读 — 改</li></ol><p>懂了这些，你应该很好看懂上面的定义。</p><p>但是你可以发现，其实某些时候，在乐观并发或者 MVCC 下，有些调度甚至是没问题的。SI 甚至让事情更模糊。这里我们可以参考另一篇论文，《Generalize Isolation Level Definitions》的定义了。</p><p>懂了这些，你应该很好看懂上面我们在第一节的定义。但是这个定义是又麻烦的：对于乐观甚至 MVCC 的实现，我没可能不会显示锁定/允许读写是并存的，那么这个定义实际上就是不能满足的。实际上我们可以 break P0/P1：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">H1: r1(x, 5) w1(x, 1) r1(y, 5) w1(y, 9) r2(x, 1) r2(y, 9) c1 c2</span><br></pre></td></tr></table></figure><p>那么，这里 break 了上面的要求，但是仍然是可串行化的调度。所以我们需要一个更 specific 的模型来描述。</p><h3 id="建模-History-Event-Order"><a href="#建模-History-Event-Order" class="headerlink" title="建模: History Event Order"></a>建模: History Event Order</h3><p>我们需要确切描述事务，我们就需要一个具体的模型。我们先远离关系的概念，从 row/tuple 开始：</p><ul><li><p>row/tuple 是一个 object，对于单个 Object 而言，事务以一个 total order 操作这个 object</p></li><li><p>一个 object 有 1 个以上的版本，可以读到 committed, uncommitted 甚至 abort 的数据</p></li><li><p>如果 $T_i$ commit 了，那么认为对 $T_i$ 而言，它写入的任何一个 Object 的版本 $x_i$ , $T_i$ install $x_i$, 如果 $T_i$ abort 了，那么 $x_i$ 不会被视作 committed 的一部分。</p></li><li><p>$T<em>{init}$ 是一个抽象的事务，它被视作最初的事务，给每个出现的 object 一个虚拟的初始版本 $X</em>{init}$ ，当事务第一次写入的时候，从 init 变成最初状态。当这个 object 被删除的时候，被标记成最终版本 $X_{dead}$ 。</p></li><li><p>如果一个对象被删除后又被插入了，那么视为两个不同的对象。</p></li></ul><p>我们把整个操作的序列称为 <strong>Transaction History</strong>，History 有两部分组成：</p><ul><li>偏序的 <strong>Events</strong> (<strong>E</strong>)</li><li>全序的 version order</li></ul><h4 id="Event"><a href="#Event" class="headerlink" title="Event"></a>Event</h4><p>对于 Event，我们可以有：</p><ol><li>Read(r)</li><li>Write(w)</li><li>commit(c)</li><li>abort(a)</li></ol><p>我们有如下的记号</p><ol><li>TXN j 读 X 读到版本 i, 获得值 v，可以记作 $r<em>j(x_i, v)$ 或者 $r_j(x</em>{i.v})$</li><li>TXN i 写 X 写入到版本 i, 值 v，可以记作 $w<em>i(x_i, v)$ 或者 $w_i(x</em>{i.v})$</li></ol><p>对于这个 order，我们要明白 Event 和 version order 的规则：</p><p>对于 Event 而言，它保证了事务的偏序关系：</p><ol><li>如果  $r<em>j(x_i, v)$ 存在，那么它 preceded by $w_i(x</em>{i.v})$, 并且对应着“最近的写入”</li><li>在 Event 中，如果 $w<em>i(x</em>{i.v})$ 和  $r<em>j(x.m)$ 中没有任何一个 $w_i(x</em>{i.{v2}})$, 那么  $r<em>j(x.m)$ 独到的必定等于 $x</em>{i.v}$</li><li>History 必须是完整的，有事务就必须有对应的 commit/abort</li></ol><h4 id="Version"><a href="#Version" class="headerlink" title="Version"></a>Version</h4><p>对于 version 而言：</p><ol><li>对象 x 有一个 init 版本和至多一个 dead 版本</li><li>它的可见版本在 init 版本和 dead 版本之间</li><li>如果 History 有 $r_j(x_i)$ 那么 $x_i$ 为可见版本，无论是否 commit</li></ol><p>同时，需要注意的是，version order 不一定和写入顺序是完全一样的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w1(x1) w2(x2) w2(y2) c1 c2</span><br><span class="line">r3(x1) w3(x3) w4(y4) a4</span><br></pre></td></tr></table></figure><p>这里 x2 在 x1 后写入，但是因为 commit 的 order，实际上对应的 x1 在 x2 前。</p><h3 id="Predicate"><a href="#Predicate" class="headerlink" title="Predicate"></a>Predicate</h3><p>对于谓词而言，我们需要引入额外的记号。P 是一个 Boolean expression，在数据集里面，满足这个要求的版本集合被称为 <code>Vset(P)</code> 。注意，这个集合 之包含存在的记录，未涉及的 init 记录这些是不存在的, 它只包含对应的 visible 对象。</p><p>对于读取而言，假设有下列的 SQL：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> EMPLOYEE <span class="keyword">WHERE</span> DEPT <span class="operator">=</span> SALES;</span><br></pre></td></tr></table></figure><p>同时有 x,  y 两个 object ，它们的版本分别为 1 2，x 满足 <code>DEPT=SALES</code>满足需求的 z0 在未来会被插入。</p><p>那么我们需要写出对应的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rj(P: Vset(P)) rj(xj) rj(yj) ...</span><br></pre></td></tr></table></figure><p>对，这下复杂了很多：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ri(dept=sales: x1; y2) rj(xj)</span><br></pre></td></tr></table></figure><h2 id="Dependencies"><a href="#Dependencies" class="headerlink" title="Dependencies"></a>Dependencies</h2><p>这篇论文定义了三种 conflict，同时分为了 regular conflict 和 predicate-based conflict。它们描述的是事务之间的依赖关系。</p><h3 id="Read-Dependencies"><a href="#Read-Dependencies" class="headerlink" title="Read Dependencies"></a>Read Dependencies</h3><h4 id="predicate-based-conflict"><a href="#predicate-based-conflict" class="headerlink" title="predicate-based conflict"></a>predicate-based conflict</h4><p>对于一个 Predicate，如果某个事务在它读之前，插入了满足 Predicate 的记录，那么会有 read dependency</p><h4 id="Directly-Read-Dependency"><a href="#Directly-Read-Dependency" class="headerlink" title="Directly Read Dependency"></a>Directly Read Dependency</h4><p>事务 $T_j$  direct read depend $T_i$ 时，会有下列的条件：</p><ul><li>directly item-read-depents: Tj 读到了 Ti 写入的记录</li><li>directly predicate-read-depends: Ti 更新了满足匹配 <code>Vset(P)</code> 的对象，并且被 Tj 读到了</li></ul><h3 id="Anti-Dependency"><a href="#Anti-Dependency" class="headerlink" title="Anti Dependency"></a>Anti Dependency</h3><p>当事务覆盖了另一个事务独到的值的时候，产生了 anti-dependency。</p><h4 id="predicate-based-conflict-1"><a href="#predicate-based-conflict-1" class="headerlink" title="predicate-based conflict"></a>predicate-based conflict</h4><p>对于一个 Predicate，如果某个事务在它读之后，插入了满足 Predicate 的记录，那么会有 anti dependency</p><h4 id="Directly-Anti-Dependency"><a href="#Directly-Anti-Dependency" class="headerlink" title="Directly Anti Dependency"></a>Directly Anti Dependency</h4><p>事务 $T_j$  direct anti depend $T_i$ 时，会有下列的条件：</p><ul><li>directly item-anti-depents: Ti 覆盖了 Tj 读到的记录</li><li>directly predicate-anti-depends: Ti 更新了满足匹配 <code>Vset(P)</code> 的对象，他之前并且被 Tj 读到了</li></ul><h3 id="Write-Dependency"><a href="#Write-Dependency" class="headerlink" title="Write Dependency"></a>Write Dependency</h3><p>如果事务 $T_i$ 覆盖了 $T_j$ 写入的版本，那么它们有 direct-write-depend。</p><h2 id="Serialization-Graph"><a href="#Serialization-Graph" class="headerlink" title="Serialization Graph"></a>Serialization Graph</h2><p><img src="https://image.mwish.me/blog-image/9702A3CB-D18C-4751-AF2E-4B346C879B2F.png" alt="9702A3CB-D18C-4751-AF2E-4B346C879B2F"></p><p>有一点关键是，事务或许不是全序的，但是至少应该是<strong>偏序</strong>的。所以，我们对事务构建 DAG，不应该存在环。</p><p>那么，通过上述几种 dependency，我们可以构建依赖的有向图，来判断具体的关系。</p><p><img src="https://image.mwish.me/blog-image/53878744-E179-4603-B768-D80DBCFD58EF.png" alt="53878744-E179-4603-B768-D80DBCFD58EF"></p><p>同时可以定义 depends 关系：</p><p><img src="https://image.mwish.me/blog-image/33241D20-8EB6-46C6-9AAD-EDAC95237199.png" alt="33241D20-8EB6-46C6-9AAD-EDAC95237199"></p><h2 id="New-Generalized-Isolation-Specifications"><a href="#New-Generalized-Isolation-Specifications" class="headerlink" title="New Generalized Isolation Specifications"></a>New Generalized Isolation Specifications</h2><blockquote><p>Like the previous approaches, we will define each iso- lation level in terms of phenomena that must be avoided at each level. Our phenomena are prefixed by “G” to denote the fact that they are general enough to allow locking and op- timistic implementations; these phenomena are named G0, G1, and so on (by analogy with P0, P1, etc of [6]). We will refer to the new levels as PL levels (where PL stands for “portable level”) to avoid the possible confusion with the degrees of isolation given in [8, 13].</p></blockquote><p>这里用 G 表示 phenomena，PL 表示 portable levels。</p><h3 id="PL-1"><a href="#PL-1" class="headerlink" title="PL-1"></a>PL-1</h3><p>这个对应的其实相当于 P0，我们抄英文看看原定义：</p><blockquote><p>we define <strong>PL-1</strong> as the level in which G0 is disallowed:</p><p><strong>G0: Write Cycles.</strong> A history H exhibits phenomenon G0 if DSG(H) contains a directed cycle consisting entirely of write-dependency edges.</p></blockquote><p><img src="https://image.mwish.me/blog-image/89DEB4D5-C31F-4430-9C08-B1E314CAF4A6.png" alt="89DEB4D5-C31F-4430-9C08-B1E314CAF4A6"></p><p>实际上覆盖写未提交的本身在 2PL 意外的实现中不一定出了大问题，但是如果有上述的重复覆盖，那么就会真正出现问题。即如上图。同时论文也给出了 predicate 相关的 $H_{wcycle}$</p><p><img src="https://image.mwish.me/blog-image/813DDC98-A805-41A7-B406-9D4986272255.png" alt="813DDC98-A805-41A7-B406-9D4986272255"></p><h3 id="PL-2"><a href="#PL-2" class="headerlink" title="PL-2"></a>PL-2</h3><p>PL-1 对读是没有限制的，当然，出现我们之前说的“脏读”就太正常了。</p><p>G1 由 G1a G1b G1c 构成：</p><p><img src="https://image.mwish.me/blog-image/DF4CBE7C-03E6-4F03-83A2-5DD32CB18F17.png" alt="DF4CBE7C-03E6-4F03-83A2-5DD32CB18F17"></p><p>G1a: 读到了 abort 事务的数据。</p><p><img src="https://image.mwish.me/blog-image/8F504CF7-0381-4DBB-810E-65126DE2D4A8.png" alt="8F504CF7-0381-4DBB-810E-65126DE2D4A8"></p><p>G1b: 读到了事务<strong>中间</strong> 的数据</p><p><img src="https://image.mwish.me/blog-image/FC512948-7B2A-4A46-BFA8-BABC63264652.png" alt="FC512948-7B2A-4A46-BFA8-BABC63264652"></p><p>G1c: 产生了 direct 的环。即 direct rr, rw, wr 的环。</p><blockquote><p>Phenomenon G1 captures the essence of no-dirty-reads and is comprised of G1a, G1b and G1c. We define isolation level <strong>PL-2</strong> as one in which phenomenon G1 is disallowed. Proscribing G1 is clearly weaker than proscribing P1 since G1 allows reads from uncommitted transactions. </p></blockquote><p>实际上，这个相当于 read committed, 但是会弱一些：</p><blockquote><p>Proscribing G1 is clearly weaker than proscribing P1 since G1 allows reads from uncommitted transactions.</p></blockquote><p>P1 不允许<strong>脏读</strong>，那么 PL-2 靠：</p><ol><li>不允许读到 abort/中间的数据，但是允许短暂读到 uncommitted 的数据</li></ol><p>实际上，这相当于，<strong>被 committed 的事务</strong> 可以读到 <strong>未提交但未来被提交</strong> 的数据。</p><p>direct 依赖的环比较难理解，就是 Figure2 那些。这个我简单推导一下为什么这个能满足 对应的 read committed：</p><ul><li>$T_i$ 事务读一组 x, y, z… 读到 $x_k$ $y_k$ …</li><li>$T_i$ 在一组子集上再次读，读到了 $T_j$ 写入的数据，这个时候，$T_i$ depend $T_j$</li><li>$T_j$ 如果有任何情况下直接依赖了 $T_i$ 的数据，那么这个顺序就被 break</li></ul><p>但是这个没有禁止 anti-dependency, 即 P2 P3 对应的</p><ul><li>$T_j$ $T_k$ 事务读一组 x, y, z… 读到 $x_k$ $y_k$ …</li><li>$T_j$ 修改了 $x_k$ ，改为 $x_j$ , commit, 这个时候 $T_k$ anti depend $T_j$</li><li>$T_k$ 读到了 $x_k$ , 这个时候 $T_j$ depent $T_k$</li></ul><p>好了，break 了！</p><h3 id="PL-3"><a href="#PL-3" class="headerlink" title="PL-3"></a>PL-3</h3><p><img src="https://image.mwish.me/blog-image/60CD6506-2D23-46AC-AAC2-655921CADD0C.png" alt="60CD6506-2D23-46AC-AAC2-655921CADD0C"></p><p>禁止所有 anti-dependency 之后，整个事务就变的<strong>有序了</strong>。这对应 serializable。其实这个相对来说是最好理解的。</p><h3 id="PL-2-99"><a href="#PL-2-99" class="headerlink" title="PL-2.99"></a>PL-2.99</h3><p>这个对应的是 repeatable read. </p><p><img src="https://image.mwish.me/blog-image/5E61590D-1A6F-4C8D-9E8A-1E542DEE85E7.png" alt="5E61590D-1A6F-4C8D-9E8A-1E542DEE85E7"></p><p>它允许 Item Anti-dependency, 用来处理可重复读。</p><h3 id="Snapshot-Isolation-PL-SI"><a href="#Snapshot-Isolation-PL-SI" class="headerlink" title="Snapshot Isolation: PL-SI"></a>Snapshot Isolation: PL-SI</h3><p>我一下没找到这个定义，有点蒙圈，后来发现在博士论文 4.3 里…</p><p>好吧，坑啊！这里定义了 PL-2+ 来引入 PL-SI：</p><h3 id="PL-2-1"><a href="#PL-2-1" class="headerlink" title="PL-2+"></a>PL-2+</h3><p>PL-2+ 表示看到一致性视图的最低级别</p><blockquote><p><strong>G-single: Single Anti-dependency Cycles.</strong> A history H exhibits phenomenon G- single if DSG(H) contains a directed cycle with exactly one anti-dependency edge.</p><p>Level <strong>PL-2+</strong> proscribes G1 and G-single. Intuitively, PL-2+ provides consistency because cycles with one anti-dependency edge occur exactly when some transaction both observes and misses modifications of another transaction.</p></blockquote><h3 id="PL-2L"><a href="#PL-2L" class="headerlink" title="PL-2L"></a>PL-2L</h3><p>这个级别表示了单调读。</p><h3 id="PL-SI"><a href="#PL-SI" class="headerlink" title="PL-SI"></a>PL-SI</h3><p><img src="https://image.mwish.me/blog-image/02E27F7E-B745-41F5-81F0-52A2D284F9D1.png" alt="02E27F7E-B745-41F5-81F0-52A2D284F9D1"></p><p>具体定义还是蛮复杂的，简单来说是：</p><ol><li>涉及一个 start 的时间戳的序，在 start 开始之后的 read-write dependency 不能存在（但是可以存在 anti-dependency, 如下文所述）</li><li>写入不发生冲突</li><li>允许 PL-2+ 定义的 consistent view, 可以有且仅有单个 anti-dependency 边的 cycle 存在。（</li></ol><h2 id="现实中的数据库"><a href="#现实中的数据库" class="headerlink" title="现实中的数据库"></a>现实中的数据库</h2><p><a href="https://github.com/ept/hermitage">https://github.com/ept/hermitage</a></p><p>上面这个链接是现实数据库中对应的隔离级别。</p>]]></content>
      
      
      
        <tags>
            
            <tag> database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>软/硬的分界: 虚拟</title>
      <link href="/2020/11/08/%E8%BD%AF-%E7%A1%AC%E7%9A%84%E5%88%86%E7%95%8C-%E8%99%9A%E6%8B%9F/"/>
      <url>/2020/11/08/%E8%BD%AF-%E7%A1%AC%E7%9A%84%E5%88%86%E7%95%8C-%E8%99%9A%E6%8B%9F/</url>
      
        <content type="html"><![CDATA[<p>如果你啃过 OSTEP 或者什么国内的教材，那么你一定知道 Paging 这些虚拟内存相关的策略，那下面我们整理一下知识点：</p><ol><li><strong>操作系统</strong> 采用了 <strong>虚拟内存</strong> 的策略，这个策略实际上很类似 CPU 的 cache</li><li><strong>CPU</strong> 使用的是<strong>虚拟地址</strong>，经 <strong>页表</strong> 转化为物理地址。这种虚拟内存的方案优势是：<ol><li>支持更大的虚拟地址空间，我们可能只有16G的 <strong>物理内存</strong>，但我们有一个 32位/64位的地址空间，同时，我们也能够适当的完成 swap </li><li>支持隔离，保护一个 <strong>进程</strong> 免受其他 <strong>进程</strong> 的影响</li></ol></li><li>虚拟地址被分为虚拟页号(可能有数级)和页内偏移，经 <strong>转化</strong> 之后称为一份</li><li><strong>页表</strong> 存储在 <strong>内存</strong> 中，对一个地址空间而言，每一个位置维护一个 page table entry 的内存开销过高，所以会采取多级页表的形式，减少 <strong>内存访问</strong> 的开销。实际上，很多时候页表的结构类似 radix tree。</li><li>因为 <strong>内存</strong> 的访问有巨大的 gap, 所以需要 TLB 作为一种 cache<ol><li>对于多个进程而言，每个<strong>进程</strong>会有一套自己独立的地址空间，上下文切换的时候，TLB 需要 Flush 对应的表项，或者给 entry 一个 <strong>标示进程</strong> 的字段</li></ol></li><li>具体访问的时候，某个 <strong>Page</strong> 可能在<strong>访问位</strong>被标记上读/写 flag，甚至会有 <strong>保护页</strong> 的存在</li></ol><p>然后，我们还知道：</p><ul><li>TLB 没有对应的 Page entry，会发生 TLB 失效。这个时候，Page 可能在<strong>内存</strong>中，需要访问加载，可能不在内存中，需要<strong>操作系统</strong> 来处理缺页异常(page fault).<ul><li>这需要额外的机制来<strong>中断</strong>正在运行中的活跃进程，将控制权转移到 <strong>操作系统</strong>，然后再恢复过来。</li></ul></li></ul><p>好吧，我最早考 OS 的时候觉得上面的观点都是很自然的，但是你会发现有问题就是：</p><ul><li>哪些部分是软件(OS)做的，哪些部分是硬件做的？</li><li>虚拟地址是对谁而言的？</li><li>进程切换 Flush TLB 这些是谁做的？</li></ul><p>这个时候你会感觉突然不正常了起来，我们需要知道的是：</p><ol><li>OS 支持了什么</li><li>ISA 支持了什么，硬件要做什么</li></ol><p>然后，OS 以 xv6 的 RISC-V 版本为例，ISA 以 RISC-V 为例，去看看问题到底是什么样子的。</p><p>最后，在具体讨论之前，需要注意的是：<strong>操作系统 和 ISA 的分界并不是平坦的，很多东西即可以软件做，又可以硬件做（但是很多时候在 ISA 上提供切口大概会方便很多）</strong>。</p><h2 id="Review"><a href="#Review" class="headerlink" title="Review"></a>Review</h2><p>我们在这个 Part 其实很早就聊过 OS 应该做什么： <a href="https://zhuanlan.zhihu.com/p/150571417">https://zhuanlan.zhihu.com/p/150571417</a></p><ul><li><p>memory translation</p></li><li><ul><li>每个运行的进程需要从 virtual 的进程转成物理内存</li><li>program 实际处理的是虚拟内存，需要硬件支持</li></ul></li><li><p>protection and privilege</p></li><li><ul><li>需要提供 user 和 supervisor 的模式，在 RISC-V 中有 machine 和 supervisor 模式</li></ul></li><li><p>更低的层次不能修改 memory mapping</p></li><li><ul><li>supervisor 可以</li><li>supervisor 有独立于用户程序的 virtual 到 physical 映射</li></ul></li><li><p>提供 traps 和 interrupt，在命令层面提供了到 supervisor 的方法</p></li></ul><p>也就是说：</p><h4 id="1-地址"><a href="#1-地址" class="headerlink" title="1: 地址"></a>1: 地址</h4><p>指令中给的有可能是 <strong>虚拟地址</strong>，也有可能是<strong>物理地址</strong>，需要 ISA/硬件 进行额外的支持。实际上，正常的用户态程序运行的时候，我们使用的地址、汇编中的地址都是 <strong>虚拟地址</strong></p><p><img src="https://image.mwish.me/blog-image/966DE38A-A499-4BDC-8BDF-46F344EFC8CC.png" alt="966DE38A-A499-4BDC-8BDF-46F344EFC8CC"></p><p>Supervisor 模式提供了一种简单基于页面的虚拟内存，这种方式如下所示：</p><p><img src="https://image.mwish.me/blog-image/43A18D7F-8D2B-4D62-8AA4-7BD8571D10CB.png" alt="43A18D7F-8D2B-4D62-8AA4-7BD8571D10CB"></p><ol><li>硬件/ISA 可以分清楚页表项，并且交给硬件进行访问</li><li>软件(OS)也可以进行对应的设置，在内存中操作，处理缺页的异常。</li></ol><p>而是否 enable 虚拟内存这种机制，取决于 <code>satp</code> 寄存器：</p><blockquote><p>一个叫 satp(Supervisor Address Translation and Protection，监管者地址转换和保护) 的 S 模式控制状态寄存器控制了分页系统。如图 10.12 所示，satp 有三个域。MODE 域可 以开启分页并选择页表级数，图 10.13 展示了它的编码。ASID(Address Space Identifier， 地址空间标识符)域是可选的，它可以用来降低上下文切换的开销。最后，PPN 字段保存 了根页表的物理地址，它以 4 KiB 的页面大小为单位。通常 M 模式的程序在第一次进入 S 模式之前会把零写入 satp 以禁用分页，然后 S 模式的程序在初始化页表以后会再次进行 satp 寄存器的写操作。</p></blockquote><p><img src="https://image.mwish.me/blog-image/D31816F2-EF17-4CFF-85B5-AD88A1CA02BB.png" alt="D31816F2-EF17-4CFF-85B5-AD88A1CA02BB"></p><p>而 <code>satp</code> 寄存器：</p><blockquote><p>当在 satp 寄存器中启用了分页时，S 模式和 U 模式中的虚拟地址会以从根部遍历页表 的方式转换为物理地址。图 10.14 描述了这个过程:</p><ol><li>satp.PPN 给出了一级页表的基址，VA[31:22]给出了一级页号，因此<strong>处理器</strong>会读取 位于地址(satp. PPN × 4096 + VA[31: 22] × 4)的页表项。</li><li>该 PTE 包含二级页表的基址，VA[21:12]给出了二级页号，因此<strong>处理器</strong>读取位于地 址(PTE. PPN × 4096 + VA[21: 12] × 4)的叶节点页表项。</li><li>叶节点页表项的 PPN 字段和页内偏移(原始虚址的最低 12 个有效位)组成了最终结果: 物理地址就是(LeafPTE. PPN × 4096 + VA[11: 0])</li></ol></blockquote><p>此外，关于之前的 TLB 的问题，指令提供了对应的支持：</p><blockquote><p>这意味着如果操 作系统修改了页表，那么这个缓存会变得陈旧而不可用。S 模式添加了另一条指令来解决 这个问题。这条 sfence.vma 会通知处理器，软件可能已经修改了页表，于是处理器可以 相应地刷新转换缓存。它需要两个可选的参数，这样可以缩小缓存刷新的范围。一个位于 rs1，它指示了页表哪个虚址对应的转换被修改了;另一个位于 rs2，它给出了被修改页表 的进程的地址空间标识符(ASID)。如果两者都是 x0，便会刷新整个转换缓存。</p></blockquote><p>和下面这段</p><blockquote><p>sfence.vma 仅影响执行当前指令的 hart 的地址转换硬件。当 hart 更改了另一个 hart 正在使 用的页表时，前一个 hart 必须用处理器间中断来通知后一个 hart，他应该执行 sfence.vma 指令。这个过程通常被称为 <em>TLB</em> 击落。</p></blockquote><p>我们可以在 xv6 看到相关的代码:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">.globl trampoline</span><br><span class="line">trampoline:</span><br><span class="line">.align 4</span><br><span class="line">.globl uservec</span><br><span class="line">uservec:    </span><br><span class="line">#</span><br><span class="line">        # trap.c sets stvec to point here, so</span><br><span class="line">        # traps from user space start here,</span><br><span class="line">        # in supervisor mode, but with a</span><br><span class="line">        # user page table.</span><br><span class="line">        #</span><br><span class="line">        # sscratch points to where the process&#x27;s p-&gt;tf is</span><br><span class="line">        # mapped into user space, at TRAPFRAME.</span><br><span class="line">        #</span><br><span class="line">        </span><br><span class="line"># swap a0 and sscratch</span><br><span class="line">        # so that a0 is TRAPFRAME</span><br><span class="line">        csrrw a0, sscratch, a0</span><br><span class="line"></span><br><span class="line">        # save the user registers in TRAPFRAME</span><br><span class="line">        sd ra, 40(a0)</span><br><span class="line">        sd sp, 48(a0)</span><br><span class="line">        sd gp, 56(a0)</span><br><span class="line">        sd tp, 64(a0)</span><br><span class="line">        sd t0, 72(a0)</span><br><span class="line">        sd t1, 80(a0)</span><br><span class="line">        sd t2, 88(a0)</span><br><span class="line">        sd s0, 96(a0)</span><br><span class="line">        sd s1, 104(a0)</span><br><span class="line">        sd a1, 120(a0)</span><br><span class="line">        sd a2, 128(a0)</span><br><span class="line">        sd a3, 136(a0)</span><br><span class="line">        sd a4, 144(a0)</span><br><span class="line">        sd a5, 152(a0)</span><br><span class="line">        sd a6, 160(a0)</span><br><span class="line">        sd a7, 168(a0)</span><br><span class="line">        sd s2, 176(a0)</span><br><span class="line">        sd s3, 184(a0)</span><br><span class="line">        sd s4, 192(a0)</span><br><span class="line">        sd s5, 200(a0)</span><br><span class="line">        sd s6, 208(a0)</span><br><span class="line">        sd s7, 216(a0)</span><br><span class="line">        sd s8, 224(a0)</span><br><span class="line">        sd s9, 232(a0)</span><br><span class="line">        sd s10, 240(a0)</span><br><span class="line">        sd s11, 248(a0)</span><br><span class="line">        sd t3, 256(a0)</span><br><span class="line">        sd t4, 264(a0)</span><br><span class="line">        sd t5, 272(a0)</span><br><span class="line">        sd t6, 280(a0)</span><br><span class="line"></span><br><span class="line"># save the user a0 in p-&gt;tf-&gt;a0</span><br><span class="line">        csrr t0, sscratch</span><br><span class="line">        sd t0, 112(a0)</span><br><span class="line"></span><br><span class="line">        # restore kernel stack pointer from p-&gt;tf-&gt;kernel_sp</span><br><span class="line">        ld sp, 8(a0)</span><br><span class="line"></span><br><span class="line">        # make tp hold the current hartid, from p-&gt;tf-&gt;kernel_hartid</span><br><span class="line">        ld tp, 32(a0)</span><br><span class="line"></span><br><span class="line">        # load the address of usertrap(), p-&gt;tf-&gt;kernel_trap</span><br><span class="line">        ld t0, 16(a0)</span><br><span class="line"></span><br><span class="line">        # restore kernel page table from p-&gt;tf-&gt;kernel_satp</span><br><span class="line">        ld t1, 0(a0)</span><br><span class="line">        csrw satp, t1</span><br><span class="line">        sfence.vma zero, zero</span><br><span class="line"></span><br><span class="line">        # a0 is no longer valid, since the kernel page</span><br><span class="line">        # table does not specially map p-&gt;tf.</span><br><span class="line"></span><br><span class="line">        # jump to usertrap(), which does not return</span><br><span class="line">        jr t0</span><br><span class="line"># 中间被我省略了</span><br><span class="line">.globl userret</span><br><span class="line">userret:</span><br><span class="line">        # userret(TRAPFRAME, pagetable)</span><br><span class="line">        # switch from kernel to user.</span><br><span class="line">        # usertrapret() calls here.</span><br><span class="line">        # a0: TRAPFRAME, in user page table.</span><br><span class="line">        # a1: user page table, for satp.</span><br><span class="line"></span><br><span class="line">        # switch to the user page table.</span><br><span class="line">        csrw satp, a1</span><br><span class="line">        sfence.vma zero, zero</span><br><span class="line"></span><br><span class="line">.globl userret</span><br><span class="line">userret:</span><br><span class="line">        # userret(TRAPFRAME, pagetable)</span><br><span class="line">        # switch from kernel to user.</span><br><span class="line">        # usertrapret() calls here.</span><br><span class="line">        # a0: TRAPFRAME, in user page table.</span><br><span class="line">        # a1: user page table, for satp.</span><br><span class="line"></span><br><span class="line">        # switch to the user page table.</span><br><span class="line">        csrw satp, a1</span><br><span class="line">        sfence.vma zero, zero</span><br><span class="line"></span><br><span class="line">        # put the saved user a0 in sscratch, so we</span><br><span class="line">        # can swap it with our a0 (TRAPFRAME) in the last step.</span><br><span class="line">        ld t0, 112(a0)</span><br><span class="line">        csrw sscratch, t0</span><br></pre></td></tr></table></figure><p>好吧，我承认 reader 手册说的不是很明白，我在 trap 和 ret 中间都省略了一些代码，关于这个 sfence.vma 使用，可以参考：<a href="https://utk.instructure.com/courses/66647/files/3182543/download?verifier=JLzdkcM2uy4hNshzq9Tus0Kll1vJys8bsoFbgcl0&amp;wrap=1">https://utk.instructure.com/courses/66647/files/3182543/download?verifier=JLzdkcM2uy4hNshzq9Tus0Kll1vJys8bsoFbgcl0&amp;wrap=1</a></p><p><img src="https://image.mwish.me/blog-image/38E18604-E8F2-428B-8D5F-FDFEB55163B2.png" alt="38E18604-E8F2-428B-8D5F-FDFEB55163B2"></p><p>所以这里相当于切换了 <code>satp</code> 从内核到用户态/从内内核态到用户态之后，fence 整个地址空间。</p><h4 id="2-特权"><a href="#2-特权" class="headerlink" title="2: 特权"></a>2: 特权</h4><p>RISC-V 提供了两种额外的模式：</p><blockquote><p> 运行最 可信的代码的机器模式(machine mode)，以及为 Linux，FreeBSD 和 Windows 等操作系统 提供支持的监管者模式(supervisor mode)</p></blockquote><p><img src="https://image.mwish.me/blog-image/41D68117-8467-417E-AD42-78503FA7754C.png" alt="41D68117-8467-417E-AD42-78503FA7754C"></p><p>硬件对指令有约束，不能在 User 模式下执行特权指令。这提供了某种情况的保护，而操作系统又有这种保护的权限，而关于 <code>m</code> 和 <code>s</code> 模式，就简要贴一下：</p><blockquote><p>默认情况下，发生所有异常(不论在什么权限模式下)的时候，控制权都会被移交到 M 模式的异常处理程序。但是 Unix 系统中的大多数例外都应该进行 S 模式下的系统调 用。M 模式的异常处理程序可以将异常重新导向 S 模式，但这些额外的操作会减慢大多数 异常的处理速度。因此，RISC-V 提供了一种异常委托机制。通过该机制可以选择性地将中 断和同步异常交给 S 模式处理，而完全绕过 M 模式。</p><p>mideleg(Machine Interrupt Delegation，机器中断委托)CSR 控制将哪些中断委托给 S 模式。</p></blockquote><p>所以实际上，这种模式是由硬件来保证的。</p><p>RISC-V 提供了一组 CSR 寄存器，如  <a href="https://zhuanlan.zhihu.com/p/150571417">https://zhuanlan.zhihu.com/p/150571417</a> 所示，帮助标示和完成异常、恢复上下文。</p><p>实际上，触发 trap 的时候，硬件需要把现在运行的指令记录到 <code>mepc</code>, 然后 stop 整个流水线，完成之前所说的异常处理。</p><p>实际上，回到之前页表，我们可以看到，xv6 中：</p><ol><li>翻译是由硬件处理的</li><li>出现缺页异常，由操作系统这样的软件来处理。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>有一张绝世好图：</p><p><img src="https://image.mwish.me/blog-image/7D933BA9-C8E0-4893-ABDD-37527C82C8B9.png" alt="7D933BA9-C8E0-4893-ABDD-37527C82C8B9"></p>]]></content>
      
      
      
        <tags>
            
            <tag> system </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cache and Related Part3: Coherent</title>
      <link href="/2020/11/01/Cache-and-Related-Part3-Coherent/"/>
      <url>/2020/11/01/Cache-and-Related-Part3-Coherent/</url>
      
        <content type="html"><![CDATA[<p>（图来自 CMU 15-418 Spring 2020 和 UCB CS152）</p><p>当我们涉及多核的时候，我们的多个核可能会共享一份内存：</p><p><img src="https://image.mwish.me/blog-image/8A003FAC-7726-4EFA-8F98-721EAE514AC4.png" alt="8A003FAC-7726-4EFA-8F98-721EAE514AC4"></p><p>单个变量的访问可能会有问题：</p><p><img src="https://image.mwish.me/blog-image/BB44A00B-A60B-4CB8-B063-728410EB5DE4.png" alt="BB44A00B-A60B-4CB8-B063-728410EB5DE4"></p><p>我们访问 memory, 可能<strong>在直觉上</strong>会是：</p><blockquote><p> 读到最近一级别存储 x 的上一个写入的值</p></blockquote><p>但是，memory 会遇到的问题是</p><ol><li>有 global 的 storage 和 local cache，而且这两个可能是不一致的<ol><li>所以我们有 write back 和 write through 的策略，来 trade 性能和 consitent</li></ol></li><li>有多个 local cache 的话，可能也会导致这种视图上的不一致</li></ol><p>但是说到底，“读到上一个写入的值”，或者，“写入时间最近的值”，究竟是什么语义呢：</p><p><img src="https://image.mwish.me/blog-image/018B5523-101F-4E00-AF0D-B3C0EE915E7F.png" alt="018B5523-101F-4E00-AF0D-B3C0EE915E7F"></p><p>事实上，我们之前介绍过 CPU Cache, 现在给出一个 L1 L2 L3 的视图</p><p><img src="https://image.mwish.me/blog-image/15293AC1-A830-4AB5-96BE-0ACEE96B962D.png" alt="15293AC1-A830-4AB5-96BE-0ACEE96B962D"></p><p>显然，现在我们对同一个变量的访问，如上上张图所示，我各个处理器本身是顺序处理的，而它们在一起，会得到一个诡异的偏序，而 P1 P2 P3 的 x 值和内存中的 x 值是 inconsistent 的。这是问题所在：我们无法定义“上一个”逻辑意义上是什么。</p><p>要在保证性能的同时，也作出各个处理器对 x 的值读写的偏序保证，我们需要 coherence</p><h3 id="Single-CPU-System-I-O"><a href="#Single-CPU-System-I-O" class="headerlink" title="Single CPU System: I/O"></a>Single CPU System: I/O</h3><p><img src="https://image.mwish.me/blog-image/BF8647F2-AC2B-4ADD-BC99-353EEF618C16.png" alt="BF8647F2-AC2B-4ADD-BC99-353EEF618C16"></p><p>单核 CPU IO 的时候，假设要读/写数据，可能会：</p><ol><li>processor 写到了 write-buffer 里，而网卡可能没有读到 buffer 中的数据，而是读到了 memory 中的 stale data，造成写 stale data</li><li>网络中数据写到了 memory 中，通知 processor, processor <code>lw</code> 读到了 cache，造成读 stale data</li></ol><p>某种意义上说，这也是一种不一致导致的，为了解决这个问题，需要下列的支持</p><ol><li>CPU 写的时候可以写到和设备的 shared buffer 中，而不是本身的 write buffer。让设备能够读到正确信息</li><li>OS 可以把读写的 page 设置成不可 cache 的，同时，IO 完成的时候 flush cache page</li><li>在生产中，DMA transfer 的频率远比 <code>lw</code> <code>sw</code> 少，所以可以接受代价较高。</li></ol><h3 id="Coherence"><a href="#Coherence" class="headerlink" title="Coherence"></a>Coherence</h3><p>终于到了 conherence 了，那么我们来讲讲，memory coherence，我必须要说，下面这张图理的绝对很清晰了：</p><p><img src="https://image.mwish.me/blog-image/A850F71C-E08B-4D09-A735-5E01922E811D.png" alt="A850F71C-E08B-4D09-A735-5E01922E811D"></p><p>. </p><ol><li>单个 Processor 对单个变量 x 的读写是顺序的</li><li><strong>write propagation</strong>: P 对一个变量的写入必须最终对其他 Process 可见</li><li><strong>write serialization</strong> : 写有全局的顺序</li></ol><p><img src="https://image.mwish.me/blog-image/42AA0894-4FD5-4BF0-9A22-98F1A12F5B3C.png" alt="42AA0894-4FD5-4BF0-9A22-98F1A12F5B3C"></p><p>以上便是违背 write serialization 的例子，对于 x 写入 <code>“a&quot;</code>  <code>&quot;b&quot;</code>, P3 P4 观察到的顺序不一致。</p><p>那么，在这种假设下，假设有三个线程 t0, t1, t2:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// t0</span></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; N; i += <span class="number">2</span>) &#123;</span><br><span class="line">X = i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// t1</span></span><br><span class="line"><span class="keyword">for</span> (j = <span class="number">1</span>; j &lt; N; j += <span class="number">2</span>) &#123;</span><br><span class="line">X = j;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// t3</span></span><br><span class="line"><span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; ..; k++) &#123;</span><br><span class="line">s[k] = X;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么，数组 s 中，可以看到我写的脑瘫程序可以输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">26980 626437 1226236 1806376 2449353 3083919 3382384 3734980 4165338 5994059 </span><br><span class="line">4872578 7435291 5586348 8893777 6262932 6539670 6875646 7205346 7535204 7873218 </span><br><span class="line">8256550 8658202 14268993 14634249 9901488 10347038 15693957 16119785 16529365 17135341 </span><br><span class="line">17836189 12867162 19251979 19962671 13929908 14261510 14598770 22698103 15331624 24051107 </span><br></pre></td></tr></table></figure><p>这里奇数/偶数都是强 order 的，但是他们之间并没有什么保证，只能保证全局有一致的 order</p><p>(题外话：但是我看到这有个问题，就是 <code>atomic + relaxed</code> 和 non-atomic 有什么区别，瞅了眼： <a href="https://stackoverflow.com/questions/63810298/what-is-the-difference-between-load-store-relaxed-atomic-and-normal-variable">https://stackoverflow.com/questions/63810298/what-is-the-difference-between-load-store-relaxed-atomic-and-normal-variable</a> 这似乎保证单个操作的原子性，比如我们 RV32I 的 auipc 和 add…)</p><p>关于实现 Cache Coherent，是下一节的内容，我们再次先看 Memory Model 吧。</p><h2 id="Memory-Consistency"><a href="#Memory-Consistency" class="headerlink" title="Memory Consistency"></a>Memory Consistency</h2><p>最实用、最有挑战性、最令人困惑的部分来了。我们现在有了变量 <code>x</code> 的 coherence，我们还需要什么呢？</p><p>Cache Coherence 保证了单个 cache block 的 loads and stores 是按照定义运行的，但是我们假设有一个 produce-consume:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// produce</span><br><span class="line">value &lt;- 5</span><br><span class="line">flag &lt;- ok</span><br><span class="line"></span><br><span class="line">// consume</span><br><span class="line">wait until flag is ok</span><br><span class="line">-- 操作 value</span><br></pre></td></tr></table></figure><p>那么，很尴尬的是，你会发现 cache coherent 没有提供可靠的保障。</p><blockquote><p>“Memory Consistency Model” (sometimes called “Memory Ordering”): do all loads and stores, even to separate cache blocks, behave correctly?</p></blockquote><p>实际上，你会发现问题的来源很多，而且来源不是上层应用，而是我们讲了2节的 cache write-buffer multi-level cache 这些给我们带来利好的东西，和 OoO 执行、编译器乱序等正常对程序员透明，现在全冒出来了的东西。</p><h4 id="Uniprocess-Memory-Model"><a href="#Uniprocess-Memory-Model" class="headerlink" title="Uniprocess Memory Model"></a>Uniprocess Memory Model</h4><p>单个程序按 program order 的语义执行、读写</p><p><img src="https://image.mwish.me/blog-image/5E768853-5AB5-4B1A-B940-F2E960E9C93A.png" alt="5E768853-5AB5-4B1A-B940-F2E960E9C93A"></p><p>这图相当于我们 Part2 说的。</p><p>那么，在并行的时候，也就是我们说的 producer-consumer 中，可能会有下图的问题：</p><p><img src="https://image.mwish.me/blog-image/97CF1A96-F3F9-4976-B35F-D30F6CD258BA.png" alt="97CF1A96-F3F9-4976-B35F-D30F6CD258BA"></p><p>write buffer 和 OoO 等乱序不能保证写入会被顺序的传播，没有 <code>happens-before</code> 的语义。</p><p>更要命的是，cache 也会在其中添乱：（当然不止是 cache，所以回头来，你要理解到，<code>volatile</code> 这个词在 C/C++ 中是危险的，不能认为它们读写内存就万事大吉了，不过我也不太清楚搞 NVM 的大佬们会不会用到这个）</p><p><img src="https://image.mwish.me/blog-image/065D74C5-5B97-40DD-8087-1A31D2CD4A5C.png" alt="065D74C5-5B97-40DD-8087-1A31D2CD4A5C"></p><p>由于 P3 上有 A 的 cache, 它并不会从内存中读取应读的值，cache coherent 也没被违背，但是这会儿程序的语义就没法保证了！</p><p>更要命的是，还有编译器的乱序，关于编译器乱序可以参考没有使用 <code>atomic</code> 的 LevelDB 的 SkipList, 它只是写了一个编译器 barrier，而没有用 CPU 的 barrier 和指令。</p><h3 id="Sequential-Consistency-SC"><a href="#Sequential-Consistency-SC" class="headerlink" title="Sequential Consistency: SC"></a>Sequential Consistency: SC</h3><p>这个是老熟人了：</p><p>Formalized by Lamport (1979)</p><ul><li>accesses of each processor in program order</li><li>all accesses appear in sequential order</li></ul><p>我理解就是简单说所有操作有一个全序，就所有操作偏序变全序。你可以用 <code>seq_cst</code> 来体验一下（</p><p>下面是它的硬件模型，描述的非常详细：</p><p><img src="https://image.mwish.me/blog-image/8D07B6F6-9B06-45FB-A3DB-5BB1DDBE47AF.png" alt="8D07B6F6-9B06-45FB-A3DB-5BB1DDBE47AF"></p><p>这个时候，写入要求：</p><blockquote><p>For each processor, delay start of memory access until previous one completes: each processor has only one outstanding memory access at a time</p></blockquote><p>读取要求</p><blockquote><p>a read completes when its return value is bound</p></blockquote><p><img src="https://image.mwish.me/blog-image/7A92B093-6B60-49FE-BA37-B121D2B1B686.png" alt="7A92B093-6B60-49FE-BA37-B121D2B1B686"></p><p>上述会带来严格的限制和可靠性，但是性能…</p><p><img src="https://image.mwish.me/blog-image/5BC3991D-5012-489B-B26E-64169EAE16E7.png" alt="5BC3991D-5012-489B-B26E-64169EAE16E7"></p><p>顺便可以提一下，对 x86 而言，一些 <code>LOCK</code> 指令会获取 Lock 相关的信息，而 <code>MFENCE</code> 会清空 Store Buffer。这里指令会<strong>按照发送的顺序</strong>来提交。</p><h3 id="Relaxed-Memory-Model"><a href="#Relaxed-Memory-Model" class="headerlink" title="Relaxed Memory Model"></a>Relaxed Memory Model</h3><p>于是我们有 relaxed 一些的模型，例如 TSO/PSO 等：</p><p><img src="https://image.mwish.me/blog-image/71298E26-F19C-4084-B6D9-3D0F971475C5.png" alt="71298E26-F19C-4084-B6D9-3D0F971475C5"></p><p>注：x86的 memory model 类似 TSO，只允许 store-load 乱序。</p><p>这在优化中获得了权衡：</p><p><img src="https://image.mwish.me/blog-image/166633FA-6A66-4370-A075-3FB0735136E8.png" alt="166633FA-6A66-4370-A075-3FB0735136E8"></p><h4 id="ARM-amp-IBM-Power-的内存模型"><a href="#ARM-amp-IBM-Power-的内存模型" class="headerlink" title="ARM &amp; IBM Power 的内存模型"></a>ARM &amp; IBM Power 的内存模型</h4><p>在这里，我们的硬件和指令可能有下面的语义：</p><p><img src="https://image.mwish.me/blog-image/70B65496-6C17-4448-9BD0-F14C42DD2CC4.png" alt="70B65496-6C17-4448-9BD0-F14C42DD2CC4"></p><p>（上图实际上是一个 non-multi-copy 的模型）</p><p>下面是指令，它的 commit 可能是乱序的，而且指令可能会在分支预测阶段：</p><ol><li>读取的时候，可能会直接读取</li><li>写的时候，要等待之前的内容 Commit</li></ol><p><img src="https://image.mwish.me/blog-image/C33C7C13-990F-440F-BC8F-95465B2E2B5C.png" alt="C33C7C13-990F-440F-BC8F-95465B2E2B5C"></p><p>摘录一下原文：</p><blockquote><p>For a read instruction, as soon as an address for the read is known, the read might be satisﬁed, binding its value to one received from the local memory (or in some cases forwarded from earlier in the thread). <strong>That value could immediately be used by later instructions in the thread that depend on it, but it and they are subject to being restarted or (if this is a speculative path) aborted until the read is committed.</strong></p><p>For a write instruction, the key points are when the address and value become determined. After that (subject to other conditions) the write can be committed, sent to the local memory; this is not subject to restart or abort. After that, the write might propagate to other threads, becoming readable by them.</p></blockquote><p>同时，指令发送的顺序和收到的顺序可能是不一样的，这里有一些分类：</p><ol><li>Weak, multi-copy-atomic memory models<ol><li>all processors see writes by another processor in same order</li><li>RISC-V RVWMO, baseline weak memory model for RISC-V</li></ol></li><li>Weak, non-multi-copy-atomic memory models<ol><li>processors can see another’s writes in different orders</li><li>ARM v7, original ARM v8, IBM POWER</li></ol></li></ol><p>IBM Power 和 ARM 中，可能会有 Load Buffer，读起来的顺序和写的顺序是不一样的。</p><h4 id="可能出现的问题和同步"><a href="#可能出现的问题和同步" class="headerlink" title="可能出现的问题和同步"></a>可能出现的问题和同步</h4><p>但是，这个时候，我们仍然要面对最初的那个问题：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// produce</span><br><span class="line">value &lt;- 5</span><br><span class="line">flag &lt;- ok</span><br><span class="line"></span><br><span class="line">// consume</span><br><span class="line">wait until flag is ok</span><br><span class="line">-- 操作 value</span><br></pre></td></tr></table></figure><p>Data Race:</p><ul><li>two conflicting accesses on different processors</li><li>not ordered by intervening accesses</li></ul><p>显然，我们对 flag 的操作本身没有经过同步，这个在仅允许 store-load 乱序的系统中，甚至没啥问题（不考虑编译器乱序）。但是，在 RISC-V 这种系统，或者 ARM 里，你就等死吧。我们需要一些机制来同步：</p><p>Properly Synchronized Programs:</p><ul><li>all synchronizations are explicitly identified</li><li>all data accesses are ordered through synchronization</li></ul><p>我们可以使用：</p><ol><li>memory barrier</li><li>显式的锁，来隐式提供 fence</li></ol><p>逻辑如下：</p><p><img src="https://image.mwish.me/blog-image/CBE31CAA-B88D-410F-9F82-21D0F68FE031.png" alt="CBE31CAA-B88D-410F-9F82-21D0F68FE031"></p><ol><li>x86 的 <code>xchg</code> 显式的帮你完成这一切，你可以 <code>acquire</code> 来获得锁，在互斥区维护 invariant，<code>release</code> 来释放锁。锁前，锁中，锁后都是可以 re-order 的，但是它们不能越过锁。</li><li><strong>MFENCE</strong> <code>LFENCE</code> <code>MFENCE</code> , fence会 stall 程序，把之前的操作执行完，来创建偏序。</li></ol><h4 id="RISC-V-中的同步"><a href="#RISC-V-中的同步" class="headerlink" title="RISC-V 中的同步"></a>RISC-V 中的同步</h4><p>RISC-V 提供了 multi-copy model，然后提供了 <code>amo</code> 来支持原子操作，首先它们对操作的数据是原子完成的。首先有 <code>aq</code> 和 <code>rl</code> 两位：</p><ol><li>如果提供了 <code>aq</code>，这条指令 “Happens Before” 之后的 <code>load</code> 和 <code>store</code> </li><li>如果提供了 <code>rl</code>，这条指令 “Happens After” 之前的 <code>store</code> 和 <code>load</code></li></ol><p>这里可以参考 <code>spinlock</code>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Acquire the lock.</span></span><br><span class="line"><span class="comment">// Loops (spins) until the lock is acquired.</span></span><br><span class="line"><span class="type">void</span></span><br><span class="line"><span class="title function_">acquire</span><span class="params">(<span class="keyword">struct</span> spinlock *lk)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// 如果:</span></span><br><span class="line">  <span class="comment">// * acquire</span></span><br><span class="line">  <span class="comment">// * timer interrupt</span></span><br><span class="line">  <span class="comment">// * timer interrupt 在调度之前拿同一把锁, 哦吼.</span></span><br><span class="line">  push_off(); <span class="comment">// disable interrupts to avoid deadlock.</span></span><br><span class="line">  <span class="keyword">if</span>(holding(lk))</span><br><span class="line">    panic(<span class="string">&quot;acquire&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// On RISC-V, sync_lock_test_and_set turns into an atomic swap:</span></span><br><span class="line">  <span class="comment">//   a5 = 1</span></span><br><span class="line">  <span class="comment">//   s1 = &amp;lk-&gt;locked</span></span><br><span class="line">  <span class="comment">//   amoswap.w.aq a5, a5, (s1)</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// 这个地方使用 acquire, 因为下面的内容不会被放到这前面.</span></span><br><span class="line">  <span class="keyword">while</span>(__sync_lock_test_and_set(&amp;lk-&gt;locked, <span class="number">1</span>) != <span class="number">0</span>)</span><br><span class="line">    ;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Tell the C compiler and the processor to not move loads or stores</span></span><br><span class="line">  <span class="comment">// past this point, to ensure that the critical section&#x27;s memory</span></span><br><span class="line">  <span class="comment">// references happen strictly after the lock is acquired.</span></span><br><span class="line">  <span class="comment">// On RISC-V, this emits a fence instruction.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// 相当于手动给 lk-&gt;cpu 插入了一个 fencing, 让上面的东西不会被重拍下来</span></span><br><span class="line">  __sync_synchronize();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Record info about lock acquisition for holding() and debugging.</span></span><br><span class="line">  lk-&gt;cpu = mycpu();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Release the lock.</span></span><br><span class="line"><span class="type">void</span></span><br><span class="line"><span class="title function_">release</span><span class="params">(<span class="keyword">struct</span> spinlock *lk)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span>(!holding(lk))</span><br><span class="line">    panic(<span class="string">&quot;release&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 这个不会被重排到下面去.</span></span><br><span class="line">  lk-&gt;cpu = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Tell the C compiler and the CPU to not move loads or stores</span></span><br><span class="line">  <span class="comment">// past this point, to ensure that all the stores in the critical</span></span><br><span class="line">  <span class="comment">// section are visible to other CPUs before the lock is released,</span></span><br><span class="line">  <span class="comment">// and that loads in the critical section occur strictly before</span></span><br><span class="line">  <span class="comment">// the lock is released.</span></span><br><span class="line">  <span class="comment">// On RISC-V, this emits a fence instruction.</span></span><br><span class="line">  __sync_synchronize();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Release the lock, equivalent to lk-&gt;locked = 0.</span></span><br><span class="line">  <span class="comment">// This code doesn&#x27;t use a C assignment, since the C standard</span></span><br><span class="line">  <span class="comment">// implies that an assignment might be implemented with</span></span><br><span class="line">  <span class="comment">// multiple store instructions.</span></span><br><span class="line">  <span class="comment">// On RISC-V, sync_lock_release turns into an atomic swap:</span></span><br><span class="line">  <span class="comment">//   s1 = &amp;lk-&gt;locked</span></span><br><span class="line">  <span class="comment">//   amoswap.w zero, zero, (s1)</span></span><br><span class="line">  __sync_lock_release(&amp;lk-&gt;locked);</span><br><span class="line"></span><br><span class="line">  pop_off();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>(上面用的仍然是 gnu C 的 <code>__sync_</code> 扩展，因为没有 <code>amoswap.rl</code>, 或者 <code>ac</code>，所以手动插入了一些 barrier)</p><p>关于 fence，可以参考：</p><p><img src="https://image.mwish.me/blog-image/D2ADEADD-86EA-4011-8033-2A4F28C1A960.png" alt="D2ADEADD-86EA-4011-8033-2A4F28C1A960"></p><p>举例而言，对于下面的图，<code>fence w, w</code> 和 <code>fence r,r</code> 之间构建了 barrier，来保证顺序：</p><p><img src="https://image.mwish.me/blog-image/D67A4594-E3A7-478D-A476-52922A7C3818.png" alt="D67A4594-E3A7-478D-A476-52922A7C3818"></p><p>上述例子中，<code>fence w, w</code> 和 <code>fence r, r</code> 构建了一个偏序关系。<code>sw data, (xdatap)</code> 保证被 <code>lw xdata, (xdatap)</code> 感知了。</p><h3 id="RISC-V-的支持：RV32A"><a href="#RISC-V-的支持：RV32A" class="headerlink" title="RISC-V 的支持：RV32A"></a>RISC-V 的支持：RV32A</h3><blockquote><p>RISC-V 具有宽松的内存一致性模型(relaxed memory consistency model)，因此其他线程看 到的内存访问可以是乱序的。图 6.2 中，所有的 RV32A 指令都有一个请求位(aq)和一个 释放位(rl)。aq 被置位的原子指令保证其它线程在随后的内存访问中看到顺序的 AMO 操 作;rl 被置位的原子指令保证其它线程在此之前看到顺序的原子操作。想要了解更详细的 有关知识，可以查看[Adve and Gharachorloo 1996]。</p></blockquote><p><img src="https://image.mwish.me/blog-image/4390486F-3FF8-4C71-A8FB-DC0598E077CF.png" alt="4390486F-3FF8-4C71-A8FB-DC0598E077CF"></p><p>RV32A 没有直接提供了 CAS FAA 的指令，而是提供了两套指令。RV32A 认为这样有更好的可扩展性：</p><p><img src="https://image.mwish.me/blog-image/23F56E11-4461-4BB4-9D02-C2E38A64A60D.png" alt="23F56E11-4461-4BB4-9D02-C2E38A64A60D"></p><h3 id="编译器乱序和语言的-memory-order"><a href="#编译器乱序和语言的-memory-order" class="headerlink" title="编译器乱序和语言的 memory_order"></a>编译器乱序和语言的 <code>memory_order</code></h3><p><a href="https://chromium.googlesource.com/external/leveldb/+/v1.15/port/atomic_pointer.h#61">https://chromium.googlesource.com/external/leveldb/+/v1.15/port/atomic_pointer.h#61</a></p><p>除了内存，编译器也会完成乱序。最佳的例子是 LevelDB 之前的编译器 barrier。</p><p>语言会提供对应的语义，如 C++ 的六种 order （实话说我 consume 那几个完全不懂）: <a href="https://en.cppreference.com/w/cpp/atomic/memory_order">https://en.cppreference.com/w/cpp/atomic/memory_order</a></p><p>或者简单点可以看看 Golang 的（</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li>CMU 15-418 Spring 2020</li><li>UCB CS152 Spring 2020</li><li>CPU Cache and Memory Ordering 何登成</li><li>RISC-V Reader</li><li>Computer Organization and Design RISC-V edition</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Cache and Related Part2: Cache 的优化</title>
      <link href="/2020/10/31/Cache-and-Related-Part2/"/>
      <url>/2020/10/31/Cache-and-Related-Part2/</url>
      
        <content type="html"><![CDATA[<p>我们上一个 part 聊过了 direct-mapped cache，这一节我们重复一些 cache 的 basics，然后聊 cache 相关的优化。</p><h2 id="Recall"><a href="#Recall" class="headerlink" title="Recall"></a>Recall</h2><p>我们之前介绍过了 direct-mapped cache，之所以叫这个名字，是因为：</p><blockquote><p>This cache structure is called <strong>direct mapped</strong>, since each memory location is mapped directly to exactly one location in the cache. </p></blockquote><p>我们上一节中，一个地址可以被分成：</p><ol><li>tag</li><li>index</li><li>offset</li></ol><p>而 cache 本身的存储不只是存放地址，它需要存放的是：</p><ol><li>Invalid bit</li><li>tag</li><li>block data</li></ol><p>我查了一下，这里 block 的概念比较接近 cacheline 的概念. 我的电脑 lscpu 下试试：</p><p>我的台式，使用 <code>lscpu</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">架构：                           x86_64</span><br><span class="line">CPU 运行模式：                   32-bit, 64-bit</span><br><span class="line">字节序：                         Little Endian</span><br><span class="line">Address sizes:                   43 bits physical, 48 bits virtual</span><br><span class="line">CPU:                             16</span><br><span class="line">在线 CPU 列表：                  0-15</span><br><span class="line">每个核的线程数：                 2</span><br><span class="line">每个座的核数：                   8</span><br><span class="line">座：                             1</span><br><span class="line">NUMA 节点：                      1</span><br><span class="line">厂商 ID：                        AuthenticAMD</span><br><span class="line">CPU 系列：                       23</span><br><span class="line">型号：                           113</span><br><span class="line">型号名称：                       AMD Ryzen 7 3800X 8-Core Processor</span><br><span class="line">步进：                           0</span><br><span class="line">Frequency boost:                 enabled</span><br><span class="line">CPU MHz：                        1961.707</span><br><span class="line">CPU 最大 MHz：                   3900.0000</span><br><span class="line">CPU 最小 MHz：                   2200.0000</span><br><span class="line">BogoMIPS：                       7802.74</span><br><span class="line">虚拟化：                         AMD-V</span><br><span class="line">L1d 缓存：                       256 KiB</span><br><span class="line">L1i 缓存：                       256 KiB</span><br><span class="line">L2 缓存：                        4 MiB</span><br><span class="line">L3 缓存：                        32 MiB</span><br><span class="line">NUMA 节点0 CPU：                 0-15</span><br></pre></td></tr></table></figure><p><img src="https://image.mwish.me/blog-image/A031FE24-E31B-45F3-82B5-2228AED1EA54.png" alt="A031FE24-E31B-45F3-82B5-2228AED1EA54"></p><p>当我们读取的时候，我们在 RISC-V Datapath 的图像上是经过 icache 和 dcache 读取 memory，但是实际上我们更多是说读/写 cache。</p><p>当我们产生读 cache miss 的时候，我们可能会保存寄存器，然后noop或者停止，来暂停执行。而我们如果有 out-of-order 的执行，那么别的部分仍然能在语义正确的情况下执行。然后等缓存加载。</p><p>处理写的时候，我们有 write-through 和 write-back 两种形式，我们在上一节提到过。但是，我们需要考虑到，如果每次write都写到底层的话，无疑，每次写都会带来很大的开销:</p><blockquote><p> With a write-through scheme, every write causes the data to be written to main memory. These writes will take a long time, likely at least 100 processor clock cycles, and could slow down the processor considerably. </p></blockquote><p>实现的时候，一个比较好的解决方案是 write-buffer。当处理写请求的时候，写到 cache 层的 write-buffer就算写成功了，处理器可以接下来进行，cache 把写给 memory 之后，write buffer 会被清空。不过 write-buffer 会面临两个问题</p><ol><li>乱序（所以某种意义上需要 memory model）</li><li>write-stall</li></ol><blockquote><p>If the write buffer is full when the processor reaches a write, the processor must stall until there is an empty position in the write buffer. </p></blockquote><p>还有一种方式是 write-through，写到 cache 上，然后被 evict 的时候写回。不过这个会面临的问题是需要自北 evict 的时候可能会 stall. write-through 也有 write allocate 等策略。write allocate 是指：如果目标内存不在 cache 中，是否要把它捞上来。</p><h2 id="其他模式与性能优化"><a href="#其他模式与性能优化" class="headerlink" title="其他模式与性能优化"></a>其他模式与性能优化</h2><p>我们之前提到 cpu cycles 都是 CPU 和 time 的 cycle，但是，考虑 memory 和 cache 之后。这几个变成了：</p><ol><li>CPU execution clock cycles</li><li>Memory-stall clock cycles</li></ol><p>上述两个乘 clock cycle time</p><p>对于 memory-stall, 我们可以分为读写：</p><p><img src="https://image.mwish.me/blog-image/3A943142-5CDA-4014-8CA3-3B1009AF43EF.png" alt="3A943142-5CDA-4014-8CA3-3B1009AF43EF"></p><p><img src="https://image.mwish.me/blog-image/28081A23-89A5-42CC-8E74-A57B2CE49DF9.png" alt="28081A23-89A5-42CC-8E74-A57B2CE49DF9"></p><h3 id="Fully-associative-cache"><a href="#Fully-associative-cache" class="headerlink" title="Fully associative cache"></a>Fully associative cache</h3><blockquote><p>A cache structure in which a block can be placed in any location in the cache.</p></blockquote><p>这个其实类似没有 index 了，每次查询的时候对所有的 cache tag 并行做一个比较（我其实不太懂硬件的实现，不过这个听上去太极端了）</p><p>在 fully-associative 和 direct-mapped 之前，也有 set-associative:</p><blockquote><p>In a set-associative cache, there are a fixed number of locations where each block can be placed. A set-associative cache with <em>n</em> locations for a block is called an <em>n</em>-way set-associative cache. An <em>n</em>-way set-associative cache consists of a number of sets, each of which consists of <em>n</em> blocks. </p></blockquote><p>内存中的每个地址，之前是 map 到 cache 中的一个 index, 现在允许 map 到一个 set, 这个 set 是 n位的，在这个set 中进行比较</p><p><img src="https://image.mwish.me/blog-image/DED1D2F9-D9FF-4411-9214-CC1F47EFB142.png" alt="DED1D2F9-D9FF-4411-9214-CC1F47EFB142"></p><p>所以其实来说，也就是一个 associate 大小的关系，direct-mapped 的情况下，这个值为1，fully-associate 的情况下，这个值为缓存的大小，下面我们来看看具体的对性能的影响</p><p><img src="https://image.mwish.me/blog-image/77D0C44E-F04F-413C-BEC0-A57DF3EBEC25.png" alt="77D0C44E-F04F-413C-BEC0-A57DF3EBEC25"></p><p>综上，一定的机制可以保证更小的 data miss rate, 但同时，比较高的 accociativity 却不会提升的太高。而在cache 的设计中，也需要做出一定的 trade-off, 读 cache 成为了下面的形式：</p><p><img src="https://image.mwish.me/blog-image/853482DD-D9E0-483D-A5F9-4D5EC50F7064.png" alt="853482DD-D9E0-483D-A5F9-4D5EC50F7064"></p><p>这种 n-way 也添加了开销：</p><ol><li>N Comparators 的时空开销</li><li>MUX 的时间开销</li></ol><p>而需要替换的时候，可以用 LRU 或者更简单的 clock 算法来标示替换 cache.</p><h3 id="Multi-Level-Caches-Reducing-the-Miss-Penalty"><a href="#Multi-Level-Caches-Reducing-the-Miss-Penalty" class="headerlink" title="Multi-Level Caches: Reducing the Miss Penalty"></a>Multi-Level Caches: Reducing the Miss Penalty</h3><blockquote><p>This second-level cache is normally on the same chip and is accessed whenever a miss occurs in the primary cache. If the second-level cache contains the desired data, the miss penalty for the first-level cache will be essentially the access time of the second-level cache, which will be much less than the access time of main memory. </p></blockquote><p>好吧，不得不承认，我看这一节之前都以为这些 cache 虽然都是 DRAM，但是造价和成本是有明显差异的。它们确实有差异，但是是体现在别的地方，我们会在下面介绍它们的。</p><p>需要明白的是，假设我们有2级的 cache, 且都没有 data, 那么一个皆 miss 的访问将会丢失更多的数据。</p><blockquote><p>With a larger total size, the secondary cache may use a larger block size than appropriate with a single-level cache. It often uses higher associativity than the primary cache given the focus of reducing miss rates.</p><p>The design considerations for a primary and secondary cache are significantly different, because the presence of the other cache changes the best choice versus a single-level cache. In particular, a two-level cache structure allows the primary cache to focus on minimizing hit time to yield a shorter clock cycle or fewer pipeline stages, while allowing the secondary cache to focus on miss rate to reduce the penalty of long memory access times.</p></blockquote><p>在i7中，我们有如下的例子：</p><p><img src="https://image.mwish.me/blog-image/59B41747-12EF-4527-A438-9F771E78F8C8.png" alt="59B41747-12EF-4527-A438-9F771E78F8C8"></p><p>对 multilevel cache , 下层需要更大的大小，允许更慢的反应速度。你可能会很奇怪，为什么都是 cache, 阿反应速度可以更慢，实际上，你可以考虑我们之前讨论的一些 trade-off</p><p><img src="https://image.mwish.me/blog-image/DC99A34F-B392-434A-956C-C0ECCBB3999D.png" alt="DC99A34F-B392-434A-956C-C0ECCBB3999D"></p><p>那么下层的 cache 允许更多的 ways，更大的大小，和更慢的访问速度。</p><h4 id="L1-L2-L3"><a href="#L1-L2-L3" class="headerlink" title="L1 L2 L3"></a>L1 L2 L3</h4><p><img src="https://image.mwish.me/blog-image/30DFE9D9-F52F-4A3E-BAEF-FB01A82F74DB.png" alt="30DFE9D9-F52F-4A3E-BAEF-FB01A82F74DB"></p><p>以上的决策允许我们作出设计</p><p><a href="https://superuser.com/questions/269080/why-are-multiple-levels-of-caches-used-in-modern-cpus">https://superuser.com/questions/269080/why-are-multiple-levels-of-caches-used-in-modern-cpus</a></p><p><a href="https://zhuanlan.zhihu.com/p/31875174">https://zhuanlan.zhihu.com/p/31875174</a></p><p><img src="https://image.mwish.me/blog-image/ECC76F17-69E7-480A-A910-F2AA4B7286B8.png" alt="ECC76F17-69E7-480A-A910-F2AA4B7286B8"></p><h3 id="缓存，访问模式，多个缓存"><a href="#缓存，访问模式，多个缓存" class="headerlink" title="缓存，访问模式，多个缓存"></a>缓存，访问模式，多个缓存</h3><blockquote><p>Caching is perhaps the most important example of the big idea of <strong>prediction</strong>. It relies on the principle of locality to try to find the desired data in the higher levels of the memory hierarchy, and provides mechanisms to ensure that when the prediction is wrong it finds and uses the proper data from the lower levels of the memory hierarchy. The hit rates of the cache prediction on modern computers are often above 95% (see Figure 5.46).</p></blockquote><p>缓存是可以 prefetch 并能够预测的，实际上，不仅是这一层的 cache, 应用层 cache 也有很多不同的算法，来减小不命中的开销。有一些算法会故意让访问模式 cache 不友好，来增加访问 cache 的开销。</p><p>LRU Clock 算法这些甚至可以做到硬件，而有一些 arc 之类的算法相对来说可以作为 db 的 cache replacement policy。</p><p>prefetch 可以带来不少性能的优势，如下图：</p><p><img src="https://image.mwish.me/blog-image/D3290C5A-C942-4434-9852-22350D87B17C.png" alt="D3290C5A-C942-4434-9852-22350D87B17C"></p><h2 id="缓存与代码"><a href="#缓存与代码" class="headerlink" title="缓存与代码"></a>缓存与代码</h2><p><code>stride * sizeof(int) == block size</code> 的时候，你的代码必定不是缓存友好地</p><p>关于缓存友好这个坑, 可以参考下：</p><ul><li><a href="https://fosschef.wordpress.com/2011/07/08/prefetch-performance-and-toxic/">https://fosschef.wordpress.com/2011/07/08/prefetch-performance-and-toxic/</a></li><li><a href="http://igoro.com/archive/gallery-of-processor-cache-effects/">http://igoro.com/archive/gallery-of-processor-cache-effects/</a></li><li><a href="https://www.aristeia.com/TalkNotes/ACCU2011_CPUCaches.pdf">https://www.aristeia.com/TalkNotes/ACCU2011_CPUCaches.pdf</a></li><li>CSAPP, 3edtion.</li></ul><p>我在我的 Mac 和 3800X 都跑过这些代码，有几个坑其实试不太出来，我也不知道咋回事，有没有人可以教教我的</p>]]></content>
      
      
      
        <tags>
            
            <tag> system </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cache and Related Part1</title>
      <link href="/2020/10/29/Cache-and-Related-Part1/"/>
      <url>/2020/10/29/Cache-and-Related-Part1/</url>
      
        <content type="html"><![CDATA[<p>在 Pipeline 执行的时候，我们拆成简单的 4/5 stage 的 pipeline 的话，我们会有一些 hazard:</p><ul><li>Structural hazard</li><li>Data hazard</li><li>Control hazard</li></ul><p>structural hazard 都给可以靠 nop 和钱解决. Data hazard 也可以 nop, 但同时，可以 forwarding 的方式，靠额外的控制逻辑，来减小这类事情的发生。而我们也有 control hazard, 对分支指令带来影响。一方面流水线有分支预测，一方面 gcc 提供了 <code>__likely__</code> 之类的操作，在生成代码的时候静态的做了一些处理。</p><p>在这个阶段的分析中，我们有点对所有指令一视同仁的味道：<code>sw</code> <code>lw</code> 被我们当成伊布/同步的，它们仿佛运转的和运算指令一样快，而且不会带来什么额外开销. 但是实际上我们都知道 load memory 和计算之间是有 gap 的，而且这个 gap 还不太小。</p><p><img src="https://image.mwish.me/blog-image/截屏2020-10-29-下午3.05.03.png" alt="截屏2020-10-29 下午3.05.03"></p><p>然后我们就到了喜闻乐见的存储层次山了：</p><p><img src="https://image.mwish.me/blog-image/截屏2020-10-29-下午3.08.22.png" alt="截屏2020-10-29 下午3.08.22"></p><p>越接近 CPU, 访问越快，但是越小、单位存储量的成本越昂贵。存储层次的思想是：</p><ul><li>上层的数据是下层的一个子集</li><li>下层在逻辑上有所有的数据</li></ul><p>同时，相关的概念有两种 locality:</p><ul><li>Temporal locality: 时间上的局部性<ul><li>如果某个 memory 被访问了，很可能近期有一定机会会再次被访问</li></ul></li><li>Spatial locality<ul><li>如果某个 memory 被访问，那它附近的内存很可能也会被访问</li></ul></li></ul><p><img src="https://image.mwish.me/blog-image/截屏2020-10-29-下午5.54.35.png" alt="截屏2020-10-29 下午5.54.35"></p><p>那么，我们在计算机系统里面有一些隐含的存储层次，这是除开显式的 mmap 或者写盘、共享内存外的形式：</p><ol><li>Register 和 memory 的读/写：由编译器或者汇编编写者生成</li><li>cache 和 main memory: 由 cache controller 管理</li><li>Main memory 和 disk: 由 OS 管理；也有 TLB 这样的缓存存在（总所周知，TLB 虽然叫做 buffer，实际上是个 cache）。</li></ol><p>上面是 locality 相关的访问模式，我们会注意到一些特征。其中需要注意的是，有的访问模式是相对来说：</p><ul><li>链式的结构可能会有 locality 不足的问题，因为实际上它的内存是离散的，</li><li>Go 语言这样的语言提供 map slice 这些相对来说 locality 好一些的结构</li><li>LevelDB 里面会用 Arena 尝试分配在连续的内存上</li></ul><p>Cache 有一点比较重要的就是，<strong>cache 对用户是透明的</strong>，这意味着：</p><ol><li>即使不知道 cache, 程序、指令也能正常的运作</li><li>不考虑效率的情况下，上层的使用者不需要知道 cache 的概念</li></ol><p>考虑 <code>lw t0, 0(t1)</code>, 这个时候 <code>t1</code> 对应的地址上的内存会被加载到缓存里。</p><p>具体而言：<code>t1 contains 0x12F0, Memory[0x12F0] = 99</code></p><ul><li>如果从 cache 中找到了对应的地址，那么直接从 cache 中读</li><li>如果 cache miss 了，那么从内存发送到 cache，再从 cache 发送到用户</li></ul><h3 id="缓存术语"><a href="#缓存术语" class="headerlink" title="缓存术语"></a>缓存术语</h3><p>读缓存的时候，可能会有三种情况</p><ul><li>Cache hit: 缓存命中</li><li>cache miss: 缓存未命中，需要从下层获取</li><li>cache miss, block replacement: cache 未命中 + 需要把原来存在的 cache 給替换掉</li></ul><p>缓存温度</p><ul><li>cold: cache empty, 没有怎么加载</li><li>warming: Cache filling with values you’ll hopefully be accessing again soon</li><li>Warm: Cache is doing its job, fair % of hits</li><li>Hot: Cache is doing very well, high % of hits</li></ul><p>感觉这个温度有两层含义，一个是缓存本身占用高，一个是缓存命中率高。</p><ul><li>hit rate: 命中缓存的比例</li><li>miss rate: 未命中缓存的比例</li><li>miss penalty: 从下一层加载到上一层需要的时间</li><li>hit time: 访问缓存的时间</li></ul><h3 id="Cache-Miss-的形式"><a href="#Cache-Miss-的形式" class="headerlink" title="Cache Miss 的形式"></a>Cache Miss 的形式</h3><p>从上面的 Miss 来看，我们可以得到一些 cache miss 的形式：</p><ol><li>compulsory misses: 程序开始的时候，因为 cold 的原因，导致的 Miss<ol><li>CPU/Cache 怎么解决的我不知道，不过我记得 Memcache 有一定解决方案：<a href="https://zhuanlan.zhihu.com/p/194347153">https://zhuanlan.zhihu.com/p/194347153</a></li></ol></li><li><strong>Conflict Misses</strong>：内存对应 cache 处于相同的位置，需要把目前的下掉，导致的 Miss</li></ol><h2 id="Cache-的逻辑结构"><a href="#Cache-的逻辑结构" class="headerlink" title="Cache 的逻辑结构"></a>Cache 的逻辑结构</h2><p>我们需要考虑下面几个理所当然的问题：</p><ul><li>Cache 的速度远远大于内存，但 Cache 远远小于内存</li></ul><p>因此，下面将由 direct-mapped cache 开始介绍 cache 相关的信息。</p><h3 id="Direct-Mapped-Cache"><a href="#Direct-Mapped-Cache" class="headerlink" title="Direct-Mapped Cache"></a>Direct-Mapped Cache</h3><p>在 direct-mapped cache 里面，每个内存地址会关联到一个 cache 中的 block，只要：</p><ol><li>查找这个 block 有没有成员</li><li>里面成员是不是自己的内存地址</li></ol><p>为了实现上面两个目的，下面这第一章逻辑的图是不够的，因为</p><ol><li>无法确认每个 block 对应的内存是多少</li></ol><p><img src="https://image.mwish.me/blog-image/CF5E4D39-E103-4CBC-ABDA-14FEE162EEB6.png" alt="CF5E4D39-E103-4CBC-ABDA-14FEE162EEB6"></p><p>所以我们的 cache 需要一个 tag:</p><p><img src="https://image.mwish.me/blog-image/BE57BF08-4B6D-41B3-AB83-C9809B02D557.png" alt="BE57BF08-4B6D-41B3-AB83-C9809B02D557"></p><p>这里把一个地址分成了三部分：</p><ol><li><strong>tag</strong> to check if have correct block</li><li><strong>index</strong> to select block </li><li>Byte <strong>offset</strong> in block</li></ol><p><img src="https://image.mwish.me/blog-image/D41799EC-8745-4B69-BAA7-2B29CF189709.png" alt="D41799EC-8745-4B69-BAA7-2B29CF189709"></p><p>RV32 的讨论：</p><ul><li>RV32 地址空间是 32bits</li><li>假设每个 block 是 2-byte，我们有 8Byte 的 cache<ul><li>offset 需要 1bit 来表示</li><li>index 表示对应位置，需要有 <code>(8 / 2)</code> 个状态，即占用 2bit</li><li>剩下的 29bits 作为 tag</li></ul></li></ul><p>同时，实际上我们可能有一个 valid bit, 当程序开始运行的时候，除了 32bits，可能需要一个 valid bit，表示这段缓存中的内存对程序而言是否是 valid 的。</p><h3 id="真实情况与假设"><a href="#真实情况与假设" class="headerlink" title="真实情况与假设"></a>真实情况与假设</h3><p>我们现在假设我们的 cache 有：</p><ol><li>16KB 的 data</li><li>direct-mapped 的模式</li><li>4-word 的 block</li></ol><p>现在我们来对照 slice 看看 direct-mapped 的访问：</p><p><img src="https://image.mwish.me/blog-image/截屏2020-10-31-下午2.42.01.png" alt="截屏2020-10-31 下午2.42.01"></p><p>那么，具体的访问如下图所示：</p><p><img src="https://image.mwish.me/blog-image/9FC2703E-B742-4671-B76B-33D8FB1E2ECF.png" alt="9FC2703E-B742-4671-B76B-33D8FB1E2ECF"></p><p>我们可以看到，在最早我们的讨论中，一个 tag 对应着可能2-byte 的内存，但是现在，我们可能一份 tag 对应 一个 block, 这个 block 可能装有比较多组的内存。实际上，这有益于 locality。</p><h3 id="Write-through-amp-Write-back"><a href="#Write-through-amp-Write-back" class="headerlink" title="Write-through &amp; Write-back"></a>Write-through &amp; Write-back</h3><p>这两种方案相信除了这里，我们介绍很多别的形式的 cache 的时候你也会碰见它们：好吧，过去、现在、还是将来，你都会遇到这两个。</p><ol><li>Write-through：写入的时候需要更新cache 和 memory</li><li>Write-back:<ol><li>写入的时候更新 cache block</li><li>添加一个 dirty flag</li><li>OS 在 IO 之前 flush cache</li></ol></li></ol><h3 id="block-size-的大小"><a href="#block-size-的大小" class="headerlink" title="block size 的大小"></a>block size 的大小</h3><ol><li>Pros:<ol><li>spatial locality: 空间 locality 受益</li><li>对 array 访问有好处</li><li>对于目前 stored-program 的形式有好处</li></ol></li><li>Cons:<ol><li>增加了 Miss penalty</li><li>If block size is too big relative to cache size, then there are too few blocks</li></ol></li></ol><p><img src="https://image.mwish.me/blog-image/7CF53EBF-159A-42A3-ADF4-68522446BC41.png" alt="7CF53EBF-159A-42A3-ADF4-68522446BC41"></p><h3 id="其他类型"><a href="#其他类型" class="headerlink" title="其他类型"></a>其他类型</h3><p>实际上，cache 有几种组织方式：</p><ul><li>fully associative</li><li>Direct mapped</li><li>N-way Set Associate</li></ul><p>我们会在下一个 part 介绍。</p>]]></content>
      
      
      
        <tags>
            
            <tag> system </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SDS Intro &amp; RISC-V Datapath(4): Pipeline</title>
      <link href="/2020/10/21/SDS-Intro-RISC-V-Datapath-4-Pipeline/"/>
      <url>/2020/10/21/SDS-Intro-RISC-V-Datapath-4-Pipeline/</url>
      
        <content type="html"><![CDATA[<p>CPU 的水太深了…我只能保证介绍比较基础的 case, 难免讲出问题，希望假以时日我能回头轻松啃下这几块吧=，=</p><p>上一节我们介绍了流水线的基本概念。相对于 Single-Cycle 的处理，并假设我们有最简单的5个 stage:</p><ol><li>IF: 取指</li><li>ID: 译码</li><li>EX: 执行</li><li>MA: 访存</li><li>WB: 写回</li></ol><p>在 15-418 里面，分为下面的：</p><ol><li>Fetch – get the next instruction from memory</li><li>Decode – figure out what to do &amp; read inputs</li><li>Execute – perform the necessary operations</li><li>Commit – write the results back to registers / memory</li></ol><p>当然需要说明的是，这是教学的一个非常简化的版本，真实 pipeline stage 会比这个多不少。</p><p><img src="https://image.mwish.me/blog-image/DA2AADD6-0808-4DAA-BD9C-8ECF81EB0922.png" alt="DA2AADD6-0808-4DAA-BD9C-8ECF81EB0922"></p><p><img src="https://image.mwish.me/blog-image/image-20201021225437486.png" alt="image-20201021225437486"></p><p>Pipeline 的基本思路是，“因为每个指令的每个阶段，用到的结构可能都是不一样的，所以我们和流水线加工一样，每个阶段都在处理不同的指令”。但是这个实现起来相对 Single-Cycle 就有各种各样的新问题了。</p><p><img src="https://image.mwish.me/blog-image/C50EED72-96F2-4434-9A88-62ADA24692C7.png" alt="C50EED72-96F2-4434-9A88-62ADA24692C7"></p><p><strong>Idea1: 准备必要的 Pipeline registers，把每个 stage 需要的 control logic 和上一阶段的数据拆分出来，让下个阶段能够正确的运行</strong></p><p><img src="https://image.mwish.me/blog-image/C60C0E6F-9F9B-4966-A051-DA907C80BB09.png" alt="C60C0E6F-9F9B-4966-A051-DA907C80BB09"></p><p>这里有：</p><ol><li>存储下一阶段需要的 inst 的 寄存器</li><li>存储下一阶段需要的数据来源，如 rs 等寄存器</li><li>PC Register</li><li>…</li></ol><p>而control logic 也是类似“多阶段的”，来完成这个控制。</p><h2 id="Pipeline-Hazards"><a href="#Pipeline-Hazards" class="headerlink" title="Pipeline Hazards"></a>Pipeline Hazards</h2><blockquote><p>A <em>hazard</em> is a situation that prevents starting the next instruction in the next clock cycle</p></blockquote><p>咋一看流水线这么运行就完了，但是细想还是会有很多问题，这里划分了3种：</p><ol><li>Structural hazard ：Datapath 组件的冲突，可能会有同时对memory 的读/写</li><li>Data hazard：寄存器等冲突，比如在不同 stage 的数据同时读写一个 reg</li><li>Control hazard</li></ol><p>这让我们不能简单的单个指令执行。</p><h3 id="Structutal-hazard"><a href="#Structutal-hazard" class="headerlink" title="Structutal hazard"></a>Structutal hazard</h3><ul><li><strong>Solution 1:</strong> 需要冲突的指令需要 stall</li><li><strong>Solution 2:</strong> 增加硬件（下面我们会看到这是怎么实现的）</li><li>永远能靠增加硬件来解决这个问题</li></ul><p>具体而言，在 decode stage, 可以读到两个 operand reg; 在writeback 阶段，可以写回一个 reg, 这个时候会产生冲突。这个时候可以分离对寄存器的读写 port，来维持状态。</p><p>这里还给出了一个访问 memory 的例子：IF 阶段取指令，MA 阶段访问存储，那么这个就有一个结构冲突了，这个时候解决方式是：</p><p><img src="https://image.mwish.me/blog-image/BF0AA0B5-DEEF-4564-91FE-56425D9FCC4D.png" alt="BF0AA0B5-DEEF-4564-91FE-56425D9FCC4D"></p><p>所以总结一下，RISC-V pipeline 出现 structral hazard 主要还是在于 memory</p><p>最佳的方式是拆分指令和数据的访问，拆分成 IMEM 和 DMEM。（我只知道有 icache 和 dcache 就是）</p><h3 id="Data-Hazard"><a href="#Data-Hazard" class="headerlink" title="Data Hazard"></a>Data Hazard</h3><p>这里是指寄存器上前后指令的冲突，具体如下图：</p><p><img src="https://image.mwish.me/blog-image/DC3BC619-FDE7-4B97-9725-B87CDFB82D41.png" alt="DC3BC619-FDE7-4B97-9725-B87CDFB82D41"></p><p>你这会儿会问，咱不是已经分离 Reg 的读写 port 了吗？为啥还会这样呢？分离端口不代表同一 stage 时间数据写/读能够有符合预期的结果：</p><blockquote><p>Might not always be possible to write then read in same cycle, especially in high-frequency designs. </p></blockquote><p>我们希望结果是符合预期的，即和非 pipeline 执行有相同的结果，那么我们就需要维护这个语义了。我们需要保证：</p><ol><li>前面写入 reg 的值能被之后的指令读 reg 读到</li><li>对同一个 reg 不依赖同一时间的读/写</li></ol><h4 id="解决方式1-Stalling"><a href="#解决方式1-Stalling" class="headerlink" title="解决方式1: Stalling"></a>解决方式1: Stalling</h4><p>（好像我们前面就讲了 stalling 但是没配图？）</p><p><img src="https://image.mwish.me/blog-image/E705CCA3-C56F-4F9D-8BFC-5FB231695B80.png" alt="E705CCA3-C56F-4F9D-8BFC-5FB231695B80"></p><p>但是 stall 会大大影响效率（这个可以找 perfbook, 里面有数据），不过编译器也可以分析并且插入 <code>add x0, x0, 0</code> 之类的 nop</p><h4 id="解决方式2-Forwarding-bypassing"><a href="#解决方式2-Forwarding-bypassing" class="headerlink" title="解决方式2: Forwarding(bypassing)"></a>解决方式2: Forwarding(bypassing)</h4><p><img src="https://image.mwish.me/blog-image/BF657B4A-8595-4056-B685-3249506D6AFA.png" alt="BF657B4A-8595-4056-B685-3249506D6AFA"></p><p>这个是真的牛逼…但是这么一来 path 和 control 感觉会巨复杂..</p><blockquote><p>Compare destination of older instructions in pipeline with sources of new instruction in decode stage.</p></blockquote><p>所以需要一个巨复杂的 forwarding control logic</p><p><img src="https://image.mwish.me/blog-image/848C745D-BCA9-4434-866C-9C2BDDBFFE65.png" alt="848C745D-BCA9-4434-866C-9C2BDDBFFE65"></p><p>同时，即使这样，我们还是需要必要的 stall:</p><p><img src="https://image.mwish.me/blog-image/1E2D7DAB-1F6B-4737-842B-D0E8308B9511.png" alt="1E2D7DAB-1F6B-4737-842B-D0E8308B9511"></p><p>这里第二条指令依赖第一条指令写入寄存器的值，所以这个需要 stall. 当然，编译器/CPU能够完成指令重排，来优化这个过程：</p><p><img src="https://image.mwish.me/blog-image/8398FD99-FE01-40F6-ACD4-08B8901B8C83.png" alt="8398FD99-FE01-40F6-ACD4-08B8901B8C83"></p><h2 id="Control-Hazard"><a href="#Control-Hazard" class="headerlink" title="Control Hazard"></a>Control Hazard</h2><p>这个反而是我最熟悉的…</p><p><img src="https://image.mwish.me/blog-image/AFADB924-9D9B-430F-9964-E73CF425A799.png" alt="AFADB924-9D9B-430F-9964-E73CF425A799"></p><p>其实可以看看 likely，影响程序的优化儿：<a href="https://en.cppreference.com/w/cpp/language/attributes/likely">https://en.cppreference.com/w/cpp/language/attributes/likely</a></p><p>likely 会静态的影响程序。</p><blockquote><ul><li>Every taken branch in simple pipeline costs 2 dead cycles</li><li>To improve performance, use “branch prediction” to guess which way branch will go earlier in pipeline</li><li>Only flush pipeline if branch prediction was incorrect</li></ul></blockquote><h3 id="Multiple-issue-“Superscalar”"><a href="#Multiple-issue-“Superscalar”" class="headerlink" title="Multiple issue “Superscalar”"></a>Multiple issue “Superscalar”</h3><p><img src="https://image.mwish.me/blog-image/86EE0F79-A6D6-49F2-B66C-87C1115A51BD.png" alt="86EE0F79-A6D6-49F2-B66C-87C1115A51BD"></p><p><img src="https://image.mwish.me/blog-image/5A2207CE-B1FA-4470-92E9-C74B1D922CCF.png" alt="5A2207CE-B1FA-4470-92E9-C74B1D922CCF"></p><p>这里需要 Execute 之前完成动态计算，并且去 superscalar 的执行</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>How to exit task</title>
      <link href="/2020/10/18/How-to-exit-task/"/>
      <url>/2020/10/18/How-to-exit-task/</url>
      
        <content type="html"><![CDATA[<p>开启一个线程不简单，关闭一个线程麻烦事更多. C++ 11 提供了 <code>std::thread</code> 的抽象，C++20 甚至提供了 coroutine. 我们的背后可能是 POSIX thread 在内的各种平台的线程。同时我们也有任务式的线程 api, 例如 <code>future</code> <code>promise</code> 对应的接口。在 Go 语言中，我们甚至能以一种更便捷的方式，以语法支持的形式创建 goroutine, 并以 CSP 的模式来通信。而背后的原生线程是隐匿的。</p><p>对于 C++11 <code>&lt;thread&gt;</code> 而言，线程抽象与 <code>std::thread</code> 是绑定的. 最好的阅读地点在：</p><p><a href="https://en.cppreference.com/w/cpp/thread/thread">https://en.cppreference.com/w/cpp/thread/thread</a> </p><blockquote><p>delays), starting at the top-level function provided as a <a href="https://en.cppreference.com/w/cpp/thread/thread/thread">constructor argument</a>. The return value of the top-level function is ignored and if it terminates by throwing an exception, <a href="https://en.cppreference.com/w/cpp/error/terminate">std::terminate</a> is called. The top-level function may communicate its return value or an exception to the caller via <a href="https://en.cppreference.com/w/cpp/thread/promise">std::promise</a> or by modifying shared variables (which may require synchronization, see <a href="https://en.cppreference.com/w/cpp/thread/mutex">std::mutex</a> and <a href="https://en.cppreference.com/w/cpp/atomic/atomic">std::atomic</a>)</p><p><code>std::thread</code> objects may also be in the state that does not represent any thread (after default construction, move from, <a href="https://en.cppreference.com/w/cpp/thread/thread/detach">detach</a>, or <a href="https://en.cppreference.com/w/cpp/thread/thread/join">join</a>), and a thread of execution may be not associated with any <code>thread</code> objects (after <a href="https://en.cppreference.com/w/cpp/thread/thread/detach">detach</a>).</p><p>No two <code>std::thread</code> objects may represent the same thread of execution; <code>std::thread</code> is not <a href="https://en.cppreference.com/w/cpp/named_req/CopyConstructible"><em>CopyConstructible</em></a> or <a href="https://en.cppreference.com/w/cpp/named_req/CopyAssignable"><em>CopyAssignable</em></a>, although it is <a href="https://en.cppreference.com/w/cpp/named_req/MoveConstructible"><em>MoveConstructible</em></a> and <a href="https://en.cppreference.com/w/cpp/named_req/MoveAssignable"><em>MoveAssignable</em></a>.</p></blockquote><p>其中，我们也要关注线程的析构：<a href="https://en.cppreference.com/w/cpp/thread/thread/~thread">https://en.cppreference.com/w/cpp/thread/thread/~thread</a></p><p>在析构的时候，如果线程是 <code>joinable</code> 的，这里会调用 <code>std::terminate</code>: <a href="https://zh.cppreference.com/w/cpp/error/terminate">https://zh.cppreference.com/w/cpp/error/terminate</a></p><p>当然，你可以用任务式的 api, 例如 <a href="https://en.cppreference.com/w/cpp/thread/async">https://en.cppreference.com/w/cpp/thread/async</a> , 让程序自己决定什么时候启动线程，指定对应的执行策略。</p><p>阅读上面一段话，你会发现一点：<code>joinable</code> 的 <code>thread</code> 会 <code>terminate</code>. 同时你可能会注意到，C++20 中，提供了   jthread <a href="https://en.cppreference.com/w/cpp/thread/jthread">https://en.cppreference.com/w/cpp/thread/jthread</a> . 关于使用，其实可以参考 CppCoreGuildlines: <a href="https://www.modernescpp.com/index.php/c-core-guidelines-taking-care-of-your-child-thread">https://www.modernescpp.com/index.php/c-core-guidelines-taking-care-of-your-child-thread</a></p><p>对，你会开始意识到，开启一个线程或许有一些小坑，但是从线程退出其实更麻烦，你在一个 noexcept 的地方抛出 <code>std::terminate</code>, 那你就等死吧。</p><h2 id="退出的目的"><a href="#退出的目的" class="headerlink" title="退出的目的"></a>退出的目的</h2><p>你可能需要：</p><ol><li><code>anyOf</code>，计算出最快的一个任务</li><li>我不再需要这个任务了</li></ol><p>那么我们可能想到两个方案：</p><ol><li>假装自己是鸵鸟，不管之前别的 thread</li><li>全部 kill/terminate 掉</li></ol><p>第一个在 C++ 可能会有 lifetime 问题哟：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">Resource ...</span><br><span class="line"><span class="keyword">for</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">Compute</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (ok) &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么你会开始头疼了，同样，假设甚至存在引用计数的时候，对，假设在 Go 语言，你还会面对 <code>Goroutine 泄漏</code> 的问题，你也要开一个 Goroutine, 接受任务完成 flag, 回收可能的资源。</p><p>第二个是 <code>terminate</code>, 或者甚至拿到 native 的 posix api, 来 terminate 它，但是下面问题来了：</p><ol><li>还是资源，资源泄漏</li><li><code>__force_unwind</code> 呢？<code>noexcept</code> 呢？全炸了？</li></ol><p>这里隐含这这么一点：你无法无痛的终止线程</p><h2 id="cancel-你该结束了"><a href="#cancel-你该结束了" class="headerlink" title="cancel: 你该结束了"></a>cancel: 你该结束了</h2><p>现在我们绕开线程，回到线程池，它是怎么终止线程的呢？</p><p>假设我们在一个很大的线程池子里，那么 Pool 要 destruct 了，这是一个很常见的场景。我们看看某些实现，可能会发现 </p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">atomic&lt;<span class="type">bool</span>&gt; stop_flag;</span><br><span class="line"></span><br><span class="line"><span class="built_in">cancel</span>() &#123;</span><br><span class="line">stop_flag = <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">loop</span>() &#123;</span><br><span class="line"><span class="keyword">while</span> (stop_flag.<span class="built_in">load</span>()) &#123;</span><br><span class="line">..</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// handle exit</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>stop_flag</code> 是一种很常见的模式，甚至也可以加上一个共享的池子上的 <code>notify</code> 和 <code>wait</code> 的 cv. 然后cv 自己有 barrier 语义，不过大意都是一样的：你在线程调用的地方提供 cancel flag。当然我们也能够提供 Poison 这样的消息，来保持这个层面的 stop 语义。</p><h2 id="Blocking？"><a href="#Blocking？" class="headerlink" title="Blocking？"></a>Blocking？</h2><p>上面语义是很清晰的，但是如果碰到 IO 呢？又来了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">do_something</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">catch</span>(thread_interrupted&amp;)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">handle_interruption</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我们又回来了，手动 interrupt，RAII…因为本质上，blocking 这还是个问题。</p><h2 id="没有无痛的方式：可-cancel-的任务"><a href="#没有无痛的方式：可-cancel-的任务" class="headerlink" title="没有无痛的方式：可 cancel 的任务"></a>没有无痛的方式：可 cancel 的任务</h2><p>我们看到了线程控制的困难性，同时，我们也能意识到，语法上 Go 不暴露 <code>thread</code> 本身的接口，所以它会用 context 模式来传递信息：</p><p><a href="https://zhuanlan.zhihu.com/p/107930946">https://zhuanlan.zhihu.com/p/107930946</a></p><p>而C#也提供了类似的接口，要把 cancel 的信息传下去</p><p>这意味着，我们某种意义上，是要对任务进行侵入的，我们可以参考 <a href="https://github.com/mapleFU/CPP-Concurrency-In-Action-2ed-2019/blob/master/content/chapter9/9.2-chinese.md">C++ Concurrency In Action 第二版</a> ，这里对相关的编程内容进行了入侵。</p><h2 id="隔离：或许我需要进程"><a href="#隔离：或许我需要进程" class="headerlink" title="隔离：或许我需要进程"></a>隔离：或许我需要进程</h2><p>回到之前的问题，我们需要停止，可能某种意义上不止需要“并发执行任务”，还需要“入侵执行任务的逻辑”。这里，我们可以突然想到，一直以来这篇文章都在纠结线程，但是进程由 OS 提供了更好的隔离和通信机制。加入我们引入了某个库，有一个 <code>ComputeHeavy</code> 函数，这个函数会调用很重的计算，那么我们可能不太好侵入。我们可以使用 <code>condition_variable_any</code> 加上 <code>future</code> , 但同时，我们也可以考虑用进程，它提供的是更好的隔离、资源回收等机制。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://github.com/mapleFU/CPP-Concurrency-In-Action-2ed-2019/blob/master/content/chapter9/9.2-chinese.md">C++ Concurrency In Action 第二版</a></li><li><a href="https://stackoverflow.com/questions/10834469/terminating-blocking-io-in-linux-c">https://stackoverflow.com/questions/10834469/terminating-blocking-io-in-linux-c</a></li><li><a href="https://zhuanlan.zhihu.com/p/143564479">https://zhuanlan.zhihu.com/p/143564479</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>SDS Intro &amp; RISC-V Datapath(3): Control logic and metric</title>
      <link href="/2020/10/18/SDS-Intro-RISC-V-Datapath-3-Control-logic-and-metric/"/>
      <url>/2020/10/18/SDS-Intro-RISC-V-Datapath-3-Control-logic-and-metric/</url>
      
        <content type="html"><![CDATA[<p>之前的 part2 我们忽略了控制逻辑是怎么实现的，把它当成一件理所当然的事情。我们可以看看 control logic 在处理器中对应的位置：</p><p><img src="https://image.mwish.me/blog-image/ADDF3668-C609-432C-96F9-63C9B78E8CCF.png" alt="ADDF3668-C609-432C-96F9-63C9B78E8CCF"></p><p>上面的 control 对应的就是下图中产生必要电信号的逻辑：</p><p><img src="https://image.mwish.me/blog-image/DF8C886C-04EF-42C2-A69A-D20F534363A7.png" alt="ADDF3668-C609-432C-96F9-63C9B78E8CCF"></p><p>其中， Control Logic 有对应的逻辑表：</p><p><img src="https://image.mwish.me/blog-image/44925410-7F57-443E-A74B-C71AC1884ECD.png" alt="44925410-7F57-443E-A74B-C71AC1884ECD"></p><p>它会根据指令的类型来判断，而指令的类型有指令中固定的字段来决定。</p><p><img src="https://image.mwish.me/blog-image/0D2C5051-0955-48A2-AC6F-861B8E04E442.png" alt="0D2C5051-0955-48A2-AC6F-861B8E04E442"></p><p>那么，实际上对应的如上所示，交给 <code>Inst</code> <code>BrEq</code> <code>BrLT</code> 之后，不同的电路会处理以上内容，产生不同的信号，供给 ALU 等使用。</p><h2 id="时间度量"><a href="#时间度量" class="headerlink" title="时间度量"></a>时间度量</h2><p><img src="https://image.mwish.me/blog-image/92C92D5E-3049-4CFC-9326-7A69F78D4A4A.png" alt="92C92D5E-3049-4CFC-9326-7A69F78D4A4A"></p><p>在一个 clock 中，对应的指令执行逻辑大概如上所示，那么，实际上</p><p><img src="https://image.mwish.me/blog-image/B0489346-356B-4449-AEFE-E30566ECF371.png" alt="B0489346-356B-4449-AEFE-E30566ECF371"></p><p>最大的时钟周期，即走 <code>lw</code> 的，为：</p><p><code>f_max = 1/800ps = 1.25GHz</code></p><p>实际上，指令执行的速度比这还快，会到每秒完成 5billion 的 add 。这归功于流水线。</p><p>那么对于 CPU 来说，什么算衡量标准呢？我的 3800X 为啥单核那么牛逼呢（误）？标准主要有：</p><ul><li>Latency: 程序需要执行的时间</li><li>Throughput: 程序一小时能够处理的请求数量</li></ul><p>即：</p><p><img src="https://image.mwish.me/blog-image/8A5BDE2B-FF96-4972-A607-E6E9EFBBF0D0.png" alt="8A5BDE2B-FF96-4972-A607-E6E9EFBBF0D0"></p><p>那么，具体到 CPU 层次而言，性能、Clock cycles per Instruction（即 CPI） 这些会有：</p><ul><li>ISA</li><li>处理器的实现（这里介绍的 RISC-V 的 CPI 为1）</li><li>Superscalar processors, CPI &lt; 1</li></ul><p>这些决定本身影响了 CPi。而 Time per Cycle 本身会被下列内容影响：</p><ol><li>处理器的 microarchitecture</li><li>技术，14nm 或者 28nm</li><li>耗电</li></ol><h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><p><img src="https://image.mwish.me/blog-image/9004ADA4-1562-4A46-A343-F5E5DCEBE907.png" alt="9004ADA4-1562-4A46-A343-F5E5DCEBE907"></p><p>把所有指令的耗时当成一致的，然后用流水线的方式执行。因为每个原件只输出上一个state的状态，这些 state 是可以隔离的。</p><p>流水线<strong>并不降低 Latency, 而是增大吞吐量</strong>。</p><p>但是，流水线并不是有几阶段就会变快几倍，实际上，填充流水线的时间和 branch，降低了流水线的可能提升。</p><h3 id="Pipeline-is-not-free"><a href="#Pipeline-is-not-free" class="headerlink" title="Pipeline is not free"></a>Pipeline is not free</h3><ul><li>pipeline stage 如果是不平衡的，可能会比较慢</li><li>寄存器的 setup time 和 clk-&gt;q 的时间可能会拖慢</li></ul><p>pipeline 的 task 如果有 dependency, 比如之前某个指令依赖某个寄存器，寄存器上的值又被后续指令修改，那么会有 dependency, 这个会造成流水线的 stall。</p><p>针对时间不平衡，例如 ALU 100ps, memory load 200ps，这个需要抹平这种时间，例如之前的 <code>t_cycle</code>, 都整成 200ps 就行了：</p><p><img src="https://image.mwish.me/blog-image/272C5EF5-4B23-49A9-8088-71751B5A9BD0.png" alt="272C5EF5-4B23-49A9-8088-71751B5A9BD0"></p><p>我们会在下一节讨论 Pipeline 的具体实现细节，现在先跳过不表。</p><h2 id="Superscalar-Processor"><a href="#Superscalar-Processor" class="headerlink" title="Superscalar Processor"></a>Superscalar Processor</h2><p>CPU 的 clock rate 由技术和电源限制，流水线可以增加阶段，但是有如下 trade-off:</p><ul><li>每个阶段做的事情少，clock cycle 会减小</li><li>但是潜在的 hazard 会增加</li></ul><p>所以可以考虑用 superscalar 处理器：</p><ul><li>把 pipeline stage 变成多个流水线</li><li>每个时钟周期执行多个指令</li><li>CPI &lt; 1, so use Instructions Per Cycle (IPC)</li><li>因为多个流水线，所以可能的 dependency 减小了</li></ul><p>此外，还可以乱序(<strong>Out-of-Order</strong>) 的执行：</p><blockquote><p>Reorder instructions dynamically in hardware to reduce impact of hazards:  EG, memory/cache misses</p></blockquote><p>x86 只有 StoreLoad 乱序，不过可以执行的乱序想必更多</p><p><img src="https://image.mwish.me/blog-image/EE918A8C-2D4B-4A42-A969-CAADBF62C2ED.png" alt="EE918A8C-2D4B-4A42-A969-CAADBF62C2ED"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>SDS Intro &amp; RISC-V Datapath(2): Datapath</title>
      <link href="/2020/10/15/SDS-Intro-RISC-V-Datapath-2-Datapath/"/>
      <url>/2020/10/15/SDS-Intro-RISC-V-Datapath-2-Datapath/</url>
      
        <content type="html"><![CDATA[<p>RV32I 需要的状态有：</p><ul><li><code>x0</code> - <code>x31</code> 的寄存器<ul><li>每一个是 32bits, 32 个寄存器</li><li>由 <code>rs1</code> <code>rs2</code> 和 <code>rd</code> 确定</li><li>对 <code>x0</code> 的写会被忽略</li></ul></li><li><code>PC</code></li><li>内存<ul><li>在一个32bits的地址空间里，存有指令和数据</li></ul></li></ul><h3 id="One-Instruction-Per-Cycle-RISC-V-Machine"><a href="#One-Instruction-Per-Cycle-RISC-V-Machine" class="headerlink" title="One-Instruction-Per-Cycle RISC-V Machine"></a>One-Instruction-Per-Cycle RISC-V Machine</h3><ul><li>现有的状态输出和输入走到 combinational logic, 在下个 clock edge 之前设置好下一个状态的值</li><li>clock edge 到来时，所有的状态都会被输出更新，然后执行状态转移到</li><li>指令和数据的内存是分开的，为了简化，内存是异步读取的，写入是同步的</li></ul><p>抽象的逻辑图如下：</p><p><img src="https://image.mwish.me/blog-image/F301427F-471C-402E-A586-55FA9CC3B3D1.png" alt="F301427F-471C-402E-A586-55FA9CC3B3D1"></p><h2 id="Instruction-phase"><a href="#Instruction-phase" class="headerlink" title="Instruction phase"></a>Instruction phase</h2><p><img src="https://image.mwish.me/blog-image/9230AA3F-BFD9-4352-831A-F67E7BFDEFEA.png" alt="9230AA3F-BFD9-4352-831A-F67E7BFDEFEA"></p><p>我们处理一条指令，可以划分为下面这些阶段：</p><ol><li>取指</li><li>Decode/Register Read</li><li>Execute</li><li>Memory</li><li>Register Write</li></ol><p>现在，我们来实现 <code>add</code>, 上一节我们介绍了 <code>add</code> ALU 对应的逻辑，现在需要看看 <code>add</code> 全流程了：</p><p><img src="https://image.mwish.me/blog-image/157C17E9-E5BA-486B-BF10-AD307C97F30F.png" alt="157C17E9-E5BA-486B-BF10-AD307C97F30F"></p><p>这个地方不涉及 memory, 需要做的事情是：</p><ol><li><code>rd = rs1 + rs2</code></li><li><code>PC = PC + 4</code></li></ol><p><img src="https://image.mwish.me/blog-image/1BCA41B9-F017-45C7-8B61-6D865F74CE31.png" alt="1BCA41B9-F017-45C7-8B61-6D865F74CE31"></p><p><code>RegWEn</code> 控制是否写寄存器，这是根据指令决定的。</p><ol><li>Clock edge 触发 PC 变化</li><li>IMEM 变化，取地址</li><li><code>Reg[]</code> 变化，Clock 触发后输出到 ALU</li><li>写会 <code>rd</code></li></ol><p>那么，要实现 sub, 需要给 ALU 的控制逻辑加料：</p><p><img src="https://image.mwish.me/blog-image/EC372F7D-B123-450D-AD55-81937FC1DC8D.png" alt="EC372F7D-B123-450D-AD55-81937FC1DC8D"></p><p>其他 R-Format Instructions 也可以用这套逻辑来实现</p><h3 id="引入立即数"><a href="#引入立即数" class="headerlink" title="引入立即数"></a>引入立即数</h3><p><img src="https://image.mwish.me/blog-image/A1F63331-0635-4D27-AEEE-AFF0D6AC0970.png" alt="A1F63331-0635-4D27-AEEE-AFF0D6AC0970"></p><p>所以引入了 imm gen</p><p><img src="https://image.mwish.me/blog-image/57188376-0D28-496F-B702-B819F534D6B3.png" alt="57188376-0D28-496F-B702-B819F534D6B3"></p><h3 id="load-words"><a href="#load-words" class="headerlink" title="load words"></a>load words</h3><p><img src="https://image.mwish.me/blog-image/7BFBC998-6986-42B2-9FB9-D64A4787EAB6.png" alt="7BFBC998-6986-42B2-9FB9-D64A4787EAB6"></p><p>现在，我们需要访问 dmem, 根据地址来输出值：</p><p><img src="https://image.mwish.me/blog-image/43D2B1BD-5DC7-4906-955B-173BAE47E43D.png" alt="43D2B1BD-5DC7-4906-955B-173BAE47E43D"></p><p>这个时候加上了 <code>WbSel</code> 和 <code>MemRw</code>, 需要读取 memory。我们现在能读取内存。</p><p><img src="https://image.mwish.me/blog-image/3CC5F8D9-7F07-448E-96D7-F2E18FB07882.png" alt="3CC5F8D9-7F07-448E-96D7-F2E18FB07882"></p><p>这个时候我们需要增加写内存的 Path:</p><p><img src="https://image.mwish.me/blog-image/206394E8-FDEE-4769-A5B6-6D2A83A1AEF9.png" alt="206394E8-FDEE-4769-A5B6-6D2A83A1AEF9"></p><p>这个时候需要一个 <code>DataW</code> 做输出到 <code>AddR</code> 的值。</p><h3 id="一值多用"><a href="#一值多用" class="headerlink" title="一值多用"></a>一值多用</h3><p><img src="https://image.mwish.me/blog-image/7BE58BEB-8C40-493A-BCBA-639A4FE58360.png" alt="7BE58BEB-8C40-493A-BCBA-639A4FE58360"></p><p>我们知道，RISC-V 的 <code>rs1</code> <code>rs2</code>  <code>rd</code> 都是出现在同一个地方的，所以所有的路径都会被用到，只是根据控制逻辑来判断这个值具体是什么语义，是立即数还是寄存器。</p><h3 id="branches"><a href="#branches" class="headerlink" title="branches"></a>branches</h3><h4 id="Conditional-branch"><a href="#Conditional-branch" class="headerlink" title="Conditional branch"></a>Conditional branch</h4><p><img src="https://image.mwish.me/blog-image/04E4E1C3-7FD5-4D0D-8A67-CEF2D9242BD2.png" alt="04E4E1C3-7FD5-4D0D-8A67-CEF2D9242BD2"></p><p><img src="https://image.mwish.me/blog-image/7F212FD8-9048-4883-A655-400FF2A8B88C.png" alt="7F212FD8-9048-4883-A655-400FF2A8B88C"></p><p>这里加入了一个 <code>Branch Comp</code> 的重要组件，然后把 PC conditional 的送到 ALU，结果再 conditional 的送回 PC</p><h4 id="unconditional-branch"><a href="#unconditional-branch" class="headerlink" title="unconditional branch"></a>unconditional branch</h4><p><img src="https://image.mwish.me/blog-image/B62E5E53-8758-4D55-897F-C9ACC98A72D3.png" alt="B62E5E53-8758-4D55-897F-C9ACC98A72D3"></p><p>这里就是直接跳转了，比之前还简单呢！</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><ul><li><p>Universal datapath</p><ul><li><p>Capable of executing all RISC-V instructions in one cycle each</p></li><li><p>Not all units (hardware) used by all instructions </p></li></ul></li><li><p>5 Phases of execution</p></li><li>IF, ID, EX, MEM, WB<ul><li>Not all instructions are active in all phases</li></ul></li><li>Controller specifies how to execute instructions<ul><li>what new instructions can be added with just most control?</li></ul></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>SDS Intro &amp; RISC-V Datapath(0): 预备知识</title>
      <link href="/2020/10/14/SDS-Intro-RISC-V-Datapath/"/>
      <url>/2020/10/14/SDS-Intro-RISC-V-Datapath/</url>
      
        <content type="html"><![CDATA[<p>我们的计算机构建在电路和芯片上，虽然程序员一般不会了解这些。现在我们可能有两种电压：</p><ul><li><code>Vdd</code> , 高电压, 在树莓派里面大概是 1.2伏特</li><li>低电压，0伏特或者接地</li></ul><p>通常，我们选择某种中间值，大于中间值的视为 <code>1</code>/<code>true</code>, 小于这个值的设置为<code>0</code>/<code>false</code>. 高中物理实验里面我们会有个电池，然后起一个电线+物理的“switch”开关，现代我们使用 CMOS 作为这个开关：</p><p><img src="https://image.mwish.me/blog-image/DFFF2237-A3C0-4A47-A529-B3F8DBBFC35A.png" alt="DFFF2237-A3C0-4A47-A529-B3F8DBBFC35A"></p><p>在 CMOS 中，我们实现了这种逻辑。图上的 <code>n</code> 是 negetive, <code>p</code> 是 positive, 具体如下：</p><p><img src="https://image.mwish.me/blog-image/FBC51C46-58ED-4A23-BCE8-ABBAADBF736E.png" alt="FBC51C46-58ED-4A23-BCE8-ABBAADBF736E"></p><p>后面两条就是高中物理知识了，短路什么的…上面两条比较重要：</p><ul><li>n-type 不带圈，低电压时，它是通的，否则通</li><li>p-type 带圈，高电压时，是通的，否则不通</li></ul><p>那么可以理解下面这图了：</p><p><img src="https://image.mwish.me/blog-image/FEB6CDCD-A282-4DB6-9BFA-F6662859DFAE.png" alt="FEB6CDCD-A282-4DB6-9BFA-F6662859DFAE"></p><p>X 为 Vdd 时，p-type 通，n-type 不通，那么 Y 电压是 1；X为 GND 时，p-type 不通，n-type 通，Y 为 0V。很显然，上面的可以算一个非门？</p><p>那么我们再来分析一个 slide 里的电路：</p><p><img src="https://image.mwish.me/blog-image/61EB95F0-389F-480B-BBF0-6334C4FD38BF.png" alt="61EB95F0-389F-480B-BBF0-6334C4FD38BF"></p><p>上图中，X Y 任意一个电压为一，那么 Z — 1V 中间是通的（这两个的 p-type 中并联了）；而下面 n-type 串联，需要 X, Y 都为 0，它们才是通的，Z 才为 0 V。</p><p>那我们可以用电路来实现一些语义，下面是你们应该都学过的一些记号，为了灌水我就贴张图了：</p><p><img src="https://image.mwish.me/blog-image/61EB95F0-389F-480B-BBF0-6334C4FD38BF.png" alt="61EB95F0-389F-480B-BBF0-6334C4FD38BF"></p><p>以上是相关的电路知识。实际上我们可以用几个数学工具来表示需要的逻辑：</p><p><img src="https://image.mwish.me/blog-image/233C6157-C855-4424-9957-2F78D8A78BEE.png" alt="233C6157-C855-4424-9957-2F78D8A78BEE"></p><p>我们可以用：</p><ul><li>Boolean expression: 与或非这些算子的布尔逻辑</li><li>Truth table: 预期的输入对应的输出的所有表格</li><li>Gate Diagram: 上述门和输入、输出的描述图</li></ul><p>实际上，<strong>电路中是会有一些 delay</strong> 的：</p><p><img src="https://image.mwish.me/blog-image/16550D9D-C7A7-45DD-BDC0-A002645C48CA.png" alt="16550D9D-C7A7-45DD-BDC0-A002645C48CA"></p><h2 id="反馈与触发器"><a href="#反馈与触发器" class="headerlink" title="反馈与触发器"></a>反馈与触发器</h2><p>我们主要介绍 <em>Synchronous Digital Systems</em>，不介绍异步的系统</p><p><strong>组合逻辑(Combinational Logic)</strong>,其输出只是当前输入的函数，与之前状态无关，无存储功能；另一种是<strong>时序逻辑(Sequential Logic)</strong>，能够存储数据供以后使用，如触发器，memory，寄存器(register,由多个触发器组成)。</p><p>上述内容提示我们，除了与或门和加法之类的 ALU 计算，我们还需要寄存器、内存等能够非顺时的保存状态的设备，同时，我们也需要状态，来结合上述各个部分，完成控制：比如我们有一个加法的组件，但是我们会希望让加法的结果在一定时间内是可读的，所以我们需要 flip-flop, 即触发器。</p><p>假设我们计算一个数组的和，即</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; size; ++i) &#123;</span><br><span class="line">sum += <span class="built_in">array</span>[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们没有地方存储 sum，那么就无法完成计算。很显然，我们需要寄存器这样的东西，那么，寄存器实际上是由一组 flip-flop 构成的.</p><h3 id="flip-flop"><a href="#flip-flop" class="headerlink" title="flip-flop"></a>flip-flop</h3><blockquote><p>Flip-flop name because the output flips and flops between 0 and 1</p></blockquote><p><img src="https://image.mwish.me/blog-image/7992A522-FFA5-4D90-A89A-7D7FDE404463.png" alt="7992A522-FFA5-4D90-A89A-7D7FDE404463"></p><p>下面是 D-type flip flop, <code>d</code> 作为输入，<code>q</code> 作为输出。它是 “positive edge-triggered” 的，即变为高电压的时候，边缘触发，并保持记录。即</p><blockquote><p>“On the rising edge of the clock, the input d is sampled and transferred to the output. At all other times, the input d is ignored.”</p></blockquote><p>同时，高位的时间中，<code>d</code> 需要保持稳定，即如下图：</p><p><img src="https://image.mwish.me/blog-image/A2377FD7-3492-45D6-A748-F19B13CC387D.png" alt="A2377FD7-3492-45D6-A748-F19B13CC387D"></p><p>我们有几个关键时间，如上图：</p><ul><li>Setup Time: when the input must be stable <em>before</em> the edge of the CLK</li><li>Hold Time: when the input must be stable <em>after</em> the edge of the CLK</li><li>“CLK-to-Q” Delay: how long it takes the output to change, measured from the edge of the CLK</li></ul><h3 id="系统模型和时钟周期"><a href="#系统模型和时钟周期" class="headerlink" title="系统模型和时钟周期"></a>系统模型和时钟周期</h3><p><img src="https://image.mwish.me/blog-image/35022F87-4627-432A-B48A-A17D4D8DB558.png" alt="35022F87-4627-432A-B48A-A17D4D8DB558"></p><p>上述是电路的基本模型，同时，对时钟周期和频率，我们有：</p><blockquote><p>Period = Max Delay = CLK-to-Q Delay + CL Delay + Setup Time</p><p>Frequency = 1/Period</p></blockquote><p>时间的计算会是后续的内容。</p><h3 id="流水线"><a href="#流水线" class="headerlink" title="流水线"></a>流水线</h3><p><img src="https://image.mwish.me/blog-image/68EBFEC9-FFFC-4498-87B5-122B932EA452.png" alt="68EBFEC9-FFFC-4498-87B5-122B932EA452"></p><p>计算的每一步依赖上一步的状态，所以我们可能要多个 register, 但是不用保持过久，因为实际上我们假设模型是如上，那么每一步只依赖上一步的状态。我们可以 pipeline 的去处理指令。</p><h3 id="回到-sum"><a href="#回到-sum" class="headerlink" title="回到 sum"></a>回到 sum</h3><p>回到 sum 的计算，我们有：</p><p><img src="https://image.mwish.me/blog-image/C6D1D07C-931A-44F6-9827-B123338E2EEF.png" alt="C6D1D07C-931A-44F6-9827-B123338E2EEF"></p><ol><li><code>S_i-1</code> 保存上一轮的 value, 由 <code>Reg</code> 持续输出</li><li><code>S_i-1</code> 和 <code>x_i</code> 经过加法器计算出 <code>S_i</code></li><li><code>reset</code> 信号将 reg 重置为 0，寄存器输出 <code>0</code></li><li><code>xi</code> 开始输入 <code>x_0</code> , 经过加法器和 <code>clk to q</code> 的时间, 提供给 Reg</li><li>CLK 起时，Reg 再次设置，成为 <code>x0</code> </li></ol><p><img src="https://image.mwish.me/blog-image/image-20201015130546809.png" alt="image-20201015130546809"></p><p>这个时期见，period 等同于最大延迟，即 <code>CLK-to-Q Delay + CL Delay + Setup Time</code></p><p>也可以观察到<code>S_i</code>  和 <code>S_(i - 1)</code> 变动的关系。</p><h3 id="Critical-path-不能抄近道"><a href="#Critical-path-不能抄近道" class="headerlink" title="Critical path: 不能抄近道"></a>Critical path: 不能抄近道</h3><p>Critical Path 指的是拿到寄存器输出的必要时间，指的是 next register 的 setup time, 也是整个逻辑电路可能的最慢的时间，即 clock 到 q 响应的时间。</p><p>极端情况是：</p><p><code>Clk-&gt;Q + **best case** combinational delay &lt; Hold time</code></p><p>这个时候我们需要甚至人为制造一些 delay, 来让它有足够的维持时间，即 hold time，来成功输入给寄存器的 flip-flop.</p><h3 id="逻辑设计"><a href="#逻辑设计" class="headerlink" title="逻辑设计"></a>逻辑设计</h3><p>寄存器本身是一个状态，电路也充满了状态，我们会有上一步的状态，下一步的状态</p><p><img src="https://image.mwish.me/blog-image/image-20201017153211876.png" alt="image-20201017153211876"></p><p>我们可以用有限状态自动机，来代表需要的逻辑。同时也可能拿到对应的输入输出的表：</p><blockquote><p>Combinational logic circuit is used to implement a function that maps from <em>present state and input</em> to <em>next state and output.</em></p></blockquote><p>根据状态机，我们可以设计 ALU:</p><p><img src="https://image.mwish.me/blog-image/image-20201017153438192.png" alt="image-20201017153438192"></p><h4 id="加法器"><a href="#加法器" class="headerlink" title="加法器"></a>加法器</h4><p>加法要有 carry-bit 实现进位，然后每两位按位相加。逻辑如下：</p><p><img src="https://image.mwish.me/blog-image/6206E039-8E6E-42AD-A0F5-C5F1956820F2.png" alt="6206E039-8E6E-42AD-A0F5-C5F1956820F2"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>RISC-V 编译、链接、加载</title>
      <link href="/2020/10/05/RISC-V-%E7%BC%96%E8%AF%91%E3%80%81%E9%93%BE%E6%8E%A5%E3%80%81%E5%8A%A0%E8%BD%BD/"/>
      <url>/2020/10/05/RISC-V-%E7%BC%96%E8%AF%91%E3%80%81%E9%93%BE%E6%8E%A5%E3%80%81%E5%8A%A0%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<p>我们介绍了 RISC-V 的指令，你可以当作介绍了汇编语言。但是，我们现在知道的是：</p><ul><li>RV32I 的格式都是 32bit 的</li><li>以上内容可以以 <code>beq</code> 等格式让读者可读，但是机器执行的还是那6种格式的代码</li></ul><p>我们也了解了 RISC-V 的 calling convention 和 ABI, 这一节介绍程序的编译、链接、加载。基础知识可以阅读 CSAPP 第七章和  <a href="https://zhuanlan.zhihu.com/p/125163040">https://zhuanlan.zhihu.com/p/125163040</a> 我之前写的垃圾。不过今天我写的会细一些。</p><p><img src="https://image.mwish.me/blog-image/7E604484-7BD6-4192-81E0-F5C0E8F31750.png" alt="7E604484-7BD6-4192-81E0-F5C0E8F31750"></p><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>编译由 <code>.c</code>  转为汇编语言，形式是 <code>.s</code>, 这个我们之前都用过了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">✗ riscv64-unknown-elf-gcc -march=rv32imac -mabi=ilp32 -S </span><br></pre></td></tr></table></figure><p>这样体验一把就行。Compiler 需要走：</p><ul><li>Lexer: 语法分析，把目标转成 token. 实际上可以借用 Lex 工具，而 Flex 是 Lex 的一个实现。</li><li>Parser: 将内容变为 AST</li><li>Semantic Analysis and Optimization: 检查 AST, 然后做一些优化</li><li>Code generation: 做寄存器 allocation, 代码生成</li></ul><p>实际上，我们生成 <code>-S</code> 也需要指定编译选项，能指定 <code>-O</code>。这里我们可以得到可靠的 RISC-V 的代码。它和我们的程序是逻辑上等价的，当然可能要进行一定的优化。</p><p>注意，在 RISC-V 中，编译是会产生便于理解的伪指令的。</p><h2 id="汇编"><a href="#汇编" class="headerlink" title="汇编"></a>汇编</h2><p>将汇编语言生成 ELF 的 object file, object file 属于 machine language 了。</p><p><img src="https://image.mwish.me/blog-image/1AD78D8D-1536-428E-99BE-5E072623028C.png" alt="1AD78D8D-1536-428E-99BE-5E072623028C"></p><p>ELF 文件包括：</p><ul><li>ELF Header, 以一个 16byte 的序列开始，描述系统 word 大小、字节顺序等</li><li><code>.text</code> text segment, 编译程序的机器代码</li><li><code>.data</code> 已初始化的 global/static C variable, 即源代码的 <code>static</code> 部分。<ul><li>Local 是在 stack 中的</li><li>未初始化的、被初始化为 0 的，在 <code>.bss</code> 中。它不占据实际空间，有点类似 gcc 的 <code>__weak__</code> .</li></ul></li><li><code>.symtab</code> ，符号表，存放定义、引用的函数、全局变量和不可被 reference 的 static 变量</li><li><code>.debug</code> 调试符号表，包含原始文件; <code>.line</code> 同样，包含行号和 <code>.text</code> 的映射。只有 <code>-g</code> 编译才会产生</li><li><code>.strtab</code> 字符串表，包含定义的 string 和 section 的名字。</li></ul><p>ELF 具体信息可以看：</p><p>那么我们还要注意，有的 directions, 即汇编指示符，会被丢给链接器，但不产生什么代码</p><ol><li><code>.text</code>  user text segment 中的片段</li><li><code>.data</code>  需要写到 user data segment 中的片段</li><li><code>.globl sym</code> 可以从其他文件引用的全局符号</li><li><code>.string str</code> 把对应的 C-Style 字符串存在内存中</li><li><code>.word w1...wn</code>  把这 n 个连续的符号连续存取</li></ol><p>同时，在链接的时候，会完成伪指令的替换，把它们全部替换成具体的指令（这里可以表示 RV32I 这样的）。</p><p>我们来看看 hello world:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;Hello, %s&quot;</span>, <span class="string">&quot;world&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 RISC-V Book 上，它生成了如下的汇编：</p><p><img src="https://image.mwish.me/blog-image/FD540A48-C82E-41A5-9218-F3899DE2A9DA.png" alt="FD540A48-C82E-41A5-9218-F3899DE2A9DA"></p><blockquote><p>其中图 3.6 中用到的指示符有:</p><ul><li>.text:进入代码段。</li><li>.align2:后续代码按22字节对齐。</li><li>.globl main:声明全局符号“main”。</li><li>.section .rodata:进入只读数据段</li><li>.balign4:数据段按4字节对齐。</li><li>.string “Hello, %s!\n”:创建空字符结尾的字符串。</li><li>.string “world”:创建空字符结尾的字符串。</li></ul></blockquote><h4 id="tail-call-optimization"><a href="#tail-call-optimization" class="headerlink" title="tail call optimization"></a>tail call optimization</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fn:</span><br><span class="line"> return foo(x)</span><br></pre></td></tr></table></figure><p>这个时候，正常行为应该是：把 <code>a0</code> 设置 x, 然后返回调用后的 <code>a0</code>, 即：</p><ul><li>然后用 <code>j</code> 或者 <code>tail</code> 直接调用 <code>foo(y)</code> ，这玩意会做个保存，把本函数的 <code>ra</code>, <code>sp</code> 保存，这样跳转的话就可以直接跳转到 <code>fn</code> 的调用者。</li></ul><p>在 RISC-V 伪指令中，有一条 <code>tail</code>, 会被解释成</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">auipc x6, offset[32:12]</span><br><span class="line">jalr x0, x6, offset[11:0]</span><br></pre></td></tr></table></figure><p>用 <code>tail</code> 和 <code>j</code> 来完成上述的 jump，而不再调用前再去设 sp/ra</p><p>这个行为让我有些头晕，我在网上找到了这篇 blog: <a href="https://www.sifive.com/blog/all-aboard-part-3-linker-relaxation-in-riscv-toolchain">https://www.sifive.com/blog/all-aboard-part-3-linker-relaxation-in-riscv-toolchain</a></p><p>上面的链接倒是介绍的比较清楚。</p><h4 id="生成机器代码"><a href="#生成机器代码" class="headerlink" title="生成机器代码"></a>生成机器代码</h4><p>我们描述过 ELF 格式了，我们有下列几个问题</p><h4 id="压缩指令"><a href="#压缩指令" class="headerlink" title="压缩指令"></a>压缩指令</h4><p>RV32C 支持压缩指令：</p><ul><li>每条短指令长度为 16bits</li><li>必须和 32bits 指令一一对应</li><li>只对汇编器和连接器可见，并且是否以短指令取代对应的宽指令由 它们决定。编译器编写者和汇编语言程序员可以幸福地忽略 RV32C 指令及其格式，他们能 感知到的则是最后的程序大小小于大多数其它 ISA 的程序。</li></ul><p><img src="https://image.mwish.me/blog-image/DB8DEC4A-F78C-4641-9652-266DB487A1F0.png" alt="DB8DEC4A-F78C-4641-9652-266DB487A1F0"></p><p>RV32C 如上</p><p><img src="https://image.mwish.me/blog-image/0119C713-D3D9-4C9F-B9F2-91F26E82EBCE.png" alt="0119C713-D3D9-4C9F-B9F2-91F26E82EBCE"></p><p>那么，考虑压缩指令，会有下列问题：</p><blockquote><p>So the presence of the 16b instructions <strong>doesn’t need to be known to anybody but the assembler and the RISC-V processor itself</strong>!</p></blockquote><h4 id="Forward-Reference"><a href="#Forward-Reference" class="headerlink" title="Forward Reference"></a>Forward Reference</h4><p>即假设 <code>L1 --&gt; L2</code>, 但 L1 在 L2 之前，那么这暗示编译器需要一张局部的符号表，并扫描不止一个 pass，来完成这个操作。</p><h4 id="jal-la-static-加载"><a href="#jal-la-static-加载" class="headerlink" title="jal/la static 加载"></a>jal/la static 加载</h4><p><code>jal</code> 会跳转一个 imm, 而 static 变量加载中，可能对应的符号来自另一个文件定义的内存中。</p><h3 id="Tables"><a href="#Tables" class="headerlink" title="Tables"></a>Tables</h3><p>为了解决上述问题，有了 symbol table 和 relocation table：</p><p>symbol table 展示可能被其他文件用到的本文件符号，例如 function call 的 label, 和 <code>.data</code> 中可以被外部访问的符号。</p><p>Relocation Table 展示 <code>jal</code> 和 <code>la</code> 中需要重定位的地址。</p><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p>讲 ELF 的 objective code 转化为可执行文件，这一过程被称为 linking, 这一过程有逻辑上如下的流程：</p><ul><li>从 <code>.o</code> 文件把 text segment 合在一起</li><li>拿到 data segment, 拼接到一起</li><li>resolve reference, 解决掉跨文件的符号、依赖问题，用绝对的地址填充</li></ul><p>实际上，<code>beq</code> <code>bne</code> <code>jal</code> 这类 PC-relevant 的指令不会被 relocate, 而用 name/label 相关的和 static 的会 relocate.</p><h2 id="加载"><a href="#加载" class="headerlink" title="加载"></a>加载</h2><p>通常 OS 会加载、运行程序：</p><p><img src="https://image.mwish.me/blog-image/B3419A1F-3922-41B9-8134-4EC45ED97B81.png" alt="B3419A1F-3922-41B9-8134-4EC45ED97B81"></p><p>它需要：</p><ol><li>读 executable 文件，加载 ELF，来知道 text 和 data 的大小</li><li>创建带 stack、text 的地址空间</li><li>把 instruction 和 data 拷贝到新的地址空间</li><li>拷贝用户的参数，传到栈上，供程序运行</li><li>初始化寄存器</li><li>跳转到用户程序，并设置 PC</li></ol><h2 id="全流程"><a href="#全流程" class="headerlink" title="全流程"></a>全流程</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>* argv[])</span> &#123;</span><br><span class="line"><span class="type">int</span> i;</span><br><span class="line"><span class="type">int</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt;= <span class="number">100</span>; i++) </span><br><span class="line">sum += i * i;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;The sum of sq from 0 .. 100 is %d\n&quot;</span>, sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译后生成：</p><p><img src="https://image.mwish.me/blog-image/7D55935F-1A5F-426F-8332-0DC6BD807E4F.png" alt="7D55935F-1A5F-426F-8332-0DC6BD807E4F"></p><p>assembly 的时候处理伪指令：</p><p><img src="https://image.mwish.me/blog-image/A7DC6FD7-197A-447C-9EC5-83058CEAE12C.png" alt="A7DC6FD7-197A-447C-9EC5-83058CEAE12C"></p><p>assembly 的时候生成 symbol table 和 relocation table：</p><p><img src="https://image.mwish.me/blog-image/9B1A0E60-E85D-4982-93E0-E573ECFA3C87.png" alt="9B1A0E60-E85D-4982-93E0-E573ECFA3C87"></p><p>以上的信息在链接的时候一起使用。</p><h2 id="动态链接库和静态链接库"><a href="#动态链接库和静态链接库" class="headerlink" title="动态链接库和静态链接库"></a>动态链接库和静态链接库</h2><p>对于静态库而言，它是可执行文件的一部分，库更新了，运行中的程序需要重新编译。这是编译时链接的。</p><p>在 Linux 下，提供了 <code>.a</code> 文件，用于处理，单个文件即使没有用到所有部分，也需要全部加载。</p><p><img src="https://image.mwish.me/blog-image/1C5CB001-2512-4A02-8763-9C2EFC1A8EF5.png" alt="1C5CB001-2512-4A02-8763-9C2EFC1A8EF5"></p><p>在动态链接库中，允许编译时、运行时链接。</p><p><img src="https://image.mwish.me/blog-image/26164010-1C75-4033-9411-7ACB84CE5056.png" alt="26164010-1C75-4033-9411-7ACB84CE5056"></p><p>共享库有 <code>.so</code> 文件，引用库的用户可以共享这些数据，而在内存中，共享库的<code>.text</code> 可以共享内存，被多个进程使用：</p><p><img src="https://image.mwish.me/blog-image/CB2186D3-34AB-4CD5-800E-51575F0E357C.png" alt="CB2186D3-34AB-4CD5-800E-51575F0E357C"></p><p>CSAPP 中，指导可以在 <code>dlfcn.h</code> 中使用该功能。</p><p>此外，为了共享，需要处理位置无关代码（Position-Independent Code, PIC）。这需要 <code>-fPIC</code> 选项。</p><p>它在编译时成功设置一个便宜量，并在运行时不改变这个便宜量，让代码能够运行便宜量上的 <code>.text</code></p><p><img src="https://image.mwish.me/blog-image/33F0D9AE-C4D1-4BEF-ADB8-0D486BB11089.png" alt="33F0D9AE-C4D1-4BEF-ADB8-0D486BB11089"></p><p>而 PLT 条目类似懒惰加载，作为链接的表来完成工作：</p><p><img src="https://image.mwish.me/blog-image/910B0674-2C61-403D-B5A2-C5BBEFF0DE82.png" alt="910B0674-2C61-403D-B5A2-C5BBEFF0DE82"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>RISC-V 指令格式</title>
      <link href="/2020/10/04/RISC-V-%E6%8C%87%E4%BB%A4%E6%A0%BC%E5%BC%8F/"/>
      <url>/2020/10/04/RISC-V-%E6%8C%87%E4%BB%A4%E6%A0%BC%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>先贴几个图</p><ul><li>RV32I 指令图</li></ul><p><img src="https://image.mwish.me/blog-image/D35C054C-DCDE-4C29-BDC1-6637C915952B.png" alt="D35C054C-DCDE-4C29-BDC1-6637C915952B"></p><ul><li>下面是具体的指令格式</li></ul><p><img src="https://image.mwish.me/blog-image/83904B69-0871-4150-98DE-1F0EA0877D17.png" alt="83904B69-0871-4150-98DE-1F0EA0877D17"></p><ul><li>下面是指令格式展开的格式</li></ul><p><img src="https://image.mwish.me/blog-image/1B9BA357-6712-4A2D-B287-FE774DF41B4F.png" alt="1B9BA357-6712-4A2D-B287-FE774DF41B4F"></p><p>上面几张图可以在包云岗老师翻译的 RISC-V book 里面找到。</p><blockquote><p>图 2.2 显示了六种基本指令格式，分别是:用于寄存器-寄存器操作的 R 类型指令，用于短立即数和访存 load 操作的 I 型指令，用于访存 store 操作的 S 型指令，用于条件跳转操作的 B 类型指令，用于长立即数的 U 型指令和用于无条件跳转的 J 型指令。图 2.3 使用图 2.2 的指令格式列出了图 2.1 中出现的所有 RV32I 指令的操作码.</p><p>为了帮助程序员，所有位全部是 0 是非法的 RV32I 指令。因此, 试图跳转到被清零的 内存区域的错误跳转将会立即触发异常，这可以帮助调试。类似地，所有位全部是 1 的指 令也是非法指令，它将捕获其他常见的错误，诸如未编程的非易失性内存设备、断开连接 的内存总线或者坏掉的内存芯片。</p></blockquote><h2 id="R-Format-Instruction"><a href="#R-Format-Instruction" class="headerlink" title="R-Format Instruction"></a>R-Format Instruction</h2><p>R-Format 用于寄存器-寄存器操作</p><p><img src="https://image.mwish.me/blog-image/98C5AAD5-6084-4061-9F60-2C4713515ACE.png" alt="98C5AAD5-6084-4061-9F60-2C4713515ACE"></p><h2 id="I-Format-Instruction"><a href="#I-Format-Instruction" class="headerlink" title="I-Format Instruction"></a>I-Format Instruction</h2><blockquote><p> 用于短立即数和访存 load 操作的 I 型指令</p></blockquote><p><img src="https://image.mwish.me/blog-image/28CB5742-AD12-4C86-8AA8-7E8DCA8EF12E.png" alt="28CB5742-AD12-4C86-8AA8-7E8DCA8EF12E"></p><p>很重要的是，RISC-V 所有的立即数都是 signed 的。例如：</p><p><img src="https://image.mwish.me/blog-image/6415DC2D-0A51-49C5-B1AE-606145CEB81F.png" alt="6415DC2D-0A51-49C5-B1AE-606145CEB81F"></p><p>除了这种 <code>add imm</code>. load 操作也是 I 型的：</p><p><img src="https://image.mwish.me/blog-image/02D8BD3A-6757-4E0F-B976-A0B66ED9A93B.png" alt="02D8BD3A-6757-4E0F-B976-A0B66ED9A93B"></p><blockquote><p>Note: if instruction has immediate, then uses at most 2 registers (one source, one destination)</p></blockquote><p>load 的模式通常是 <code>load rd, rs</code> 或者 <code>load rd, imm(rs)</code>.</p><h2 id="S-Format"><a href="#S-Format" class="headerlink" title="S-Format"></a>S-Format</h2><p>需要保存2个 Register 和一个小的 imm:</p><p><img src="https://image.mwish.me/blog-image/5890A79A-BC93-4D19-AC79-447D0273E059.png" alt="5890A79A-BC93-4D19-AC79-447D0273E059"></p><blockquote><p>RISC-V design decision is move low 5 bits of immediate to where rd field was in other instructions – keep <strong>rs1</strong>/<strong>rs2</strong> fields in same place.</p></blockquote><p>因为 store 只是把寄存器的存到内存中，所以没有“目标寄存器”。</p><hr><p>以上指令中，你会发现，RISC-V 希望 <code>rs1</code> <code>rs2</code> <code>rd</code> 三个寄存器 <strong>存在的话即有相同的位置</strong>。</p><blockquote><ul><li>By always placing the read sources in the same place, the register file can read without hesitation. If the data ends up being unnecessary (e.g. I-Type), it can be ignored</li></ul></blockquote><hr><h2 id="B-Format-和-Label"><a href="#B-Format-和-Label" class="headerlink" title="B-Format 和 Label"></a>B-Format 和 Label</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BEQx1,x2,Label</span><br></pre></td></tr></table></figure><p>上面是一个很正常的跳转指令，但是本身 .label 如何在机器码上存在呢？</p><p>在 RISC-V 中，一切都是有内存位置的，包括指令，那么跳转到对应指令的内存即可。在这里，因为 <code>.code</code> 端本身占用内存的大小有限，所以这里使用 PC-Relative Addressing:</p><ul><li>使用 <code>imm</code> 字段，表示 PC 的二进制补码偏移量。（<code>Could specify ± 211 addresses offset from the PC</code>)</li><li>To improve the reach of a single branch instruction, <em>in principle</em>, could multiply the offset by four bytes before adding to PC (<em>instructions are 4 bytes and word aligned</em>). 因为我们的 RV32I 都是 32bits 的，而且是 4bytes align 的，所以可以把偏移量 <code>* 32</code></li><li>This would allow one branch instruction to reach <code>± 211 × 32-bit</code> instructions either side of PC</li></ul><p>但是，考虑压缩指令，即扩展的 16-bit instructions，RISC-V 需要支持的还有 16bits 的扩展指令。</p><ul><li>To enable this, RISC-V always scales the branch offset by 2 bytes - even when there are no 16-bit instructions</li></ul><p>所以需要处理 size, 不能 <code>*32</code>, </p><p>在 RISC-V 中，conditional branch 逻辑如下：</p><ul><li>如果跳转成功了，<code>PC = PC + imm</code>, imm 是二进制补码，是 signed 的</li><li>否则，<code>PC = PC + 4</code></li></ul><p>最后，指令的支持形式如下</p><p><img src="https://image.mwish.me/blog-image/8E9E3C64254443AF66A352BF0DD83DB4.png" alt="8E9E3C64254443AF66A352BF0DD83DB4"></p><p><img src="https://image.mwish.me/blog-image/7ACB61F8-C66F-4612-9DBD-1F7095D2CE9E.png" alt="7ACB61F8-C66F-4612-9DBD-1F7095D2CE9E"></p><p>下面给了一个例子：</p><p><img src="https://image.mwish.me/blog-image/36F645F0-136D-449D-BCCF-97C8ED834226.png" alt="36F645F0-136D-449D-BCCF-97C8ED834226"></p><p>以上是 16bytes，而我们有 <code>imm[12]</code>, 偏移量相当于乘了 byte，同时预留了一个虚拟 <code>0</code> bit, 相当于 <code>*2byte</code>, 实在不够，会使用 <code>branch</code> + <code>jal</code> 的方式支持。</p><h2 id="U-Format"><a href="#U-Format" class="headerlink" title="U-Format"></a>U-Format</h2><blockquote><p> 用于长立即数的 U 型指令</p></blockquote><p><img src="https://image.mwish.me/blog-image/04E9659D-BA95-4219-ACF8-A031BD9F7472.png" alt="04E9659D-BA95-4219-ACF8-A031BD9F7472"></p><ul><li>AUIPC – Add Upper Immediate to PC</li><li>LUI – Load Upper Immediate</li></ul><p>注意这俩对应的都是高位。可以用 <code>lui</code> + <code>addi</code> 构造 32位的数（毕竟立即数不够大）。</p><p>需要注意的是，<code>addi</code> 指令中，写入 <code>imm[11:0]</code>, 看上去和 lui 没有冲突，但是如果构造 <code>0xDEADBEEF</code>这种，因为这辆都是二进制补码，需要处理低12位中，<code>imm[11]</code> 是 1的问题，这会导致整个结果成一个负数。</p><p>这里我们要回到二进制补码的特点：加一个负数的时候加法仍然是按位加的，但是进位是要从高位 <code>-1</code> 的 。这里需要高位再 <code>+1</code> 再处理。</p><p><img src="https://image.mwish.me/blog-image/80146EE9-9531-455F-86F9-1C7BBB41A9A8.png" alt="80146EE9-9531-455F-86F9-1C7BBB41A9A8"></p><h2 id="J-Format"><a href="#J-Format" class="headerlink" title="J-Format"></a>J-Format</h2><p>下面是 JAL 和 JALR</p><p><img src="https://image.mwish.me/blog-image/BECEBBA9-B72D-4E25-A767-DD54718C7AA5.png" alt="BECEBBA9-B72D-4E25-A767-DD54718C7AA5"></p><p><code>jal</code> 根据 <code>imm</code> 来跳跃，<code>rd</code> 存储。这个 <code>jal</code> 中遵循和 branch 中一样的测试，即 <code>*2byte</code></p><p><img src="https://image.mwish.me/blog-image/96F9098A-5CC8-4041-8448-92AAFAA92718.png" alt="96F9098A-5CC8-4041-8448-92AAFAA92718"></p><p><code>jalr</code> 中，把结果存到寄存器中, 注意，这回儿它就不 <code>*2byte</code> 了</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Integer &amp; Endian</title>
      <link href="/2020/09/19/Integer-Endian/"/>
      <url>/2020/09/19/Integer-Endian/</url>
      
        <content type="html"><![CDATA[<p>古早写过一篇：<a href="https://zhuanlan.zhihu.com/p/94406822">https://zhuanlan.zhihu.com/p/94406822</a></p><h2 id="Two’s-Complement-二进制补码"><a href="#Two’s-Complement-二进制补码" class="headerlink" title="Two’s Complement(二进制补码)"></a>Two’s Complement(二进制补码)</h2><p>虽然这是大部分入门计算机的人都学过的——不如说整篇文章都是，但是我们还是走流程复习一遍</p><p>如果表示 <code>unsigned</code> 相对来说很简单，那么表示 signed 就不行了。我们可以先验的知道一些结论，例如：</p><p><a href="https://en.cppreference.com/w/cpp/language/types">https://en.cppreference.com/w/cpp/language/types</a></p><ul><li>char 的范围是 <code>-128 to 127</code></li></ul><p>那么，教科书可能会提到的一些朴素的实现：比方说用边缘的某一位表示 signed 或者 unsigned. 因为这样可能会有一个 +0 和一个 -0</p><p>不过我们回忆一下，也有这种模型来的不是，比如 IEEE 浮点数。</p><h3 id="Sign-and-Magnitude-最高位表示-signed"><a href="#Sign-and-Magnitude-最高位表示-signed" class="headerlink" title="Sign and Magnitude: 最高位表示 signed"></a>Sign and Magnitude: 最高位表示 signed</h3><p>会引入 <code>+0</code> <code>-0</code> ，同时，加法/减法需要不同的行为。</p><p><a href="https://en.wikipedia.org/wiki/Signed_number_representations#Signed_magnitude_representation">https://en.wikipedia.org/wiki/Signed_number_representations#Signed_magnitude_representation</a></p><h3 id="One’s-Complement"><a href="#One’s-Complement" class="headerlink" title="One’s Complement"></a>One’s Complement</h3><blockquote><p>positive numbers have leading 0s, negative numbers have leadings 1s.</p></blockquote><p><a href="https://en.wikipedia.org/wiki/Ones&#39;_complement">https://en.wikipedia.org/wiki/Ones%27_complement</a></p><p>当然这个也有 <code>+0</code> <code>-0</code> 的问题，One’s Complement 也是最高位表示 signed/unsigned 的</p><p>这个加减法都可以一定程度上统一，但是会带来 negative zero 的问题，而不带来 negative zero 又给计算增加了额外的复杂度。</p><h3 id="Two’s-complement"><a href="#Two’s-complement" class="headerlink" title="Two’s complement"></a>Two’s complement</h3><p><a href="https://en.wikipedia.org/wiki/Two&#39;s_complement#Arithmetic_operations">https://en.wikipedia.org/wiki/Two%27s_complement#Arithmetic_operations</a></p><p><a href="https://zh.wikipedia.org/wiki/二補數">https://zh.wikipedia.org/wiki/%E4%BA%8C%E8%A3%9C%E6%95%B8</a></p><p>现在有了 two complement, 这个问题就被很好地解决啦！</p><p>本节，完结！</p><h2 id="Store-data-in-memory"><a href="#Store-data-in-memory" class="headerlink" title="Store data in memory"></a>Store data in memory</h2><p>这一节或许需要回顾：<a href="https://zhuanlan.zhihu.com/p/118749234">https://zhuanlan.zhihu.com/p/118749234</a></p><p>当数据存在内存的时候，我们或许会有字节流：<code>0x28872887</code>，假如这里面全是32位有符号整数，我们怎么解释它们呢？</p><p>在 32位 RISC-V 中，我们是 Little-Endian 的，这意味着我们有如下布局：</p><p><img src="https://image.mwish.me/blog-image/DE4A8B7C-67CC-4304-A0BC-2721362FB6B1.png" alt="DE4A8B7C-67CC-4304-A0BC-2721362FB6B1"></p><p>发现没有，每个 byte 的顺序是不变的，但是一个 16 位整数中， byte 之间的顺序是不一样的，对于 <code>0x28</code> 来说，如果我们是 Little Endian, 那么，我们是 <code>0x28</code>, 而对于 BigEndian 来说，我们是 <code>0x82</code>.</p><p>那么再回到 <code>0x28872887</code>, 假设我们会有一个 <code>int32_t s[4]</code> 变成了以上的 <code>0x28872887</code>，或者有：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">X</span> &#123;</span></span><br><span class="line">  <span class="type">int</span> i1;</span><br><span class="line">  <span class="type">int</span> i2;</span><br><span class="line">  <span class="type">int</span> i3;</span><br><span class="line">  <span class="type">int</span> i4;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么，他们会怎么办？假如是大端序？答案是 i1 i2 i3 i4 仍然只代表 <code>0x28</code> <code>0x87</code> <code>0x28</code> <code>0x87</code> 所在的那 16位，这个顺序是不会改变的。</p><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><p><a href="https://en.wikipedia.org/wiki/Endianness#Optimization">https://en.wikipedia.org/wiki/Endianness#Optimization</a></p><p>Little-Endian 提供了一个很好的性质，帮助用户完成上述的优化。</p><h3 id="转化"><a href="#转化" class="headerlink" title="转化"></a>转化</h3><p>你接触过 Unix 网络编程的话，可能会对下列的 api 有一定印象：</p><p><a href="https://linux.die.net/man/3/htons">https://linux.die.net/man/3/htons</a></p><p>网络传输一般采用大端序，也被称之为网络字节序，或<em>网络序</em>。现在假设你做了一个程序，需要从网络读写，可以走上面这一套…</p><p>等等，我们是不是忽略了什么？那浮点数呢？</p><p>我们都知道浮点数有 IEEE 754 标准，那么：</p><blockquote><h3 id="Floating-point-edit"><a href="#Floating-point-edit" class="headerlink" title="Floating point[edit]"></a>Floating point[<a href="https://en.wikipedia.org/w/index.php?title=Endianness&amp;action=edit&amp;section=8">edit</a>]</h3><p>Although the ubiquitous x86 processors of today use little-endian storage for all types of data (integer, floating point), there are a number of hardware architectures where <a href="https://en.wikipedia.org/wiki/Floating-point">floating-point</a> numbers are represented in big-endian form while integers are represented in little-endian form.<a href="https://en.wikipedia.org/wiki/Endianness#cite_note-16">[13]</a> There are <a href="https://en.wikipedia.org/wiki/ARM_architecture">ARM</a> processors that have half little-endian, half big-endian floating-point representation for double-precision numbers: both 32-bit words are stored in little-endian like integer registers, but the most significant one first. Because there have been many floating-point formats with no “<a href="https://en.wikipedia.org/wiki/Computer_network">network</a>“ standard representation for them, the <a href="https://en.wikipedia.org/wiki/External_Data_Representation">XDR</a> standard uses big-endian IEEE 754 as its representation. It may therefore appear strange that the widespread <a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE 754</a> floating-point standard does not specify endianness.<a href="https://en.wikipedia.org/wiki/Endianness#cite_note-17">[14]</a> Theoretically, this means that even standard IEEE floating-point data written by one machine might not be readable by another. However, on modern standard computers (i.e., implementing IEEE 754), one may in practice safely assume that the endianness is the same for floating-point numbers as for integers, making the conversion straightforward regardless of data type. (Small <a href="https://en.wikipedia.org/wiki/Embedded_system">embedded systems</a> using special floating-point formats may be another matter however.)</p></blockquote><p>在 boost.endian中，甚至对 floating point 只有有限的支持：</p><blockquote><p>Is there floating point support?</p><p>An attempt was made to support four-byte <code>float</code>s and eight-byte <code>double</code>s, limited to <a href="http://en.wikipedia.org/wiki/IEEE_floating_point">IEEE 754</a> (also known as ISO/IEC/IEEE 60559) floating point and further limited to systems where floating point endianness does not differ from integer endianness. Even with those limitations, support for floating point types was not reliable and was removed. For example, simply reversing the endianness of a floating point number can result in a signaling-NAN.</p><p>Support for <code>float</code> and <code>double</code> has since been reinstated for <code>endian_buffer</code>, <code>endian_arithmetic</code> and the conversion functions that reverse endianness in place. The conversion functions that take and return by value still do not support floating point due to the above issues; reversing the bytes of a floating point number does not necessarily produce another valid floating point number.</p></blockquote><h3 id="走向-Reader"><a href="#走向-Reader" class="headerlink" title="走向 Reader"></a>走向 Reader</h3><p>所以，当我们读取的时候，我们可能有大端序的整数读取：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Read_</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* buf, T* v)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">static_assert</span>(is_fundamental_v&lt;T&gt;);</span><br><span class="line">  *v = buf[<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">1</span>; i &lt; <span class="built_in">sizeof</span>(T); ++i) &#123;</span><br><span class="line">    *v &lt;&lt;= <span class="number">8</span>;</span><br><span class="line">    *v |= <span class="built_in">static_cast</span>&lt;<span class="type">uint8_t</span>&gt;(buf[i]);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="整型转换"><a href="#整型转换" class="headerlink" title="整型转换"></a>整型转换</h2><blockquote><h4 id="整型转换-1"><a href="#整型转换-1" class="headerlink" title="整型转换"></a>整型转换</h4><p>任何整数类型或无作用域枚举类型的<a href="https://zh.cppreference.com/w/cpp/language/value_category#.E7.BA.AF.E5.8F.B3.E5.80.BC">纯右值</a>都可隐式转换成任何其他整数类型。若其转换列出于整数类型提升之下，则它是提升而非转换。</p><ul><li><p>若目标类型为无符号，则结果值是等于源值<a href="https://en.wikipedia.org/wiki/Modular_arithmetic">模</a> <em>2n<br>\</em> 的最小无符号值，其中 <em>n</em> 是用于表示目标类型的位数。</p></li><li><p>若目标类型有符号，则当源整数能以目标类型表示时，不更改其值。否则结果是实现定义的 (C++20 前)与源值对 <em>2n<br>\</em> 同余的唯一目标类型值，其中 <em>n</em> 是用于表示目标类型的位数 (C++20 起)（注意这不同于未定义的<a href="https://zh.cppreference.com/w/cpp/language/operator_arithmetic#.E6.BA.A2.E5.87.BA">有符号整数算术溢出</a>）。</p></li><li>若源类型为 bool，则值 false 转换为目标类型的零，而值 true 转换成目标类型的一（注意若目标类型为 int，则这是整数类型提升，而非整数类型转换）。</li><li>若目标类型为 bool，则这是布尔转换（见下文）。</li></ul></blockquote><p>事实上，TiKV 代码依赖了这点，unsigned/signed 在下层统一用 <code>signed</code> 表示，然后依赖转换的语义。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>tenet 观影笔记</title>
      <link href="/2020/09/07/tenet-%E8%A7%82%E5%BD%B1%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/09/07/tenet-%E8%A7%82%E5%BD%B1%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="逆转的时间"><a href="#逆转的时间" class="headerlink" title="逆转的时间"></a>逆转的时间</h1><p>2010上映的盗梦空间中，导演诺兰尝试了以梦境来扭曲空间进行叙事。彼时电影在国内大受好评，笔者在读初中的时候，在贴吧上看到网友大呼“烧脑”。2020年，诺兰导演尝试了时间上的扭曲。需要说明的是，这不仅是设定上对于时间的扭曲，而且包括在视觉效果上的逆时间行走，这一次作品评价任然“烧脑”，但却褒贬不一。</p><p>需要说明的是，玩弄时间并不是什么新鲜事，时间旅行的原型大概来自 1843 年的 A Christmas Carol. 著名的 Docker Who 系列也有对本作的致敬。而科幻黄金时代，更是有《永恒的终结》、《你们这些回魂尸》这样经典的作品，以及《回到未来》等经典的作品，甚至时间早已成为科幻作家的拿手好戏，它本身可以带来蝴蝶效应式的改变、在时间轴上旅行的伦理问题、时间产生的悖论、不可抗拒的命运、个人的自由意志、不同时间轴上偿还时间债的孤独，甚至包括17年的约定这种叙事上的骗局。这都是时间的常用考量。在解构主义的动画\<Rick&Morty\>里，主角们甚至多次以时间旅行的形式嘲讽“这一套已经烂大街了”。</p><p>而逆着时光行走也并非2020年才有的设定，在海伯利安中，光阴冢来自未来，像魔鬼又像神明的伯劳逆着时光而行走；在《你一生的故事》中，主角通过文字领悟了时间维度上的自我；而一步步返老还童，也是科幻提到的题材。不过不得不说，以上几个例子中，光阴冢和伯劳没有被从第一视角描写过，你一生的故事则领悟多于描写，大部分返老还童的例子中，人们和别人行走在同样的时间剪头上，只是自己一步一步变年轻。TeneT 塑造的是完全对着时间反向行走的主角，并且在视觉上用逆向表现了这一点。这点尝试是很勇敢、很了不起的。但是，与《盗梦空间》扭曲空间不同，时间上的扭转并不是这么容易表现的。在《盗梦空间》或者今敏的《红辣椒》中，没有接触过任何科幻概念的人，也能理解作品在分镜与镜头上的表现力与伟大：空间上的利用是所见即所得的，红辣椒从电影院开始游行给人一种可以接受但又觉得梦幻的震撼，但是时间上的表现没有那么明显：诺兰采用了物理上的反向（这一点表现上很显著）和时间上的回环叙事来表现，前者相对来说好理解一些，但是观众仍然眼花缭乱，后者则需要十分的注意和构建这种方向的能力——阅读小说的时候，我们或许能理解反向时间的奇妙现象，但是在视觉上表现并让观众接受，恐怕难得多。所以，虽然很敬佩诺兰在时间上的尝试，但是从褒贬不一的评论来看——不能说电影不好，但它显然不够直观。</p><p>抛去设定来讲，Tenet 相对来说内核比较平凡，它讲了一个有关宿命的美国大片式故事，也带给我们一些宿命般的哀愁，但是这些哀愁相对混乱的打斗和炫技，并没有被很好的传达给观众——与盗梦空间在决战中和前妻一路叙事相比，观众们对 TeneT 会感到茫然不少。在叙事的深度和情感的传达上，TeneT 无论相对于导演自己的作品，还是时间相关的前作都逊色不少。与《凉宫春日的消失》相比，后者在时间旅行上也并不新鲜，但它的重点在感情上的表达。而 TeneT 感情上的表达并不出色：这不是罪过，电影没有必要强烈的表达感情也能获得其他方面的赞誉，但是在视觉效果已经不那么有趣的情况下，就成了压垮骆驼的稻草了。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Network Layer &amp; End To End System Design</title>
      <link href="/2020/09/05/Network-Layer-End-To-End-System-Design/"/>
      <url>/2020/09/05/Network-Layer-End-To-End-System-Design/</url>
      
        <content type="html"><![CDATA[<p>这一节我们会介绍网络的分层（老熟人了）和 End To End System Design. 计算机网络以分组的方式来提供对物理等层面的抽象。各层的所有协议被称为协议栈(protocol stack)，而 internet 提供了 物理层、链路层、网络层、运输层和应用层：</p><ol><li>对于应用层而言，数据是 message</li><li>对于运输层而言，它们在应用 endpoint 中传输上层的 message。我们把这一层的分组叫做 segment。这一层的协议包括 TCP 和 UDP</li><li>网络层负责将 datagram 移动到另一边。这一层包括著名的 IP 协议，同时它包含一些路由选择协议, 给运输层运输 packet</li><li>链路层依靠链路层的服务（还记得我们前两讲介绍的吗）讲消息传给下一个节点，链路层的分组称为 frame / packet.</li><li>物理层中，我们完成了对物理信号等对程序员来说没啥影响，但是必要的电路等信息。这一层向上一层提供了光纤、铜线等提供的物理信号，给上层提供 0/1。</li></ol><p>应当说明的是，上面是 Internet 的网络分层，实际上你可能还听说过 OSI 7层模型等分层。</p><p>在分层的网络中，对于上层而言，下层类似 api，下层提供一些封装过后的保证，上层用一定的方式和一定的保证来获得下一层的数据。</p><h3 id="链路层和网络层"><a href="#链路层和网络层" class="headerlink" title="链路层和网络层"></a>链路层和网络层</h3><p>1/2/5 实际上相对来说好理解，大部分人都或多或少有印象。但是 4-5 之间有什么区别呢？我们知道网络层包括 IP 协议，实际上，情况类似下面：</p><p><img src="https://image.mwish.me/blog-image/CB61FDA0-C769-4B9E-A2EF-ABDE2535C9D3.png" alt="CB61FDA0-C769-4B9E-A2EF-ABDE2535C9D3"></p><p>We’ll divide the world into switches and routers</p><ol><li>Switches will route on your, Link Layer (L2) Addresses </li><li>Routers will operate on IP (L3) Addresses</li></ol><p><img src="https://image.mwish.me/blog-image/639D4B96-BEB7-407C-B054-22FF26A861D8.png" alt="639D4B96-BEB7-407C-B054-22FF26A861D8"></p><p>这两层使用的 Route 方式不同，这一点我们即将介绍 IP，就会了解了。</p><p>实际上，IP 这个抽象相对来说相当重要，它提供了一个比较独立的网络的抽象，同时，对于异质性的网络，网络层也需要作出一定的协调和妥协：</p><ul><li>网络的带宽更大，发送的数据更快，而满的网络来不及接受，IP 需要丢弃来自生产快的网络的包</li><li>IP 层不能保证 loss-free 和消息传递的 order （This is called best effort service.）</li><li>有些网络有着更大的 packet，这个时候需要支持 fragementation 来拆分 packet</li></ul><p><img src="https://image.mwish.me/blog-image/55771480-6AB4-4711-82FD-617C7F5F46E4.png" alt="55771480-6AB4-4711-82FD-617C7F5F46E4"></p><p>下面继续丢图：</p><p><img src="https://image.mwish.me/blog-image/0FD97745-8A4A-43BE-9344-FCCF18DB4F71.png" alt="0FD97745-8A4A-43BE-9344-FCCF18DB4F71"></p><p>同时，对于上层的应用而言，我们也有不同层次的信息（正如我们一开始介绍的）：</p><p><img src="https://image.mwish.me/blog-image/6CA008EC-D656-423C-8619-79782173A59E.png" alt="6CA008EC-D656-423C-8619-79782173A59E"></p><p>每层的信息有不同的 header, 来表示这一层承载的信息。</p><h2 id="End-To-End-arguments-in-system-design"><a href="#End-To-End-arguments-in-system-design" class="headerlink" title="End To End arguments in system design"></a>End To End arguments in system design</h2><p>这是 84 年的一篇文章，介绍了那个时候互联网应用设计的一些思考。作者认为应该合理的抽象，在底层实现一些语意以优化性能，在高层实现高层真正想要的语义，因为在底层做抽象是很昂贵的，并且它们提供的语意也不一定真正可靠（当然你是金融公司或者很有钱啥的，都能自己搭海底光缆搞高频交易了，你大概也有钱在下层做优化了）。</p><p>文章最开始举了个简单的例子：文件传输程序。</p><blockquote><p>用户从 fs 中读取一个文件，然后经过程序一定处理，发送给网络另一端，另一个用户接收并写入 fs。</p></blockquote><p>这个事件本身各个层次都可能出现错误。我们不仅需要底层各种保证和错误处理，实际上我们需要端到端的确认，即应用确认文件写入完成，并且 checksum 等一致。</p><p><img src="https://image.mwish.me/blog-image/1E186DDA-D9B7-4241-90C8-8ED18C84818C.png" alt="1E186DDA-D9B7-4241-90C8-8ED18C84818C"></p><p>同时，我们虽然有 tcp 之类的协议能保证 order 和内容可靠，但是可靠的内容不一定被处理了，从这个角度来看，仅仅 tcp 是不可靠的。但是相对更底层的协议，或者 UDP 而言，底层实现对应的语义能保证性能上的 bonus. 我们可能需要下列的方案来保证应用层次的可靠：</p><ol><li>Encryption</li><li>First-in-first-out ordering</li><li>Duplicate message surpression </li><li>Multi-message transactions</li></ol><p>slide 给出了总结，我就不献丑翻译了：</p><p>Basic argument: If you can implement functionality correctly and completely at endpoints, do it there and not at a lower layer.</p><ul><li>It saves on redundant work in the system, and avoids confusion later. Exceptions okay for performance optimizations.</li></ul><p>Strong argument: Avoid putting unneeded functionality at lower layers of your system altogether because it’s harmful!</p><ul><li>Extra functionality at low layers constrains how applications are designed at higher layers.</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Notes: Scaling Memcache at Facebook</title>
      <link href="/2020/08/22/Notes-Scaling-Memcache-at-Facebook/"/>
      <url>/2020/08/22/Notes-Scaling-Memcache-at-Facebook/</url>
      
        <content type="html"><![CDATA[<h1 id="Notes-Scaling-Memcached-at-Facebook"><a href="#Notes-Scaling-Memcached-at-Facebook" class="headerlink" title="Notes: Scaling Memcached at Facebook"></a>Notes: Scaling Memcached at Facebook</h1><p>这篇文章介绍的是 FB 的缓存系统 Memcache, 这套系统构建在 memcached 上，提供了可靠的、大规模的缓存。这篇论文主要内容有：</p><ol><li>memcache 的简单的架构</li><li>memcache 性能的优化<ol><li>c/s communication 上的优化，即使用一定更改的 UDP 来实现 Get 语义和 batch 与并行请求</li><li>减轻对 db 的压力<ol><li>压力来源包括 stale sets 和 thundering herds ，这里 memcache 实现了 Lease 机制</li><li>用 memcache pool 和 pool 内部的 replication 来提供一定层次的共享</li></ol></li><li>处理因为 memcache failure 导致的 cascading failure (国内好像把这个叫雪崩?) ，引入了一个小的 Gutter </li></ol></li><li>在单 Region 中，引入 replication</li><li>跨地区的主-从备份中，保持一致性（话说主从备份这个词还能用吗？）</li><li>单机优化，slab 优化内存和 MGet 来处理Batch Key load，我没看的很细。</li></ol><p>阅读这篇文章需要注意一点，<code>memcache != memcached</code>。希望看的同学不要搞混了。同时这篇文章只介绍了 1-3. 4和5我看的都比较草率。</p><h2 id="architecture"><a href="#architecture" class="headerlink" title="architecture"></a>architecture</h2><p><img src="https://image.mwish.me/blog-image/65A9A79E-E6E9-4FEC-B143-10EDD305309E.png" alt="65A9A79E-E6E9-4FEC-B143-10EDD305309E"></p><p>memcache 系统作为一个 look-aside cache，我们可以回顾一下 look-aside cache：</p><p><img src="https://image.mwish.me/blog-image/A4E36A75-DDBD-4708-AD25-2DFD87A26E47.png" alt="A4E36A75-DDBD-4708-AD25-2DFD87A26E47"></p><ol><li>Get 会尝试 read from cache, 如果没有的话，会 read from db 再更新 cache</li><li>Set 会 update db, 然后 invalid cache</li></ol><p>同时，memcached 本身不会实现和其他 peer 的通信。引入 memcache 的客户端会有：</p><ol><li>memcached 客户端</li><li>一个 proxy 服务器，用于 batch 和 proxy.</li></ol><p>涉及这个系统的时候，有几个需要注意的地方：</p><ol><li>可能会有热数据和陈旧的/很少更新的数据</li><li>复制是必要的，但是可能会导致 fan-out 很大，即更新一处需要更新换多的副本或者 cascade 的关系</li><li>读 &gt;&gt;&gt; 写，作为 cache，读是主要的负载</li></ol><h2 id="In-a-Cluster-Latency-amp-Load"><a href="#In-a-Cluster-Latency-amp-Load" class="headerlink" title="In a Cluster: Latency &amp; Load"></a>In a Cluster: Latency &amp; Load</h2><h3 id="Latency"><a href="#Latency" class="headerlink" title="Latency"></a>Latency</h3><p>作为 web 应用的通用缓存，与数据库依赖的 k-v 存储不同，Get 模式通常是进入一个网页，然后捞起很多子组件的数据，甚至相互之间有加载的依赖关系。论文里面表示一次用户请求可能引起上百个 cache get key的访问。这样就会造成服务器负担比较重。同时因为 memcached 本身不提供服务器沟通，所以 memcache 在客户端上解决这个问题。</p><p>引入客户端，需要引入 memcache 的客户端会有：</p><ol><li>memcached 客户端</li><li>一个 proxy 服务器 <code>mcrouter</code>，用于 batch 和 proxy.</li></ol><p>同时有辅助的列表，来提供访问。</p><p>那么，客户端提供了 batch 和并行访问，客户端会 Batch 用户的请求，把一些级联的访问组织成 DAG, 来并行的访问，感觉类似数据库这种访问方式：</p><p><img src="https://image.mwish.me/blog-image/5D991D77-209D-4817-B6CB-DBACDF1807DC.png" alt="5D991D77-209D-4817-B6CB-DBACDF1807DC"></p><p>客户端在读请求上以 UDP + 拥塞控制 来实现，来降低 TCP Connection 带来的 CPU 和 memory 开销。为了避免 incast congestion, 即 Get 过多导致 floyd, 它实现了慢启动 + 滑动窗口。</p><p>下面是论文相关的一些性能分析：</p><blockquote><p>Under peak load, memcache clients observe that 0.25% of get requests are discarded. About 80% of these drops are due to late or dropped packets, while the remainder are due to out of order delivery. Clients treat get er- rors as cache misses, but web servers will skip inserting entries into memcached after querying for data to avoid putting additional load on a possibly overloaded network or server.</p></blockquote><p><img src="https://image.mwish.me/blog-image/98971E72-B68F-4CC4-988A-1D7844A74612.png" alt="98971E72-B68F-4CC4-988A-1D7844A74612"></p><blockquote><p>Web servers rely on a high degree of parallelism and over-subscription to achieve high throughput. The high memory demands of open TCP connections makes it prohibitively expensive to have an open connection be- tween every web thread and memcached server without some form of connection coalescing via mcrouter. Coalescing these connections improves the efficiency of the server by reducing the network, CPU and memory resources needed by high throughput TCP connections. Figure 3 shows the average, median, and 95<em>th</em> percentile latencies of web servers in production getting keys over UDP and through mcrouter via TCP. In all cases, the standard deviation from these averages was less than 1%. As the data show, relying on UDP can lead to a 20% reduction in latency to serve requests.</p></blockquote><p><img src="https://image.mwish.me/blog-image/C607914C-75A5-498C-9416-513855303E33.png" alt="C607914C-75A5-498C-9416-513855303E33"></p><h3 id="Reducing-Loads"><a href="#Reducing-Loads" class="headerlink" title="Reducing Loads"></a>Reducing Loads</h3><p>有两个问题会给数据库带来问题</p><ol><li>stale sets</li><li>thundering herds</li></ol><p>（第一个感觉是一致性问题啊）</p><p>第一个是读写都有的时候，回写带来值和数据库中值的不一致，我们考虑下面的过程：有 T1 T2 T3, 和对象 x, x 初始值是 x1, 未命中用 miss 表示，RC 表示读 cache, WC 表示写 Cache, D 代表DB, Inv 代表 Invalid Cache 那么假设如下的操作序列</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">T1: RCx(m) RDx1                    WCx1</span><br><span class="line">T2: RCx(m)           RDx2     WCx2</span><br><span class="line">T3:             WDx2      Inv     </span><br></pre></td></tr></table></figure><p>那么，cache 最后的剩下的就是 x1 了，和数据库不一致。</p><p>为了解决这个问题，memcache 使用了 lease, 在 cache 未命中的时候，拿到一个 lease, 这是一个 64bit 的 random token, 最后用这个 lease 来保证写会的版本是正确的。如果 cache 被 invalid 了，之前的 cache 都会被 inv, 回写会因为 lease 被 invalid 而失效。这样保证上述的情景不会发生。</p><p>Thundering herds 表示的是另一种场景：当一个 cache 读很重的时候，出现了一个 invalid，那完蛋了，这些读全部会打到 db 上，造成 db 写急剧放大。</p><p>这个问题解决还是和 lease 有关，lease 发放场景的时机是：“在 cache 未命中的时候，拿到一个 lease”。</p><blockquote><p>By default, we configure these servers to return a token only once every 10 seconds per key. Requests for a key’s value within 10 seconds of a token being issued results in a special notification telling the client to wait a short amount of time. Typically, the client with the lease will have successfully set the data within a few milliseconds. Thus, when waiting clients retry the request, the data is often present in cache.</p></blockquote><p>通过限定 lease 的频率，memcache 达到了类似“每次只让一个 key query 访问 db” 这样的效果，从而缓解了 db 因为此导致的压力。</p><p>同时，虽然为了保证与db一致，memcache会用 lease, 但是它允许一些不需要一致的应用读 stale value (毕竟一致也意味着代价):</p><blockquote><p>We can further reduce this time by identifying situations in which re- turning slightly out-of-date data is acceptable. When a key is deleted, its value is transferred to a data structure that holds recently deleted items, where it lives for a short time before being flushed. A get request can re- turn a lease token or data that is marked as stale. Appli- cations that can continue to make forward progress with stale data do not need to wait for the latest value to be fetched from the databases. Our experience has shown that since the cached value tends to be a monotonically increasing snapshot of the database, most applications can use a stale value without any changes.</p></blockquote><h4 id="Memcache-Pool"><a href="#Memcache-Pool" class="headerlink" title="Memcache Pool"></a>Memcache Pool</h4><p>memcache pool 的想法是按 key 分割 memcache. 因为实际上各个应用访问模式不同，有不同读写频率。混合负载会导致负面干扰，所以有 memcache pool. 然后用不同的策略来处理，例如：</p><blockquote><p>例如，我们可以为经常访问但对于 cache miss 的开销不大的 key 提供一个小的 pool 。我们还可以为不经常访问的 key 提供一个大型 pool ，对于这些 key 而言，cache miss 的代价非常高。</p></blockquote><p><img src="https://image.mwish.me/blog-image/669F5DED-F469-402F-8A49-CE13CD37A21B.png" alt="669F5DED-F469-402F-8A49-CE13CD37A21B"></p><p>(这张图后面还会讲)</p><p>把冷热-高低代价的数据放在不同的池子里，然后 tunning, 来保证系统效率。</p><p>Memcache Pool 需要每个 Pool 内部 replication 降低负载，这个的逻辑在于：</p><ol><li>如果是 sharding 的话，对于一个 100keys 的请求，两边任然要处理这么多 Query，只是每个 Query 拿的 key 少了，这是存储问题，但是不能解决 QPS 过高</li><li>replica 会降低每个机器的读开销, 不过需要额外维护一致性。</li></ol><blockquote><p>Each client chooses replicas based on its own IP address. This approach requires delivering invalidations to all replicas to maintain consistency.</p></blockquote><h3 id="Handling-Failures"><a href="#Handling-Failures" class="headerlink" title="Handling Failures"></a>Handling Failures</h3><p>Failure 是指池子之类的可能会坏掉/下线。因为是缓存，所以不影响数据库本身的正确性，但是请求仍然会全部打到数据库上。这被称为 cascading failure.</p><p>我们必须从两个方面解决故障：</p><ol><li>由于网络或服务器故障而导致无法访问少量主机</li><li>影响 cluster 中很大比例的服务器的广泛停机。</li></ol><p>对于小故障，我们依靠自动修复系统。这些操作不是即时的，可能需要几分钟。该持续时间足够长，以致导致上述 cascading failure，因此我们引入了一种机制，以使后端服务与故障进一步隔离。我们专用于一小组名为 Gutter 的机器来接管几台故障服务器的职责（类似 MapReduce 中那种剩余几台的 worker ）。 Gutter约占集群中Memcached服务器的1％。</p><p>请求 timeout，再次请求 Gutter 池子，然后按照原来的策略处理。Gutter 会很快 expire，同时会提供 stale 数据：</p><blockquote><p>Entries in Gutter expire quickly to obviate Gutter invalidations. Gutter limits the load on backend services at the cost of slightly stale data.</p></blockquote><p>上面那段含义类似写入不会 invalid Gutter, 所以它可能读旧数据… 感觉这也算是写入和一致的权衡吧，在 cache 坏的时候读 stale data 时合理的就会这样？</p><p>对于 hot keys, 论文说这个和 hot keys 是不同的层面：</p><blockquote><p>Note that this design differs from an approach in which a client rehashes keys among the remaining memcached servers. Such an approach risks cascading failures due to non-uniform key access frequency. For example, a single key can account for 20% of a server’s requests. The server that becomes responsible for this hot key might also become overloaded. By shunting load to idle servers we limit that risk.</p></blockquote><h2 id="In-a-Region-Replication"><a href="#In-a-Region-Replication" class="headerlink" title="In a Region: Replication"></a><strong>In a Region: Replication</strong></h2><p>在 Region 层面，memcache 系统再次提供了某种意义上的 replica 和冷热分割.</p><p>它提出了 frontend cluster, 即一组 服务器和memcached。多组 frontend cluster 存储到底层的 storage 上。</p><p><img src="https://image.mwish.me/blog-image/BD349449-EBD4-4152-8AF6-10F56DA54425.png" alt="BD349449-EBD4-4152-8AF6-10F56DA54425"></p><p>那么不同的 cache 间又要处理一致性了（我的天啊…）。 Region 提供了上层的和下层的 expire：</p><blockquote><p>Reducing packet rates: While mcsqueal could contact memcached servers directly, the resulting rate of packets sent from a backend cluster to frontend clusters would be unacceptably high. This packet rate problem is a consequence of having many databases and many memcached servers communicating across a cluster boundary. Invalidation daemons batch deletes into fewer packets and send them to a set of dedicated servers running mcrouter instances in each frontend cluster. These mcrouters then unpack individual deletes from each batch and route those invalidations to the right memcached server co-located within the frontend cluster. The batching results in an 18× improvement in the median number of deletes per packet.</p><p>Invalidation via web servers: It is simpler for web servers to broadcast invalidations to all frontend clusters. This approach unfortunately suffers from two problems. First, it incurs more packet overhead as web servers are less effective at batching invalidations than mcsqueal pipeline. Second, it provides little recourse when a systemic invalidation problem arises such as misrouting of deletes due to a configuration error. In the past, this would often require a rolling restart of the entire memcache infrastructure, a slow and disruptive process we want to avoid. In contrast, embedding invalidations in SQL statements, which databases commit and store in reliable logs, allows mcsqueal to simply replay invalidations that may have been lost or misrouted.</p></blockquote><p>在 Region 层面，也有 Region Pool, 这是一种资源共享。Region 中 frontend 请求不一，但对应存储层是一样的。对于图5中的 B 类数据：即数量少访问贵的，可以被移到一个共享的池子中。</p><blockquote><p> The decision to migrate data into regional pools is currently based on a set of manual heuristics based on access rates, data set size, and num- ber of unique users accessing particular items.</p></blockquote><h3 id="code-and-warm-重启"><a href="#code-and-warm-重启" class="headerlink" title="code and warm: 重启"></a>code and warm: 重启</h3><p>缓存的 code 是指：</p><ol><li>可能挂掉重启，内存全丢了</li><li>可能刚拉起来，内存还是没东西</li></ol><p>这个时候请求会落到 db 上，带来写入的放大。这个时候，简单的策略是直接从别的 warm 集群 cache 读，来优化效率。</p><p>但是这样又可能有不一致的问题了。所以 memcache 有下列解决机制：</p><ol><li>机制开启时，delete 有 hold-off 时间</li><li>hold-off 中，对这个 key 添加会失败</li><li>这代表不一致，然后需要重新去捞数据</li></ol><blockquote><p>Care must be taken to avoid inconsistencies due to race conditions. For example, if a client in the cold cluster does a database update, and a subsequent request from another client retrieves the stale value from the warm cluster before the warm cluster has received the invalidation, that item will be indefinitely inconsistent in the cold cluster. Memcached deletes support nonzero hold-off times that reject add operations for the specified hold-off time. By default, all deletes to the cold cluster are issued with a two second hold-off. When a miss is detected in the cold cluster, the client re-requests the key from the warm cluster and adds it into the cold cluster. The failure of the add indicates that newer data is available on the database and thus the client will refetch the value from the databases. While there is still a theoretical possibility that deletes get delayed more than two seconds, this is not true for the vast majority of the cases. The operational benefits of cold cluster warmup far outweigh the cost of rare cache consistency issues. We turn it off once the cold cluster’s hit rate stabilizes and the benefits diminish.</p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>notes: Spanner</title>
      <link href="/2020/08/19/notes-Spanner/"/>
      <url>/2020/08/19/notes-Spanner/</url>
      
        <content type="html"><![CDATA[<p>Spanner 也是地理隔离的数据库，把数据 sharding 地存在多组 Paxos 状态机上。这些机器位于可能地理隔离的不同区域内。</p><p>网上的 Spanner 产品有：<a href="https://cloud.google.com/spanner/docs/true-time-external-consistency?hl=zh-cn">https://cloud.google.com/spanner/docs/true-time-external-consistency?hl=zh-cn</a> . 关于它的内容有着中文的翻译。可以在上面阅读外部一致性相关的内容，我理解的外部一致性就是：</p><ul><li>提供了时间等外部的约束上的一致性</li><li>在一个时间戳下面的跨越数据库的全球一致性的读操作</li></ul><p>对于 MVCC 和对应语义的系统来说，事务的 ts 是绝对重要的。Spanner 提供了 TrueTime API, 暴露了时间和不确定性，来实现对应的内容。</p><blockquote><p>实现这种特性的关键技术就是一个新的 TrueTime API 及其实现。这个 API 可以直接暴露 时钟不确定性，Spanner 时间戳的保证就是取决于这个 API 实现的界限。如果这个不确定性 很大，Spanner 就降低速度来等待这个大的不确定性结束。谷歌的集群管理提供了一个 TrueTime API 的实现。这种实现可以保持较小的不确定性(通常小于 10ms)，主要是借助于 现代时钟参考值(比如 GPS 和原子钟)。</p></blockquote><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>一个 Spanner 集群被称为一个 universe:</p><p>Spanner 被部署成多个 zone 的集合，每个 zone 类似一个 BigTable. 我个人感觉像是一个可用区内的集群：</p><ul><li>一个 zone 包含一个 zonemaster</li><li>包含成百上千个 spanserver，类似 Chunk Server, 具体存储数据，把数据给客户端</li><li>客户端用 location proxy 来找到读写的数据</li><li>Universe master 主要是 一个控制台，它显示了关于 zone 的各种状态信息，可以用于相互之间的调试。</li><li>Placement driver 会周期性地与 spanserver 进行交互，来发现那些需要被转移的数据，或者是为了满足 新的副本约束条件，或者是为了进行负载均衡。</li></ul><p><img src="https://image.mwish.me/blog-image/74610E36-2947-44EA-908C-A5F32E889030.png" alt="74610E36-2947-44EA-908C-A5F32E889030"></p><h3 id="Spanserver"><a href="#Spanserver" class="headerlink" title="Spanserver"></a>Spanserver</h3><p><img src="https://image.mwish.me/blog-image/95264B0F-64B2-4C4F-B8E9-4F86D5992AC8.png" alt="95264B0F-64B2-4C4F-B8E9-4F86D5992AC8"></p><p>感觉开始套娃了。不过比较重要的是，SpanServer 也是跨数据中心的。</p><p>SpanServer 包含很多的 tablets。</p><p>Spanner 会把 TS 分配给数据，让其成为一个 MVCC 的 KV（还记得 TiKV 吗）。单个 tablet 的状态是以文件的形式存储的，被组织为：</p><ul><li>B-Tree 的文件形式</li><li>WAL</li></ul><p>并被存储在 GFS 的进化版， Colossus 上。不过感觉上面就是单纯 B-Tree 或者 LSMTree 层了。</p><p>Spanner 实现了 Leader-based 的 Paxos, 来实现一系列被复制的 k-v 操作。</p><p>（我很奇怪的是已经有 Colossus 了为什么还要封装一套 Paxos 来复制？看了下感觉是 Colossus 是不跨数据中心的）</p><p>一个写操作来临时，会写两次：</p><ul><li>写 Paxos 日志</li><li>对 tablet 写日志，并进行写操作。</li></ul><p>Paxos 实现的时候是 Pipeline 化的，但是会顺序 apply 日志。</p><p>（论文对 Paxos 提的感觉比较类似于 ZooKeeper 那种，似乎读可以本地读。）</p><p>Paxos Group 是 Leader based 的，如果你是 leader, spanserver 会  Lock Table，来支持分布式的事务实现, 同时针对长事务做了特化。（这里不知道是不是可以参考 Percolator）。同时，spanserver 也会实现事务管理器，来实现跨 paxos group 的事务。</p><blockquote><p>其中一个 Participant Group， 会被选为协调者，该组的 participant leader 被称为 coordinator leader，该组的 participant slaves 被称为 coordinator slaves。每个事务管理器的状态，会被保存到底层的 Paxos Group。</p></blockquote><p>（上面这段话很重要，你读到后面还会回来的，因为我就是这么回来的）</p><h3 id="Directory"><a href="#Directory" class="headerlink" title="Directory"></a>Directory</h3><p>Spanner 支持 Directory 的抽象，我感觉类似 Column Family. 一个 directory 是数据存放和调度的基本单元。属于一个目录的所有数据，都具有相同的副本配置。 当数据在不同的 Paxos 组之间进行移动时，会一个目录一个目录地调度。</p><p>dir 从属于 Paxos Group.</p><p>以上的调度可以防止热点，分散负载。如果一个 dir 过大，Spanner 会把它 sharding，然后分配到不同的 Paxos Group 上。</p><p><img src="https://image.mwish.me/blog-image/319E211E-A5F3-4945-B082-60204EA0EE3C.png" alt="319E211E-A5F3-4945-B082-60204EA0EE3C"></p><blockquote><p>最后，在 BigTable 中跨行事务的缺乏来导致了用户频繁的抱怨; Percolator[32]的开发就是用来部分解决这个问题的。</p></blockquote><p><img src="https://image.mwish.me/blog-image/64392CAF-4FEF-45BA-AD40-E7037E0E1CD1.png" alt="64392CAF-4FEF-45BA-AD40-E7037E0E1CD1"></p><p>Spanner 数据模型如上所示，感觉还是比较接近 directory + key 的行存的。</p><h2 id="TrueTime"><a href="#TrueTime" class="headerlink" title="TrueTime"></a>TrueTime</h2><p>本人对“时间”这个计算机概念不是很熟悉，所以时间这块会过的很草率，等以后补好了回头再看看。</p><p><img src="https://image.mwish.me/blog-image/795C6B9C-F39B-4AE2-B0B1-D014FB8C07FA.png" alt="795C6B9C-F39B-4AE2-B0B1-D014FB8C07FA"></p><p>TrueTime API 会提供一个时间的可信度区间。在 Google，这个 API 是由原子钟 + GPS 实现的，用同一个数据中心多个 master 和机器上的 slave + GPS 共同实现时钟同步的机制。</p><p>后续内容中，有需要判断 after 的，也有需要等待 after 的。</p><h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><p>Spanner 的并发主要指它实现事务。</p><h4 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h4><ol><li>对于只读事务和快照读而言，一旦已经选定一个时间戳，那么，提交就是不可避免的， 除非在那个时间点的数据已经被垃圾回收了</li><li>把 Spanner 客户端的写操作和 Paxos 看到的写操作这二者进行区分，是非常 重要的，我们把 Paxos 看到的写操作称为 Paxos 写操作。例如，两阶段提交会为准备提交阶 段生成一个 Paxos 写操作，这时不会有相应的客户端写操作。</li><li>在时间戳为 t 的时刻的数据库读操作，一定只能看到在 t 时刻之 前已经提交的事务。</li><li>事务读和写采用 S2PL 协议。As a result, they can be assigned timestamps at any time when all locks have been acquired, but before any locks have been released.</li><li>For a given transaction, Spanner as- signs it the timestamp that Paxos assigns to the Paxos write that represents the transaction commit.</li></ol><p>Spanner 依赖下面这些单调性:</p><ol><li>在每个 Paxos Group 内，Spanner 会以单调增加的顺序给每个 Paxos 写操作分配时间戳，即使在跨越多个领导者时也是如此。</li><li>在多个领导者之间就会强制实现彼此隔离的不连贯:一个领导者必须只能分配属于它自己 Lease 区间内的时间戳。当分配一个 s 时，Paxos Group 的 Leader 的 <code>smax</code> lease 需要大于 <code>s</code>.</li></ol><p>Spanner 也保证了 Paxos Group 针对外部的一致性：</p><blockquote><p>if the start of a transaction T occurs after the commit of a transaction T1, then the commit timestamp of T2 must be greater than the commit timestamp of T1.</p></blockquote><p>这描述了 Spanner 自身 Commit 的约束，因为它似乎只分配了一个 ts, 没有 跟 Percolator 那样分配 start_ts 和 commit_ts。</p><p>客户端的读依赖 timestamp 和对应的机器，在上面拿到 SnapShot 来读，而写需要过 Leader。所有的 Retry 会试图在系统内部进行，不需要 Spanner 做额外的操作。</p><p>Spanner 的读写肯定都会和 Paxos 逻辑有关，感觉有点类似 Lease + Raft。Leader 会有一个 Lease，在 replica 写完成的时候，会延续自己的 lease, 而 Leader 需要 explicit 的续命。Spanner 允许切换 Leader, 但是要定义一个 <code>Smax</code>, 只有时间超过 <code>Smax</code>, 即 <code>TT.after(s_max)</code>, 才会允许切换。</p><p>事务中，Spanner 使用 2PC，事务会分配时间戳，代表<strong>事务提交的时间</strong>（Percolator 会在 提交 和 开始 都分配时间戳，判断重复的区间）。</p><blockquote><p>Spanner 依赖下面这些单调性:在每个 Paxos 组内，Spanner 会以单调增加的顺序给每个 Paxos 写操作分配时间戳，即使在跨越多个领导者时也是如此。一个单个的领导者副本，可 以很容易地以单调增加的方式分配时间戳。在多个领导者之间就会强制实现彼此隔离的不连 贯:一个领导者必须只能分配属于它自己租约时间区间内的时间戳。要注意到，一旦一个时 间戳 s 被分配，smax 就会被增加到 s，从而保证彼此隔离性(不连贯性)。</p></blockquote><p>所以写的时候，会有全局的时间戳。但是同时，很吊诡的是，这个时间戳是在开始的时候被分配的</p><p><img src="https://image.mwish.me/blog-image/71547DDC-3204-4DD8-B279-F6218F60D296.png" alt="71547DDC-3204-4DD8-B279-F6218F60D296"></p><p>读取的事务会有一个 <code>t_safe</code> , 这个值代表安全读取的时间戳，没有到的话可能是要阻塞/重试的，那么可能更改的有：</p><ul><li>写入状态机的最大时间 Paxos 的 safe, 即被应用到 Paxos 状态机的最大时间戳。</li><li>Transaction Manager 的事务相关的 ts, 如果小于写入的 ts 的话，可能会有冲突，需要 block</li></ul><h3 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h3><blockquote><p>Like Bigtable, writes that occur in a transaction are buffered at the client until commit. As a result, reads in a transaction do not see the effects of the transaction’s writes. This design works well in Spanner because a read returns the timestamps of any data read, and uncommit- ted writes have not yet been assigned timestamps.</p></blockquote><p>这个是靠 <code>ts_safe</code> 那个约束处理的。</p><p>RW 事务中，先请求一个 Paxos Group，拿到读锁，读需要读的数据，然后 boffer 所有的 write。然后开始 2PC：</p><ol><li>Participant 拿到写锁，分配一个单调递增的 prepare ts，提交一个 Prepare Paxos Log，然后把对应的 prepare ts 给 Coodinator</li><li>Coodinator 拿到一个递增的，大于 <em>TT.now</em>().<em>latest</em> 、大于所有 prepare ts 的 commit ts<ol><li>The coordinator leader then logs a commit record through Paxos (or an abort if it timed out while waiting on the other participants).</li></ol></li><li>Before allowing any coordinator replica to apply the commit record, the coordinator leader waits until <em>TT.after</em>(<em>s</em>), so as to obey the commit-wait rule described in Section 4.1.2. </li></ol><p>也就是说，单机上的任何冲突靠 wound-wait, 多机器靠上面的协议实现。</p><p>读相对简单的多，拿到 Group 的 scope 然后拿到 <code>safe_ts</code> 来读。不过 <code>safe_ts</code> 选举也是有技巧的：</p><blockquote><p>If the scope’s values are served by a single Paxos group, then the client issues the read-only transaction to that group’s leader. (The current Spanner implementa- tion only chooses a timestamp for a read-only transac- tion at a Paxos leader.) That leader assigns s<em>read</em> and ex- ecutes the read. For a single-site read, Spanner gener- ally does better than <em>TT.now</em>().<em>latest</em>. Define <em>LastTS</em>() to be the timestamp of the last committed write at a Paxos group. If there are no prepared transactions, the assign- ment s<em>read</em> = <em>LastTS</em>() trivially satisfies external consis- tency: the transaction will see the result of the last write, and therefore be ordered after it.</p><p>If the scope’s values are served by multiple Paxos groups, there are several options. The most complicated option is to do a round of communication with all of the groups’s leaders to negotiate s<em>read</em> based on <em>LastTS</em>(). Spanner currently implements a simpler choice. The client avoids a negotiation round, and just has its reads execute at s<em>read</em> = <em>TT.now</em>().<em>latest</em> (which may wait for safe time to advance). All reads in the transaction can be sent to replicas that are sufficiently up-to-date.</p></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/47870235">https://zhuanlan.zhihu.com/p/47870235</a></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>notes: Aurora</title>
      <link href="/2020/08/16/notes-Aurora/"/>
      <url>/2020/08/16/notes-Aurora/</url>
      
        <content type="html"><![CDATA[<h1 id="Aurora"><a href="#Aurora" class="headerlink" title="Aurora"></a>Aurora</h1><p>让我们继续 6.824 阅读。Lecture 10 的标题是:</p><blockquote><p>Lecture 10: Database logging, quorums, Amazon Aurora</p></blockquote><p>与前面的 Raft/CRAQ 不同，Aurora 展示了一种技术很牛逼也卖得很好的共享存储架构。我们可以说这是经过了考验的设计良好的架构。</p><p>6.824 主要介绍的是 AZ 和 Quorum，虽然这些东西都很厉害，不过我总觉得没介绍 Aurora 最牛的东西？</p><p><img src="https://image.mwish.me/blog-image/2F83C406-2307-437E-9E86-772AF7D89F39.png" alt="2F83C406-2307-437E-9E86-772AF7D89F39"></p><p>EC2 是 Amazon 的云服务器，由本地的 SSD，并有多租户等特性，S3 是亚马逊的对象存储. 在 S3 上存上去了能保证安全性。</p><p>这里的 RW 表示有读/写权限的 Primary, RO 表示只读的机器。运算节点机器部署在 Amazon 的 VPC 上，而存储依赖于部署在各地、有本地 SSD 的存储节点。它也会产生类似 binlog 的文件，同步到 Amazon S3 对象存储上。</p><p>6.824 给了一些 AWS 服务的介绍：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">EC2 is great for www servers</span><br><span class="line">  more load -&gt; rent more EC2 instances</span><br><span class="line">  crash -&gt; who cares, stateless, data in DB</span><br><span class="line">EC2 is not ideal for DB e.g. MySQL</span><br><span class="line">  limited scaling options -- just read/only DB replicas</span><br><span class="line">  limited fault-tolerance; if phys machine dies, disk dies with it</span><br><span class="line">    periodic DB backups to Amazon&#x27;s &quot;S3&quot; bulk storage service</span><br></pre></td></tr></table></figure><p>此外还需要介绍 Amazon EBS, 即 Block Store，AWS 的块存储。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Amazon EBS (Elastic Block Store)</span><br><span class="line">  [diagram of EC2 instance, two EBS servers -- left half of Figure 2]</span><br><span class="line">  block storage that&#x27;s still available even if an EC2 instance crashes</span><br><span class="line">  looks like a disk to EC2 instances, mount e.g. Linux ext4 on EBS volume</span><br><span class="line">  implemented as pairs of servers with disk drives, chain replication,</span><br><span class="line">    paxos-based configuration manager</span><br><span class="line">  both replicas are in the same &quot;availability zone&quot; (AZ)</span><br><span class="line">    AZ = machine room or datacenter</span><br><span class="line">    for speed, since all client writes have to wait for both EBS servers</span><br><span class="line">  for a DB on EC2, much better fault-tolerance than locally-attached storage!</span><br><span class="line">    if DB EC2 instance crashes, just re-start it on another EC2 instance</span><br><span class="line">    and attach to the same EBS volume</span><br><span class="line">  note: only one EC2 instance can use a given EBS volume at a time</span><br><span class="line">    EBS is not shared storage</span><br></pre></td></tr></table></figure><p>传统的 Mirror 方案 Pipeline 如下：</p><p><img src="https://image.mwish.me/blog-image/F2166CAF-99B5-4B32-BFE9-A5008D68FF2B.png" alt="F2166CAF-99B5-4B32-BFE9-A5008D68FF2B"></p><p>（异步的方案或许只要读取 binlog, 但是同步复制则需要做上面的操作 <a href="https://dev.mysql.com/doc/refman/8.0/en/replication-semisync.html）">https://dev.mysql.com/doc/refman/8.0/en/replication-semisync.html）</a></p><p>上述的操作或者方案会带来很大的写放大。此外，Aurora 认为，在一个集群中，慢的机器和慢的/同步的操作很容易成为瓶颈，例如：</p><ul><li>事务的 Commit 阻塞冲突的事务</li><li>分布式事务的 2PC</li><li>单机的 Cache Miss</li></ul><p>Aurora 把上层保留（不过可能也要做一些适配），然后在存储层替换为了分布式的：</p><p><img src="https://image.mwish.me/blog-image/76F2664C-65A4-4D5C-AF5D-10334065E8BA.png" alt="76F2664C-65A4-4D5C-AF5D-10334065E8BA"></p><blockquote><p>First, by building storage as an independent fault- tolerant and self-healing service across multiple data-centers, we protect the database from performance variance and transient or permanent failures at either the networking or storage tiers. We observe that a failure in durability can be modeled as a long- lasting availability event, and an availability event can be modeled as a long-lasting performance variation – a well-designed system can treat each of these uniformly [42]. Second, by only writing redo log records to storage, we are able to reduce network IOPS by an order of magnitude. Once we removed this bottleneck, we were able to aggressively optimize numerous other points of contention, obtaining significant throughput improvements over the base MySQL code base from which we started. Third, we move some of the most complex and critical functions (backup and redo recovery) from one-time expensive operations in the database engine to continuous asynchronous operations amortized across a large distributed fleet.</p></blockquote><p>Aurora 主要思路是：</p><ol><li>提供共享的存储和 RWN, 在多个可用区保证可靠性</li><li>The log is the database, 共享存储与 Log</li><li>基于(2) 的事务</li></ol><p>我觉得 1 其实很好理解，2对我这种没看过的比较新奇，但是也可以理解，3这段很难</p><h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Goal: better fault tolerance by cross-AZ replication</span><br></pre></td></tr></table></figure><p>Available Zone 可用区，简单理解类似于阿里云 xx 机房，特性是：</p><ul><li>内部机器物理上大概很接近，零点几毫秒 ping 一下</li><li>硬件一般故障其实概率都差不多，但是高温、发洪水、网络延迟之类的可能导致整个机房都不可用</li></ul><p>Aurora 采取3AZ + 每个 AZ 两台的形式，在 RWN 协议下保证了：</p><ul><li>一个 AZ 内全部坏掉 + 额外坏一台，是可读的</li><li>一个 AZ 全部坏掉，是可写的</li></ul><p>（我的问题是这样写入不会延迟巨高么=。=）</p><p>Aurora 将：</p><ul><li>长期的机器坏掉</li><li>短暂的网络延迟</li><li>更新</li></ul><p>上述的问题都视作系统的不可用。现在它想要保证的是：</p><ul><li>无法减少故障修复时间</li><li>—&gt; 希望减少 MTTF （平均故障间隔），来让上述不可用很少发生，保证系统有 Quorum</li></ul><p>Aurora 采用 Segment Storage, 来分10G段存储，分段修复。</p><blockquote><p>之所以选择10G，是因为在万兆网络条件下，恢复一个数据段只需要10秒钟。在这种情况，如果要打破多数派，那么必须同时出现两个数据段同时故障加上一个AZ故障，同时AZ故障不包含之前两个数据段故障的独立事件。通过我们对故障率的观察，这种情况出现的概率足够低，即使是在我们现在为客户服务的数据库量级上。</p></blockquote><p>以上的是模型上的思路，Aurora 提供了 EBS 级别的容错：</p><ul><li>EBS 部署在上述所叙述的情况下，来保证写入的 Quorum</li></ul><p>话说 6.824 在这里简单介绍了一下 Quorum read/write，Amazon 在实现 Dynamo 的时候也用了这套：</p><ul><li>可能写入需要维护版本</li><li>N 是总副本的数量，R是读的数量，W是成功写的数量，那么：<ul><li>R + W &gt; N, 即刻说明读写必定有交集，必定能读到写入的数据</li></ul></li></ul><p>6.824 介绍如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> the goal: fault-tolerant storage,</span><br><span class="line">   read latest data even if some failures</span><br><span class="line">how to decide which is the most recent copy?</span><br><span class="line">   cannot vote on content!</span><br><span class="line">     only one server in read quorum might be up to date</span><br><span class="line">   writer assigns increasing version numbers to its writes</span><br><span class="line">   storage servers must remember version of each item</span><br><span class="line">   reader takes max version # of the R copies it receives</span><br><span class="line"> what if a read or write can&#x27;t assemble a quorum?</span><br><span class="line">   keep trying.</span><br></pre></td></tr></table></figure><p>下面是它的 pros and cons</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">What is the benefit of quorum read/write storage systems?</span><br><span class="line">  In contrast to e.g. chain replication.</span><br><span class="line">  Smooth handling of dead or slow or partitioned storage servers</span><br><span class="line">    No need to wait, no need to detect failure, no timeout</span><br><span class="line">    Important for Amazon for remote AZs and temporarily slow servers</span><br><span class="line">    No risk of split brain among the storage servers</span><br><span class="line">  Can adjust R and W to make reads or writes faster (but not both).</span><br><span class="line">  But:</span><br><span class="line">    Servers not in write quorum must catch up (e.g. Aurora&#x27;s gossip).</span><br><span class="line">    Can only tolerate min(N-W, N-R) failures.</span><br><span class="line">    Requirement for version numbers makes it most suitable for single writer.</span><br></pre></td></tr></table></figure><p>同时，数据按照 segment 进行 sharding:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">What if the database is too big for a replica to fit into one storage server?</span><br><span class="line">  Data pages are sharded into 10-GB Protection Groups (PGs).</span><br><span class="line">  Each PG is separately replicated as six &quot;segments&quot; (on six replicas).</span><br><span class="line">    Different PGs likely to be on different sets of six storage servers.</span><br><span class="line">  [DB server, two PGs on 12 storage servers]</span><br></pre></td></tr></table></figure><h2 id="The-log-is-the-database"><a href="#The-log-is-the-database" class="headerlink" title="The log is the database"></a>The log is the database</h2><p><img src="https://image.mwish.me/blog-image/image.png" alt="image"></p><p>Aurora 只会同步 Redo Log，而不要像之前的 MySQL 那样同步很多别的 write 操作。Redo log 描述要进行的操作。日志和存储层下沉到了存储节点。你可能会记得下面的：</p><p><img src="https://image.mwish.me/blog-image/9DE4AA15-CD61-4C5E-852B-22B34EC48A82.png" alt="9DE4AA15-CD61-4C5E-852B-22B34EC48A82"></p><p>这要求系统大概要满足 no-steal/no-force 的特性：未完成事务的页不能刷到盘上. 我们会在 Log 部分再次讨论这一段。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Storage servers understand how to apply DB&#x27;s log to data pages</span><br><span class="line">  So only need to send (small) log entries, not (big) dirty pages</span><br><span class="line">  Sending to many replicas, but not much data</span><br></pre></td></tr></table></figure><p><img src="https://image.mwish.me/blog-image/509272B2-DDAB-49AB-9DE3-4B2131B96997.png" alt="509272B2-DDAB-49AB-9DE3-4B2131B96997"></p><p>通过上述的策略和异步的 apply, Aurora 减少了写入的延时：log 写入放入 Update Queue 即可，大大降低了 Latency.</p><h2 id="日志和-SQL"><a href="#日志和-SQL" class="headerlink" title="日志和 SQL"></a>日志和 SQL</h2><p>Log 需要对应的 LSN。对日志处理的层在 Storage Layer 上，所以它们知道日志的语义，能够 apply 这些日志。</p><p>以上的写入流程是过于简单的，然而读总要读到像样的东西吧！既然和 MySQL 来 PK，总要有事务的语义吧！</p><p>数据库要确认下列信息：</p><ul><li>VCL（Volume Complete LSN）：保证之前都被持久化的 LSN</li><li>CPL（Consistency Point LSN）：对于事务的语义的 CP</li><li>VDL（Volume Durable LSN）: 副本最大的 CPL</li></ul><blockquote><p>CPL必须小于或者等VCL，所有大于VDL的日志记录都可以被截断丢掉</p></blockquote><p>那么，甚至 VDL 之前的一些都要在语义上视作没 Commit. 写入北推进的时候，VCL CPL VDL 被推进，来实现事务的语义。</p><p>6.824 对 Log Write 有个比较精炼的描述：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">What does an Aurora quorum write look like?</span><br><span class="line">  Not a classic quorum write:</span><br><span class="line">    DB server&#x27;s writes to storage servers do *not* modify existing data items!</span><br><span class="line">  A write consists of a new log entry.</span><br><span class="line">    For an in-progress transaction.</span><br><span class="line">    Or a commit log record.</span><br><span class="line">  Aurora sends each log record to all six storage servers.</span><br><span class="line">  Transaction commit waits for all of xaction&#x27;s log records to be on a quorum.</span><br><span class="line">    Stated as VDL &gt;= transaction&#x27;s last record.</span><br><span class="line">    So every xaction through this one can be recovered after a crash.</span><br><span class="line">  Commit ==&gt; release locks, reply to client.</span><br></pre></td></tr></table></figure><p>在写入的时候，你要写 Quorum, 然后 <code>VDL &gt; 日志的 CPL</code> 时, 提交就是安全的，你可以 Commit 了。</p><p>读取的时候流程如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">What does an ordinary Aurora read look like?</span><br><span class="line">  Not a quorum read!</span><br><span class="line">  The Aurora DB server needs a data page, due to a cache miss.</span><br><span class="line">    Writes are log entries; reads yield data pages.</span><br><span class="line">  Needs to find a storage server that has all the relevant log entries.</span><br><span class="line">  Database server tracks each storage server&#x27;s SCL (Segment Complete LSN).</span><br><span class="line">    Each storage server has all log entries &lt;= its SCL.</span><br><span class="line">    Reports back to the database server.</span><br><span class="line">  DB server reads from any storage server whose SCL &gt;= highest committed LSN.</span><br><span class="line">    That storage server may need to apply some log records to the data page.</span><br></pre></td></tr></table></figure><p>数据库建立一个读时间点，表示这个时候读到什么数据是安全的，然后在对应 Segment 下读.</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>notes: Skiplist-based lsm-tree</title>
      <link href="/2020/08/12/notes-Skiplist-based-lsm-tree/"/>
      <url>/2020/08/12/notes-Skiplist-based-lsm-tree/</url>
      
        <content type="html"><![CDATA[<h1 id="The-Skiplist-Based-LSM-Tree"><a href="#The-Skiplist-Based-LSM-Tree" class="headerlink" title="The Skiplist-Based LSM Tree"></a>The Skiplist-Based LSM Tree</h1><p>读这篇论文是因为原始 SkipList 那个 Btree 读的脑阔疼，我又不是很了解 Btree。这篇文章又和使用最广的 RocksDB/LevelDB 比较接近。</p><p>LSM Tree 提供了层级的数据来提供写优化的数据系统。原始的论文中，作者在每个层次中使用的都是类似 B-Tree 的结构，在 sLSM 中，Buffer 结构都是一系列的 Skiplist.</p><p>LSMTree Paper 有一套冷热数据计算的式子。把新插入的 hot 数据放在内存中，冷的下层数据放在 secondary storage 中，来让写被均摊。同时，原论文介绍了 two-component （即可视作只有内存和 disk）的 LSM 之后，也介绍了 multi-component 的 LSM Tree, 通过多层次来均摊 Compaction 的开销。这个在这有一些简洁的答案：</p><p><a href="https://www.zhihu.com/question/396452321">https://www.zhihu.com/question/396452321</a></p><p>同时，LSM Tree 可以用 Bloom Filter（这个用的应该很多）、fence pointer（我记得是 FD-Tree 里的？）</p><blockquote><p>The remainder of this paper will proceed as follows: Section 2 will detail the design of the Skiplist-Based LSM (sLSM), including the in-memory component, the on-disk component, indexing structures, key algorithms, theoretical guarantees, and the range of design knobs; Section 3 will provide extensive experimental results, including parameter tuning and performance analysis; and Section 4 will discuss and conclude.</p></blockquote><p>阅读这篇文章也是因为，这个 LSMTree 相对来说和 LevelDB/RocksDB 有一定相似之处。</p><h2 id="SLSM-设计"><a href="#SLSM-设计" class="headerlink" title="SLSM 设计"></a>SLSM 设计</h2><ul><li>内存中有 R 个 SkipList, 只有一个是 active 的。</li><li>如果 Insert 出现，现有的 SkipList 达到了大小的上限（好奇这个上限是怎么设置的）后，会尝试把现在的 SkipList 变成只读的，然后尝试在新的 SkipList 写。如果内存满了：<ul><li>按比例把 m 个现有的 SkipList 与 Secondary Storage 进行 merge</li></ul></li></ul><p>读取的话会按照 SkipList 的新旧读，再访问磁盘。</p><h4 id="SkipList"><a href="#SkipList" class="headerlink" title="SkipList"></a>SkipList</h4><p>这篇文章介绍了 SkipList 的两个优化：</p><ol><li>Fast Random Levels：利用 random bits 生成 random Level</li><li>Vertical Arrays, Horizontal Pointers</li></ol><blockquote><p>While the differential densities of the levels precludes an array-based structure in the horizontal direction, it is wasteful to include links from nodes of value k to another node of value k on the next level. Instead, in our implementation a skiplist node includes one key, one value, and an array of pointers to other skiplist nodes. This array can be thought of as a vertical column of level pointers, where pointers above the node’s level are null and each pointer below points to the next node on that particular level. In this way, skipping down a level is a matter of reading a value that was already loaded into the cache, rather than chasing a pointer somewhere random in memory. Because we implemented the skiplist in this way from the beginning we do not report differential performance between this cache-conscious and the alternative, naive way.</p></blockquote><p>其实感觉说的比较像 LevelDB 的了：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">SkipList</span>&lt;Key, Comparator&gt;::Node &#123;</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">Node</span><span class="params">(<span class="type">const</span> Key&amp; k)</span> : key(k) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  Key <span class="type">const</span> key;</span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// Array of length equal to the node height.  next_[0] is lowest level link.</span></span><br><span class="line">  std::atomic&lt;Node*&gt; next_[<span class="number">1</span>];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="Disk-Based-Storage"><a href="#Disk-Based-Storage" class="headerlink" title="Disk-Based Storage"></a>Disk-Based Storage</h3><blockquote><p>“is only touched by merges from the memory buffer”</p><p>There are L disk levels, each with D runs on each level. A run is an immutable sequence of sorted key-value pairs, and is captured within one memory-mapped file on disk. </p><p>Each disk run is indexed similarly to the in-memory run, with max/min keys and Bloom filters. </p></blockquote><p>除此之外之外这里还引入了 fence pointer, FD-Tree 也有 fence pointer, 这是带层次的查找优化：</p><blockquote><p>These are fixed-width indices that store the key of elements in increments of some logical page size in memory. </p></blockquote><p><img src="https://image.mwish.me/blog-image/An-illustration-of-the-implementation-of-the-Fence-Pointers.jpg" alt="An-illustration-of-the-implementation-of-the-Fence-Pointers"></p><h3 id="Merging"><a href="#Merging" class="headerlink" title="Merging"></a>Merging</h3><p>LSMTree 的 Merge 还是很复杂的：</p><ul><li>merge 是把某一层按比例 m 和下层合并，用写来减小读放大</li><li><code>the number of elements at level k is O((mD)^k).</code></li><li>可能会有 cascading 的 merge</li></ul><blockquote><p>We propose a heap-based merging algorithm that runs in O(n log(mD)) time and O(mD) space, where n is the number of elements being merged.</p></blockquote><p><img src="https://image.mwish.me/blog-image/4104B498-0C10-4479-A53E-A1A55A0B0181.png" alt="4104B498-0C10-4479-A53E-A1A55A0B0181"></p><p>具体来说，每个 list 都是 sorted 的，LSMTree 会对它们 heap sort .</p><p>实现的时候，这里采取了多线程的方式：</p><blockquote><p>In our implementation, we also use multithreaded merging to decrease our latency. When an insertion triggers a merge, a dedicated merge thread takes ownership of the runs to merge and executes the merge in parallel, allowing the main thread to rebuild the buffer and continue to answer queries. If a lookup request comes while the merge thread is executing the merge, the main thread searches the memory buffer for the requested key, and if unsuccessful, waits for the merge to complete before querying the disk levels.</p></blockquote><p>下面是 param table 和读的性能分析：</p><p><img src="https://image.mwish.me/blog-image/07BA999F-C722-4C4B-B91F-174E677E4D0C.png" alt="07BA999F-C722-4C4B-B91F-174E677E4D0C"></p><p><img src="https://image.mwish.me/blog-image/3D826C1F-830A-4255-B7D2-F32294459FD4.png" alt="3D826C1F-830A-4255-B7D2-F32294459FD4"></p><h3 id="Range"><a href="#Range" class="headerlink" title="Range"></a>Range</h3><p>Range 是一个比较复杂但是很需要的操作，我们可能会：</p><ul><li>拿到 Snapshot 或者迭代器，然后在这上面 iter</li></ul><p>这种操作和 PointGet 不一样，是需要知道所有的 table 情景然后查询的。</p><p>这里操作是：首先按range和值过滤，然后从新到旧遍历，并构建一个 hashtable 来 O(1) 的去重。</p><blockquote><p>Because collecting elements in the range in both skiplists and disk runs is a linear-time operation, and because hashing is an amortized constant-time operation, a range query over n keys is expected to take O(n) time.</p></blockquote><p>这个 <code>O(n)</code> 是 n keys, 我不太清楚这个放大是什么情况，总觉得不太清楚</p><h2 id="Perf"><a href="#Perf" class="headerlink" title="Perf"></a>Perf</h2><blockquote><p>We tested the sLSM on a DigitalOcean Droplet Server running 64-bit Ubuntu 4.4.0 with 32 Intel Xeon E5-2650L v3 @ 1.80GHz CPUs, a 500 GB SSD, 224GB main memory, and 30MB L3 cache.</p></blockquote><p>(我也想有这么好的机器)</p><p>再次贴一下参数表：</p><p><img src="https://image.mwish.me/blog-image/07BA999F-C722-4C4B-B91F-174E677E4D0C.png" alt="07BA999F-C722-4C4B-B91F-174E677E4D0C"></p><h4 id="R"><a href="#R" class="headerlink" title="R"></a>R</h4><blockquote><p>In determining the optimal R, we found that the smaller R is, the smaller the memory buffer is, and the more frequent merges will be. Thus, lower R leads to lower insertion throughput. However, with few runs to search, lookups are very quick with small R. Analogously, higher R is linked to faster insertion but slower lookup, since more runs need to be searched. With Bloom filters, it is possible to set R high enough to achieve extremely fast insertion while enjoying significant speedup on lookups due to the filters. More formally, R does not enter the amortized insertion time function, and there are significant constant factors hidden in that equation that correspond to the speed and frequency of merges. However, lookups depend linearly upon R, as proven above. The graph in Fig. 2 details the tradeoff between insertion time and lookup time for a number of values of R. As such, setting the number of runs intelligently also allows us to tune the performance of the sLSM to the workload at hand- more runs for more writes, and fewer for more lookups.</p></blockquote><p>发原文总觉得没什么诚意，但是这一段说的比我能介绍的精细多了。</p><p><img src="https://image.mwish.me/blog-image/69D6C0BB-39D4-4E80-B21F-6C9E6A6E1BCA.png" alt="69D6C0BB-39D4-4E80-B21F-6C9E6A6E1BCA"></p><ul><li>R 变大，写入受 Compaction 的影响和 Stall 变小</li><li>读取效率变低，因为要在内存中寻找多个 skiplist</li></ul><p>读取效率变低我真的没太理解，感觉走到 disk 上肯定会更慢，但是 R*Rn 值固定的时候，感觉上面的就可以理解了，而且这两个参数也会影响 flush 的效率。</p><h4 id="Rn"><a href="#Rn" class="headerlink" title="Rn"></a>Rn</h4><blockquote><p>For each value of R, increasing Rn increases insertion rate while decreasing lookup throughput. This is because a larger Rn allows for fewer merges over the lifetime of the workload due to the larger memory buffer. However, this increase in the size of each run increases the runtime of each lookup, since skiplist queries are logarithmic in their size. </p></blockquote><p>这个应该相对更好理解一些。</p><p><img src="https://image.mwish.me/blog-image/B441272A-7A46-4382-9AEB-CAD3BC6CAA53.png" alt="B441272A-7A46-4382-9AEB-CAD3BC6CAA53"></p><p>也可以参考 RocksDB 的 Flushing Options</p><p><a href="https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide#flushing-options">https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide#flushing-options</a></p><h4 id="Disk-and-Merge-Parameters"><a href="#Disk-and-Merge-Parameters" class="headerlink" title="Disk and Merge Parameters"></a>Disk and Merge Parameters</h4><p>也可以参考 <a href="https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide#level-style-compaction">https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide#level-style-compaction</a></p><ol><li>m is set under 0.5, merges would happen too frequently for sizeable datasets, causing the OS to run out of file descriptors</li></ol><p><img src="https://image.mwish.me/blog-image/2FF5FFBA-4142-44FF-B842-570DC70ABA69.png" alt="2FF5FFBA-4142-44FF-B842-570DC70ABA69"></p><p>D 变大时，写入性能是提升的，但是读会被放大。m 变大时，compaction 变得不那么频繁。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>notes on craq</title>
      <link href="/2020/08/06/notes-on-craq/"/>
      <url>/2020/08/06/notes-on-craq/</url>
      
        <content type="html"><![CDATA[<h1 id="Notes-on-CRAQ"><a href="#Notes-on-CRAQ" class="headerlink" title="Notes on CRAQ"></a>Notes on CRAQ</h1><p><img src="https://image.mwish.me/blog-image/51CB14FC-1504-474F-BA8D-74D2CBFCC14D.png" alt="51CB14FC-1504-474F-BA8D-74D2CBFCC14D"></p><p>这篇文章介绍了 CRAQ，链式复制的改进。</p><p>本人主要阅读了 1-3 章，第三章的 scaling 和 5.3 的 membership changes 没有完全理解它的思路，4.1 的 mini-transaction 没有读的很细，以后可能会回头来改。</p><p>也欢迎懂的朋友留言或者给 anmmscs_maple@qq.com 邮件。</p><h3 id="Recall"><a href="#Recall" class="headerlink" title="Recall"></a>Recall</h3><h4 id="GFS"><a href="#GFS" class="headerlink" title="GFS"></a>GFS</h4><p>GFS 分为 Master 和 Chunk Server, Master 有 Chunk 的 metadata，负责文件映射的信息、Chunk信息，也负责管理 lease、回收 Chunk、Chunk 迁移。Master 节点使用心跳信息周期地和每个 Chunk 服务器通讯，发送指令到各个 Chunk 服务器并接收 Chunk 服务器的状态信息。</p><p>ChunkServer 维护自己的逻辑，运行在 Linux File System 上。Chunk 类似系统的 block 这种概念，默认 64MB。它的大小会影响内部碎片和通信效率/空间效率：Chunk 越大，内部碎片肯定越小，但是 metadata 空间效率也会变大，请求次数也会变更。不过这样也不利于存储小文件。</p><p>ChunkServer 会有备份的模型。当写入的时候，我们需要保证多个 replica 写入顺序上是一致的。Master 会给 Chunk 分配 lease，这个 chunk 会给出写入的操作序列，被称为 primary chunk。</p><p><img src="https://image.mwish.me/blog-image/23269A8F-9449-4BA0-869A-66AD962A75E8.png" alt="23269A8F-9449-4BA0-869A-66AD962A75E8"></p><p>GFS 的数据流和控制流是分开的，写入的时候，client 会拿到某个 chunk 的元数据并做缓存，然后想上图3一样：</p><blockquote><p>数据沿着一个 Chunk 服务器链顺序的推送，而不是以其它拓扑形式分散 推送(例如，树型拓扑结构)。线性推送模式下，每台机器所有的出口带宽都用于以最快的速度传输数据，而 不是在多个接受者之间分配带宽。</p><p>为了尽可能的避免出现网络瓶颈和高延迟的链接(eg，inter-switch 最有可能出现类似问题)，每台机器 都尽量的在网络拓扑中选择一台还没有接收到数据的、离自己最近的机器作为目标推送数据。假设客户机把 数据从 Chunk 服务器 S1 推送到 S4。它把数据推送到最近的 Chunk 服务器 S1。S1 把数据推送到 S2，因为 S2 和 S4 中最接近的机器是 S2。同样的，S2 把数据传递给 S3 和 S4 之间更近的机器，依次类推推送下去。我们 的网络拓扑非常简单，通过 IP 地址就可以计算出节点的“距离”。</p></blockquote><p>某种意义上，这也是一种链式复制。</p><h2 id="CRAQ"><a href="#CRAQ" class="headerlink" title="CRAQ"></a>CRAQ</h2><h3 id="为什么要-CRAQ"><a href="#为什么要-CRAQ" class="headerlink" title="为什么要 CRAQ"></a>为什么要 CRAQ</h3><p>这篇论文介绍的就是一种链式复制和优化，论文介绍了 CRAQ 和普通链式复制的区别，以及它是如何在保证性能的情况下提供强一致性和别的loose一点的一致性的的。</p><p>文章还介绍了 geo-replication 相关的实现。</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Influential: CRAQ and many others build on CR.</span><br><span class="line">    Ceph, Parameter Server, COPS, FAWN.</span><br></pre></td></tr></table></figure></blockquote><p>上面这些都用了 chain replication(哇我以前都不知道)，它的大致思路如下：</p><ul><li>A-&gt;B-&gt;C-&gt;D 构成一条链，</li><li>client 在头写，在尾读，A落盘后写 B，B 落盘后写 C，D中落盘即可读</li><li>这种方式比较好 pipeline 化</li><li>节点变多的时候，可能需要 Consistet Hashing 来 sharding。</li></ul><p>上面的缺点是：</p><ul><li>读在尾部，很容易成为潜在的瓶颈</li><li>单个节点 failure 可能会影响系统</li><li>Consistet Hashing 仍然有潜在的热点问题（这个我没研究过），读请求会全部落在热点的尾部。</li></ul><p>MIT 6.824 的 course notes 指出了 CR 的优点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Why is CR attractive (vs Raft)?</span><br><span class="line">  Client RPCs split between head and tail, vs Raft&#x27;s leader handles both.</span><br><span class="line">  Head sends each write just once, vs Raft&#x27;s leader sends to all.</span><br><span class="line">  Reads involve just one server, not all as in Raft.</span><br><span class="line">  Situation after failure simpler than in Raft (remember Figure 7).</span><br></pre></td></tr></table></figure><p>而对象存储特点是，不需要所有操作的 total order，需要的是单个对象的order。</p><p>CRAQ 提供：</p><ul><li>CR 一样的强一致性</li><li>CRAQ的设计自然支持读操作之间的最终一致性，以降低写争用期间的延迟读取，以及在临时分区期间降级为只读行为。CRAQ允许应用程序指定读取操作可接受的最大 stale 可能性。（论文里是 <em>Apportioned Queries</em>）</li><li>在读分摊的 load-balance 之外，提供了 geo-replication 的方案，读可以从本地的集群读，同时借助 ZooKeeper 维护 members。</li></ul><h3 id="CR-的一致性讨论"><a href="#CR-的一致性讨论" class="headerlink" title="CR 的一致性讨论"></a>CR 的一致性讨论</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Intuition for linearizability of CR?</span><br><span class="line">  When no failures, almost as if the tail were the only server.</span><br><span class="line">    Head picks an order for writes, replicas apply in that order,</span><br><span class="line">      so they will stay in sync except for recent (uncommitted) writes.</span><br><span class="line">    Tail exposes only committed writes to readers.</span><br><span class="line">  Failure recovery, briefly.</span><br><span class="line">    Good news: every replica knows of every committed write.</span><br><span class="line">    But need to push partial writes down the chain.</span><br><span class="line">    If head fails, successor takes over as head, no commited writes lost.</span><br><span class="line">    If tail fails, predecessor takes over as tail, no writes lost.</span><br><span class="line">    If intermediate fails, drop from chain, predecessor may need to</span><br><span class="line">      re-send recent writes.</span><br></pre></td></tr></table></figure><ul><li>没有 failure 的时候，显然是 Linearizable 的，毕竟是单点 apply</li><li>failure 的时候，因为 apply 的顺序是一致的，所以没关系。</li></ul><p>（不过我感觉这论文主要重点还是单对象的一致）</p><h3 id="CRAQ-1"><a href="#CRAQ-1" class="headerlink" title="CRAQ"></a>CRAQ</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">The CRAQ paper admits there is at least one other way to skin this cat:</span><br><span class="line">  Split objects over many chains, each server participates in multiple chains.</span><br><span class="line">  C1: S1 S2 S3</span><br><span class="line">  C2: S2 S3 S1</span><br><span class="line">  C3: S3 S1 S2</span><br><span class="line">This works if load is more or less evenly divided among chains.</span><br></pre></td></tr></table></figure><p>在 CRAQ 中：</p><ul><li>每个 node 可以存储多个版本的对象，版本可以是 <em>clean</em> 或者 <em>dirty</em> 的。</li><li>当 node 接收到写入的时候：<ul><li>如果是 tail, 那么接受写入，并 ACK 通知之前的节点，写入成功</li><li>否则把 <code>(key, value)</code> 添加到版本链中，标记为 dirty.</li></ul></li><li>当非 tail 的节点收到 ACK 的时候，把对应版本 dirty 标记为 clean，然后删除之前的版本</li></ul><p>那么，当一个节点收到读请求的时候，如果不要求一致性，可以返回最新的版本，否则：</p><ul><li>如果查询的对象是 clean 的，返回（意味着写入 tail 完成，前面即使有些这个 key, 也是 dirty 的）</li><li>否则，向 tail 进行一个 version query</li></ul><p><img src="https://image.mwish.me/blog-image/F50E8A60-D378-4A03-84C6-A5954F0E1EB1.png" alt="F50E8A60-D378-4A03-84C6-A5954F0E1EB1"></p><p>论文认为，在两种情况下，性能是有提升的</p><ul><li>Read-mostly workloads: 读多的情况下，读会被均摊</li><li>Write-heavily workloads: 对 tail 查询版本比全部落在 tail 轻量，这意味着读请求依然是均摊的。</li></ul><p>这样的情况下，认为任然是 Linearizable 的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Intuition for why same as CR (i.e. linearizable) (assuming no failure):</span><br><span class="line">  If replica has only clean, it MUST match tail, since no write has passed it.</span><br><span class="line">  If replica has dirty, it asks tail, in which case it matches tail as well.</span><br></pre></td></tr></table></figure><p>不过，在以上的情况之外， CRAQ 仍然提供别的一致性：</p><ul><li>Eventual Consistency：允许读最新的 seesion 版本，同时，如果读不垮节点，那么系统有单调读一致性</li><li>Eventual Consistency with Maximum-Bounded Inconsistency: 允许返回</li></ul><h3 id="recovery-amp-membership-changes"><a href="#recovery-amp-membership-changes" class="headerlink" title="recovery &amp; membership changes"></a>recovery &amp; membership changes</h3><p>主要在论文第五节</p><blockquote><p>When a head fails, its immediate successor takes over as the new chain head; likewise, the tail’s predecessor takes over when the tail fails. Nodes joining or failing from within the middle of the chain must insert themselves between two nodes, much like a doubly-linked list. The proofs of correct- ness for dealing with system failures are similar to CR; we avoid them here due to space limitations. Section §5 describes the details of failure recovery in CRAQ, as well as the integration of our coordination service. In particular, CRAQ’s choice of allowing a node to join anywhere in a chain (as opposed only to at its tail [47]), as well as properly handling failures during recovery, requires some careful consideration.</p></blockquote><p>然后系统有：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Equivalently, why can&#x27;t 2nd node take over as head if it can&#x27;t reach the head?</span><br><span class="line">  Partition -- split brain -- the 2nd node must wait patiently.</span><br></pre></td></tr></table></figure><h3 id="Scale"><a href="#Scale" class="headerlink" title="Scale"></a>Scale</h3><blockquote><ul><li>Most or all writes to an object might originate in a single datacenter.</li><li>Some objects may be only relevant to a subset of datacenters.</li><li>Popular objects might need to be heavily replicated while unpopular ones can be scarce.</li></ul></blockquote><p>对象标识符由链标识符和密钥标识符组成。链标识符确定 CRAQ 中的哪些节点将存储该链中的所有 keys，而密钥标识符为每个链提供唯一的命名。论文描述了多种指定应用程序需求的方法：</p><ol><li><code>&#123;num_datacenters, chain_size&#125;</code>  分布在整个数据中心，用 consistency hashing 映射. 固定的数据中心存储固定的 chain。</li><li><code>&#123;chain_size, dc1, dc2, ..., dcN&#125;</code> 每个数据中心使用同样的 chain-size，dc1, dc2 里面 chain 的大小都是 <code>chain_size</code>, 由 consistency hashing 决定 dc 内部的节点。</li><li><code>&#123;*dc*1, *chain*_*size*1, ..., *dc**N*, *chain*_*size**N*&#125;</code> 在每个中心内，chain-size 是提供好的。</li></ol><p>2 3 中，dc1 都可以成为 master 集合，这意味着即使有集群头节点变换，写入也要落到这个数据中心。</p><blockquote><p>Otherwise, if <em>dc</em>1 is disconnected from the rest of the chain, <em>dc</em>2 could become the new head and take over write operations un- til <em>dc</em>1 comes back online. When a master is not defined, writes will only continue in a partition if the partition con- tains a majority of the nodes in the global chain. Otherwise, the partition will become read-only for maximum- bounded inconsistent read operations, as defined in Section 2.4.</p></blockquote><p>在单个数据中心中，sharding 可以靠任意的 consistency hashing, 也可以引入 naming service. 多个数据中心中，读写代价会放大：</p><blockquote><p>Even with an optimized chain, the latency of write operations over wide-area links will increase as more datacenters are added to the chain. Although this in- creased latency could be significant in comparison to a primary/backup approach which disseminates writes in parallel, it allows writes to be pipelined down the chain. This vastly improves write throughput over the primary/backup approach.</p></blockquote><p>同时，如果在多集群中引入 ZooKeeper 这样的协调系统，可以：</p><ul><li>引入某种层次的 zk 的协调</li></ul><blockquote><p>Placing multiple ZooKeeper nodes within a single datacenter improves Zookeeper read scalability within that datacenter, but at the cost of wide-area performance. Since the vanilla implementa- tion has no knowledge of datacenter topology or notion of hierarchy, coordination messages between Zookeeper nodes are transmitted over the wide-area network mul- tiple times. Still, our current implementation ensures that CRAQ nodes always receive notifications from <em>local</em> Zookeeper nodes, and they are further notified only about chains and node lists that are relevant to them. We expand on our coordination through Zookeper in §5.1.</p><p>To remove the redundancy of cross-datacenter ZooKeeper traffic, one could build a hierarchy of Zookeeper instances: Each datacenter could contain its own local ZooKeeper instance (of multiple nodes), as well as having a representative that participates in the global ZooKeeper instance (perhaps selected through leader election among the local instance). Separate functionality could then coordinate the sharing of data between the two. An alternative design would be to modify ZooKeeper itself to make nodes aware of network topology, as CRAQ currently is. We have yet to fully investigate either approach and leave this to future work.</p></blockquote><p>感觉还是很麻烦的。</p><h3 id="4-Extensions"><a href="#4-Extensions" class="headerlink" title="4. Extensions"></a>4. Extensions</h3><h4 id="4-1-Mini-Transactions"><a href="#4-1-Mini-Transactions" class="headerlink" title="4.1 Mini Transactions"></a>4.1 Mini Transactions</h4><p>CRAQ 支持下面的 mini-txn</p><blockquote><ol><li>Prepend/Append: Adds data to the beginning or end of an object’s current value.</li><li>Increment/Decrement: Adds or subtracts to a key’s object, interpreted as an integer value.</li><li>Test-and-Set: Only update a key’s object if its current version number equals the version number spec- ified in the operation.</li></ol></blockquote><p>如果是第一类和第二类，可以直接添加到头/尾然后传播新版本。写入比较多的话可以 batch。</p><p>如果是 test-and-set, 如果本身有 dirty 版本或者未完成的 cache 写就拒绝，否则传播。</p><p>下面来考虑具体的实现(4.1.2)：</p><blockquote><p>A mini-transaction is defined by a compare, read, and write set; Sinfonia exposes a linear address space across many memory nodes. </p></blockquote><p>本质上相当于在前面三类的基础上控制读写集和冲突。</p><p>涉及多个 chain 的事务时候，需要对 chain 之首处理 2PC。</p><h4 id="4-2-Lowering-Write-Latency-with-Multicast"><a href="#4-2-Lowering-Write-Latency-with-Multicast" class="headerlink" title="4.2 Lowering Write Latency with Multicast"></a>4.2 Lowering Write Latency with Multicast</h4><p>Raft 的协议会完成一个 majority 的写。CRAQ 也可以利用 multicast 来 bonus 写性能：</p><blockquote><p>Then, instead of propagating a full write serially down a chain, which adds latency proportional to the chain length, the actual value can be multicast to the entire chain. Then, only a small metadata message needs to be propagated down the chain to ensure that all replicas have received a write before the tail. If a node does not receive the multi- cast for any reason, the node can fetch the object from its predecessor after receiving the write commit message and before further propagating the commit message.</p></blockquote><p>通过广播写入数据，然后从头到尾传播 metadata 而不是全部信息，来保证写入是有效的。</p><p>同时，单个 dc 尾部收到 ACK 或者完成写入的时候，也可以用 multicast 提升性能：</p><blockquote><p>This reduces both the amount of time it takes for a node’s object to re-enter the clean state after a write, as well as the client’s perceived write delay.</p></blockquote><h3 id="5-Management-and-Implementation"><a href="#5-Management-and-Implementation" class="headerlink" title="5 Management and Implementation"></a>5 Management and Implementation</h3><h4 id="5-3-Handling-Memberships-Changes"><a href="#5-3-Handling-Memberships-Changes" class="headerlink" title="5.3 Handling Memberships Changes"></a>5.3 Handling Memberships Changes</h4><p>论文 2.3 提到了一定的要求，即：</p><ul><li>header 出问题了把 header-&gt;next 当新的 header</li><li>tail 出问题了把 tail-prev 当 tail</li><li>在中间加入/删除要通知前后</li></ul><p>以上都是 recover 或者下线的过程，原始的论文似乎不会考虑在任何一个位置 Join，只会在尾部插入。这样的话似乎同步完数据然后就可以加入了。Join 会复杂很多，这篇论文介绍了一种新的方式：back-propagation（注意，不是传播写入完成 ACK），这种方式让任意插入的系统 recover。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Notes on Consistency: Raft &amp; ZooKeeper and Potpourri</title>
      <link href="/2020/07/22/Notes-on-Consistency-Raft-ZooKeeper-and-Potpourri/"/>
      <url>/2020/07/22/Notes-on-Consistency-Raft-ZooKeeper-and-Potpourri/</url>
      
        <content type="html"><![CDATA[<h1 id="Notes-on-Consistency-Raft-amp-ZooKeeper"><a href="#Notes-on-Consistency-Raft-amp-ZooKeeper" class="headerlink" title="Notes on Consistency: Raft &amp; ZooKeeper"></a>Notes on Consistency: Raft &amp; ZooKeeper</h1><p><img src="https://image.mwish.me/blog-image/B95597B6-1F4D-4579-B286-76A6D16A1A25.png" alt="B95597B6-1F4D-4579-B286-76A6D16A1A25"></p><p>Raft 协议按照论文实现的话，是能保证 Linearizable 的，这是最强的一致性模型，在整个系统中，operation 有序并原子的完成，每个操作都像瞬间发生一样，在这个时间点之后看到这个对象都是写入的值，在这个点之前看到的都是前一个值。</p><p>以上只是一个我自己理解的很模糊的说法，实际内容可以参考：</p><ul><li><a href="https://en.wikipedia.org/wiki/Linearizability">https://en.wikipedia.org/wiki/Linearizability</a></li></ul><p>实际上，在了解 Wing&amp;Gong 算法之类的判别法之前，我们可以尝试看看上面的 history4:</p><ul><li>Wx0 在 Rx1 Rx2 之前发生，这意味着如果系统是 Linearizable 的，读取之前就发生了 Wx1 和 Wx2</li><li>C2 Rx1 之后 Rx2, 没有重叠的情况下，2 应该在 1之后被写入</li></ul><p>你可能会在两种地方看到 Linearizable ：</p><ul><li>你在单机的多核处理器中实现了一个 Queue, 需要判断在多核处理器下访问它的语义是否是 Linearizable 的</li><li>你实现了一个 Raft, 要来判断他是否满足 Linearizable</li></ul><p>Linearizable 实现的代价很高，当你实现一个基础的 kv raft 的时候，你得保证：</p><ul><li>Raft 把你写消息广播到了大部分机器上</li><li>在你读取的时候，Raft Leader 仍然是大部分集群的 Leader</li><li>…</li></ul><p>在系统中，我们可能需要 Linearizable 的协调单点，来完成这样的语义。</p><h2 id="Sequential-Consistency"><a href="#Sequential-Consistency" class="headerlink" title="Sequential Consistency"></a>Sequential Consistency</h2><blockquote><p>… the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.</p></blockquote><p>以上是 Sequential Consistency 的定义，它保证了操作是 total order 的，并且在你读到一个值之后，你就再也不会读到它之前的值了。</p><p>但是，有一点需要注意的是，有的时候你并没有“同时”这个保证：Linearizable 系统中，A写入了，B同时一定就能读到（假设没有其他的 Writer）。但是 Sequential Consistency 的系统中，你可以保证 Total Order，但不能保证这一点。</p><p>你如果了解过 memory order 的话，可能会比较熟悉 <code>acquire</code> <code>release</code> <code>acq_rel</code> <code>seq_cst</code>, 在 stackoverflow 有后两个的讨论，或许能帮你更加了解：</p><ul><li><a href="https://stackoverflow.com/questions/12340773/how-do-memory-order-seq-cst-and-memory-order-acq-rel-differ">https://stackoverflow.com/questions/12340773/how-do-memory-order-seq-cst-and-memory-order-acq-rel-differ</a></li></ul><p>ZooKeeper 提供一种类似 Sequential Consistency 的定义，它称为 Linearizable-Write</p><ul><li>写会被有序全局广播</li><li>读会读 local-cache</li><li>通过 watch 来看等待通知</li></ul><p>可以参见我之前翻译的 Paper</p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>Jepsen 根据调用的图提供了验证方式，etcd 等都用 Jepsen 来做一些一致性验证和混沌情况下的一致性验证，可以看看 Jepsen 对应的文档：</p><ul><li><a href="https://jepsen.io/consistency/models/linearizable">https://jepsen.io/consistency/models/linearizable</a></li><li><a href="https://jepsen.io/consistency/models/sequential">https://jepsen.io/consistency/models/sequential</a></li></ul><h2 id="多个变量"><a href="#多个变量" class="headerlink" title="多个变量"></a>多个变量</h2><p>当你要处理多个变量的“一致性” 的时候，你可能需要的是数据库的一致性。</p><p>Generalized Isolation Level Definitions 这篇论文介绍了包括 SI 下它的详细定义，PostgreSQL 的 SSI 也是在这基础上实现的。</p><p>之前做过一个相关的 slide: <a href="https://docs.google.com/presentation/d/1FrW41bGt6iSjxQwbYu0YulYR-SoV2iiqyKpDV4SPxxc/edit?usp=sharing">https://docs.google.com/presentation/d/1FrW41bGt6iSjxQwbYu0YulYR-SoV2iiqyKpDV4SPxxc/edit?usp=sharing</a></p><p>实际上，Jepsen 的 elle 也对这种情况进行了实验：</p><p><a href="https://github.com/jepsen-io/elle">https://github.com/jepsen-io/elle</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>SQL &amp; ORM notes</title>
      <link href="/2020/07/17/SQL-ORM-notes/"/>
      <url>/2020/07/17/SQL-ORM-notes/</url>
      
        <content type="html"><![CDATA[<h1 id="ORM-和-SQL-备忘"><a href="#ORM-和-SQL-备忘" class="headerlink" title="ORM 和 SQL 备忘"></a>ORM 和 SQL 备忘</h1><p>今天被上头派去写 SQL, 发现自己把 SQL 忘光了，把以前做的笔记翻出来看了一遍。</p><p>这篇文章写的很丢人，纯当作备忘了…</p><h1 id="MySQL-amp-SQLAlchemy-查询1"><a href="#MySQL-amp-SQLAlchemy-查询1" class="headerlink" title="MySQL &amp; SQLAlchemy: 查询1"></a>MySQL &amp; SQLAlchemy: 查询1</h1><h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><h2 id="基础查询"><a href="#基础查询" class="headerlink" title="基础查询"></a>基础查询</h2><p>查询可以从mysql查询出一个或<strong>多个</strong>列</p><p>可以多列，甚至用 * 指定多列查询</p><p>用<code>SELECT DISTINCT col FROM table</code> 指定<strong>不同的行</strong></p><p>用limit指定搜索的结果, 可以<code>LIMIT BEGIN, END</code>也可以 <code>LIMIT NUMS</code>。注意从0行开始。</p><p>SQL 形式类似于<code>LIMIT &lt;COUNT&gt; offset</code></p><p><code>SELECT tablename.column</code>SELECT后可以跟着表名</p><h2 id="排序查询"><a href="#排序查询" class="headerlink" title="排序查询"></a>排序查询</h2><p>直接查询返回的是没有排序的结果，建议<code>order_by</code><br>(排序被称为是<strong>子句</strong> clause)</p><p>order_by 可以指定多个列，按顺序排序(like 字符串)。</p><p>如 <code>ORDER BY c1 DESC, c2</code></p><p>指定DESC可以反序查询，完成美妙的操作</p><h2 id="过滤查询"><a href="#过滤查询" class="headerlink" title="过滤查询"></a>过滤查询</h2><p>MYSQL中可以对查询指定条件</p><p>具体可以看看<a href="http://blog.csdn.net/haibo0668/article/details/52539880">这里</a></p><ol><li>WHERE子句<br><code>SELECT ... FROM ... WHERE x = a</code><br>做相等性测试，这里支持的操作很多<br>ORDER_BY 在where之后</li><li><code>BETWEEN a AND b</code>可以做范围检查。必须指定低值到高端值。</li><li>AND OR 支持多个条件的逻辑运算，可以括号联系起来，在where后指定 NOT否定。关于计算持续可以用括号做自己的一些制定</li><li><strong>Like clause</strong> Like 可以指定WILECARD(通配符)。<code>%</code>表示任意匹配(任意长度，任意词)，<code>jet%</code>表示jet开头所有，大小写敏感<code>_</code>匹配任意单个字符。</li><li>SQL 定义了 substring, upper, concat 之类的算子，可以帮用户完成操作。不过在各种 sql 实现里可能不一样/</li><li><strong>REGEX搜索</strong> <code>WHERE COLUMN REGEXP ‘a|b’</code></li><li><code>IS NULL</code>做空值查询。</li><li>IN 操作是做条件匹配，<code>IN (v1, v2, ...)</code> 相当于在里面的都是valid的操作。</li></ol><h1 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> instance <span class="keyword">in</span> session.query(User).order_by(User.<span class="built_in">id</span>):</span><br><span class="line"><span class="meta">... </span>    <span class="built_in">print</span>(instance.name, instance.fullname)</span><br></pre></td></tr></table></figure><p>query()会创建对象，帮助做查询，用order_by表顺序维持，返回一个tuple</p><p>也可以对专门的字段进行查询</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> row <span class="keyword">in</span> session.query(User, User.name).<span class="built_in">all</span>():</span><br><span class="line"><span class="meta">... </span>   <span class="built_in">print</span>(row.User, row.name)</span><br></pre></td></tr></table></figure><p>结果是显然的</p><p>query对象通常返回一个新的query对象，可以用.filter().filter()… 等实现and操作的逻辑</p><p>filter的过滤操作可见此中的<a href="https://github.com/linux-wang/sqlalchemy-docs-CN/blob/master/SQLAlchemyORM/Object-Relational-Tutorial.md">常用过滤操作</a>(有equal unequal like ilike in isnull 等)</p><ul><li><p>用text对象包装SQL</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>stmt = text(<span class="string">&quot;SELECT name, id, fullname, password &quot;</span></span><br><span class="line"><span class="meta">... </span>            <span class="string">&quot;FROM users where name=:name&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>stmt = stmt.columns(User.name, User.<span class="built_in">id</span>, User.fullname, User.password)</span><br><span class="line">SQL&gt;&gt;&gt; session.query(User).from_statement(stmt).params(name=<span class="string">&#x27;ed&#x27;</span>).<span class="built_in">all</span>()</span><br><span class="line">[&lt;User(name=<span class="string">&#x27;ed&#x27;</span>, fullname=<span class="string">&#x27;Ed Jones&#x27;</span>, password=<span class="string">&#x27;f8s7ccs&#x27;</span>)&gt;]</span><br></pre></td></tr></table></figure></li></ul><p>text可写入原生的SQL语句查询</p><h3 id="返回哪些"><a href="#返回哪些" class="headerlink" title="返回哪些"></a>返回哪些</h3><p>有<code>.first()</code> <code>.all()</code>两个常用, 有的 ORM 也定义了 <code>single</code></p><p><code>.one()</code>返回一个，没有会抛出异常，<code>.one_or_none()</code>没有时会返回无</p><h2 id="SQLAlchemy-amp-MySQL备忘：基本操作-CUD-与完整性约束"><a href="#SQLAlchemy-amp-MySQL备忘：基本操作-CUD-与完整性约束" class="headerlink" title="SQLAlchemy&amp;MySQL备忘：基本操作(CUD)与完整性约束"></a>SQLAlchemy&amp;MySQL备忘：基本操作(CUD)与完整性约束</h2><h1 id="创建-Create-、更新-Update-与删除-Delete"><a href="#创建-Create-、更新-Update-与删除-Delete" class="headerlink" title="创建(Create)、更新(Update)与删除(Delete)"></a>创建(Create)、更新(Update)与删除(Delete)</h1><p>Create, read, update and delete 简称CRUD，表示我们常做的操作。</p><p>下面来讲插入，这里就不介绍目的了…大家都能理解的，对吧…</p><h2 id="经常要做的插入操作"><a href="#经常要做的插入操作" class="headerlink" title="经常要做的插入操作"></a>经常要做的插入操作</h2><ol><li>插入完整的行</li><li>插入行的一部分(???)</li><li>插入多行</li><li>插入查询的结果</li></ol><h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO tables VALUES(...)</span><br></pre></td></tr></table></figure><p>INSERT 语句一般不会产生输出，对每个列提供一个值。</p><p><code>INSERT INTO table(c1, c2, ..., cn) VALUES(c1r, c2r, ..., cnr)</code> 更加的安全</p><p>给出列名的可改变文本中列的顺序</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INTO table(...) VALURS (), ()</span><br></pre></td></tr></table></figure><p>VALUES 后可跟多个tuple</p><h2 id="插入查找的结果"><a href="#插入查找的结果" class="headerlink" title="插入查找的结果"></a>插入查找的结果</h2><p><code>INSERT INTO table ... SELECT cols FROM ...</code></p><p>可以让你插入查找的结果。</p><h1 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h1><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><ol><li>表名</li><li>更新操作</li><li>过滤条件</li></ol><h2 id="操作-1"><a href="#操作-1" class="headerlink" title="操作"></a>操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">UPDATE table </span><br><span class="line">SET c1 = , c2 = ,...</span><br><span class="line">WHERE conds</span><br></pre></td></tr></table></figure><p>注意更新如果失败，前面所有操作CANCEL, 若希望继续执行，则用<code>UPDATE IGNORE</code></p><h1 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h1><h2 id="操作-2"><a href="#操作-2" class="headerlink" title="操作"></a>操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE table WHERE conds</span><br></pre></td></tr></table></figure><p>想删除所有数据用<code>TRUNCATE TABLE</code></p><h1 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h1><h2 id="结构-1"><a href="#结构-1" class="headerlink" title="结构"></a>结构</h2><p>注意狗屎编码问题，UTF-8天下第一</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE tablename (</span><br><span class="line">    (colname type constraint,)*</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="约束"><a href="#约束" class="headerlink" title="约束"></a><a href="https://segmentfault.com/a/1190000006671061">约束</a></h2><p>约束可能要满足参照完整性(referential integrity) 或者 单个关系的完整性约束。</p><p>约束的<a href="https://www.ibm.com/support/knowledgecenter/zh/SSEPGG_9.5.0/com.ibm.db2.luw.admin.dbobj.doc/doc/c0020114.html">类型</a></p><p><strong>注意：约束可以是联合的</strong>，在 SQLAlchemy 中设置联合可以参照<a href="http://www.pythondoc.com/flask-sqlalchemy/models.html">这里</a>: 比如设置多个primary_key = True即可。</p><h3 id="NOT-NULL"><a href="#NOT-NULL" class="headerlink" title="NOT NULL"></a><code>NOT NULL</code></h3><p>需要指定</p><h3 id="AUTOINCREMENT"><a href="#AUTOINCREMENT" class="headerlink" title="AUTOINCREMENT"></a><code>AUTOINCREMENT</code></h3><p>自增</p><h3 id="DEFAULT"><a href="#DEFAULT" class="headerlink" title="DEFAULT"></a><code>DEFAULT</code></h3><p>制定默认值</p><h3 id="PRIMARY-KEY"><a href="#PRIMARY-KEY" class="headerlink" title="PRIMARY KEY"></a><code>PRIMARY KEY</code></h3><p>主键</p><p>有可能出现联合主键这样的情况,格式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE student(       </span><br><span class="line">          name VARCHAR(20),</span><br><span class="line">          class VARCHAR(20),</span><br><span class="line">         CONSTRAINT PK_STUD_ID PRIMARY KEY(name,class)       </span><br><span class="line">          )</span><br></pre></td></tr></table></figure><h3 id="UNIQUE"><a href="#UNIQUE" class="headerlink" title="UNIQUE"></a><code>UNIQUE</code></h3><p>UNIQUE KEY</p><h3 id="CHECK"><a href="#CHECK" class="headerlink" title="CHECK"></a><code>CHECK</code></h3><p>检查</p><p>MySQL没有这玩意。应用于关系声明时<code>check(P)</code>指定谓词P，每个被插入的数据都要满足P</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE table (</span><br><span class="line">attr1 type ...,</span><br><span class="line">...,</span><br><span class="line">check (attr1 in (&#x27;老司机&#x27;, &#x27;马老爷&#x27;, &#x27;付垃圾&#x27;, &#x27;天阳哥&#x27;))</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>check允许对子集加以限制。</p><h3 id="FOREIGN-KEY-外键约束"><a href="#FOREIGN-KEY-外键约束" class="headerlink" title="FOREIGN KEY 外键约束"></a><code>FOREIGN KEY</code> 外键约束</h3><p>我们在从表中可以设置对父表的外键</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CONSTRAINT fk_class_id FOREIGN KEY(classe_id) REFERENCES classes(id)</span><br></pre></td></tr></table></figure><p>没有References，默认是PRIMARY KEY</p><h4 id="CASCADE-级联"><a href="#CASCADE-级联" class="headerlink" title="CASCADE(级联)"></a>CASCADE(级联)</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FOREIGN KEY(student) REFERENCE dorm403</span><br><span class="line">on delete cascade</span><br><span class="line">on update cascade,</span><br></pre></td></tr></table></figure><p>也可以选择<code>set null</code>, <code>set default</code>。cascade 在从表中设置，表示当你更新或删除主键表时，那么外键表也会跟随一起更新或删除。student对应属性的删除、更新会传播到整个链中。</p><h2 id="更新表"><a href="#更新表" class="headerlink" title="更新表"></a>更新表</h2><p>希望在表的层面增加操作(针对列)</p><p><code>ALTER TABLE table OPERATIONS</code>是需要用到的语法</p><p>一般使用<code>ADD</code>, <code>DROP</code>操作并写上列。</p><p><code>DROP TABLE</code>删除整个表，不仅仅是删除其内容。</p><h3 id="表约束的修改"><a href="#表约束的修改" class="headerlink" title="表约束的修改"></a>表约束的修改</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//删除主键约束  </span><br><span class="line">ALTER TABLE 表名 DROP PRIMARY KEY;    </span><br><span class="line">//添加主键  </span><br><span class="line">ALTER TABLE 表名 ADD PRIMARY KEY(列名);    </span><br><span class="line">//修改列为主键</span><br><span class="line">ALTER TABLE 表名 MODIFY 列名 数据类型 PRIMARY KEY;</span><br></pre></td></tr></table></figure><h2 id="删除-1"><a href="#删除-1" class="headerlink" title="删除"></a>删除</h2><p><a href="https://www.quora.com/What-is-the-main-difference-between-Truncate-Delete-and-Drop-in-a-database">https://www.quora.com/What-is-the-main-difference-between-Truncate-Delete-and-Drop-in-a-database</a></p><p><a href="http://blog.csdn.net/hanxuemin12345/article/details/7818662">http://blog.csdn.net/hanxuemin12345/article/details/7818662</a></p><p>DELETE TRUNCATE DROP等操作</p><h2 id="SQLAlchemy-MySQL-备忘-计算字段和分组查询"><a href="#SQLAlchemy-MySQL-备忘-计算字段和分组查询" class="headerlink" title="SQLAlchemy-MySQL-备忘-计算字段和分组查询"></a>SQLAlchemy-MySQL-备忘-计算字段和分组查询</h2><h1 id="MYSQL和理论部分"><a href="#MYSQL和理论部分" class="headerlink" title="MYSQL和理论部分"></a>MYSQL和理论部分</h1><h2 id="计算字段"><a href="#计算字段" class="headerlink" title="计算字段"></a>计算字段</h2><p>(这里根据我的理解更像对搜索出的数据函数调用)<br>不同于直接存储的数据</p><p>计算字段搜索的结果是按你在计算字段编写的逻辑显示的，比如说你编写的指定是<code>MAN(money)</code>, 显示出来就是<code>FXW(-100)</code>.</p><p>Concat可以在形式上合并多个字段，进行操作<br><code>SELECT Concat(col1, &#39;(&#39;, cow2, &#39;)&#39;) FROM table ORDER BY ...</code><br>输出的形式是col1(col2)，同时也可以对选定的算术运算。</p><p>实际上说是函数，但是 + - * 都是可以直接写的，函数更多指的是文本处理等方面。</p><p>可以使用文本处理函数，比如DATE等(实际上需要日期使用Date，Time指的实际上比Date更细一层)</p><p>也有time对象，但是推荐使用日期是必定用Date</p><h2 id="汇总数据与aggregate-function"><a href="#汇总数据与aggregate-function" class="headerlink" title="汇总数据与aggregate function"></a>汇总数据与aggregate function</h2><p>有的时候不需要完整数据 只需要单行单列的信息，这个时候可以用汇总数据获得</p><h3 id="聚集函数"><a href="#聚集函数" class="headerlink" title="聚集函数"></a>聚集函数</h3><p>运行在行组上，返回单个值，我们希望能够</p><ol><li>获得表中的行数</li><li>获得表中行组(按你定义的规则分组)</li><li>获得表中一列的统计量</li></ol><p>有AVG，SUM，COUNT等函数。对<strong>一列</strong>操作，也可以对多列的计算字段操作。</p><p>注意这些东西一般都会忽略值为null的行</p><p>需注意COUNT：</p><ol><li>COUNT(<em>) 返回行数<br>`SELECT COUNT(</em>) AS cow1 FROM table`<br>输出table表行数</li><li>上面改成<code>COUNT(cow)</code>改成一列的和，<strong>忽略null</strong></li></ol><p>DISTINCT指定：上述操作是对ALL的指定，也就是对所有非null字段计算</p><p><strong>在aggregete中指定DISTINCT对不等值汇总</strong>，相当于一个数据子走一趟=&gt;<code>SELECT COUNT(DISTINCT id) from ...</code>这个distinct可能不同。</p><p>SUM 可以对多个值计算，指定适当的指定的结果。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT COUNT(*) AS all, MIN(prod) as min FROM ...</span><br></pre></td></tr></table></figure><p>允许对多个行列进行操作。</p><h1 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h1><p>希望把大量的，所有的数据分成几个逻辑组，对每个组计算。</p><h2 id="分组操作"><a href="#分组操作" class="headerlink" title="分组操作"></a>分组操作</h2><p>计算字段很有用，更多在于和分组结合以后。对每个小组进行计算</p><p>多个字段的存储很多有相同的vent_id, 统计每个vent_id的数目</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT vent_id, COUNT(*) from table GROUP BY vent_id</span><br></pre></td></tr></table></figure><p>这个操作针对 vent_id 来分组，得到vent_id对应的数目。</p><p>关于GROUP BY的坑</p><ol><li>可以包含任意数目的 Row，能让分组更加的细致</li><li>所有列一起计算。</li><li>使用的都是列或者有效的表达式，在<code>SELECT</code>选定表达式<code>(c1 * c2)</code> 在 <code>GROUP BY</code>一样使用同样的expr.</li><li>NULL 值被当成一个单独的分组返回</li><li>必须在where , order by 之间</li></ol><h3 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h3><p>对于这样的分组，我们有的时候需要过滤，此时用<code>HAVING</code> 子句，它的用法同<code>WHERE</code>。</p><p>但是<code>WHERE</code>指定的是行，只有<code>HAVING</code>子句相对的指定的是分组，能够让我们对分组进行一定程度的过滤。可以把where当成分组前过滤，事实上where中排除的值不再会出现在分组中。</p><p>(Having对分组过滤，例如上一个例子加上<code>HAVING COUNT(*) &gt;= 2</code>)</p><p>GROUP BY 只负责分组不负责排序，所以尽量使用之后sort把</p><p><strong>HAVING子句经常和SUM等聚集函数结合</strong>，又如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT val1, SUM(val2*val3) AS val23 FROM table ORDER BY val23 HAVING SUM(val2*val3) &gt;= 50</span><br></pre></td></tr></table></figure><h2 id="过滤相关理论-相当重要！！！"><a href="#过滤相关理论-相当重要！！！" class="headerlink" title="过滤相关理论(相当重要！！！)"></a>过滤相关理论(相当重要！！！)</h2><ol><li>先用<code>from</code>计算关系</li><li>出现<code>where</code>子句，filter 1的结果</li><li><code>group by</code> 进行分组，分出新的组们</li><li><code>having</code> 进行过滤</li><li><code>SELECT</code> 追踪查询</li></ol><h1 id="实操-1"><a href="#实操-1" class="headerlink" title="实操"></a>实操</h1><p>.group_by实现分组查询</p><p><code>from sqlalchemy import func</code>在func中有很多有用的包。比如func.count(<em>), 相当于COUNT(</em>)。同理又恨多别的这样的库函数。以下参考SQLAlchemy的文档</p><blockquote><p>Using the Query, we build a statement like this from the inside out. The statement accessor returns a SQL expression representing the statement generated by a particular Query - this is an instance of a select() construct, which are described in SQL Expression Language Tutorial:</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from sqlalchemy.sql import func</span><br><span class="line">&gt;&gt;&gt; stmt = session.query(Address.user_id, func.count(&#x27;*&#x27;).\</span><br><span class="line">...         label(&#x27;address_count&#x27;)).\</span><br><span class="line">...         group_by(Address.user_id).subquery()</span><br></pre></td></tr></table></figure><h1 id="SQLAlchemy-amp-MySQL-备忘-组合查询"><a href="#SQLAlchemy-amp-MySQL-备忘-组合查询" class="headerlink" title="SQLAlchemy &amp; MySQL 备忘: 组合查询"></a>SQLAlchemy &amp; MySQL 备忘: 组合查询</h1><h1 id="组合-Union-查询"><a href="#组合-Union-查询" class="headerlink" title="组合(Union)查询"></a>组合(Union)查询</h1><h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>执行多个查询，并当成单个查询返回</p><p>实际上任何拥有多个<code>WHERE</code>条件的查询都可以当成组合查询</p><h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><p>组合查询可以用关键字UNION，来组合多个查询</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> c1, c2, c3 <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> cond1</span><br><span class="line"><span class="keyword">UNION</span></span><br><span class="line"><span class="keyword">SELECT</span> c1, c2, c3 <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> cond2</span><br></pre></td></tr></table></figure><p>相当于<code>WHERE cond1 OR cond2</code></p><ol><li>UNION 在每两个相邻的 SELECT 中</li><li>每个 SELECT 查询的数据相同</li><li>列的数据类型必须是兼容的</li></ol><h2 id="重复的行"><a href="#重复的行" class="headerlink" title="重复的行"></a>重复的行</h2><p>两个查询的条件都满足却 UNION ，重复的行会被 UNIQUE，但是 如果使用<code>UNION ALL</code>, 则不取消重复的行。</p><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><p>再最后一个SELECT后，链式用 <code>ORDER BY</code>排序</p><h2 id="组合不同表"><a href="#组合不同表" class="headerlink" title="组合不同表"></a>组合不同表</h2><p>实际上我们可以看到，UNION是把搜索的结果做一个交集，同样我们也可使用不同的表，但是需要同样的 schema，例如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Select</span> Col1, Col2, Col3, Col4, Col5 <span class="keyword">from</span> Table1</span><br><span class="line"><span class="keyword">Union</span></span><br><span class="line"><span class="keyword">Select</span> Col1, Col2, Col3, <span class="keyword">Null</span> <span class="keyword">as</span> Col4, <span class="keyword">Null</span> <span class="keyword">as</span> Col5 <span class="keyword">from</span> Table2</span><br></pre></td></tr></table></figure><p>Python:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sqlalchemy.orm <span class="keyword">import</span> aliased</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Part</span>(<span class="title class_ inherited__">Base</span>):</span><br><span class="line">    __tablename__ = <span class="string">&#x27;part&#x27;</span></span><br><span class="line">    part = Column(String, primary_key=<span class="literal">True</span>)</span><br><span class="line">    sub_part = Column(String, primary_key=<span class="literal">True</span>)</span><br><span class="line">    quantity = Column(Integer)</span><br><span class="line"></span><br><span class="line">included_parts = session.query(</span><br><span class="line">                Part.sub_part,</span><br><span class="line">                Part.part,</span><br><span class="line">                Part.quantity).\</span><br><span class="line">                    <span class="built_in">filter</span>(Part.part==<span class="string">&quot;our part&quot;</span>).\</span><br><span class="line">                    cte(name=<span class="string">&quot;included_parts&quot;</span>, recursive=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">incl_alias = aliased(included_parts, name=<span class="string">&quot;pr&quot;</span>)</span><br><span class="line">parts_alias = aliased(Part, name=<span class="string">&quot;p&quot;</span>)</span><br><span class="line">included_parts = included_parts.union_all(</span><br><span class="line">    session.query(</span><br><span class="line">        parts_alias.sub_part,</span><br><span class="line">        parts_alias.part,</span><br><span class="line">        parts_alias.quantity).\</span><br><span class="line">            <span class="built_in">filter</span>(parts_alias.part==incl_alias.c.sub_part)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">q = session.query(</span><br><span class="line">        included_parts.c.sub_part,</span><br><span class="line">        func.<span class="built_in">sum</span>(included_parts.c.quantity).</span><br><span class="line">            label(<span class="string">&#x27;total_quantity&#x27;</span>)</span><br><span class="line">    ).\</span><br><span class="line">    group_by(included_parts.c.sub_part)</span><br></pre></td></tr></table></figure><p>其中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">included_parts = session.query(</span><br><span class="line">                Part.sub_part,</span><br><span class="line">                Part.part,</span><br><span class="line">                Part.quantity).\</span><br><span class="line">                    <span class="built_in">filter</span>(Part.part==<span class="string">&quot;our part&quot;</span>).\</span><br><span class="line">                    cte(name=<span class="string">&quot;included_parts&quot;</span>, recursive=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>和</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">included_parts = included_parts.union_all(</span><br><span class="line">    session.query(</span><br><span class="line">        parts_alias.sub_part,</span><br><span class="line">        parts_alias.part,</span><br><span class="line">        parts_alias.quantity).\</span><br><span class="line">            <span class="built_in">filter</span>(parts_alias.part==incl_alias.c.sub_part)</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>使用了<code>UNION ALL</code></p><blockquote><p>当然，这个我觉得很大程度上和使用<code>WHERE</code> + <code>AND</code>/<code>OR</code> 等是等价的。</p></blockquote><h1 id="SQLAlchemy-amp-MySQL-备忘-关系-relationship-与连接-join"><a href="#SQLAlchemy-amp-MySQL-备忘-关系-relationship-与连接-join" class="headerlink" title="SQLAlchemy &amp; MySQL 备忘: 关系(relationship)与连接(join)"></a>SQLAlchemy &amp; MySQL 备忘: 关系(relationship)与连接(join)</h1><p>设计良好，能够不犯太多事的情况下好好添加的数据库称之为 可伸缩性好(scale well).</p><h1 id="重点"><a href="#重点" class="headerlink" title="重点"></a>重点</h1><ol><li>子表类用foreign key引用父表类, 外键定义了两张表的关系。</li><li><code>students = db.relationship(&#39;Student&#39;, backref=&#39;_class&#39;, lazy=&quot;select&quot;)</code> STUDENTS是子对象的列表。</li></ol><h2 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h2><p><strong>目标：我们希望储存在多个表，相关联的数据能被一个查询找出来。</strong></p><p>显然我们已经知道每个表有唯一标识，被称为主键。</p><p>外键是一个表中的一列，包含了另一个表单的主键，定义了数据库的表间的关系</p><p>联结是一种机制，在一条<code>select</code>语句中处理关联表。它并不在数据库中实际存在，而是一种操作。</p><h2 id="等值联结-equijoin"><a href="#等值联结-equijoin" class="headerlink" title="等值联结(equijoin)"></a>等值联结(equijoin)</h2><p>这里只用到了SELECT FROM WHERE，不过有两张表，并且在where中详细标注了(完全限定列名)。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> col <span class="keyword">from</span> tables <span class="keyword">where</span> table1 x table2 <span class="operator">=</span> ... <span class="keyword">order</span> <span class="keyword">by</span> ...</span><br></pre></td></tr></table></figure><p>可以 成功在两张表中搜索</p><p>没有where的话你会很兴奋的看到笛卡尔积。作为保证我们希望所有子句都含有where.</p><h2 id="内部联结-Inner-Join"><a href="#内部联结-Inner-Join" class="headerlink" title="内部联结(Inner Join)"></a>内部联结(Inner Join)</h2><p>关键字是 <code>INNER JOIN</code> 和 <code>ON</code>。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> cols <span class="keyword">FROM</span> table1 <span class="keyword">INNER</span> <span class="keyword">JOIN</span> table2 <span class="keyword">ON</span> cond</span><br></pre></td></tr></table></figure><p>事实上首选是 <code>Inner Join</code></p><h2 id="多表联结"><a href="#多表联结" class="headerlink" title="多表联结"></a>多表联结</h2><p>选择的表数目没有限制，但是表的数量越多，数据库查找速度下降越快。</p><p>也可以选择select from多个表，然后where处指定条件</p><p>在A字段定义B的relationship完成了A有多个B的关系</p><h2 id="表的别名"><a href="#表的别名" class="headerlink" title="表的别名"></a>表的别名</h2><p><code>FROM table1 as t1, table2 as t2</code> 允许你在查询中使用别名并不反馈到列中。</p><h2 id="自联结"><a href="#自联结" class="headerlink" title="自联结"></a>自联结</h2><p>一个表里有所有科目的所有成绩(不要问我为什么这么设计)，我们想找到高等数学挂科的人，看看他的概率统计是不是也挂了.</p><p>可以利用表别名, 给同一个表多个别名，完成查询操作。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> p1.mathgrade, p2.xxx <span class="keyword">FROM</span> students <span class="keyword">as</span> p1, students <span class="keyword">AS</span> p2 <span class="keyword">WHERE</span> p1.(cond) <span class="keyword">AND</span> p2.(cond)</span><br></pre></td></tr></table></figure><h2 id="自然联结"><a href="#自然联结" class="headerlink" title="自然联结"></a>自然联结</h2><p>目的：至少有一个列(字段)出现在不止一个表中，自然联结让每个列返回一次。事实上我们做的都是自然联结。</p><p>R S中，如果R中的一行r和S中的一行s在$R\cap S$ 中的值相等，则将其连接</p><h2 id="外部联结"><a href="#外部联结" class="headerlink" title="外部联结"></a>外部联结</h2><p>联结把有外键关联的行联结。但是有的时候我们希望统计没关联的行。</p><p>有的时候也希望关联没有关联的行，这里口述不是很能说清，大概相当于左／右联结的时候，如果另一侧没有联结的<code>ON ...</code>数据，则为<code>本侧 | null</code> 的形式。</p><p>可以瞅一眼<a href="http://www.cnblogs.com/youzhangjin/archive/2009/05/22/1486982.html">这里的DEMO</a></p><p>使用 <code>LEFT OUTER JOIN</code> <code>RIGHT OUTER JOIN</code> 表示这种外部联结。</p><h2 id="带聚集函数的联结"><a href="#带聚集函数的联结" class="headerlink" title="带聚集函数的联结"></a>带聚集函数的联结</h2><p>目的：希望对联结后得到的那张表进行分组</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT ..., COUNT(,,,) AS ... FROM table1 INNER JOIN table2 GROUP BY ...;</span><br></pre></td></tr></table></figure><p>WORKFLOW：<br>内联结 – &gt; 分组 – &gt; 筛选出来</p><h1 id="SQLAlchemy"><a href="#SQLAlchemy" class="headerlink" title="SQLAlchemy"></a>SQLAlchemy</h1><p>relationship第一个字段基于类名，可以与backref等合起来构成反向索引</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from sqlalchemy import ForeignKey</span><br><span class="line">&gt;&gt;&gt; from sqlalchemy.orm import relationship</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; class Address(Base):</span><br><span class="line">...     __tablename__ = &#x27;addresses&#x27;</span><br><span class="line">...     id = Column(Integer, primary_key=True)</span><br><span class="line">...     email_address = Column(String, nullable=False)</span><br><span class="line">...     user_id = Column(Integer, ForeignKey(&#x27;users.id&#x27;))</span><br><span class="line">...</span><br><span class="line">...     user = relationship(&quot;User&quot;, back_populates=&quot;addresses&quot;)</span><br><span class="line">...</span><br><span class="line">...     def __repr__(self):</span><br><span class="line">...         return &quot;&lt;Address(email_address=&#x27;%s&#x27;)&gt;&quot; % self.email_address</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; User.addresses = relationship(</span><br><span class="line">...     &quot;Address&quot;, order_by=Address.id, back_populates=&quot;user&quot;)</span><br></pre></td></tr></table></figure><p>ForeignKey约束指col被约束为其他地方应当存在的值。foreignkey参数指定的事table name</p><p>Address.user是多对一关系。以上市制定了back_populates的情况，并且互相标清出了字段的名称，backref只能在子表定义foreign_ky</p><p>在一对多关系中，子表ForeignKey应用父表参考字段。</p><h2 id="一对一关系"><a href="#一对一关系" class="headerlink" title="一对一关系"></a>一对一关系</h2><p><code>child = relationship(&quot;Child&quot;, uselist=False, back_populates=&quot;parent&quot;)</code><br>uselist = false，设置一对一关系</p><p>也可以<br><code>child = relationship(&quot;Child&quot;, backref=backref(&quot;parent&quot;, uselist=False))</code></p><blockquote><p>注意在应用关系的过程中，ORM模型可以通过<code>Father.child</code>表示对应的对象，但是这个对象是靠foreigning key存储在referencing table中的。</p><p>因为以上的愿意，所以有lazy = “xxx” 的属性，来表示这个属性是否是</p></blockquote><h2 id="多对多关系"><a href="#多对多关系" class="headerlink" title="多对多关系"></a>多对多关系</h2><p>比如人-关注-人<br>采用一张中间表</p><h1 id="SQLAlchemy-关系操作"><a href="#SQLAlchemy-关系操作" class="headerlink" title="SQLAlchemy : 关系操作"></a>SQLAlchemy : 关系操作</h1><ul><li>join操作作用在query对象上</li><li>对关系操作，返回是对象</li></ul><h2 id="es"><a href="#es" class="headerlink" title="es"></a>es</h2><p>一对多的多，调用字段(对象的字段/属性)查询会返回列表。</p><h2 id="join操作"><a href="#join操作" class="headerlink" title="join操作"></a>join操作</h2><p>指定了<br>join指定条件，两表连接查询。</p><blockquote><p>对应了SQL中的联结的关系</p></blockquote><p>以下隐式的指定id为相同 key 来进行查询</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>session.query(User).join(Address).\</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">filter</span>(Address.email_address==<span class="string">&#x27;jack@google.com&#x27;</span>).\</span><br><span class="line"><span class="meta">... </span>        <span class="built_in">all</span>()</span><br><span class="line">[&lt;User(name=<span class="string">&#x27;jack&#x27;</span>, fullname=<span class="string">&#x27;Jack Bean&#x27;</span>, password=<span class="string">&#x27;gjffdd&#x27;</span>)&gt;]</span><br></pre></td></tr></table></figure><p>Query.join() knows how to join between User and Address because there’s only one foreign key between them. If there were no foreign keys, or several, Query.join() works better when one of the following forms are used:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">query.join(User.addresses)                       </span><br><span class="line"># specify relationship from left to right</span><br><span class="line">query.join(Address, User.addresses)              # same, with explicit target</span><br><span class="line">query.join(&#x27;addresses&#x27;)                          # same, using a string</span><br></pre></td></tr></table></figure><p>join操作指的是对于两张或者多张表，给定共同的条件并且对于共同的条件来进行查询</p><p>因为查询的是join, 所以查询的顺序是(A对象, B对象)</p><p>在这里通过对query对象操作来产生新的 query对象，可以指定</p><ol><li><p>明确的条件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">query.join(Address, User.id==Address.user_id)   </span><br><span class="line"># explicit condition</span><br></pre></td></tr></table></figure></li><li><p>一个键的关联</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">query.join(User.addresses)</span><br><span class="line"># pecify relationship from left to right</span><br></pre></td></tr></table></figure></li><li><p>被关联的字段-关联字段外键</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">query.join(Address, User.addresses)</span><br></pre></td></tr></table></figure></li><li><p>字段字符串名</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">query.join(&#x27;addresses&#x27;)                          </span><br><span class="line"># same, using a string</span><br></pre></td></tr></table></figure></li><li><p>outerjoin<code>query.outerjoin(User.addresses)</code></p></li></ol><h3 id="多个entity的返回值确定"><a href="#多个entity的返回值确定" class="headerlink" title="多个entity的返回值确定"></a>多个entity的返回值确定</h3><p><code>query = session.query(User, Address).select_from(Address).join(User)</code><br>select_from指定了查询返回值的类型，否则join最左侧的项</p><h2 id="SQLAlchemy-MySQL备忘：子查询"><a href="#SQLAlchemy-MySQL备忘：子查询" class="headerlink" title="SQLAlchemy-MySQL备忘：子查询"></a>SQLAlchemy-MySQL备忘：子查询</h2><p>#SQLAlchemy-MySQL备忘：子查询和集合</p><h2 id="概念-2"><a href="#概念-2" class="headerlink" title="概念"></a>概念</h2><p>任何SQL语句都是查询，虽然一般查询指的是select</p><p>SQL允许创建子查询(subquery)</p><p>子查询指的是相当于查询套查询。一般我们是希望处理多个表中的数据（比方说某g开头的老司机想黑我的号，就调用豆瓣 github 的数据库所有邮箱为 1506118561@qq.com的号。）</p><p>编写时建议向下方这样分成多行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT col FROM table1 WHERE col2 IN (</span><br><span class="line">    SELECT ...</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="使用注意"><a href="#使用注意" class="headerlink" title="使用注意"></a>使用注意</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WHERE v1, v2 IN (SELECT r1, r2 FROM TABLE)</span><br></pre></td></tr></table></figure><p>最常见的子查询是在 WHERE 和 IN 中，在限定的tuple（行）中做查询。</p><p>SELECT返回的是选出行数据的tuple，需要拥有相同的列</p><p>子查询效果不一定比的上联结</p><p>子查询需要<strong>完全比较列名</strong>，因为可能有多义性，比方说一定要执行<code>a.x = b.x</code></p><p>需要对所有成员计算(比方说对条件中的成员用COUNT(*)计算总数目)，可以采用子查询。</p><h2 id="相关子查询"><a href="#相关子查询" class="headerlink" title="相关子查询"></a>相关子查询</h2><p>涉及外部列的子查询。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(SELECT r1 form TABLE_IN WHERE TABLE_IN.name = TABLE_OUT.name)</span><br></pre></td></tr></table></figure><p>需要我们限制有歧义的列名。</p><p>可以在以下的链接查看子查询相关理论。</p><p><a href="http://blog.csdn.net/raptor/article/details/48735159">http://blog.csdn.net/raptor/article/details/48735159</a></p><p>也可以使用一组tuple表示相关的内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">SELECT COUNT(DISTINCT id)</span><br><span class="line">FROM takes</span><br><span class="line">WHERE (attr1, attr2, attr3) in</span><br><span class="line">(</span><br><span class="line">    SELECT attr1, attr2, attr3</span><br><span class="line">    FROM ...</span><br><span class="line">    WHERE</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="集合的比较-some-any-all…"><a href="#集合的比较-some-any-all…" class="headerlink" title="集合的比较: some, any, all…"></a>集合的比较: some, any, all…</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SELECT name </span><br><span class="line">FROM table</span><br><span class="line">WHERE table.attr1 &gt; SOME (</span><br><span class="line">    SELECT attr2...</span><br><span class="line">    FROM ..</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>从table中找出name，然后使其大于之查询的某一个(只要找到一个即可).</p><p>同时，<code>&lt;some</code>, <code>&gt;=some</code> 等比较操作在这里也是受支持的。</p><p>有<code>all</code>等操作，表示每一个</p><h2 id="空关系查找与判断：-exists"><a href="#空关系查找与判断：-exists" class="headerlink" title="空关系查找与判断： exists"></a>空关系查找与判断： exists</h2><ul><li>首先我们得明确一点，之查询的外界的值可以代入子查询内。使用了外层查询相关的叫相关子查询</li></ul><p>找出符合两个条件的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT value1</span><br><span class="line">FROM table as T</span><br><span class="line">WHERE value1 = &quot;&quot; and value2=&quot;&quot;</span><br><span class="line">and EXISTS (</span><br><span class="line">    SELECT * FROM table as S</span><br><span class="line">    where T.name = S.name</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>以上找到v1 = v2, 而且满足内部条件的行</p><p>再给出一个范例：对于学生选修的课程，看看哪些学生选修的课程包含生物系的课程。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT S.ID, S.name</span><br><span class="line">FROM students AS S  // 学生的表</span><br><span class="line">WHERE NOT EXISTS (</span><br><span class="line">    (SELECT ... )</span><br><span class="line">    EXCEPT</span><br><span class="line">    (SELECT ... )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><code>NOT EXISTS (B EXCEPT A)</code> –&gt; 关系A包含关系B，即B - A = 空集, 实际上表示B包含于A。</p><p>这个可以用于一定的复杂的逻辑，以上是包含生物系课程，以下的逻辑表示：此人选课包括了生物系的所有课程</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">SELECT S.ID, S.name</span><br><span class="line">FROM students AS S  // 学生的表</span><br><span class="line">WHERE NOT EXISTS (</span><br><span class="line">    (</span><br><span class="line">        SELECT course_id</span><br><span class="line">        FROM classes JOIN take USING(class_id)</span><br><span class="line">        WHERE </span><br><span class="line">    )</span><br><span class="line">    EXCEPT</span><br><span class="line">    (SELECT ... )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="重复行的存在性测试"><a href="#重复行的存在性测试" class="headerlink" title="重复行的存在性测试"></a>重复行的存在性测试</h2><p>对“是否存在”这个特征进行判断。<br>例子：2009年至少开设两次的课程</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SELECT course_name, course_id </span><br><span class="line">FROM courses</span><br><span class="line">WHERE not unique (</span><br><span class="line">    SELECT C1.course_id</span><br><span class="line">    FROM courses as C1,</span><br><span class="line">        courses as C2</span><br><span class="line">    WHERE C1.course_id = C2.course_id</span><br><span class="line">    AND C1.year = 2009</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="from-子句中的子查询"><a href="#from-子句中的子查询" class="headerlink" title="from 子句中的子查询"></a>from 子句中的子查询</h2><p>把from的内容当成一个子查询返回的表。</p><p>例子：选出工资大于42000的系的成员的平均工资</p><p>–&gt; 总感觉跟分组查询没什么很大的区别…</p><h2 id="with-子句的使用"><a href="#with-子句的使用" class="headerlink" title="with 子句的使用"></a>with 子句的使用</h2><p>功能：定义临时关系，只对这句话有效。和from select子查询是等价的，但是相当于语法糖，能够表现的更加清晰。</p><p>（总觉得有点像视图，视图过会儿讲）</p><h2 id="SQLAlchemy-amp-MySQL备忘：事务和视图的使用"><a href="#SQLAlchemy-amp-MySQL备忘：事务和视图的使用" class="headerlink" title="SQLAlchemy&amp;MySQL备忘：事务和视图的使用"></a>SQLAlchemy&amp;MySQL备忘：事务和视图的使用</h2><h1 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h1><h2 id="概念目的"><a href="#概念目的" class="headerlink" title="概念目的"></a>概念目的</h2><p>视图相当于把一个SQL的查找等过程存储为一张伪表，它并不实际上创建一张表、不存储数据，而是作为<strong>“虚关系”</strong>。同时，底层数据发生变化的时候，视图的结果仍然是符合要求的。</p><p>希望能够重用SQL语句并且一定程度上能够保护数据。</p><p>许多时候用于检索而非更新。</p><h2 id="定义与使用"><a href="#定义与使用" class="headerlink" title="定义与使用"></a>定义与使用</h2><p><code>CREATE VIEW</code> <code>DROP VIEW</code>完成视图的创建删除。</p><p><code>SHOW CREATE VIEW</code>查看：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE VIEW faculty AS</span><br><span class="line">SELECT ID, name, dept_name</span><br><span class="line">FROM instructor;</span><br></pre></td></tr></table></figure><p>AS查询语句，得到这里的view。</p><p>查询到的是视图，可以类似table使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SELECT ID FROM faculty </span><br><span class="line">WHERE cond</span><br></pre></td></tr></table></figure><p>视图这里相当于子查询。</p><p><strong>注意，视图不允许使用recursive.</strong></p><h2 id="materialized-view"><a href="#materialized-view" class="headerlink" title="materialized view"></a>materialized view</h2><p><a href="https://blog.csdn.net/joshua_peng1985/article/details/6213593">物化视图</a></p><p>特定的数据库允许存储视图关系，并且定义的关系改变，这个视图也跟着改变，这样的视图被称为：materialized view。</p><p>同时，一般对视图只能进行查询，但是有限的情况下，允许对视图关系进行修改，不同数据库对这个提供了不同的支持。</p><p>对视图更新一般是不允许的…但是…有的数据库系统制定了允许更新的关旭，一般来说：</p><ul><li>from 自由一个数据库关系</li><li>select 只含关系，没有表达式、聚集、DISTINCT等</li><li>没有出现在select的属性可以空</li><li>无having或group by</li></ul><h2 id="SQLAlchemy-use"><a href="#SQLAlchemy-use" class="headerlink" title="SQLAlchemy use"></a>SQLAlchemy use</h2><blockquote><p><em>out of the box</em>: 开箱即用的，即已经封装好的，缩写为OOTB</p></blockquote><p>关于read-only un-materialized view, 似乎没有直接的支持，可以看看<a href="https://stackoverflow.com/questions/9766940/how-to-create-an-sql-view-with-sqlalchemy">这里</a></p><p>对于materialized views, 可以参考<a href="https://stackoverflow.com/questions/21469184/sqlalchemy-materialized-relationships">这里</a>，和这个用<a href="http://www.jeffwidman.com/blog/847/using-sqlalchemy-to-create-and-manage-postgresql-materialized-views/">PostgreSQL的例子</a>似乎要用到比较多的高级属性？</p><h1 id="数据库事务-transaction"><a href="#数据库事务-transaction" class="headerlink" title="数据库事务(transaction)"></a>数据库事务(transaction)</h1><p>可以设置commit, rollback. 可以设置多个点便于提交/回滚。</p><p>事务有着ACID的特性，请看<a href="https://www.cnblogs.com/fjdingsd/p/5273008.html">老哥博客</a></p><p>这里暂时简单提一下<code>transaction</code>，以后会详细介绍。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Inside C++ Object Model 读书笔记: Part2</title>
      <link href="/2020/07/15/Inside-C-Object-Model-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-Part2/"/>
      <url>/2020/07/15/Inside-C-Object-Model-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-Part2/</url>
      
        <content type="html"><![CDATA[<h2 id="P-review-C-继承和设计"><a href="#P-review-C-继承和设计" class="headerlink" title="(P)review: C++ 继承和设计"></a>(P)review: C++ 继承和设计</h2><h3 id="virtual"><a href="#virtual" class="headerlink" title="virtual"></a>virtual</h3><p>虚函数机制和继承几乎总是一起提的。编译器和链接器会保证：</p><ul><li>对象和(包括虚函数的)函数的正确关联。</li></ul><p>这一点提供了运行期的多态。顺便提一嘴，实际上在 C++ 上运行期多态和编译器多态还是很清晰的，如果你没写过 C++ 直接去写 Rust 的话，可能会对下面的区别感到头晕：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">trait</span> <span class="title class_">Sample</span> &#123;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">call</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">call_sample1</span>(s: <span class="type">Box</span>&lt;<span class="keyword">dyn</span> Sample&gt;) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">call_sample2</span>&lt;T: Sample&gt;(s: T) &#123;&#125;</span><br></pre></td></tr></table></figure><p>我们可以回顾一下上一个笔记写的：</p><p><img src="https://image.mwish.me/blog-image/0FBB20FB-1264-4C0B-AE42-5211962234B8.png" alt="0FBB20FB-1264-4C0B-AE42-5211962234B8"></p><p>你需要/可能 <code>override</code> 掉 <code>virtual</code>, 建议显式这么做。（<code>overload</code> =  <code>override</code> )。同时也记住 <code>final</code> 这个关键字。</p><h3 id="返回类型放松"><a href="#返回类型放松" class="headerlink" title="返回类型放松"></a>返回类型放松</h3><p>C++ 返回是协变的，这意味着：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Expr</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="built_in">Expr</span>();</span><br><span class="line"><span class="built_in">Expr</span>(<span class="type">const</span> Expr&amp;);</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> Expr* <span class="title">clone</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以直接写：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Cond</span>: <span class="keyword">public</span> Expr &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="built_in">Cond</span>();</span><br><span class="line"><span class="built_in">Cond</span>(<span class="type">const</span> Cond&amp;);</span><br><span class="line"><span class="function">Cond* <span class="title">clone</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">Cond</span>(*<span class="keyword">this</span>);&#125;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上这个还是很常见的。</p><p>而一定的逆变性来自于：基类的指针可以承载子类对象。</p><h3 id="virtual-base-class"><a href="#virtual-base-class" class="headerlink" title="virtual base class"></a>virtual base class</h3><p><img src="https://image.mwish.me/blog-image/AB0CEA77-F056-413A-A504-4D6D4BDFB768.png" alt="AB0CEA77-F056-413A-A504-4D6D4BDFB768"></p><p>这是 C++ Reference 中的建议。建议认为，虚基类应该为了“共享对象”而承载成员。</p><p>虚基类的构造语义有下列的补充：</p><ul><li>虚基类构造函数保证只调用一次，由最终对象调用</li><li>虚基类的构造函数会在派生类的构造函数之前呗调用。</li></ul><p>在 C++ 中，基类可以为了下列的目的或者混合的目的：</p><ul><li>接口继承</li><li>实现继承</li></ul><p>书上比较有意思的是写了个 lval_box 的例子，这里用 protect 来继承 implement，用 public 继承接口。</p><p>书上给了个很有趣的例子：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">X</span>: <span class="keyword">public</span> <span class="keyword">virtual</span> Interface, <span class="keyword">protected</span> Implement &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在继承链中把 interface 当成 virtual class 使用。</p><p>同时，关于虚继承有下列一些特点：</p><blockquote><p>所有虚基类子对象都在任何非虚基类子对象之前初始化，故只有最终派生类会在其<a href="https://zh.cppreference.com/w/cpp/language/initializer_list">成员初始化器列表</a>中调用虚基类的构造函数</p></blockquote><h2 id="Data-语义学"><a href="#Data-语义学" class="headerlink" title="Data 语义学"></a>Data 语义学</h2><h3 id="NonStatic-Data-Members"><a href="#NonStatic-Data-Members" class="headerlink" title="NonStatic Data Members"></a>NonStatic Data Members</h3><p>当对一个 nonstatic data member 做 load/store 的时候，编译器的基本操作会是：</p><ul><li>编译时已经知道对应的地址的偏移量</li><li>效率等同于存取 C struct member</li></ul><p>在引入虚拟继承之前，代价都是一致的，在引入虚拟继承后，如果通过 virtual base class 的引用访问它的可访问成员，那么这会在运行时决定具体访问的对象。（问题：在继承/多继承的层次中，基类指针是怎么表示的？怎么样导致这种 bias 的？）</p><p>当然，编译器可能有一定的上下文，来优化掉这种开销。</p><h4 id="继承与-data-member"><a href="#继承与-data-member" class="headerlink" title="继承与 data member"></a>继承与 data member</h4><p>实现的时候，如果没有 virtual base class，一个子类的对象布局类似于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">base class members</span><br><span class="line">---</span><br><span class="line">my members</span><br></pre></td></tr></table></figure><p>一般来说，非 virtual base member 的基类成员，都会在对象的头部出现。</p><p>当 user 不需要运行时多态，即不使用 virtual class 的时候，对象会被”拼接“在一起。不过下面有几个疑问：</p><ul><li>如何处理 padding ？</li><li>如何支持 RTTI？</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// The parts below means 3.1 in the projects.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Concrete</span> &#123;</span><br><span class="line">    <span class="type">int32_t</span> value;</span><br><span class="line">    <span class="type">char</span> f1;</span><br><span class="line">    <span class="type">char</span> f2;</span><br><span class="line">    <span class="type">char</span> f3;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">PartConcrete1</span> &#123;</span><br><span class="line">    <span class="type">int32_t</span> value;</span><br><span class="line">    <span class="type">char</span> f1;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">PartConcrete2</span> &#123;</span><br><span class="line">    PartConcrete1 p1;</span><br><span class="line">    <span class="type">char</span> f2;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">PartConcrete3</span> &#123;</span><br><span class="line">    PartConcrete2 p2;</span><br><span class="line">    <span class="type">char</span> f2;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">DerivedConcrete2</span>: <span class="keyword">public</span> PartConcrete1 &#123;</span><br><span class="line">    <span class="type">char</span> f2;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">DerivedConcrete3</span>: <span class="keyword">public</span> DerivedConcrete2 &#123;</span><br><span class="line">    <span class="type">char</span> f3;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// the code below is testing code:    println(&quot;below is 3.1 data part&quot;);</span></span><br><span class="line">    <span class="built_in">print_t_size</span>&lt;Concrete&gt;();  <span class="comment">// 8</span></span><br><span class="line">    <span class="built_in">print_t_size</span>&lt;PartConcrete1&gt;(); <span class="comment">// 8</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print_t_size</span>&lt;PartConcrete2&gt;(); <span class="comment">// 12</span></span><br><span class="line">    <span class="built_in">print_t_size</span>&lt;PartConcrete3&gt;(); <span class="comment">// 16</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print_t_size</span>&lt;DerivedConcrete2&gt;(); <span class="comment">// 12</span></span><br><span class="line">    <span class="built_in">print_t_size</span>&lt;DerivedConcrete3&gt;(); <span class="comment">// 12</span></span><br></pre></td></tr></table></figure><p>这回可不是 ebo 了！</p><ul><li>组合的时候，clang 实现上还是会保证 padding 的</li><li>继承的时候，可能会优化掉可能的 padding</li></ul><p><img src="https://image.mwish.me/blog-image/ACD1A13D-FEC3-43E5-885C-DDF0E7BAEF06.png" alt="ACD1A13D-FEC3-43E5-885C-DDF0E7BAEF06"></p><p>书上的代码成书的时候实现还是比较类似组合这样的。接下来再对我们上述贴的类型进行一点小实验：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">DerivedConcrete2 d2 &#123;<span class="number">1</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>&#125;;</span><br><span class="line">DerivedConcrete3 d3 &#123; <span class="number">2</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;e&#x27;</span>&#125;;</span><br><span class="line"></span><br><span class="line">PartConcrete1* p1, *p2;</span><br><span class="line">&#123;</span><br><span class="line">    DerivedConcrete3 d_temp = d3;</span><br><span class="line">    p1 = &amp;d_temp, p2 = &amp;d2;</span><br><span class="line">    *p1 = *p2;</span><br><span class="line">    std::cout &lt;&lt; d_temp.f2 &lt;&lt; <span class="string">&#x27; &#x27;</span> &lt;&lt; d_temp.f3 &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// d e</span></span><br><span class="line">&#125;</span><br><span class="line">&#123;</span><br><span class="line">    DerivedConcrete3 d_temp = d3;</span><br><span class="line">    DerivedConcrete2* p21, * <span class="type">const</span> p22 = &amp;d2;</span><br><span class="line">    p21 = &amp;d_temp;</span><br><span class="line">    *p21 = *p22;</span><br><span class="line">    std::cout &lt;&lt; d_temp.f2 &lt;&lt; <span class="string">&#x27; &#x27;</span> &lt;&lt; d_temp.f3 &lt;&lt; <span class="string">&#x27;\n&#x27;</span>; <span class="comment">// b e</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果你没看前面的内容，只是自己写这些代码的话，上面的内容应该是非常符合直觉的，<code>*p21 = *p22</code> 如果改了 <code>d_temp.f3</code> 的话怎么想都是不合适的。但是你知道 <code>DerivedConcrete2</code> 和 <code>DerivedConcrete3</code> 一样大之后，感觉就会奇怪起来。</p><p>实际上，可以在 cppreference 上找到子类型相关的定义：</p><ul><li><a href="https://en.cppreference.com/w/cpp/language/object#Subobjects">https://en.cppreference.com/w/cpp/language/object#Subobjects</a></li><li><a href="https://en.cppreference.com/w/cpp/types/is_trivially_copyable">https://en.cppreference.com/w/cpp/types/is_trivially_copyable</a></li></ul><blockquote><p>In general, for any trivially copyable type <code>T</code> and an object <code>obj1</code> of <code>T</code>, the underlying bytes of <code>obj1</code> can be copied (e.g. by means of std::memcpy or std::memmove) into an array of <code>char</code>, <code>unsigned char</code> or <a href="https://en.cppreference.com/w/cpp/types/byte"><code>std::byte</code></a> or into <code>obj2</code>, a distinct object of <code>T</code>. Neither <code>obj1</code> nor <code>obj2</code> may be a potentially-overlapping subobject.</p></blockquote><p>再加上 non-virtual 的多态后，对象需要添加一个 word 大小的 vptr，并且为这个类生成一个 vtable. 现在很多编译器将其置放在对象的起始部位。在多继承中，上述两种机制被混合起来，对象一个个排列，并且遵照之前说的方式进行。</p><p>但是这种转化有一个疑问就是，转化之后指针赋值应该怎么处理呢：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Base1</span> &#123;</span><br><span class="line">    <span class="comment">// members</span></span><br><span class="line">    <span class="type">int32_t</span> v1;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Base2</span> &#123;</span><br><span class="line">    <span class="comment">// members</span></span><br><span class="line">    <span class="type">int32_t</span> v2;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Derived</span>: <span class="keyword">public</span> Base1, <span class="keyword">public</span> Base2 &#123;</span><br><span class="line">    <span class="type">int32_t</span> v3; </span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    Derived d_object&#123;&#125;;</span><br><span class="line">    Base1* pb1 = &amp;d_object;</span><br><span class="line">    Base2* pb2 = &amp;d_object;</span><br><span class="line">    <span class="built_in">println</span>(pb1); <span class="comment">// 0x7ffee0f0a940</span></span><br><span class="line">    <span class="built_in">println</span>(pb2); <span class="comment">// 0x7ffee0f0a944</span></span><br><span class="line">    <span class="built_in">println</span>(<span class="built_in">reinterpret_cast</span>&lt;<span class="type">void</span>*&gt;(pb1) == <span class="built_in">reinterpret_cast</span>&lt;<span class="type">void</span>*&gt;(pb2)); <span class="comment">// false</span></span><br><span class="line">    <span class="keyword">auto</span> pd1 = <span class="built_in">static_cast</span>&lt;Derived*&gt;(pb1);</span><br><span class="line">    <span class="keyword">auto</span> pd2 = <span class="built_in">static_cast</span>&lt;Derived*&gt;(pb2);</span><br><span class="line">    <span class="built_in">println</span>(pd1); <span class="comment">// 0x7ffee0f0a940</span></span><br><span class="line">    <span class="built_in">println</span>(pd2); <span class="comment">// 0x7ffee9496940</span></span><br><span class="line">    <span class="built_in">println</span>(pd1 == pd2); <span class="comment">// true</span></span><br><span class="line">    <span class="built_in">println</span>(&amp;d_object == pd1); <span class="comment">// true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上，这里做了一个地址的 cast。</p><h3 id="引入虚拟继承"><a href="#引入虚拟继承" class="headerlink" title="引入虚拟继承"></a>引入虚拟继承</h3><p><img src="https://image.mwish.me/blog-image/2119B240-BD4F-4303-A8B9-D41000E16E28.png" alt="2119B240-BD4F-4303-A8B9-D41000E16E28"></p><p>在引入虚拟继承之后，class 会生成一个 <code>vbase</code>，同时动态的决定 vbase 对象的位置。同时，继承自 vbase 的类，会带有一个 vbase 对象的 ptrdiff。这种情况下，多个对象分部的 bias 会被指向同一个具体的布局位置。这种情况下，对象带来了一次 bias 寻址的开销。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://stackoverflow.com/questions/27007797/the-size-of-base-class-object-and-derived-class-object-in-c">https://stackoverflow.com/questions/27007797/the-size-of-base-class-object-and-derived-class-object-in-c</a></li><li><a href="https://www.cprogramming.com/tutorial/size_of_class_object.html#:~:text=sizeof(Derived">https://www.cprogramming.com/tutorial/size_of_class_object.html#:~:text=sizeof(Derived)%20will%20be%2012,won’t%20add%20anything%20more.</a> will be 12,won’t add anything more.)</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Inside C++ Object Model 读书笔记</title>
      <link href="/2020/07/13/Inside-C-Object-Model-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/07/13/Inside-C-Object-Model-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="Inside-the-C-Object-Model-读书笔记"><a href="#Inside-the-C-Object-Model-读书笔记" class="headerlink" title="Inside the C++ Object Model 读书笔记"></a>Inside the C++ Object Model 读书笔记</h1><h2 id="Object-Lessons"><a href="#Object-Lessons" class="headerlink" title="Object Lessons"></a>Object Lessons</h2><p>C++ 被称为 <code>zero cost abstraction</code>, 某种程度上，这代表着：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Point3D</span> &#123;</span><br><span class="line"><span class="type">float</span> x;</span><br><span class="line"><span class="type">float</span> y;</span><br><span class="line"><span class="type">float</span> z;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>和你傻傻的在程序里单独维护 <code>x y z</code>，空间等开销是没有额外增加的。当然 <code>Point3D</code> 是一个很 Plain 的类。实现的时候，可能会有：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Point3D</span> &#123;</span><br><span class="line"><span class="built_in">Point3D</span>(<span class="type">float</span> x, <span class="type">float</span> y, <span class="type">float</span> z): <span class="built_in">x_</span>(x) </span><br><span class="line">...</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line"><span class="type">float</span> x_;</span><br><span class="line"><span class="type">float</span> y_;</span><br><span class="line"><span class="type">float</span> z_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>或者：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Point3D</span>: Point2D &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line"><span class="type">float</span> z_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>甚至带上泛型</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> <span class="type">edge_t</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Point3D</span> &#123;</span><br><span class="line"><span class="type">edge_t</span> x, y, z;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> <span class="type">edge_t</span>, <span class="type">int</span> dim&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Point3D</span> &#123;</span><br><span class="line"><span class="type">edge_t</span>[dim] edges_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下意识我们会觉得，运行时这些类的布局成本都是一样的。实际上，C++ 在 layout（空间）和 load/store （时间等）伤的成本是 <code>virtual</code> 引起的：</p><ul><li>Virtual function: 支持高效的运行期多态</li><li>virtual base class (这个笔者之前用的很少，可能不太了解)：被棱型等方式继承的 base class.</li></ul><h3 id="C-Object-Model"><a href="#C-Object-Model" class="headerlink" title="C++ Object Model"></a>C++ Object Model</h3><p>这本书的内容比较老，无法保证和最新的 clang/gcc/msvc 实现一样，不过它介绍的一些模型还是值得看的，姑且把它这个推导过程 copy 一下。</p><p>第一个介绍的模型是：</p><p><img src="https://image.mwish.me/blog-image/418F4DC7-51DC-4C7F-8F26-A3FA24ABFDE5.png" alt="418F4DC7-51DC-4C7F-8F26-A3FA24ABFDE5"></p><p>这个针对每个函数和成员都生成了对应的 Pointer/ 对应内存位置。所有的指向都是间接的，函数也有对应的指针。</p><p>书上写的第二个对象模型分为了函数的 table 和成员的 table，布局如下：</p><p><img src="https://image.mwish.me/blog-image/4DD61565-8EBE-4F05-A11F-165A71DE0AFF.png" alt="4DD61565-8EBE-4F05-A11F-165A71DE0AFF"></p><p>这本书上最后介绍了当时 C++ 的 object model：</p><ol><li>如图 <code>1.2</code>. 产生指向虚函数的指针，成为 virtual table (vtbl). <code>vtbl</code> 是以类为单位生成的。同时，一个动态的 <code>type_info</code> 也被生成，可以用于动态的 RTTI。</li><li>每个有 <code>virtual</code> 的类的<em>对象</em> 生成指向类的 <code>vtbl</code> 的指针 <code>vptr</code>.</li></ol><p>对于 virtual 继承，本书提供了两种方案：</p><ul><li>子类的对象留出一定的内存位置，指向 base class 的地址</li><li>生成一个 base class table</li></ul><p>下图是逻辑上的模型。</p><p><img src="https://image.mwish.me/blog-image/C4C279FD-5CD9-420C-896E-9B8E64E975A4.png" alt="C4C279FD-5CD9-420C-896E-9B8E64E975A4"></p><p>这样引入了一定的间接性质（有点像 Python MRO 那套？）</p><h3 id="对象模型对程序的影响"><a href="#对象模型对程序的影响" class="headerlink" title="对象模型对程序的影响"></a>对象模型对程序的影响</h3><p>首先，对象模型会影响你需要重新编译、链接的东西，决定编译器会怎么生成对 vtbl 等操作。</p><p>此外，这本书里提到了<code>The Politically Correct Struct</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">BPlusTree</span> &#123;</span><br><span class="line"><span class="comment">// ... 成员信息</span></span><br><span class="line">BTreeIndex index[];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">mumble</span> &#123;</span><br><span class="line">  <span class="type">char</span> index[<span class="number">1</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>C 这样让 <code>Index</code> 和 <code>BPlusTree</code> 一起布局。在 C++ 中，你要注意：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">BPlusTree</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">...</span><br><span class="line">BTreeIndex index[];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">stumble</span> &#123;</span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">    <span class="type">char</span> index[<span class="number">1</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种情况下是否 不同<code>section</code> 中，<code>index</code> 还会出现在结构的尾部。</p><p>同时，你注意到了可能存在的不同布局和 ABI，为了 C/C++ 兼容（这是个很常见的需求），你可能要：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">extern &quot;C&quot; &#123;</span><br><span class="line">// ... 写你封装的东西</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>考此来提供一定的保证（组合/继承？）</p><h3 id="指针的类型"><a href="#指针的类型" class="headerlink" title="指针的类型"></a>指针的类型</h3><p>一些语言中会有 fat pointer 的存在，比如 Rust 的 <code>Box&lt;dyn Trait&gt;</code>, 这让这些指针有更多的信息。</p><p>C++ 只靠指针类型编译时的信息来决定，指针都是一个 <code>word</code> 的大小，具体可以参考这个回答：</p><blockquote><p> Golang和Rust的胖指针与C++的指针指向虚表哪种设计更好? - F001的回答 - 知乎 <a href="https://www.zhihu.com/question/340855881/answer/791076420">https://www.zhihu.com/question/340855881/answer/791076420</a></p></blockquote><p><img src="https://image.mwish.me/blog-image/38D54D51-BC06-4ABA-82A7-AE7A677EC9F3.png" alt="38D54D51-BC06-4ABA-82A7-AE7A677EC9F3"></p><h2 id="The-Semantics-of-Constructors"><a href="#The-Semantics-of-Constructors" class="headerlink" title="The Semantics of Constructors"></a>The Semantics of Constructors</h2><p>我不怎么会写 C++，但是我心目中，C++ 最重要的概念绝对包含 RAII。</p><p><img src="https://image.mwish.me/blog-image/the-rule-of-five.png" alt="the rule of five"></p><p>同时，这里会涉及一些 RVO/NRVO 之类的优化：</p><p><a href="[https://github.com/mapleFU/CppCoreGuidelines-zh-CN/blob/master/CppCoreGuidelines-zh-CN.md#p9-%E4%B8%8D%E8%A6%81%E6%B5%AA%E8%B4%B9%E6%97%B6%E9%97%B4%E6%88%96%E7%A9%BA%E9%97%B4](https://github.com/mapleFU/CppCoreGuidelines-zh-CN/blob/master/CppCoreGuidelines-zh-CN.md#p9-不要浪费时间或空间">一个不保证 NRVO 的例子</a>)</p><h3 id="Default-Constructor"><a href="#Default-Constructor" class="headerlink" title="Default Constructor"></a>Default Constructor</h3><p><a href="https://zh.cppreference.com/w/cpp/language/default_constructor">cppreference</a> 介绍了它生成的条件。</p><p>default constructor 在默认的时候生成. 但它不会做多余的事：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ListNode</span> &#123;</span><br><span class="line">ListNode* prev;</span><br><span class="line"><span class="type">int</span> value;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">ListNode v;</span><br></pre></td></tr></table></figure><p>创建 <code>v</code> 的时候，<code>prev</code> <code>value</code> 不会在 default constructor 被初始化。这点是为了效率。</p><p>这里可以联系上述 cppreference 中的概念：</p><blockquote><p>平凡默认构造函数是不进行任何动作的构造函数。所有与 C 语言兼容的数据类型（POD 类型）都是可平凡默认构造的。</p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ListNode</span> &#123;</span><br><span class="line">ListNode* prev;</span><br><span class="line"><span class="type">int</span> value;</span><br><span class="line"><span class="type">another1_t</span> another1;</span><br><span class="line">  <span class="type">another2_t</span> another2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>假设 <code>another1_t</code> <code>another2_t</code> 有自己的 default constructor, 那么 <code>ListNode</code> 构造的时候会<strong>按顺序</strong>调用这些必要的信息，可能会生成：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ListNode::<span class="built_in">ListNode</span>() &#123;</span><br><span class="line"><span class="type">another1_t</span>::<span class="built_in">another1_t</span>();</span><br><span class="line"><span class="type">another2_t</span>::<span class="built_in">another2_t</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// ... your default code...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>类似上面的<em>顺序</em>。</p><h4 id="带-virtual-function-的-class"><a href="#带-virtual-function-的-class" class="headerlink" title="带 virtual function 的 class"></a>带 virtual function 的 class</h4><p>编译器需要生成一个 <code>vptr</code> ，同时指向这个 class 的 <code>vtbl</code>.</p><h3 id="Copy-Constructor"><a href="#Copy-Constructor" class="headerlink" title="Copy Constructor"></a>Copy Constructor</h3><p>传送门：<a href="https://zh.cppreference.com/w/cpp/language/copy_constructor">https://zh.cppreference.com/w/cpp/language/copy_constructor</a></p><p>小传送门：<a href="https://zh.cppreference.com/w/cpp/language/copy_elision">https://zh.cppreference.com/w/cpp/language/copy_elision</a></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">X</span> &#123;</span><br><span class="line"><span class="built_in">X</span>(std::string name, ...): <span class="built_in">name_</span>(std::<span class="built_in">move</span>(name)) &#123;</span><br><span class="line"><span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">std::string name_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>（不考虑这个愚蠢的类怎么改）显然这里如果传参的话，一定会走 <code>std::string</code> 的拷贝构造函数。</p><p>在最原始的情况下，编译器会考虑 <code>bitwise copy semantics</code>，类似：</p><blockquote><h3 id="平凡复制构造函数"><a href="#平凡复制构造函数" class="headerlink" title="平凡复制构造函数"></a>平凡复制构造函数</h3><p>当下列各项全部为真时，类 <code>T</code> 的复制构造函数为平凡的：</p><ul><li>它不是用户提供的（即它是隐式定义或预置的），且若它被预置，则其签名与隐式定义的相同 (C++14 前)；</li><li><code>T</code> 没有虚成员函数；</li><li><code>T</code> 没有虚基类；</li><li>为 <code>T</code> 的每个直接基类选择的复制构造函数都是平凡的；</li><li>为 <code>T</code> 的每个类类型（或类类型数组）的非静态成员选择的复制构造函数都是平凡的；</li></ul><p>非联合类的平凡复制构造函数，效果为复制实参的每个标量子对象（递归地包含子对象的子对象，以此类推），且不进行其他动作。不过不需要复制填充字节，甚至只要其值相同，每个复制的子对象的对象表示也不必相同。</p><p><a href="https://zh.cppreference.com/w/cpp/named_req/TriviallyCopyable"><em>可平凡复制</em> <em>(TriviallyCopyable)</em> </a>对象，可以通过手动复制其对象表示来进行复制，例如用 <a href="https://zh.cppreference.com/w/cpp/string/byte/memmove">std::memmove</a>。所有与 C 语言兼容的数据类型（POD 类型）均为可平凡复制的。</p></blockquote><p>当然，这不一定是用户需要的。讲一个最简单的例子：浅拷贝。下面这个例子你当然会考虑用 <code>unique_ptr</code> 之类的东西包住，但是就这么做示范的话，结果可能会很奇葩。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">x</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line"><span class="type">resource_t</span>* ptr_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不平凡的时候，调用也是逐个按顺序进行的。</p><h4 id="vptr-与行为"><a href="#vptr-与行为" class="headerlink" title="vptr 与行为"></a>vptr 与行为</h4><p>假设类型有一个虚成员函数，那么它理应拥有一个 <code>vptr</code>, 根据 cppreference, 它不会拥有平凡复制构造函数，因为它要对 <code>vptr</code> 的复制产生合法的结果：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ZooAnimal</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">fn</span><span class="params">()</span> </span>&#123; <span class="comment">// ... &#125;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bear</span>: ZooAnimal &#123;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">fn</span><span class="params">()</span> <span class="keyword">override</span> </span>&#123; <span class="comment">// ...&#125;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Bear b;</span><br><span class="line">ZooAnimal s = b;</span><br></pre></td></tr></table></figure><h3 id="程序语义转换"><a href="#程序语义转换" class="headerlink" title="程序语义转换"></a>程序语义转换</h3><p>(感觉这一节比较像在介绍 RVO/NRVO/Copy Elision)</p><ul><li><a href="https://zh.cppreference.com/w/cpp/language/copy_elision">https://zh.cppreference.com/w/cpp/language/copy_elision</a></li></ul><p>上述地址介绍了所有相关的技术。注意 NRVO 不是强制的，所以 CppCoreGuidelines 有下列链接：</p><p><a href="[https://github.com/mapleFU/CppCoreGuidelines-zh-CN/blob/master/CppCoreGuidelines-zh-CN.md#p9-%E4%B8%8D%E8%A6%81%E6%B5%AA%E8%B4%B9%E6%97%B6%E9%97%B4%E6%88%96%E7%A9%BA%E9%97%B4](https://github.com/mapleFU/CppCoreGuidelines-zh-CN/blob/master/CppCoreGuidelines-zh-CN.md#p9-不要浪费时间或空间">一个不保证 NRVO 的例子</a>)</p><p>你可能防止默认的 move constructor 实现的话，如果 NRVO 不进行，优化的能力会减少。</p><h3 id="member-initialization-list"><a href="#member-initialization-list" class="headerlink" title="member initialization list"></a>member initialization list</h3><p>list 中的初始化次序是 class 中的 member 声明顺序决定的。顺序 constructor, 逆序 destructor</p><p>聪明的编译器应该能告诉你出了问题，所以别担心hhh。</p><p>当然，如果你写出下面的代码，任何一本书都会阻止你：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">X</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="built_in">X</span>(<span class="type">const</span> Y&amp; y) &#123;</span><br><span class="line">y_ = y;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">Y y_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译器会把初始化插入在 explicit 的代码之前。</p><h2 id="Data-的语义"><a href="#Data-的语义" class="headerlink" title="Data 的语义"></a>Data 的语义</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">X</span> &#123;&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Y</span>: <span class="keyword">public</span> <span class="keyword">virtual</span> X &#123;&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Z</span>: <span class="keyword">public</span> <span class="keyword">virtual</span> X &#123;&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>: <span class="keyword">public</span> Y, <span class="keyword">public</span> Z &#123;&#125;;</span><br></pre></td></tr></table></figure><p>哦，还有一个很好玩的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">H</span> &#123;</span><br><span class="line"><span class="type">int</span> s[];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面让我们来看看对它们进行 <code>sizeof</code> 的结果。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Created by mwish on 2020/7/14.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">X</span> &#123;&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DerivedX</span>: <span class="keyword">public</span> X &#123;&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Y</span>: <span class="keyword">public</span> <span class="keyword">virtual</span> X &#123;&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Z</span>: <span class="keyword">public</span> <span class="keyword">virtual</span> X &#123;&#125;;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">A</span>: <span class="keyword">public</span> Y, <span class="keyword">public</span> Z &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">H</span> &#123;</span><br><span class="line">    <span class="type">int</span> s[];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">print_t_size</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; __PRETTY_FUNCTION__ &lt;&lt; <span class="string">&quot;:&quot;</span> &lt;&lt; <span class="built_in">sizeof</span>(T) &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">print_t_size</span>&lt;X&gt;();</span><br><span class="line">    <span class="built_in">print_t_size</span>&lt;DerivedX&gt;();</span><br><span class="line">    <span class="built_in">print_t_size</span>&lt;Y&gt;();</span><br><span class="line">    <span class="built_in">print_t_size</span>&lt;Z&gt;();</span><br><span class="line">    <span class="built_in">print_t_size</span>&lt;A&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print_t_size</span>&lt;H&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">void print_t_size() [T = X]:1</span><br><span class="line">void print_t_size() [T = DerivedX]:1</span><br><span class="line">void print_t_size() [T = Y]:8</span><br><span class="line">void print_t_size() [T = Z]:8</span><br><span class="line">void print_t_size() [T = A]:16</span><br><span class="line">void print_t_size() [T = H]:0</span><br></pre></td></tr></table></figure><p>实际上，可以考虑看看 ebo: <a href="https://zh.cppreference.com/w/cpp/language/ebo">https://zh.cppreference.com/w/cpp/language/ebo</a></p><blockquote><p>为保证同一类型的不同对象地址始终有别，要求任何<a href="https://zh.cppreference.com/w/cpp/language/object">对象</a>或成员子对象（除非为 [[no_unique_address]] ——见下文） (C++20 起)的大小至少为 1，即使该类型是空的<a href="https://zh.cppreference.com/w/cpp/language/class">类类型</a>（即没有非静态数据成员的 class 或 struct）也是如此。</p></blockquote><p>（也可以看看这个 FAQ: <a href="https://isocpp.org/wiki/faq/classes-and-objects#sizeof-empty）">https://isocpp.org/wiki/faq/classes-and-objects#sizeof-empty）</a></p><p>所以 <code>static_assert(sizeof(X) &gt;= 1)</code> 必定是成立的。</p><p>一个对象的大小额外开销（相对于C语言那样朴素的布局）在于：</p><ul><li>语言 <code>virtual base class</code> 和 <code>virtual</code> 的额外负担。关于这个还可以阅读：<a href="https://zh.cppreference.com/w/cpp/named_req/StandardLayoutType">https://zh.cppreference.com/w/cpp/named_req/StandardLayoutType</a></li><li>编译器的一些特殊处理，例如下列提到的<em>空基类优化</em></li><li>Alignment: 这里介绍的比较好的是 wiki 的。</li></ul><p>这里继续说一下 ebo, 定义一下：</p><blockquote><p>若空基类之一亦为首个非静态数据成员的类型或其类型的基类，则禁用空基优化，因为要求两个同类型基类子对象在最终派生类型的对象表示中必须拥有不同地址。</p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Compond2X</span> &#123;</span><br><span class="line">    X x_;</span><br><span class="line">    <span class="type">uint32_t</span> value;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span>  <span class="title class_">Derived3X</span>: <span class="keyword">public</span> X &#123;</span><br><span class="line">    X x_;</span><br><span class="line">    <span class="type">uint32_t</span> value;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// void print_t_size() [T = Derived2X]:4</span></span><br><span class="line"><span class="comment">// 应用了空基类优化</span></span><br><span class="line"><span class="built_in">print_t_size</span>&lt;Derived2X&gt;();</span><br><span class="line"><span class="comment">// 8</span></span><br><span class="line"><span class="built_in">print_t_size</span>&lt;Compond2X&gt;();</span><br><span class="line"><span class="comment">// 8</span></span><br><span class="line"><span class="built_in">print_t_size</span>&lt;Derived3X&gt;();</span><br></pre></td></tr></table></figure><p>书上 3.1 节介绍了类和名称查找相关的信息，感觉书上写的一般，我也没看太懂，就不贴了。</p><h3 id="Data-Member-Layout"><a href="#Data-Member-Layout" class="headerlink" title="Data Member Layout"></a>Data Member Layout</h3><p>当你 <code>repr(C)</code> 的时候，对象都是按顺序布局的，C++ 一定程度上有这个保证——只对同样访问权限的对象而言。</p><p>具体我找到了这个链接：<a href="https://stackoverflow.com/questions/36149462/does-public-and-private-have-any-influence-on-the-memory-layout-of-an-object">https://stackoverflow.com/questions/36149462/does-public-and-private-have-any-influence-on-the-memory-layout-of-an-object</a></p><p>只能说如果你有依赖这样语义的操作，记得 <code>static_assert</code>.</p><p>而 <code>static member</code> 并不是对象的一部分，不参与对象的布局。</p><h3 id="static-member-and-name-mangling"><a href="#static-member-and-name-mangling" class="headerlink" title="static member and name-mangling"></a>static member and name-mangling</h3><ul><li><a href="https://en.cppreference.com/w/cpp/language/identifiers">https://en.cppreference.com/w/cpp/language/identifiers</a></li><li><a href="https://en.cppreference.com/w/cpp/language/language_linkage">https://en.cppreference.com/w/cpp/language/language_linkage</a></li></ul><p>你要是 g++/clang++ 编译过 C++ 代码大概就会知道的…</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>OS 和 Virtual Memory: RISC-V 视角</title>
      <link href="/2020/06/17/OS-%E5%92%8C-Virtual-Memory-RISC-V-%E8%A7%86%E8%A7%92/"/>
      <url>/2020/06/17/OS-%E5%92%8C-Virtual-Memory-RISC-V-%E8%A7%86%E8%A7%92/</url>
      
        <content type="html"><![CDATA[<p>这是个 Ring，代表我们用的 OS 软件的层次结构：</p><p><img src="https://image.mwish.me/blog-image/A379A81B-5886-404B-9DE7-B290E7A5D1BE.png" alt="A379A81B-5886-404B-9DE7-B290E7A5D1BE"></p><p>在操作系统中，我们可以看到操作系统的任务、职责：</p><ul><li>系统开启的第一个应用</li><li>控制操作系统的 IO</li><li>开启文件系统，网络栈等服务</li><li>程序的加载器和运行程序的管理者</li></ul><p>OS 工作的核心：</p><ul><li>运行进程的 isolation</li><li>让系统和外部的 disk 等通信，完成 IO 等</li></ul><p>OS 需要硬件支持的部分：</p><ul><li>memory translation<ul><li>每个运行的进程需要从 virtual 的进程转成物理内存</li><li>program 实际处理的是虚拟内存，需要硬件支持</li></ul></li><li>protection and privilege<ul><li>需要提供 user 和 supervisor 的模式，在 RISC-V 中有 machine 和 supervisor 模式</li></ul></li><li>更低的层次不能修改 memory mapping<ul><li>supervisor 可以</li><li>supervisor 有独立于用户程序的 virtual 到 physical 映射</li></ul></li><li>提供 traps 和 interrupt，在命令层面提供了到 supervisor 的方法</li></ul><p>在 RISC-V 中，硬件可以提供 Control and Status Registers，即 CSR 寄存器，这是一组可以原子读写的寄存器。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CSRRW rd rs csr</span><br></pre></td></tr></table></figure><p>上述读取 <code>csr</code> 写到 <code>rd</code>, <code>rs</code> 不为0写到 <code>csr</code>。这不是普通的寄存器，用来与硬件沟通</p><p>我们需要 interrupt 和 exceptions，它们的相同点和区别是：</p><ul><li>interrupt 是程序外部对程序的中断</li><li>exception：运行程序内部丢的毛病：需要读 csr, 可能是执行了违法指令，或者读了不合法内存<ul><li><code>ECALL</code> 用来实现 syscall</li><li><code>EBREAK</code> 在现在的优先级引发 exception</li></ul></li></ul><p>trap 有一定的 flow: 由其他进程处理 —&gt; OS 处理</p><p>在 CS61C 的定义中：</p><ul><li>interrupt: 由外部引起，对于程序是异步的</li><li>exception: 由内部引起，同步</li><li>trap: 需要跳到 hardware 处理异常，并跳到 interrupt or trap handler 的代码</li></ul><p>Trap:</p><ul><li>Trap 之前的指令都被执行，之后的指令在 trap 返回之前不能被执行</li><li>很多时候，如果指定了 handler，用户会存储自己的寄存器，stack 等，然后返回。<ul><li>interrupt 处理器不一定要理硬件，其他 trap 可能会有个 trap code</li></ul></li></ul><p>硬件处理 interrupt:</p><ul><li>硬件需要调整，大部分情况会调整到 supervisor</li><li>禁止 interrupt</li><li>把旧的程序的 PC 用 <code>csr</code> 指令写到 <code>sepc</code></li><li>把 trap 的原因写入csr 寄存器 <code>scause</code></li><li>把 PC 设置成 <code>stvec</code> 寄存器<ul><li><code>stvec</code> 设置了 trap handler</li><li>处理 exception</li></ul></li></ul><p>对于软件而言，需要处理的是：</p><ul><li>保存所有寄存器</li><li>读对应的 <code>csr</code> ，发现除了什么问题</li><li>恢复所有寄存器</li><li>返回程序原先的位置</li></ul><p>保存寄存器：</p><ul><li>supervisor 模式下，在 <code>sscratch</code> 存储 trap handler</li><li><code>csrrw x1 x1 sscratch</code> 将 x1 与 sccratch 交换</li><li><code>sepc</code> 这个 CSR 寄存器处写 PC</li><li>最后保存 <code>x1</code>, 恢复 <code>sscratch</code></li></ul><p><img src="https://image.mwish.me/blog-image/1A003613-A174-469A-87CE-3B6746CA8A47.png" alt="1A003613-A174-469A-87CE-3B6746CA8A47"></p><p>所以这里先把所有 x1 相关的参数写到 <code>sscratch</code> 的位置，然后把 <code>sepc</code> 写到 x2，并继续保存它。然后恢复我们之前的，把 x1 （即原来的 <code>sscratch</code> ）写到 <code>sscratch</code> ，把原来的 <code>sscratch</code> 写到 x2。这个时候再把 <code>sscratch</code> 写回。</p><p>以上流程相当于在 <code>sscratch</code> 保存 <code>x1</code> <code>x2</code> … 再保存 <code>sepc</code>。</p><p>然后我们需要再后面决定之后的调用是什么：</p><ul><li>如果是一个 <code>ECALL</code> 指令，就执行具体的 ecall</li><li>如果是不合法指令，直接 kill</li><li>memory 相关的就加载内存</li><li>timer interrupt 就进行 context switch</li></ul><p>处理完之后，我们要恢复所有的寄存器，<code>ecall</code> 需要在 <code>a0</code> 写返回值。然后调用<code>SRET</code> 指令。</p><p><code>sret</code> 指令返回硬件，我们在调用 <code>sret</code> 之前要先处理 <code>ecall</code> 之后做的软件行为：</p><ul><li>恢复所有的寄存器</li><li>恢复 <code>sepc</code>，如果是 <code>ecall</code>, 返回 PC + 4 对应的位置</li><li>恢复所有的其他寄存器，<ul><li>可能需要跳转到 <code>sscratch</code></li><li>如果是 <code>ecall</code>，设置 <code>a0</code> 作为返回值</li></ul></li><li>执行 <code>sret</code></li></ul><p><code>sret</code> 和 <code>ecall</code> 对应，有着下列的硬件行为：</p><ul><li>恢复 interrupt</li><li>从 supervisor 回到 user level</li><li><code>spec</code> 中恢复 <code>pc</code></li><li>继续运行</li></ul><h3 id="功能和代价"><a href="#功能和代价" class="headerlink" title="功能和代价"></a>功能和代价</h3><p>interrupt 的功能：</p><p>在 user mode, 程序不能控制 virtual memory，但是可以改变虚拟内存的内容。</p><p>这份虚拟内存与 <code>satp</code> 这个 csr 寄存器有关，<code>satp</code> 是 page table pointer，表示物理内存上的页表。</p><p>这让调用 trap handler 之外不会 trap 系统调用。</p><p>interrupt 的代价：</p><ul><li>需要 flush pipeline</li><li>需要保存和恢复所有的寄存器</li><li>因为 trap handler 是不相关的代码，所以 cache 可能受影响</li></ul><h3 id="Context-Switch"><a href="#Context-Switch" class="headerlink" title="Context Switch"></a>Context Switch</h3><p>硬件支持了 timer interrupt, 触发的时候，硬件执行 context switch，把寄存器 <code>sscratch</code> 周围存储的寄存器存到现有进程的数据结构中，然后把 <code>satp</code> 和相关拷贝到 memory mapping 相关的数据结构中。然后根据 scheduler 来选择目标进程，恢复目标进程的 <code>satp</code> <code>sepc</code> 等，并调用 <code>sret</code> 返回。</p><h2 id="IO"><a href="#IO" class="headerlink" title="IO"></a>IO</h2><p>CPU 需要与不同的 IO 设备交互。</p><p><img src="https://image.mwish.me/blog-image/交互.png" alt="交互"></p><p>软件希望：输入/输出一堆 bytes，同时希望能够提供一些 memory 相关的接口或者独立的指令。</p><p>对于 memory mapped I/O, 对于一段 address, 我们可以用 lw/sw 等指令处理 IO。</p><p>下面是课件上的一些 memory mapping 的效率，结论是 IO 设备处理数据的速度是远慢于 CPU 的</p><p><img src="https://image.mwish.me/blog-image/391D529F-58C6-49C2-9448-EF5A47ACCA76.png" alt="391D529F-58C6-49C2-9448-EF5A47ACCA76"></p><p>同通用场景下， device registers 有两个寄存器：</p><ul><li>control register: 表示 I/O 是否 ready</li><li>data register: 包含数据</li></ul><p>常用的手段包含 </p><ol><li>polling: PIO 轮询 control register ，看看是否准备好了。这样比较消耗 cpu</li><li>interrupt: 硬件在有数据的时候触发 interrupt，在 IO 频率高的情况下，例如鼠标、键盘、网络等，实际上会触发很多的 IO</li><li>DMA</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>RISC-V 入门 Part2: ABI &amp;&amp; Calling Convention</title>
      <link href="/2020/06/07/RISC-V-%E5%85%A5%E9%97%A8-Part2/"/>
      <url>/2020/06/07/RISC-V-%E5%85%A5%E9%97%A8-Part2/</url>
      
        <content type="html"><![CDATA[<h1 id="RISC-V-入门-Part2-ABI-amp-amp-Calling-Convention"><a href="#RISC-V-入门-Part2-ABI-amp-amp-Calling-Convention" class="headerlink" title="RISC-V 入门 Part2: ABI &amp;&amp; Calling Convention"></a>RISC-V 入门 Part2: ABI &amp;&amp; Calling Convention</h1><p>长度单位：</p><ul><li><code>b</code> byte</li><li><code>h</code> halfword</li><li><code>w</code> word</li></ul><p><code>i</code> 的尾坠代表 <code>imm</code>, 立即数, 比如 <code>addi</code>, <code>andi</code></p><p><code>jump</code> 基于<code>jalr</code> ，这个 <code>r</code> 是 register。</p><hr><p>u类指令格式:</p><ul><li><code>lui</code>: load upper immediate, 用于构造一个 32-bit constants</li><li><code>auipc</code>: add upper immediate to PC. PC +  偏移量写入 <code>register</code></li></ul><hr><p>我们上一个 Part 介绍了 bne 等 conditional branch，此外还有难理解一些的 unconditional branch. 例如伪指令 <code>j</code>, 它基于 <code>jal</code>, 即 jump and link 实现：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">jal rd offset</span><br><span class="line">jalr rd rs (offset)</span><br></pre></td></tr></table></figure><p>jal 用来实现函数调用的语义：它 PC 跳转 <code>offset</code> （长度为 20bits），或者对应的寄存器，然后把 PC + 4 （RV32I 指令长度是 32bit, 即 4Byte，表示下一条指令）写到 <code>rd</code> 寄存器。</p><p><code>jal</code> 用来实现函数调用和循环中的 unconditional jump.</p><h2 id="C-to-RISC-V"><a href="#C-to-RISC-V" class="headerlink" title="C to RISC-V"></a>C to RISC-V</h2><p><img src="https://image.mwish.me/blog-image/DC87168C-5240-43EA-9A36-40D0E23563F3.png" alt="DC87168C-5240-43EA-9A36-40D0E23563F3"></p><p>上面这张图 cmu 15-445 有更好玩的版本。</p><p><img src="https://image.mwish.me/blog-image/8D576B0E-28AC-450C-9752-9088942AB8C4.png" alt="8D576B0E-28AC-450C-9752-9088942AB8C4"></p><p>这里面写了调用一个函数的6步，即函数调用规范(<strong>Calling convention</strong>) . </p><ul><li>把函数参数放到函数能访问的地方</li><li>把控制权给函数（使用 <code>jal</code> 指令）</li><li>拿到 memory 中的资源 （获取函数需要的局部存储资源，按需保存寄存器）</li><li>运行函数中的指令</li><li>把值写到 memory/register 中 （将返回值存储到调用者能够访问到的位置，恢复寄存器，释放局部存储资源）</li><li>返回 ( <code>ret</code> 指令)</li></ul><p>寄存器有 <em>caller-saved</em> 和 <em>callee-saved</em> 两种：</p><ul><li><em>caller-saved</em>: callee 可以随便搞，从这里读数据，然后操作它们</li><li><em>callee-saved</em>: callee 在返回前应该保存的</li></ul><p>ABI：调用其它函数时，关于汇编、参数、寄存器等的双方约定。（我觉得有几个答案补充的很好）. 实际上 ABI 兼容性是一个和编译器等都有关的话题。ABI 定义了 calling convention，同时 ABI 定义了约束：有些寄存器是不可写的。</p><p>同时，你可以在上面的图里面看到很奇妙的事情，这里没有再使用 <code>x0</code> - <code>x15</code> 这样的记号，而是用了 <code>s0</code> <code>fp</code> 这样相对来说名字好理解一些的。</p><hr><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">Leaf</span><span class="params">(<span class="type">int</span> g, <span class="type">int</span> h, <span class="type">int</span> i, <span class="type">int</span> j)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> f;</span><br><span class="line">    f = (g + h) - (i + j);</span><br><span class="line">    <span class="keyword">return</span> f;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>用 <code>riscv64-unknown-elf-gcc</code> 编译</p><p>可以看到，为了存放旧的值，需要 stack.<code>sp</code> 寄存器和 stack 有关，同时有 push/pop. 鉴于 stack 是自顶向下生长的，push 会减小 <code>sp</code>, pop 会增大 <code>sp</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">✗ riscv64-unknown-elf-gcc -march=rv32imac -mabi=ilp32 -S leaf.c </span><br></pre></td></tr></table></figure><p>编译一下 leaf:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">.file&quot;leaf.c&quot;</span><br><span class="line">.option nopic</span><br><span class="line">.attribute arch, &quot;rv32i2p0_m2p0_a2p0_c2p0&quot;</span><br><span class="line">.attribute unaligned_access, 0</span><br><span class="line">.attribute stack_align, 16</span><br><span class="line">.text</span><br><span class="line">.align1</span><br><span class="line">.globlLeaf</span><br><span class="line">.typeLeaf, @function</span><br><span class="line">Leaf:</span><br><span class="line">addisp,sp,-48 # 修改 stack, 降低以 push 值</span><br><span class="line">sws0,44(sp)   # 把 s0 写进 44(sp), s0 这里代表 frame pointer</span><br><span class="line">addis0,sp,48  # s0 = sp + 48, s0 为 frame pointer</span><br><span class="line">swa0,-36(s0)  # 把 a0 - a3 存了。a0-a1 用来存返回值，a0-a7 用来传参</span><br><span class="line">swa1,-40(s0)</span><br><span class="line">swa2,-44(s0)</span><br><span class="line">swa3,-48(s0)</span><br><span class="line"></span><br><span class="line">lwa4,-36(s0) # 把原本 a0 a1 加载到 a4 a5</span><br><span class="line">lwa5,-40(s0)</span><br><span class="line">adda4,a4,a5   # a4 = a4 + a5</span><br><span class="line">lwa3,-44(s0) # a3, a5 加载</span><br><span class="line">lwa5,-48(s0)</span><br><span class="line">adda5,a3,a5 # a5 = a3 + a5</span><br><span class="line">suba5,a4,a5   # a5 = a4 - a5  这两段完成函数主要的计算</span><br><span class="line">swa5,-20(s0) </span><br><span class="line">lwa5,-20(s0)</span><br><span class="line">mva0,a5 # a0 = a5, a0 是返回值</span><br><span class="line">lws0,44(sp) # s0 = sp + 44</span><br><span class="line">addisp,sp,48 # 修改 sp</span><br><span class="line">jrra # ra 是 return address, 返回 ra</span><br><span class="line">.sizeLeaf, .-Leaf</span><br><span class="line">.ident&quot;GCC: (GNU) 9.2.0&quot;</span><br></pre></td></tr></table></figure><ul><li>改变 <code>s0</code> 这个 frame pointer 和 <code>sp</code> 这个 stack pointer</li><li>把原来的 <code>a0 - a4</code> 放到栈上</li><li>用 <code>a4 a5</code> 来运算</li><li>改回 <code>sp, s0</code></li><li><code>jr</code> 返回</li></ul><p>跳转回来的伪指令如下：</p><p><img src="https://image.mwish.me/blog-image/C5B138C9-1928-4101-A199-E972CF81657F.png" alt="C5B138C9-1928-4101-A199-E972CF81657F"></p><p><img src="https://image.mwish.me/blog-image/B488D822-AF29-4ACB-82B0-D02416ADCA81.png" alt="B488D822-AF29-4ACB-82B0-D02416ADCA81"></p><p>顺便，<code>-O2</code> 编译的时候：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">.file&quot;leaf.c&quot;</span><br><span class="line">.option nopic</span><br><span class="line">.attribute arch, &quot;rv32i2p0_m2p0_a2p0_c2p0&quot;</span><br><span class="line">.attribute unaligned_access, 0</span><br><span class="line">.attribute stack_align, 16</span><br><span class="line">.text</span><br><span class="line">.align1</span><br><span class="line">.globlLeaf</span><br><span class="line">.typeLeaf, @function</span><br><span class="line">Leaf:</span><br><span class="line">adda0,a0,a1</span><br><span class="line">adda2,a2,a3</span><br><span class="line">suba0,a0,a2</span><br><span class="line">ret</span><br><span class="line">.sizeLeaf, .-Leaf</span><br><span class="line">.ident&quot;GCC: (GNU) 9.2.0&quot;</span><br></pre></td></tr></table></figure><p>这里 <code>a0, a1, a2, a3</code> 四个是参数。</p><p>下面：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">mult</span><span class="params">(<span class="type">int</span>, <span class="type">int</span>)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">sumSquare</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> mult(x, x) + y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成汇编：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">.file&quot;ss.c&quot;</span><br><span class="line">.option nopic</span><br><span class="line">.attribute arch, &quot;rv32i2p0_m2p0_a2p0_c2p0&quot;</span><br><span class="line">.attribute unaligned_access, 0</span><br><span class="line">.attribute stack_align, 16</span><br><span class="line">.text</span><br><span class="line">.align1</span><br><span class="line">.globlsumSquare</span><br><span class="line">.typesumSquare, @function</span><br><span class="line">sumSquare:</span><br><span class="line">addisp,sp,-16 # reserve space on stack</span><br><span class="line">swra,12(sp)   # save ret addr</span><br><span class="line">sws0,8(sp)# 存储原来的 s0</span><br><span class="line">mvs0,a1# s0 存储 y</span><br><span class="line">mva1,a0# a1 = a0 (= x)</span><br><span class="line">callmult</span><br><span class="line">adda0,a0,s0</span><br><span class="line">lwra,12(sp)</span><br><span class="line">lws0,8(sp)</span><br><span class="line">addisp,sp,16</span><br><span class="line">jrra</span><br><span class="line">.sizesumSquare, .-sumSquare</span><br><span class="line">.ident&quot;GCC: (GNU) 9.2.0&quot;</span><br></pre></td></tr></table></figure><hr><h2 id="Stack-Pointer-amp-Frame-Pointer-amp-Memory"><a href="#Stack-Pointer-amp-Frame-Pointer-amp-Memory" class="headerlink" title="Stack Pointer &amp; Frame Pointer &amp; Memory"></a>Stack Pointer &amp; Frame Pointer &amp; Memory</h2><p>当然，以上演示的很多都在 stack 上，实际上我们可能需要打理的东西还更多：</p><p><img src="https://image.mwish.me/blog-image/QQ20201003-0.png" alt="QQ20201003-0"></p><p>堆/栈的分配是 ISA 的一部分（指令集同样是 ISA 的一部分）</p><p><img src="https://image.mwish.me/blog-image/6F1CCA2D-7402-4958-92E0-14B74AED1E8E.png" alt="6F1CCA2D-7402-4958-92E0-14B74AED1E8E"></p><p>以上是对 stack 的操作，在 x86 里面我们有原子的 push-pop, 但是这里我们得谨慎的多。</p><p>看前面那个 s0 的例子，用 frame pointer(<code>s0</code>) 而不是 sp 取地址相对值. 同时我们还有 <code>fp</code>, 即 frame pointer, 它中文叫“帧指针”。</p><blockquote><p>The calling convention says it doesn’t matter if you use a frame pointer or not!</p><p>It is just a callee saved register, so if you use it as a frame pointer…  It will be preserved just like any other saved register.</p><p>But if you just use it as <strong>s0</strong>, that makes no difference!</p></blockquote><p>栈帧内返回地址是在local variables前还是在它们后面？ - RednaxelaFX的回答 - 知乎 <a href="https://www.zhihu.com/question/33920941/answer/57597076">https://www.zhihu.com/question/33920941/answer/57597076</a></p><p>实际上 fp sp 关系类似<code>fp</code> —  <code>sp</code> , 同时 <code>fp</code> 不是必须的，但是对 debug 而言大有裨益。</p><p>接着举例子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">list</span> &#123;</span></span><br><span class="line">    <span class="type">void</span> *car;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">list</span> *<span class="title">cdr</span>;</span></span><br><span class="line">&#125; List;</span><br><span class="line"></span><br><span class="line">List *<span class="title function_">map</span><span class="params">(List *src, <span class="type">void</span> *(*f)(<span class="type">void</span> *))</span> &#123;</span><br><span class="line">    List *ret;</span><br><span class="line">    <span class="keyword">if</span> (!src)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    ret = (List *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(List));</span><br><span class="line">    ret-&gt;car = (*f)(src-&gt;car);</span><br><span class="line">    ret-&gt;car = <span class="built_in">map</span>(src-&gt;cdr, f);</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译一下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">.file&quot;rich-list.c&quot;</span><br><span class="line">.option nopic</span><br><span class="line">.attribute arch, &quot;rv32i2p0_m2p0_a2p0_c2p0&quot;</span><br><span class="line">.attribute unaligned_access, 0</span><br><span class="line">.attribute stack_align, 16</span><br><span class="line">.text</span><br><span class="line">.align1</span><br><span class="line">.globlmap</span><br><span class="line">.typemap, @function</span><br><span class="line">map:</span><br><span class="line">addisp,sp,-16</span><br><span class="line">swra,12(sp)</span><br><span class="line">sws0,8(sp) # 存储 s0-s2</span><br><span class="line">sws1,4(sp) </span><br><span class="line">sws2,0(sp)</span><br><span class="line">beqa0,zero,.L3 # is-null, a0 是 src</span><br><span class="line">mvs0,a0    # save src</span><br><span class="line">lia0,8     # a0 = 8, call malloc with size 8</span><br><span class="line">mvs2,a1 # s2 = a1</span><br><span class="line">callmalloc</span><br><span class="line">mvs1,a0</span><br><span class="line">lwa0,0(s0)</span><br><span class="line">jalrs2  # jalr 调用函数，a1 是一个 function</span><br><span class="line">mva5,a0</span><br><span class="line">lwa0,4(s0)</span><br><span class="line">swa5,0(s1)</span><br><span class="line">mva1,s2</span><br><span class="line">callmap</span><br><span class="line">lwra,12(sp)</span><br><span class="line">lws0,8(sp)</span><br><span class="line">swa0,0(s1)</span><br><span class="line">lws2,0(sp)</span><br><span class="line">mva0,s1</span><br><span class="line">lws1,4(sp)</span><br><span class="line">addisp,sp,16</span><br><span class="line">jrra</span><br><span class="line">.L3:# is-null, 直接返回了</span><br><span class="line">lwra,12(sp)</span><br><span class="line">lws0,8(sp)</span><br><span class="line">lis1,0      # li rd, imm 读取立即数，这里把 s1, 即返回值，置为0</span><br><span class="line">lws2,0(sp)</span><br><span class="line">mva0,s1     # a0 = 0</span><br><span class="line">lws1,4(sp)</span><br><span class="line">addisp,sp,16</span><br><span class="line">jrra</span><br><span class="line">.sizemap, .-map</span><br><span class="line">.ident&quot;GCC: (GNU) 9.2.0&quot;</span><br></pre></td></tr></table></figure><p>这里的 requirements 是：我们会调用 <code>malloc</code>, 并在之后使用 <code>src</code> 和 <code>f</code> 参数</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LevelDB memtable</title>
      <link href="/2020/06/02/LevelDB-memtable/"/>
      <url>/2020/06/02/LevelDB-memtable/</url>
      
        <content type="html"><![CDATA[<h2 id="SkipList"><a href="#SkipList" class="headerlink" title="SkipList"></a>SkipList</h2><p><a href="https://en.wikipedia.org/wiki/Skip_list">SkipList</a> 介绍的地方应该比较多，邓俊晖老师数据结构 9.2 节对它的时空复杂度都有一个分析。相对于我们常用的 binary search tree, SkipList 时空效率都有一点不如。但是如果要实现<strong>Thread-safe ordered maps</strong>，SkipList 相对简单，而且可以利用 lock-free 的方式做一些很棒的优化。</p><p>介绍 LevelDB SkipList, 本文重点关注它是如何实现一写多读的语义的。</p><p><a href="https://github.com/google/leveldb/blob/master/db/skiplist.h#L8">https://github.com/google/leveldb/blob/master/db/skiplist.h#L8</a> </p><p>这段注释提到了几点：</p><ul><li>写入操作需要外部同步，只能单线程的写入。这个我们之前介绍 <code>Put</code> 的时候大概讲过它是怎么实现的。</li><li>SkipList 这里只会<code>Insert</code> 和 <code>Get</code>, 利用 <code>Arena</code> 申请内存，在SkipList 使用完毕的时候，一起释放内存。</li><li>已经插入的数据不会被更新</li></ul><p>同时，阅读代码之前需要注意：SkipList 把所有信息都丢到 Key 里去了</p><p>比较有趣的是 <code>Node</code> 的 barrier:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Implementation details follow</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">SkipList</span>&lt;Key, Comparator&gt;::Node &#123;</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">Node</span><span class="params">(<span class="type">const</span> Key&amp; k)</span> : key(k) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  Key <span class="type">const</span> key;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Accessors/mutators for links.  Wrapped in methods so we can</span></span><br><span class="line">  <span class="comment">// add the appropriate barriers as necessary.</span></span><br><span class="line">  <span class="function">Node* <span class="title">Next</span><span class="params">(<span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(n &gt;= <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// Use an &#x27;acquire load&#x27; so that we observe a fully initialized</span></span><br><span class="line">    <span class="comment">// version of the returned Node.</span></span><br><span class="line">    <span class="keyword">return</span> next_[n].<span class="built_in">load</span>(std::memory_order_acquire);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">SetNext</span><span class="params">(<span class="type">int</span> n, Node* x)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(n &gt;= <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// Use a &#x27;release store&#x27; so that anybody who reads through this</span></span><br><span class="line">    <span class="comment">// pointer observes a fully initialized version of the inserted node.</span></span><br><span class="line">    next_[n].<span class="built_in">store</span>(x, std::memory_order_release);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// No-barrier variants that can be safely used in a few locations.</span></span><br><span class="line">  <span class="function">Node* <span class="title">NoBarrier_Next</span><span class="params">(<span class="type">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(n &gt;= <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">return</span> next_[n].<span class="built_in">load</span>(std::memory_order_relaxed);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">NoBarrier_SetNext</span><span class="params">(<span class="type">int</span> n, Node* x)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">assert</span>(n &gt;= <span class="number">0</span>);</span><br><span class="line">    next_[n].<span class="built_in">store</span>(x, std::memory_order_relaxed);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// Array of length equal to the node height.  next_[0] is lowest level link.</span></span><br><span class="line">  std::atomic&lt;Node*&gt; next_[<span class="number">1</span>];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ul><li><code>NoBarrier</code> 在 <code>relaxed</code> 下操作</li><li>有 Barrier 的在 <code>acquire</code>/<code>release</code> 下操作</li></ul><p>首先看看至关重要的 <code>FindGreaterOrEqual</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Return the earliest node that comes at or after key.</span></span><br><span class="line"><span class="comment">// Return nullptr if there is no such node.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If prev is non-null, fills prev[level] with pointer to previous</span></span><br><span class="line"><span class="comment">// node at &quot;level&quot; for every level in [0..max_height_-1].</span></span><br><span class="line"><span class="function">Node* <span class="title">FindGreaterOrEqual</span><span class="params">(<span class="type">const</span> Key&amp; key, Node** prev)</span> <span class="type">const</span></span>;</span><br></pre></td></tr></table></figure><p>这个 <code>FindGreaterOrEqual</code> 的 prev 会把一个逐层的指针赋予 <code>prev</code>, 即 <code>prev[4]</code> 为 <code>level = 4</code> 的 Node 中对应 prev 的一个，直到 <code>level = 0</code>.</p><p>具体实现的时候，我们注意它调用的是 <code>x-&gt;Next(level)</code>。它是一个 memory order 为 <code>acquire</code> 的操作。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="keyword">typename</span> SkipList&lt;Key, Comparator&gt;::Node*</span><br><span class="line">SkipList&lt;Key, Comparator&gt;::<span class="built_in">FindGreaterOrEqual</span>(<span class="type">const</span> Key&amp; key,</span><br><span class="line">                                              Node** prev) <span class="type">const</span> &#123;</span><br><span class="line">  Node* x = head_;</span><br><span class="line">  <span class="type">int</span> level = <span class="built_in">GetMaxHeight</span>() - <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    Node* next = x-&gt;<span class="built_in">Next</span>(level);</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">KeyIsAfterNode</span>(key, next)) &#123;</span><br><span class="line">      <span class="comment">// Keep searching in this list</span></span><br><span class="line">      x = next;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (prev != <span class="literal">nullptr</span>) prev[level] = x;</span><br><span class="line">      <span class="keyword">if</span> (level == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> next;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// Switch to next list</span></span><br><span class="line">        level--;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以 <code>Insert</code> 的时候，在有外部同步的情况下，我们可以：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Key, <span class="keyword">class</span> <span class="title class_">Comparator</span>&gt;</span><br><span class="line"><span class="type">void</span> SkipList&lt;Key, Comparator&gt;::<span class="built_in">Insert</span>(<span class="type">const</span> Key&amp; key) &#123;</span><br><span class="line">  <span class="comment">// TODO(opt): We can use a barrier-free variant of FindGreaterOrEqual()</span></span><br><span class="line">  <span class="comment">// here since Insert() is externally synchronized.</span></span><br><span class="line">  Node* prev[kMaxHeight];</span><br><span class="line">  Node* x = <span class="built_in">FindGreaterOrEqual</span>(key, prev);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Our data structure does not allow duplicate insertion</span></span><br><span class="line">  <span class="built_in">assert</span>(x == <span class="literal">nullptr</span> || !<span class="built_in">Equal</span>(key, x-&gt;key));</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> height = <span class="built_in">RandomHeight</span>();</span><br><span class="line">  <span class="keyword">if</span> (height &gt; <span class="built_in">GetMaxHeight</span>()) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="built_in">GetMaxHeight</span>(); i &lt; height; i++) &#123;</span><br><span class="line">      prev[i] = head_;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// It is ok to mutate max_height_ without any synchronization</span></span><br><span class="line">    <span class="comment">// with concurrent readers.  A concurrent reader that observes</span></span><br><span class="line">    <span class="comment">// the new value of max_height_ will see either the old value of</span></span><br><span class="line">    <span class="comment">// new level pointers from head_ (nullptr), or a new value set in</span></span><br><span class="line">    <span class="comment">// the loop below.  In the former case the reader will</span></span><br><span class="line">    <span class="comment">// immediately drop to the next level since nullptr sorts after all</span></span><br><span class="line">    <span class="comment">// keys.  In the latter case the reader will use the new node.</span></span><br><span class="line">    max_height_.<span class="built_in">store</span>(height, std::memory_order_relaxed);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  x = <span class="built_in">NewNode</span>(key, height);</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; height; i++) &#123;</span><br><span class="line">    <span class="comment">// NoBarrier_SetNext() suffices since we will add a barrier when</span></span><br><span class="line">    <span class="comment">// we publish a pointer to &quot;x&quot; in prev[i].</span></span><br><span class="line">    x-&gt;<span class="built_in">NoBarrier_SetNext</span>(i, prev[i]-&gt;<span class="built_in">NoBarrier_Next</span>(i));</span><br><span class="line">    prev[i]-&gt;<span class="built_in">SetNext</span>(i, x);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><code>max_height_</code> 的 store 和 load 都是 relaxed 的，另一个线程只会读到旧的值，但不会读到过大的值。</li><li>插入的时候是从 0 层到最高层插入的。<code>FindGreaterOrEqual</code> 是反过来的。</li><li>插入的时候是 <code>x-&gt;NoBarrier_SetNext</code>  再 <code>prev[i]-&gt;SetNext</code> 。前者是一个<code>relaxed</code>, 后者是一个<code>release</code>.</li></ul><p>我们 <code>Insert</code> 是单线程的，但是 SkipList 的 Iterator 可能会调用 <code>FindGreaterOrEqual</code>。它的 <code>Next</code> 是一个 <code>acquire</code> 的操作。</p><h2 id="Memtable"><a href="#Memtable" class="headerlink" title="Memtable"></a>Memtable</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> leveldb &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InternalKeyComparator</span>;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MemTableIterator</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MemTable</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// MemTables are reference counted.  The initial reference count</span></span><br><span class="line">  <span class="comment">// is zero and the caller must call Ref() at least once.</span></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">MemTable</span><span class="params">(<span class="type">const</span> InternalKeyComparator&amp; comparator)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">MemTable</span>(<span class="type">const</span> MemTable&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  MemTable&amp; <span class="keyword">operator</span>=(<span class="type">const</span> MemTable&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Increase reference count.</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Ref</span><span class="params">()</span> </span>&#123; ++refs_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Drop reference count.  Delete if no more references exist.</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Unref</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    --refs_;</span><br><span class="line">    <span class="built_in">assert</span>(refs_ &gt;= <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (refs_ &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">delete</span> <span class="keyword">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Returns an estimate of the number of bytes of data in use by this</span></span><br><span class="line">  <span class="comment">// data structure. It is safe to call when MemTable is being modified.</span></span><br><span class="line">  <span class="function"><span class="type">size_t</span> <span class="title">ApproximateMemoryUsage</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Return an iterator that yields the contents of the memtable.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// The caller must ensure that the underlying MemTable remains live</span></span><br><span class="line">  <span class="comment">// while the returned iterator is live.  The keys returned by this</span></span><br><span class="line">  <span class="comment">// iterator are internal keys encoded by AppendInternalKey in the</span></span><br><span class="line">  <span class="comment">// db/format.&#123;h,cc&#125; module.</span></span><br><span class="line">  <span class="function">Iterator* <span class="title">NewIterator</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Add an entry into memtable that maps key to value at the</span></span><br><span class="line">  <span class="comment">// specified sequence number and with the specified type.</span></span><br><span class="line">  <span class="comment">// Typically value will be empty if type==kTypeDeletion.</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">Add</span><span class="params">(SequenceNumber seq, ValueType type, <span class="type">const</span> Slice&amp; key,</span></span></span><br><span class="line"><span class="params"><span class="function">           <span class="type">const</span> Slice&amp; value)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If memtable contains a value for key, store it in *value and return true.</span></span><br><span class="line">  <span class="comment">// If memtable contains a deletion for key, store a NotFound() error</span></span><br><span class="line">  <span class="comment">// in *status and return true.</span></span><br><span class="line">  <span class="comment">// Else, return false.</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">Get</span><span class="params">(<span class="type">const</span> LookupKey&amp; key, std::string* value, Status* s)</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">MemTableIterator</span>;</span><br><span class="line">  <span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">MemTableBackwardIterator</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">KeyComparator</span> &#123;</span><br><span class="line">    <span class="type">const</span> InternalKeyComparator comparator;</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">KeyComparator</span><span class="params">(<span class="type">const</span> InternalKeyComparator&amp; c)</span> : comparator(c) &#123;</span>&#125;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> <span class="type">char</span>* a, <span class="type">const</span> <span class="type">char</span>* b)</span> <span class="type">const</span></span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">typedef</span> SkipList&lt;<span class="type">const</span> <span class="type">char</span>*, KeyComparator&gt; Table;</span><br><span class="line"></span><br><span class="line">  ~<span class="built_in">MemTable</span>();  <span class="comment">// Private since only Unref() should be used to delete it</span></span><br><span class="line"></span><br><span class="line">  KeyComparator comparator_;</span><br><span class="line">  <span class="type">int</span> refs_;</span><br><span class="line">  Arena arena_;</span><br><span class="line">  Table table_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace leveldb</span></span><br></pre></td></tr></table></figure><p>这个还是很清晰的…</p><h3 id="Put-Get-Codec"><a href="#Put-Get-Codec" class="headerlink" title="Put Get Codec"></a>Put Get Codec</h3><p>codec 需要理解 varint: <a href="https://developers.google.com/protocol-buffers/docs/encoding">https://developers.google.com/protocol-buffers/docs/encoding</a> . 数字的表示形式成为了 <code>msb + 7byte</code> 的形式。因为这实际上是个 <code>unsigned</code>, 所以不需要别的处理。如果是 <code>signed</code> 的话或许还要考虑 zigzag 来编码。</p><p>在 LevelDB 中，我们会 <code>Add(SequenceNumber s, ValueType type, const Slice&amp; key, const Slice&amp; value)</code>。但是我们在 SkipList 中，可以看到，<code>Node</code> 里面是只有 Key 的。 LevelDB 会把这四个进行 codec, 同时让我们能够高效读写，支持 <code>Get</code> 函数。</p><p>Key 编码如下：</p><ul><li><code>varint32</code> 的 key length</li><li><code>key</code> 的内容（长度为 <code>key.size()</code>）</li><li><code>(s &lt;&lt; 8) | type</code> 。type 是一个 1byte 的 enum, 表示是 Put 还是 delete，剩下的 <code>s</code> 表示操作的递增的序列号。</li><li><code>varint32</code> 的 value length</li><li><code>value</code> 的内容</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">MemTable::Add</span><span class="params">(SequenceNumber s, ValueType type, <span class="type">const</span> Slice&amp; key,</span></span></span><br><span class="line"><span class="params"><span class="function">                   <span class="type">const</span> Slice&amp; value)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Format of an entry is concatenation of:</span></span><br><span class="line">  <span class="comment">//  key_size     : varint32 of internal_key.size()</span></span><br><span class="line">  <span class="comment">//  key bytes    : char[internal_key.size()]</span></span><br><span class="line">  <span class="comment">//  value_size   : varint32 of value.size()</span></span><br><span class="line">  <span class="comment">//  value bytes  : char[value.size()]</span></span><br><span class="line">  <span class="type">size_t</span> key_size = key.<span class="built_in">size</span>();</span><br><span class="line">  <span class="type">size_t</span> val_size = value.<span class="built_in">size</span>();</span><br><span class="line">  <span class="type">size_t</span> internal_key_size = key_size + <span class="number">8</span>;</span><br><span class="line">  <span class="type">const</span> <span class="type">size_t</span> encoded_len = <span class="built_in">VarintLength</span>(internal_key_size) +</span><br><span class="line">                             internal_key_size + <span class="built_in">VarintLength</span>(val_size) +</span><br><span class="line">                             val_size;</span><br><span class="line">  <span class="type">char</span>* buf = arena_.<span class="built_in">Allocate</span>(encoded_len);</span><br><span class="line">  <span class="type">char</span>* p = <span class="built_in">EncodeVarint32</span>(buf, internal_key_size);</span><br><span class="line">  std::<span class="built_in">memcpy</span>(p, key.<span class="built_in">data</span>(), key_size);</span><br><span class="line">  p += key_size;</span><br><span class="line">  <span class="built_in">EncodeFixed64</span>(p, (s &lt;&lt; <span class="number">8</span>) | type);</span><br><span class="line">  p += <span class="number">8</span>;</span><br><span class="line">  p = <span class="built_in">EncodeVarint32</span>(p, val_size);</span><br><span class="line">  std::<span class="built_in">memcpy</span>(p, value.<span class="built_in">data</span>(), val_size);</span><br><span class="line">  <span class="built_in">assert</span>(p + val_size == buf + encoded_len);</span><br><span class="line">  table_.<span class="built_in">Insert</span>(buf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同时可以关注一下 <code>Encode</code> 的逻辑，x86 CPU 是小端序的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">EncodeFixed64</span><span class="params">(<span class="type">char</span>* dst, <span class="type">uint64_t</span> value)</span> </span>&#123;</span><br><span class="line">  <span class="type">uint8_t</span>* <span class="type">const</span> buffer = <span class="built_in">reinterpret_cast</span>&lt;<span class="type">uint8_t</span>*&gt;(dst);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Recent clang and gcc optimize this to a single mov / str instruction.</span></span><br><span class="line">  buffer[<span class="number">0</span>] = <span class="built_in">static_cast</span>&lt;<span class="type">uint8_t</span>&gt;(value);</span><br><span class="line">  buffer[<span class="number">1</span>] = <span class="built_in">static_cast</span>&lt;<span class="type">uint8_t</span>&gt;(value &gt;&gt; <span class="number">8</span>);</span><br><span class="line">  buffer[<span class="number">2</span>] = <span class="built_in">static_cast</span>&lt;<span class="type">uint8_t</span>&gt;(value &gt;&gt; <span class="number">16</span>);</span><br><span class="line">  buffer[<span class="number">3</span>] = <span class="built_in">static_cast</span>&lt;<span class="type">uint8_t</span>&gt;(value &gt;&gt; <span class="number">24</span>);</span><br><span class="line">  buffer[<span class="number">4</span>] = <span class="built_in">static_cast</span>&lt;<span class="type">uint8_t</span>&gt;(value &gt;&gt; <span class="number">32</span>);</span><br><span class="line">  buffer[<span class="number">5</span>] = <span class="built_in">static_cast</span>&lt;<span class="type">uint8_t</span>&gt;(value &gt;&gt; <span class="number">40</span>);</span><br><span class="line">  buffer[<span class="number">6</span>] = <span class="built_in">static_cast</span>&lt;<span class="type">uint8_t</span>&gt;(value &gt;&gt; <span class="number">48</span>);</span><br><span class="line">  buffer[<span class="number">7</span>] = <span class="built_in">static_cast</span>&lt;<span class="type">uint8_t</span>&gt;(value &gt;&gt; <span class="number">56</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同时需要注意具体的 Comparator:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">InternalKeyComparator::Compare</span><span class="params">(<span class="type">const</span> Slice&amp; akey, <span class="type">const</span> Slice&amp; bkey)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Order by:</span></span><br><span class="line">  <span class="comment">//    increasing user key (according to user-supplied comparator)</span></span><br><span class="line">  <span class="comment">//    decreasing sequence number</span></span><br><span class="line">  <span class="comment">//    decreasing type (though sequence# should be enough to disambiguate)</span></span><br><span class="line">  <span class="type">int</span> r = user_comparator_-&gt;<span class="built_in">Compare</span>(<span class="built_in">ExtractUserKey</span>(akey), <span class="built_in">ExtractUserKey</span>(bkey));</span><br><span class="line">  <span class="keyword">if</span> (r == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">uint64_t</span> anum = <span class="built_in">DecodeFixed64</span>(akey.<span class="built_in">data</span>() + akey.<span class="built_in">size</span>() - <span class="number">8</span>);</span><br><span class="line">    <span class="type">const</span> <span class="type">uint64_t</span> bnum = <span class="built_in">DecodeFixed64</span>(bkey.<span class="built_in">data</span>() + bkey.<span class="built_in">size</span>() - <span class="number">8</span>);</span><br><span class="line">    <span class="keyword">if</span> (anum &gt; bnum) &#123;</span><br><span class="line">      r = <span class="number">-1</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (anum &lt; bnum) &#123;</span><br><span class="line">      r = +<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>具体 Get 的时候，代码如下：</p><ul><li>某一个 key 长度是一定的，很容易构造同样的 key_length 和 key, 尝试在 SkipList 中 调用 Seek, 找到 Key</li><li>我们使用的编码是 7byte 的 seq, 1byte 的 put/del flag，所以 Seek 会尝试找到<ul><li>如果 user_key 不一样，即本 key 不存在</li><li>存在的话，能够保证 Seek 到的是最新版本，或是给定 seq 内的最新版本。判断 type 并读出 value 即可。</li></ul></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">MemTable::Get</span><span class="params">(<span class="type">const</span> LookupKey&amp; key, std::string* value, Status* s)</span> </span>&#123;</span><br><span class="line">  Slice memkey = key.<span class="built_in">memtable_key</span>();</span><br><span class="line">  <span class="function">Table::Iterator <span class="title">iter</span><span class="params">(&amp;table_)</span></span>;</span><br><span class="line">  iter.<span class="built_in">Seek</span>(memkey.<span class="built_in">data</span>());</span><br><span class="line">  <span class="keyword">if</span> (iter.<span class="built_in">Valid</span>()) &#123;</span><br><span class="line">    <span class="comment">// entry format is:</span></span><br><span class="line">    <span class="comment">//    klength  varint32</span></span><br><span class="line">    <span class="comment">//    userkey  char[klength]</span></span><br><span class="line">    <span class="comment">//    tag      uint64</span></span><br><span class="line">    <span class="comment">//    vlength  varint32</span></span><br><span class="line">    <span class="comment">//    value    char[vlength]</span></span><br><span class="line">    <span class="comment">// Check that it belongs to same user key.  We do not check the</span></span><br><span class="line">    <span class="comment">// sequence number since the Seek() call above should have skipped</span></span><br><span class="line">    <span class="comment">// all entries with overly large sequence numbers.</span></span><br><span class="line">    <span class="type">const</span> <span class="type">char</span>* entry = iter.<span class="built_in">key</span>();</span><br><span class="line">    <span class="type">uint32_t</span> key_length;</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span>* key_ptr = <span class="built_in">GetVarint32Ptr</span>(entry, entry + <span class="number">5</span>, &amp;key_length);</span><br><span class="line">    <span class="keyword">if</span> (comparator_.comparator.<span class="built_in">user_comparator</span>()-&gt;<span class="built_in">Compare</span>(</span><br><span class="line">            <span class="built_in">Slice</span>(key_ptr, key_length - <span class="number">8</span>), key.<span class="built_in">user_key</span>()) == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// Correct user key</span></span><br><span class="line">      <span class="type">const</span> <span class="type">uint64_t</span> tag = <span class="built_in">DecodeFixed64</span>(key_ptr + key_length - <span class="number">8</span>);</span><br><span class="line">      <span class="keyword">switch</span> (<span class="built_in">static_cast</span>&lt;ValueType&gt;(tag &amp; <span class="number">0xff</span>)) &#123;</span><br><span class="line">        <span class="keyword">case</span> kTypeValue: &#123;</span><br><span class="line">          Slice v = <span class="built_in">GetLengthPrefixedSlice</span>(key_ptr + key_length);</span><br><span class="line">          value-&gt;<span class="built_in">assign</span>(v.<span class="built_in">data</span>(), v.<span class="built_in">size</span>());</span><br><span class="line">          <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">case</span> kTypeDeletion:</span><br><span class="line">          *s = Status::<span class="built_in">NotFound</span>(<span class="built_in">Slice</span>());</span><br><span class="line">          <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LevelDB Log: WAL of LSMTree C0</title>
      <link href="/2020/05/29/LevelDB-Log-WAL-of-LSMTree-C0/"/>
      <url>/2020/05/29/LevelDB-Log-WAL-of-LSMTree-C0/</url>
      
        <content type="html"><![CDATA[<p>如果对 WAL 这个名词陌生的话…我想这篇文章的读者应该不会真的没听过 WAL 吧…</p><p>实际上数据库的 WAL 还是比较难阅读的，以 B+Tree + Undo/Redo Log 为例，Log 的 Undo/Redo 和 checkout point, GC 本身有比较大的复杂性，这给阅读带来了很大的困难。</p><p>LevelDB 的结构是 LSMTree, LSMTree 原论文中，它的结构如下：</p><p><img src="https://image.mwish.me/blog-image/9F1865E8-603E-4385-B237-C776166512E8.png" alt="9F1865E8-603E-4385-B237-C776166512E8"></p><p>这是论文中的 figure 2.1, 我们可以看到C0 是在内存中的。也就是说，LevelDB 有相对简单的 WAL，作为写 memtable 之前写入的日志。</p><p>我们需要关注的是：</p><ol><li>日志的结构是什么样的</li><li>日志是什么时候开始写，有什么时候删除的</li><li>对于盘的故障，日志怎么处理</li><li>日志命名策略是什么</li></ol><hr><h3 id="日志的结构"><a href="#日志的结构" class="headerlink" title="日志的结构"></a>日志的结构</h3><p>关于问题1，最好的阅读地点是：<a href="https://github.com/google/leveldb/blob/master/doc/log_format.md">https://github.com/google/leveldb/blob/master/doc/log_format.md</a></p><p>大概有这样的逻辑关系：</p><ol><li>The <strong>log file</strong> contents are a sequence of <em>32KB</em> blocks. The only exception is that the tail of the file may contain a partial block.</li><li>Each block consists of a sequence of records:</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">block := record* trailer?</span><br><span class="line">record :=</span><br><span class="line">  checksum: uint32     // crc32c of type and data[] ; little-endian</span><br><span class="line">  length: uint16       // little-endian</span><br><span class="line">  type: uint8          // One of FULL, FIRST, MIDDLE, LAST</span><br><span class="line">  data: uint8[length]</span><br></pre></td></tr></table></figure><p>总结一下：</p><ul><li>日志文件是可能的一个 header 加上若干个 block</li><li>每个 block 结构这个有点像正则表达式，包含 <code>*</code> 个 record 和可能存在的 trailer</li><li>每个 record 包含 crc32, little-endian 的 length, 一个类型和具体的 byte 数据</li></ul><blockquote><p>A record never starts within the last six bytes of a block (since it won’t fit). Any leftover bytes here form the trailer, which must consist entirely of zero bytes and must be skipped by readers.</p></blockquote><ul><li><code>trailer</code> 如上述内容，相当于是尾部的 padding，上一块的内容小于6即可跳过这些 padding。</li></ul><blockquote><p> 为什么是 7byte</p></blockquote><p>可以贴一下<code>db/log_format.h</code> 的代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Copyright (c) 2011 The LevelDB Authors. All rights reserved.</span></span><br><span class="line"><span class="comment">// Use of this source code is governed by a BSD-style license that can be</span></span><br><span class="line"><span class="comment">// found in the LICENSE file. See the AUTHORS file for names of contributors.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Log format information shared by reader and writer.</span></span><br><span class="line"><span class="comment">// See ../doc/log_format.md for more detail.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifndef</span> STORAGE_LEVELDB_DB_LOG_FORMAT_H_</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> STORAGE_LEVELDB_DB_LOG_FORMAT_H_</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> leveldb &#123;</span><br><span class="line"><span class="keyword">namespace</span> log &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">RecordType</span> &#123;</span><br><span class="line">  <span class="comment">// Zero is reserved for preallocated files</span></span><br><span class="line">  kZeroType = <span class="number">0</span>,</span><br><span class="line"></span><br><span class="line">  kFullType = <span class="number">1</span>,</span><br><span class="line"></span><br><span class="line">  <span class="comment">// For fragments</span></span><br><span class="line">  kFirstType = <span class="number">2</span>,</span><br><span class="line">  kMiddleType = <span class="number">3</span>,</span><br><span class="line">  kLastType = <span class="number">4</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="type">static</span> <span class="type">const</span> <span class="type">int</span> kMaxRecordType = kLastType;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">const</span> <span class="type">int</span> kBlockSize = <span class="number">32768</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Header is checksum (4 bytes), length (2 bytes), type (1 byte).</span></span><br><span class="line"><span class="type">static</span> <span class="type">const</span> <span class="type">int</span> kHeaderSize = <span class="number">4</span> + <span class="number">2</span> + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace log</span></span><br><span class="line">&#125;  <span class="comment">// namespace leveldb</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span>  <span class="comment">// STORAGE_LEVELDB_DB_LOG_FORMAT_H_</span></span></span><br></pre></td></tr></table></figure><ul><li><code>kBlockSize</code> 是 32k, 即<code>32 * 1024 = 32768</code></li><li><code>RecordType</code> 是个 <code>enum</code>, 有下列几种类型。<code>enum</code> 在 C++ 默认是 int, 不过似乎它就用了一位<ul><li><code>kFullType</code> 全记录</li><li><code>kFirstType</code> <code>kMiddleType</code> <code>kLastType</code>: 截断的记录的 <code>first, middle..., last</code></li><li><code>kZeroType</code> 不了解</li></ul></li><li><code>kHeaderSize</code> 包含 checksum, length, type。长度如前文所述。</li></ul><p>关于 first middle last 还可以参考文档：</p><blockquote><p>Example: consider a sequence of user records:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">A: length 1000</span><br><span class="line">B: length 97270</span><br><span class="line">C: length 8000</span><br></pre></td></tr></table></figure><p><strong>A</strong> will be stored as a FULL record in the first block.</p><p><strong>B</strong> will be split into three fragments: first fragment occupies the rest of the first block, second fragment occupies the entirety of the second block, and the third fragment occupies a prefix of the third block. This will leave six bytes free in the third block, which will be left empty as the trailer.</p><p><strong>C</strong> will be stored as a FULL record in the fourth block.</p></blockquote><p>（吐槽一下，这么大的 kv，内存肯定一次分配了hhh）</p><h3 id="filename"><a href="#filename" class="headerlink" title="filename"></a>filename</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::string <span class="title">LogFileName</span><span class="params">(<span class="type">const</span> std::string&amp; dbname, <span class="type">uint64_t</span> number)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">assert</span>(number &gt; <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">MakeFileName</span>(dbname, number, <span class="string">&quot;log&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着看</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> std::string <span class="title">MakeFileName</span><span class="params">(<span class="type">const</span> std::string&amp; dbname, <span class="type">uint64_t</span> number,</span></span></span><br><span class="line"><span class="params"><span class="function">                                <span class="type">const</span> <span class="type">char</span>* suffix)</span> </span>&#123;</span><br><span class="line">  <span class="type">char</span> buf[<span class="number">100</span>];</span><br><span class="line">  std::<span class="built_in">snprintf</span>(buf, <span class="built_in">sizeof</span>(buf), <span class="string">&quot;/%06llu.%s&quot;</span>,</span><br><span class="line">                <span class="built_in">static_cast</span>&lt;<span class="type">unsigned</span> <span class="type">long</span> <span class="type">long</span>&gt;(number), suffix);</span><br><span class="line">  <span class="keyword">return</span> dbname + buf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以 <code>dbname_number.log</code> 形式保存文件</p><h3 id="Log-与-Writer"><a href="#Log-与-Writer" class="headerlink" title="Log 与 Writer"></a>Log 与 Writer</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> leveldb &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WritableFile</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> log &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Writer</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// Create a writer that will append data to &quot;*dest&quot;.</span></span><br><span class="line">  <span class="comment">// &quot;*dest&quot; must be initially empty.</span></span><br><span class="line">  <span class="comment">// &quot;*dest&quot; must remain live while this Writer is in use.</span></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">Writer</span><span class="params">(WritableFile* dest)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Create a writer that will append data to &quot;*dest&quot;.</span></span><br><span class="line">  <span class="comment">// &quot;*dest&quot; must have initial length &quot;dest_length&quot;.</span></span><br><span class="line">  <span class="comment">// &quot;*dest&quot; must remain live while this Writer is in use.</span></span><br><span class="line">  <span class="built_in">Writer</span>(WritableFile* dest, <span class="type">uint64_t</span> dest_length);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">Writer</span>(<span class="type">const</span> Writer&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  Writer&amp; <span class="keyword">operator</span>=(<span class="type">const</span> Writer&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">  ~<span class="built_in">Writer</span>();</span><br><span class="line"></span><br><span class="line">  <span class="function">Status <span class="title">AddRecord</span><span class="params">(<span class="type">const</span> Slice&amp; slice)</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="function">Status <span class="title">EmitPhysicalRecord</span><span class="params">(RecordType type, <span class="type">const</span> <span class="type">char</span>* ptr, <span class="type">size_t</span> length)</span></span>;</span><br><span class="line"></span><br><span class="line">  WritableFile* dest_;</span><br><span class="line">  <span class="type">int</span> block_offset_;  <span class="comment">// Current offset in block</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// crc32c values for all supported record types.  These are</span></span><br><span class="line">  <span class="comment">// pre-computed to reduce the overhead of computing the crc of the</span></span><br><span class="line">  <span class="comment">// record type stored in the header.</span></span><br><span class="line">  <span class="type">uint32_t</span> type_crc_[kMaxRecordType + <span class="number">1</span>];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">&#125;  <span class="comment">// namespace log</span></span><br><span class="line">&#125;  <span class="comment">// namespace leveldb</span></span><br></pre></td></tr></table></figure><ul><li>带 <code>dest_length</code> 的相当于对 file 自带一定的 <code>offset</code></li><li><code>AddRecord</code> 是 public 的，外部交给它添加日志</li><li><code>EmitPhysicalRecord</code> 是实际写入的函数</li></ul><p>添加日志代码如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">Writer::AddRecord</span><span class="params">(<span class="type">const</span> Slice&amp; slice)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// left is for slice.</span></span><br><span class="line">  <span class="type">const</span> <span class="type">char</span>* ptr = slice.<span class="built_in">data</span>();</span><br><span class="line">  <span class="type">size_t</span> left = slice.<span class="built_in">size</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Fragment the record if necessary and emit it.  Note that if slice</span></span><br><span class="line">  <span class="comment">// is empty, we still want to iterate once to emit a single</span></span><br><span class="line">  <span class="comment">// zero-length record</span></span><br><span class="line">  Status s;</span><br><span class="line">  <span class="type">bool</span> begin = <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> leftover = kBlockSize - block_offset_;</span><br><span class="line">    <span class="built_in">assert</span>(leftover &gt;= <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// &lt; 7 byte, just padding it.</span></span><br><span class="line">    <span class="keyword">if</span> (leftover &lt; kHeaderSize) &#123;</span><br><span class="line">      <span class="comment">// Switch to a new block</span></span><br><span class="line">      <span class="keyword">if</span> (leftover &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// Fill the trailer (literal below relies on kHeaderSize being 7)</span></span><br><span class="line">        <span class="built_in">static_assert</span>(kHeaderSize == <span class="number">7</span>, <span class="string">&quot;&quot;</span>);</span><br><span class="line">        dest_-&gt;<span class="built_in">Append</span>(<span class="built_in">Slice</span>(<span class="string">&quot;\x00\x00\x00\x00\x00\x00&quot;</span>, leftover));</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// to a new block.</span></span><br><span class="line">      block_offset_ = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Invariant: we never leave &lt; kHeaderSize bytes in a block.</span></span><br><span class="line">    <span class="built_in">assert</span>(kBlockSize - block_offset_ - kHeaderSize &gt;= <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 目前 block 中可写入的量</span></span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> avail = kBlockSize - block_offset_ - kHeaderSize;</span><br><span class="line">    <span class="comment">// 目前这个 block 中需要写入的数据量</span></span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> fragment_length = (left &lt; avail) ? left : avail;</span><br><span class="line"></span><br><span class="line">    RecordType type;</span><br><span class="line">    <span class="comment">// end 表示在这个 block 内能否写完</span></span><br><span class="line">    <span class="type">const</span> <span class="type">bool</span> end = (left == fragment_length);</span><br><span class="line">    <span class="keyword">if</span> (begin &amp;&amp; end) &#123;</span><br><span class="line">      type = kFullType;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (begin) &#123;</span><br><span class="line">      type = kFirstType;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (end) &#123;</span><br><span class="line">      type = kLastType;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      type = kMiddleType;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    s = <span class="built_in">EmitPhysicalRecord</span>(type, ptr, fragment_length);</span><br><span class="line">    ptr += fragment_length;</span><br><span class="line">    left -= fragment_length;</span><br><span class="line">    begin = <span class="literal">false</span>;</span><br><span class="line">  &#125; <span class="keyword">while</span> (s.<span class="built_in">ok</span>() &amp;&amp; left &gt; <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">Writer::EmitPhysicalRecord</span><span class="params">(RecordType t, <span class="type">const</span> <span class="type">char</span>* ptr,</span></span></span><br><span class="line"><span class="params"><span class="function">                                  <span class="type">size_t</span> length)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">assert</span>(length &lt;= <span class="number">0xffff</span>);  <span class="comment">// Must fit in two bytes</span></span><br><span class="line">  <span class="built_in">assert</span>(block_offset_ + kHeaderSize + length &lt;= kBlockSize);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Format the header</span></span><br><span class="line">  <span class="type">char</span> buf[kHeaderSize];</span><br><span class="line">  buf[<span class="number">4</span>] = <span class="built_in">static_cast</span>&lt;<span class="type">char</span>&gt;(length &amp; <span class="number">0xff</span>);</span><br><span class="line">  buf[<span class="number">5</span>] = <span class="built_in">static_cast</span>&lt;<span class="type">char</span>&gt;(length &gt;&gt; <span class="number">8</span>);</span><br><span class="line">  buf[<span class="number">6</span>] = <span class="built_in">static_cast</span>&lt;<span class="type">char</span>&gt;(t);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Compute the crc of the record type and the payload.</span></span><br><span class="line">  <span class="type">uint32_t</span> crc = crc32c::<span class="built_in">Extend</span>(type_crc_[t], ptr, length);</span><br><span class="line">  crc = crc32c::<span class="built_in">Mask</span>(crc);  <span class="comment">// Adjust for storage</span></span><br><span class="line">  <span class="built_in">EncodeFixed32</span>(buf, crc);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Write the header and the payload</span></span><br><span class="line">  Status s = dest_-&gt;<span class="built_in">Append</span>(<span class="built_in">Slice</span>(buf, kHeaderSize));</span><br><span class="line">  <span class="keyword">if</span> (s.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">    s = dest_-&gt;<span class="built_in">Append</span>(<span class="built_in">Slice</span>(ptr, length));</span><br><span class="line">    <span class="keyword">if</span> (s.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">      s = dest_-&gt;<span class="built_in">Flush</span>();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  block_offset_ += kHeaderSize + length;</span><br><span class="line">  <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我感觉没啥好说的，这代码真的很好理解，我加的注释都感觉很多余…</p><p><code>EmitPhysicalRecord</code>如果写坏了（即 <code>s.ok</code> 不满足），会直接跳过这条记录</p><h3 id="Reader"><a href="#Reader" class="headerlink" title="Reader"></a>Reader</h3><p><code>Reader</code> 代码相对会复杂很多，这里简单介绍一下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Reader</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// Interface for reporting errors.</span></span><br><span class="line">  <span class="keyword">class</span> <span class="title class_">Reporter</span> &#123;</span><br><span class="line">   <span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">virtual</span> ~<span class="built_in">Reporter</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Some corruption was detected.  &quot;size&quot; is the approximate number</span></span><br><span class="line">    <span class="comment">// of bytes dropped due to the corruption.</span></span><br><span class="line">    <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">Corruption</span><span class="params">(<span class="type">size_t</span> bytes, <span class="type">const</span> Status&amp; status)</span> </span>= <span class="number">0</span>;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Create a reader that will return log records from &quot;*file&quot;.</span></span><br><span class="line">  <span class="comment">// &quot;*file&quot; must remain live while this Reader is in use.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// If &quot;reporter&quot; is non-null, it is notified whenever some data is</span></span><br><span class="line">  <span class="comment">// dropped due to a detected corruption.  &quot;*reporter&quot; must remain</span></span><br><span class="line">  <span class="comment">// live while this Reader is in use.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// If &quot;checksum&quot; is true, verify checksums if available.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// The Reader will start reading at the first record located at physical</span></span><br><span class="line">  <span class="comment">// position &gt;= initial_offset within the file.</span></span><br><span class="line">  <span class="built_in">Reader</span>(SequentialFile* file, Reporter* reporter, <span class="type">bool</span> checksum,</span><br><span class="line">         <span class="type">uint64_t</span> initial_offset);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">Reader</span>(<span class="type">const</span> Reader&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  Reader&amp; <span class="keyword">operator</span>=(<span class="type">const</span> Reader&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">  ~<span class="built_in">Reader</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Read the next record into *record.  Returns true if read</span></span><br><span class="line">  <span class="comment">// successfully, false if we hit end of the input.  May use</span></span><br><span class="line">  <span class="comment">// &quot;*scratch&quot; as temporary storage.  The contents filled in *record</span></span><br><span class="line">  <span class="comment">// will only be valid until the next mutating operation on this</span></span><br><span class="line">  <span class="comment">// reader or the next mutation to *scratch.</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">ReadRecord</span><span class="params">(Slice* record, std::string* scratch)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Returns the physical offset of the last record returned by ReadRecord.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Undefined before the first call to ReadRecord.</span></span><br><span class="line">  <span class="function"><span class="type">uint64_t</span> <span class="title">LastRecordOffset</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// Extend record types with the following special values</span></span><br><span class="line">  <span class="keyword">enum</span> &#123;</span><br><span class="line">    kEof = kMaxRecordType + <span class="number">1</span>,</span><br><span class="line">    <span class="comment">// Returned whenever we find an invalid physical record.</span></span><br><span class="line">    <span class="comment">// Currently there are three situations in which this happens:</span></span><br><span class="line">    <span class="comment">// * The record has an invalid CRC (ReadPhysicalRecord reports a drop)</span></span><br><span class="line">    <span class="comment">// * The record is a 0-length record (No drop is reported)</span></span><br><span class="line">    <span class="comment">// * The record is below constructor&#x27;s initial_offset (No drop is reported)</span></span><br><span class="line">    kBadRecord = kMaxRecordType + <span class="number">2</span></span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Skips all blocks that are completely before &quot;initial_offset_&quot;.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Returns true on success. Handles reporting.</span></span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">SkipToInitialBlock</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 返回 kMaxRecordType 定义的 type 或者 eof</span></span><br><span class="line">  <span class="comment">// Return type, or one of the preceding special values</span></span><br><span class="line">  <span class="function"><span class="type">unsigned</span> <span class="type">int</span> <span class="title">ReadPhysicalRecord</span><span class="params">(Slice* result)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Reports dropped bytes to the reporter.</span></span><br><span class="line">  <span class="comment">// buffer_ must be updated to remove the dropped bytes prior to invocation.</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">ReportCorruption</span><span class="params">(<span class="type">uint64_t</span> bytes, <span class="type">const</span> <span class="type">char</span>* reason)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">ReportDrop</span><span class="params">(<span class="type">uint64_t</span> bytes, <span class="type">const</span> Status&amp; reason)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// SequentialFile,  * const 即不会指向别的对象</span></span><br><span class="line">  SequentialFile* <span class="type">const</span> file_;</span><br><span class="line">  <span class="comment">// Reporter 上报事件</span></span><br><span class="line">  Reporter* <span class="type">const</span> reporter_;</span><br><span class="line">  <span class="comment">// 是否使用 checksum</span></span><br><span class="line">  <span class="type">bool</span> <span class="type">const</span> checksum_;</span><br><span class="line">  <span class="comment">// 感觉上 backing_store_ 是一个 kBlockSize 大小的数组</span></span><br><span class="line">  <span class="comment">// 用来存放读到的信息。</span></span><br><span class="line">  <span class="type">char</span>* <span class="type">const</span> backing_store_;</span><br><span class="line">  <span class="comment">// 读 buffer, 指向 backing_store</span></span><br><span class="line">  Slice buffer_;</span><br><span class="line">  <span class="comment">// EOF 处理</span></span><br><span class="line">  <span class="type">bool</span> eof_;  <span class="comment">// Last Read() indicated EOF by returning &lt; kBlockSize</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 文件中 last_record 读的 offset</span></span><br><span class="line">  <span class="comment">// Offset of the last record returned by ReadRecord.</span></span><br><span class="line">  <span class="type">uint64_t</span> last_record_offset_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 维护的 buffer 的 offset</span></span><br><span class="line">  <span class="comment">// Offset of the first location past the end of buffer_.</span></span><br><span class="line">  <span class="type">uint64_t</span> end_of_buffer_offset_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The Reader will start reading at the first record located at physical</span></span><br><span class="line">  <span class="comment">//   position &gt;= initial_offset within the file.</span></span><br><span class="line">  <span class="comment">// Offset at which to start looking for the first record to return</span></span><br><span class="line">  <span class="type">uint64_t</span> <span class="type">const</span> initial_offset_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// True if we are resynchronizing after a seek (initial_offset_ &gt; 0). In</span></span><br><span class="line">  <span class="comment">// particular, a run of kMiddleType and kLastType records can be silently</span></span><br><span class="line">  <span class="comment">// skipped in this mode</span></span><br><span class="line">  <span class="comment">// 是否需要重新同步，通常因为 initial_offset_ seek 之后导致</span></span><br><span class="line">  <span class="type">bool</span> resyncing_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ul><li>外部调用 read-offset 来读取信息</li><li><code>backing_store_</code> 和 <code>buffer_</code> 用来管理读到的信息，<code>end_of_buffer_offset_</code> 是标注<code>buffer_</code> 读到的信息的 length 的</li><li><code>eof_</code> 表示读取是否是 <code>eof</code> 状态</li><li><code>initial_offset_</code> 表示最初跳过的 offset, 实现的时候为了对齐之类的理由不会直接 seek 到对应位置，而是 seek 到 block 的开头，然后 <code>resyncing_</code> 。</li></ul><p>reader 构造函数如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Reader::<span class="built_in">Reader</span>(SequentialFile* file, Reporter* reporter, <span class="type">bool</span> checksum,</span><br><span class="line">               <span class="type">uint64_t</span> initial_offset)</span><br><span class="line">    : <span class="built_in">file_</span>(file),</span><br><span class="line">      <span class="built_in">reporter_</span>(reporter),</span><br><span class="line">      <span class="built_in">checksum_</span>(checksum),</span><br><span class="line">      <span class="built_in">backing_store_</span>(<span class="keyword">new</span> <span class="type">char</span>[kBlockSize]),</span><br><span class="line">      <span class="built_in">buffer_</span>(),</span><br><span class="line">      <span class="built_in">eof_</span>(<span class="literal">false</span>),</span><br><span class="line">      <span class="built_in">last_record_offset_</span>(<span class="number">0</span>),</span><br><span class="line">      <span class="built_in">end_of_buffer_offset_</span>(<span class="number">0</span>),</span><br><span class="line">      <span class="built_in">initial_offset_</span>(initial_offset),</span><br><span class="line">      <span class="built_in">resyncing_</span>(initial_offset &gt; <span class="number">0</span>) &#123;&#125;</span><br></pre></td></tr></table></figure><p>其实比较有意思的是 <code>backing_store_</code> 的初始化，为什么要在堆上捏=，=我也不太了解</p><p>读流程大致如下，可以参考 <code>ReadRecord</code> 和 <code>ReadPhysicalRecord</code>：</p><ul><li>尝试seek到 block 的开头，然后每次读取的时候，读取一个 block。数据会被读取到 <code>backing_store_</code> 里，并以 <code>buffer_</code> 的形式访问</li><li>在<code>buffer_</code> 中还有足够内容的时候，从里面读取 <code>record</code></li><li>读取不完整的话会写入到 <code>scratch</code> 里，<code>ReadRecord</code> 实现了一个类似状态机的模型，最后会把 <code>record</code> 完整吐出来。</li></ul><h3 id="日志与错误处理"><a href="#日志与错误处理" class="headerlink" title="日志与错误处理"></a>日志与错误处理</h3><p>大部分错误处理我觉得看 reader 代码能学到不少。</p><p>文档里还提到了和 <code>RecordIO Data Format</code> 的对比：<a href="http://mesos.apache.org/documentation/latest/recordio/">http://mesos.apache.org/documentation/latest/recordio/</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LevelDB Arena: memory of skiplist</title>
      <link href="/2020/05/25/LevelDB-Arena-memory-of-skiplist/"/>
      <url>/2020/05/25/LevelDB-Arena-memory-of-skiplist/</url>
      
        <content type="html"><![CDATA[<p><code>Arena</code> 的英文意思大概是</p><blockquote><p>An <strong>arena</strong> is an enclosed area that showcases theatre, musical performances or sporting events.</p></blockquote><p>在 LevelDB 中，<code>Arena</code> 是给 SkipList 提供内存来源的，SkipList 会提供 <code>key-value</code> 的数据。同时，SkipList 是 mvcc 的，它在 Minor Compaction 的时候，才会去掉一些 deleted data, 这意味着 SkipList 在内存中只会 “尝试增加内存”。</p><p>同时，<code>key-value</code> （再加上版本）一般也不会特别大，如果大的话可以参考 WiscKey 的文章，这里转发一篇别人写的博客：</p><ul><li><a href="https://zhuanlan.zhihu.com/p/30953751">https://zhuanlan.zhihu.com/p/30953751</a></li></ul><p>以上两点需求可以帮助我们了解 <code>Arena</code> 的需求：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Arena</span> &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">Arena</span>();</span><br><span class="line"></span><br><span class="line">  <span class="built_in">Arena</span>(<span class="type">const</span> Arena&amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  Arena&amp; <span class="keyword">operator</span>=(<span class="type">const</span> Arena&amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">  ~<span class="built_in">Arena</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Return a pointer to a newly allocated memory block of &quot;bytes&quot; bytes.</span></span><br><span class="line">  <span class="function"><span class="type">char</span>* <span class="title">Allocate</span><span class="params">(<span class="type">size_t</span> bytes)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Allocate memory with the normal alignment guarantees provided by malloc.</span></span><br><span class="line">  <span class="function"><span class="type">char</span>* <span class="title">AllocateAligned</span><span class="params">(<span class="type">size_t</span> bytes)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Returns an estimate of the total memory usage of data allocated</span></span><br><span class="line">  <span class="comment">// by the arena.</span></span><br><span class="line">  <span class="function"><span class="type">size_t</span> <span class="title">MemoryUsage</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> memory_usage_.<span class="built_in">load</span>(std::memory_order_relaxed);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="type">char</span>* <span class="title">AllocateFallback</span><span class="params">(<span class="type">size_t</span> bytes)</span></span>;</span><br><span class="line">  <span class="function"><span class="type">char</span>* <span class="title">AllocateNewBlock</span><span class="params">(<span class="type">size_t</span> block_bytes)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Allocation state</span></span><br><span class="line">  <span class="type">char</span>* alloc_ptr_;</span><br><span class="line">  <span class="type">size_t</span> alloc_bytes_remaining_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Array of new[] allocated memory blocks</span></span><br><span class="line">  std::vector&lt;<span class="type">char</span>*&gt; blocks_;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Total memory usage of the arena.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// TODO(costan): This member is accessed via atomics, but the others are</span></span><br><span class="line">  <span class="comment">//               accessed without any locking. Is this OK?</span></span><br><span class="line">  std::atomic&lt;<span class="type">size_t</span>&gt; memory_usage_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ul><li>skiplist 可以拿到对应的 arena, arena 负责申请内存</li><li><code>MemoryUsage</code> 返回 <code>Arena</code> 总共申请的内存</li><li><code>Allocate</code> 和 <code>AllocateAlign</code> 给 skiplist 申请内存，也防止内存的碎片化</li></ul><p>有一点问题是，看上去 <code>Arena</code> 使用似乎是单线程的。</p><h2 id="申请流程"><a href="#申请流程" class="headerlink" title="申请流程"></a>申请流程</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">const</span> <span class="type">int</span> kBlockSize = <span class="number">4096</span>;</span><br><span class="line"></span><br><span class="line">Arena::<span class="built_in">Arena</span>()</span><br><span class="line">    : <span class="built_in">alloc_ptr_</span>(<span class="literal">nullptr</span>), <span class="built_in">alloc_bytes_remaining_</span>(<span class="number">0</span>), <span class="built_in">memory_usage_</span>(<span class="number">0</span>) &#123;&#125;</span><br><span class="line"></span><br><span class="line">Arena::~<span class="built_in">Arena</span>() &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; blocks_.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">    <span class="keyword">delete</span>[] blocks_[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>Arena</code> 在 <code>blocks_</code> 中管理自己的内存，<code>alloc_ptr_</code> 指向现在管理的 <code>block</code>, <code>alloc_bytes_remaining_</code> 管理现有 <code>block</code> 剩余的内存</p><p>下面是 allocate 的流程：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">char</span>* <span class="title">Arena::Allocate</span><span class="params">(<span class="type">size_t</span> bytes)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// The semantics of what to return are a bit messy if we allow</span></span><br><span class="line">  <span class="comment">// 0-byte allocations, so we disallow them here (we don&#x27;t need</span></span><br><span class="line">  <span class="comment">// them for our internal use).</span></span><br><span class="line">  <span class="built_in">assert</span>(bytes &gt; <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">if</span> (bytes &lt;= alloc_bytes_remaining_) &#123;</span><br><span class="line">    <span class="type">char</span>* result = alloc_ptr_;</span><br><span class="line">    alloc_ptr_ += bytes;</span><br><span class="line">    alloc_bytes_remaining_ -= bytes;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">AllocateFallback</span>(bytes);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>现有的 <code>alloc_bytes_remaining_</code> 有空间，会直接尝试返回</li><li>否则进入 <code>AllocateFallback</code></li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">char</span>* <span class="title">Arena::AllocateFallback</span><span class="params">(<span class="type">size_t</span> bytes)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (bytes &gt; kBlockSize / <span class="number">4</span>) &#123;</span><br><span class="line">    <span class="comment">// Object is more than a quarter of our block size.  Allocate it separately</span></span><br><span class="line">    <span class="comment">// to avoid wasting too much space in leftover bytes.</span></span><br><span class="line">    <span class="type">char</span>* result = <span class="built_in">AllocateNewBlock</span>(bytes);</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// We waste the remaining space in the current block.</span></span><br><span class="line">  alloc_ptr_ = <span class="built_in">AllocateNewBlock</span>(kBlockSize);</span><br><span class="line">  alloc_bytes_remaining_ = kBlockSize;</span><br><span class="line"></span><br><span class="line">  <span class="type">char</span>* result = alloc_ptr_;</span><br><span class="line">  alloc_ptr_ += bytes;</span><br><span class="line">  alloc_bytes_remaining_ -= bytes;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 <code>AllocateFallback</code> 中逻辑是：</p><ul><li>如果申请内存过大（大于 <code>kBlockSize / 4</code>）即直接申请新的块返回</li><li>否则 <code>AllocateNewBlock</code>, 同时把现有的指针指向新的 block</li></ul><p>注意的一点是，内存过大的时候，不会改变 <code>alloc_ptr_</code>，也就是说，插入了新的 <code>block_</code>, 但是不改变现有的 <code>alloc_ptr_</code>。</p><p>对于申请 new block, 代码很简单：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">char</span>* <span class="title">Arena::AllocateNewBlock</span><span class="params">(<span class="type">size_t</span> block_bytes)</span> </span>&#123;</span><br><span class="line">  <span class="type">char</span>* result = <span class="keyword">new</span> <span class="type">char</span>[block_bytes];</span><br><span class="line">  blocks_.<span class="built_in">push_back</span>(result);</span><br><span class="line">  memory_usage_.<span class="built_in">fetch_add</span>(block_bytes + <span class="built_in">sizeof</span>(<span class="type">char</span>*),</span><br><span class="line">                          std::memory_order_relaxed);</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="一些问题"><a href="#一些问题" class="headerlink" title="一些问题"></a>一些问题</h2><ul><li>对于 <code>Allocate</code>, 假设一开始碎片化的神奇，剩下900余 bytes, 再申请一个 900+ bytes 的内存，是否会造成比较大的内存碎片？</li><li>jemalloc 之类的分配器对于处理小内存应该有比较好的方案，这个时候 <code>Arena</code> 有什么帮助。</li></ul><p>不知道有没有人能推荐便于阅读的 allocator…</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LevelDB Put: How it batch</title>
      <link href="/2020/05/25/LevelDB-Put-How-it-batch/"/>
      <url>/2020/05/25/LevelDB-Put-How-it-batch/</url>
      
        <content type="html"><![CDATA[<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Convenience methods</span></span><br><span class="line"><span class="function">Status <span class="title">DBImpl::Put</span><span class="params">(<span class="type">const</span> WriteOptions&amp; o, <span class="type">const</span> Slice&amp; key, <span class="type">const</span> Slice&amp; val)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> DB::<span class="built_in">Put</span>(o, key, val);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用的是</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Default implementations of convenience methods that subclasses of DB</span></span><br><span class="line"><span class="comment">// can call if they wish</span></span><br><span class="line"><span class="function">Status <span class="title">DB::Put</span><span class="params">(<span class="type">const</span> WriteOptions&amp; opt, <span class="type">const</span> Slice&amp; key, <span class="type">const</span> Slice&amp; value)</span> </span>&#123;</span><br><span class="line">  WriteBatch batch;</span><br><span class="line">  batch.<span class="built_in">Put</span>(key, value);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">Write</span>(opt, &amp;batch);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们先介绍一下<code>Writer</code>, 这玩意实际上是 <code>DBImpl::Writer</code></p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Information kept for every waiting writer</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">DBImpl</span>::Writer &#123;</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">Writer</span><span class="params">(port::Mutex* mu)</span></span></span><br><span class="line"><span class="function">      : batch(nullptr), sync(false), done(false), cv(mu) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  Status status;</span><br><span class="line">  WriteBatch* batch;</span><br><span class="line">  <span class="type">bool</span> sync;</span><br><span class="line">  <span class="type">bool</span> done;</span><br><span class="line">  port::CondVar cv;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ul><li><code>batch</code> 指定了一批写入的 <code>WriteBatch</code></li><li><code>cv</code> 是跨平台的 condvar（看来这个代码不是 C++11 写的），用上层的 <code>mutex_</code> 构建 cv, 来表示本次写入的状态</li><li><code>done</code> 表示写入的状态，用来交给 caller</li><li><code>sync</code> 表示写入是否强制做sync 用于喂给 callee</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DBImpl::Write</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, WriteBatch* updates)</span> </span>&#123;</span><br><span class="line">  <span class="function">Writer <span class="title">w</span><span class="params">(&amp;mutex_)</span></span>;</span><br><span class="line">  w.batch = updates;</span><br><span class="line">  w.sync = options.sync;</span><br><span class="line">  w.done = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">MutexLock <span class="title">l</span><span class="params">(&amp;mutex_)</span></span>;</span><br><span class="line">  writers_.<span class="built_in">push_back</span>(&amp;w);</span><br><span class="line">  <span class="keyword">while</span> (!w.done &amp;&amp; &amp;w != writers_.<span class="built_in">front</span>()) &#123;</span><br><span class="line">    w.cv.<span class="built_in">Wait</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (w.done) &#123;</span><br><span class="line">    <span class="keyword">return</span> w.status;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// May temporarily unlock and wait.</span></span><br><span class="line">  Status status = <span class="built_in">MakeRoomForWrite</span>(updates == <span class="literal">nullptr</span>);</span><br><span class="line">  <span class="type">uint64_t</span> last_sequence = versions_-&gt;<span class="built_in">LastSequence</span>();</span><br><span class="line">  Writer* last_writer = &amp;w;</span><br><span class="line">  <span class="keyword">if</span> (status.<span class="built_in">ok</span>() &amp;&amp; updates != <span class="literal">nullptr</span>) &#123;  <span class="comment">// nullptr batch is for compactions</span></span><br><span class="line">    WriteBatch* write_batch = <span class="built_in">BuildBatchGroup</span>(&amp;last_writer);</span><br><span class="line">    WriteBatchInternal::<span class="built_in">SetSequence</span>(write_batch, last_sequence + <span class="number">1</span>);</span><br><span class="line">    last_sequence += WriteBatchInternal::<span class="built_in">Count</span>(write_batch);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Add to log and apply to memtable.  We can release the lock</span></span><br><span class="line">    <span class="comment">// during this phase since &amp;w is currently responsible for logging</span></span><br><span class="line">    <span class="comment">// and protects against concurrent loggers and concurrent writes</span></span><br><span class="line">    <span class="comment">// into mem_.</span></span><br><span class="line">    &#123;</span><br><span class="line">      mutex_.<span class="built_in">Unlock</span>();</span><br><span class="line">      status = log_-&gt;<span class="built_in">AddRecord</span>(WriteBatchInternal::<span class="built_in">Contents</span>(write_batch));</span><br><span class="line">      <span class="type">bool</span> sync_error = <span class="literal">false</span>;</span><br><span class="line">      <span class="keyword">if</span> (status.<span class="built_in">ok</span>() &amp;&amp; options.sync) &#123;</span><br><span class="line">        status = logfile_-&gt;<span class="built_in">Sync</span>();</span><br><span class="line">        <span class="keyword">if</span> (!status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">          sync_error = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">        status = WriteBatchInternal::<span class="built_in">InsertInto</span>(write_batch, mem_);</span><br><span class="line">      &#125;</span><br><span class="line">      mutex_.<span class="built_in">Lock</span>();</span><br><span class="line">      <span class="keyword">if</span> (sync_error) &#123;</span><br><span class="line">        <span class="comment">// The state of the log file is indeterminate: the log record we</span></span><br><span class="line">        <span class="comment">// just added may or may not show up when the DB is re-opened.</span></span><br><span class="line">        <span class="comment">// So we force the DB into a mode where all future writes fail.</span></span><br><span class="line">        <span class="built_in">RecordBackgroundError</span>(status);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (write_batch == tmp_batch_) tmp_batch_-&gt;<span class="built_in">Clear</span>();</span><br><span class="line"></span><br><span class="line">    versions_-&gt;<span class="built_in">SetLastSequence</span>(last_sequence);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    Writer* ready = writers_.<span class="built_in">front</span>();</span><br><span class="line">    writers_.<span class="built_in">pop_front</span>();</span><br><span class="line">    <span class="keyword">if</span> (ready != &amp;w) &#123;</span><br><span class="line">      ready-&gt;status = status;</span><br><span class="line">      ready-&gt;done = <span class="literal">true</span>;</span><br><span class="line">      ready-&gt;cv.<span class="built_in">Signal</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (ready == last_writer) <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Notify new head of write queue</span></span><br><span class="line">  <span class="keyword">if</span> (!writers_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">    writers_.<span class="built_in">front</span>()-&gt;cv.<span class="built_in">Signal</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> status;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>前期是做一些 checking, 很重要的是 <code>BuildBatchGroup</code> 这个函数，我觉得这个函数写的好奇妙</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Status <span class="title">DBImpl::Write</span><span class="params">(<span class="type">const</span> WriteOptions&amp; options, WriteBatch* updates)</span> </span>&#123;</span><br><span class="line">  <span class="function">Writer <span class="title">w</span><span class="params">(&amp;mutex_)</span></span>;</span><br><span class="line">  w.batch = updates;</span><br><span class="line">  w.sync = options.sync;</span><br><span class="line">  w.done = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">MutexLock <span class="title">l</span><span class="params">(&amp;mutex_)</span></span>;</span><br><span class="line">  writers_.<span class="built_in">push_back</span>(&amp;w);</span><br><span class="line">  <span class="keyword">while</span> (!w.done &amp;&amp; &amp;w != writers_.<span class="built_in">front</span>()) &#123;</span><br><span class="line">    w.cv.<span class="built_in">Wait</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (w.done) &#123;</span><br><span class="line">    <span class="keyword">return</span> w.status;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// May temporarily unlock and wait.</span></span><br><span class="line">  Status status = <span class="built_in">MakeRoomForWrite</span>(updates == <span class="literal">nullptr</span>);</span><br><span class="line">  <span class="type">uint64_t</span> last_sequence = versions_-&gt;<span class="built_in">LastSequence</span>();</span><br><span class="line">  Writer* last_writer = &amp;w;</span><br><span class="line">  <span class="keyword">if</span> (status.<span class="built_in">ok</span>() &amp;&amp; updates != <span class="literal">nullptr</span>) &#123;  <span class="comment">// nullptr batch is for compactions</span></span><br><span class="line">    <span class="comment">// write_batch 是 write 的时候批量写内容，把 last_writer 调整到了真正的 batch 写的末尾。</span></span><br><span class="line">    WriteBatch* write_batch = <span class="built_in">BuildBatchGroup</span>(&amp;last_writer);</span><br><span class="line">    WriteBatchInternal::<span class="built_in">SetSequence</span>(write_batch, last_sequence + <span class="number">1</span>);</span><br><span class="line">    last_sequence += WriteBatchInternal::<span class="built_in">Count</span>(write_batch);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Add to log and apply to memtable.  We can release the lock</span></span><br><span class="line">    <span class="comment">// during this phase since &amp;w is currently responsible for logging</span></span><br><span class="line">    <span class="comment">// and protects against concurrent loggers and concurrent writes</span></span><br><span class="line">    <span class="comment">// into mem_.</span></span><br><span class="line">    &#123;</span><br><span class="line">      mutex_.<span class="built_in">Unlock</span>();</span><br><span class="line">      <span class="comment">// 先写 Log 再写 mem_</span></span><br><span class="line">      status = log_-&gt;<span class="built_in">AddRecord</span>(WriteBatchInternal::<span class="built_in">Contents</span>(write_batch));</span><br><span class="line">      <span class="type">bool</span> sync_error = <span class="literal">false</span>;</span><br><span class="line">      <span class="keyword">if</span> (status.<span class="built_in">ok</span>() &amp;&amp; options.sync) &#123;</span><br><span class="line">        status = logfile_-&gt;<span class="built_in">Sync</span>();</span><br><span class="line">        <span class="keyword">if</span> (!status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">          sync_error = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (status.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">        status = WriteBatchInternal::<span class="built_in">InsertInto</span>(write_batch, mem_);</span><br><span class="line">      &#125;</span><br><span class="line">      mutex_.<span class="built_in">Lock</span>();</span><br><span class="line">      <span class="keyword">if</span> (sync_error) &#123;</span><br><span class="line">        <span class="comment">// The state of the log file is indeterminate: the log record we</span></span><br><span class="line">        <span class="comment">// just added may or may not show up when the DB is re-opened.</span></span><br><span class="line">        <span class="comment">// So we force the DB into a mode where all future writes fail.</span></span><br><span class="line">        <span class="built_in">RecordBackgroundError</span>(status);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (write_batch == tmp_batch_) tmp_batch_-&gt;<span class="built_in">Clear</span>();</span><br><span class="line"></span><br><span class="line">    versions_-&gt;<span class="built_in">SetLastSequence</span>(last_sequence);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    Writer* ready = writers_.<span class="built_in">front</span>();</span><br><span class="line">    writers_.<span class="built_in">pop_front</span>();</span><br><span class="line">    <span class="comment">// w 是现在管的，本身没有必要 signal</span></span><br><span class="line">    <span class="keyword">if</span> (ready != &amp;w) &#123;</span><br><span class="line">      ready-&gt;status = status;</span><br><span class="line">      ready-&gt;done = <span class="literal">true</span>;</span><br><span class="line">      ready-&gt;cv.<span class="built_in">Signal</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (ready == last_writer) <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Notify new head of write queue</span></span><br><span class="line">  <span class="keyword">if</span> (!writers_.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">    writers_.<span class="built_in">front</span>()-&gt;cv.<span class="built_in">Signal</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> status;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么我们主要的逻辑就看完了，回头再看看 <code>MakeRoomForWrite</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// REQUIRES: mutex_ is held</span></span><br><span class="line"><span class="comment">// REQUIRES: this thread is currently at the front of the writer queue</span></span><br><span class="line"><span class="function">Status <span class="title">DBImpl::MakeRoomForWrite</span><span class="params">(<span class="type">bool</span> force)</span> </span>&#123;</span><br><span class="line">  mutex_.<span class="built_in">AssertHeld</span>();</span><br><span class="line">  <span class="built_in">assert</span>(!writers_.<span class="built_in">empty</span>());</span><br><span class="line">  <span class="type">bool</span> allow_delay = !force;</span><br><span class="line">  Status s;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!bg_error_.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">      <span class="comment">// Yield previous error</span></span><br><span class="line">      s = bg_error_;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (allow_delay &amp;&amp; versions_-&gt;<span class="built_in">NumLevelFiles</span>(<span class="number">0</span>) &gt;=</span><br><span class="line">                                  config::kL0_SlowdownWritesTrigger) &#123;</span><br><span class="line">      <span class="comment">// We are getting close to hitting a hard limit on the number of</span></span><br><span class="line">      <span class="comment">// L0 files.  Rather than delaying a single write by several</span></span><br><span class="line">      <span class="comment">// seconds when we hit the hard limit, start delaying each</span></span><br><span class="line">      <span class="comment">// individual write by 1ms to reduce latency variance.  Also,</span></span><br><span class="line">      <span class="comment">// this delay hands over some CPU to the compaction thread in</span></span><br><span class="line">      <span class="comment">// case it is sharing the same core as the writer.</span></span><br><span class="line">      </span><br><span class="line">      <span class="comment">// L0 file 到极限的时候, 可以参考 LevelDB 的 WriteStall 文档</span></span><br><span class="line">      mutex_.<span class="built_in">Unlock</span>();</span><br><span class="line">      env_-&gt;<span class="built_in">SleepForMicroseconds</span>(<span class="number">1000</span>);</span><br><span class="line">      allow_delay = <span class="literal">false</span>;  <span class="comment">// Do not delay a single write more than once</span></span><br><span class="line">      mutex_.<span class="built_in">Lock</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!force &amp;&amp;</span><br><span class="line">               (mem_-&gt;<span class="built_in">ApproximateMemoryUsage</span>() &lt;= options_.write_buffer_size)) &#123;</span><br><span class="line">      <span class="comment">// There is room in current memtable</span></span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (imm_ != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">      <span class="comment">// We have filled up the current memtable, but the previous</span></span><br><span class="line">      <span class="comment">// one is still being compacted, so we wait.</span></span><br><span class="line">      <span class="built_in">Log</span>(options_.info_log, <span class="string">&quot;Current memtable full; waiting...\n&quot;</span>);</span><br><span class="line">      background_work_finished_signal_.<span class="built_in">Wait</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (versions_-&gt;<span class="built_in">NumLevelFiles</span>(<span class="number">0</span>) &gt;= config::kL0_StopWritesTrigger) &#123;</span><br><span class="line">      <span class="comment">// There are too many level-0 files.</span></span><br><span class="line">      <span class="built_in">Log</span>(options_.info_log, <span class="string">&quot;Too many L0 files; waiting...\n&quot;</span>);</span><br><span class="line">      background_work_finished_signal_.<span class="built_in">Wait</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// Attempt to switch to a new memtable and trigger compaction of old</span></span><br><span class="line">      <span class="built_in">assert</span>(versions_-&gt;<span class="built_in">PrevLogNumber</span>() == <span class="number">0</span>);</span><br><span class="line">      <span class="type">uint64_t</span> new_log_number = versions_-&gt;<span class="built_in">NewFileNumber</span>();</span><br><span class="line">      WritableFile* lfile = <span class="literal">nullptr</span>;</span><br><span class="line">      s = env_-&gt;<span class="built_in">NewWritableFile</span>(<span class="built_in">LogFileName</span>(dbname_, new_log_number), &amp;lfile);</span><br><span class="line">      <span class="keyword">if</span> (!s.<span class="built_in">ok</span>()) &#123;</span><br><span class="line">        <span class="comment">// Avoid chewing through file number space in a tight loop.</span></span><br><span class="line">        versions_-&gt;<span class="built_in">ReuseFileNumber</span>(new_log_number);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">delete</span> log_;</span><br><span class="line">      <span class="keyword">delete</span> logfile_;</span><br><span class="line">      logfile_ = lfile;</span><br><span class="line">      logfile_number_ = new_log_number;</span><br><span class="line">      log_ = <span class="keyword">new</span> log::<span class="built_in">Writer</span>(lfile);</span><br><span class="line">      imm_ = mem_;</span><br><span class="line">      has_imm_.<span class="built_in">store</span>(<span class="literal">true</span>, std::memory_order_release);</span><br><span class="line">      mem_ = <span class="keyword">new</span> <span class="built_in">MemTable</span>(internal_comparator_);</span><br><span class="line">      mem_-&gt;<span class="built_in">Ref</span>();</span><br><span class="line">      force = <span class="literal">false</span>;  <span class="comment">// Do not force another compaction if have room</span></span><br><span class="line">      <span class="built_in">MaybeScheduleCompaction</span>();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是给 <code>memTable</code> 写足够的空间，然后逻辑上作出后续处理。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Types In Golang: Part2</title>
      <link href="/2020/05/01/Types-In-Golang-Part2/"/>
      <url>/2020/05/01/Types-In-Golang-Part2/</url>
      
        <content type="html"><![CDATA[<h4 id="string"><a href="#string" class="headerlink" title="string"></a>string</h4><p>Golang 里面的 string 是 immutable 的，它的 cap/len 是同一个值。我们可能需要涉及两个别的类型：</p><ul><li><p>string 是一个 <code>byte</code> (<code>uint8</code> ) 组成的对象，形式上可以脑补 Rust 的 <code>&amp;[u8]</code> (感觉我说的不太对，有不是 bytes 组成的 string 么)</p></li><li><p>我们需要涉及另一个类型 <code>rune</code> ，即 unicode。具体 string 可能由不定长的不同 unicode 构成，所以</p><blockquote><p>在Go中，所有的字符串常量都被视为是UTF-8编码的。 在编译时刻，非法UTF-8编码的字符 串常量将导致编译失败。 在运行时刻，Go运行时无法阻止一个字符串是非法UTF-8编码的。</p></blockquote></li></ul><blockquote><p>字符串类型没有内置的方法。我们可以</p><ul><li>使用strings标准库 􏰀 提供的函数来进行各种字符串操作。</li><li>调用内置函数 len 来获取一个字符串值的长度(此字符串中存储的字节数)。</li><li>使用容器元素索引(第18章)语法aString[i]来获取aString中的第i个 byte。 表达 式 aString[i] 是不可寻址的。换句话说， aString[i] 不可被修改。 使用子切片语法(第18章)aString[start:end]来获取aString的一个子字符串。 这 里， start (包括)和 end (不包括)均为 aString 中存储的字节的下标。</li></ul><p>对于标准编译器来说，一个字符串的赋值完成之后，此赋值中的目标值和源值将共享底层字节。 一个子切片表达式 aString[start:end] 的估值结果也将和基础字符串 aString 共享一部分底层 字节。</p></blockquote><p>比较重要的是：索引的对象是 byte：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fmt.Printf(&quot;%T \n&quot;, hello[0]) // uint8</span><br></pre></td></tr></table></figure><p>对于字符串而言，我们经常类型转换，比如把某个 string 丢给 etcd 发送请求。</p><blockquote><ol><li><p>一个字符串值可以被显式转换为一个字节切片(byte slice)，反之亦然。 一个字节切片类型是 一个元素类型为内置类型byte的切片类型。 或者说，一个字节切片类型的底层类型为[]byte (亦即 []uint8 )。</p></li><li><p>一个字符串值可以被显式转换为一个码点切片(rune slice)，反之亦然。 一个码点切片类型是一个元素类型为内置类型rune的切片类型。 或者说，一个码点切片类型的底层类型为 []rune (亦即 []int32 )。</p></li></ol><p>在一个从码点切片到字符串的转换中，码点切片中的每个码点值将被UTF-8编码为一到四个字节至结果 字符串中。 如果一个码点值是一个不合法的Unicode码点值，则它将被视为Unicode替换字符(码点) 值0xFFFD(Unicode replacement character)。 替换字符值0xFFFD将被UTF-8编码为三个字节0xef 0xbf 0xbd。</p><p>当一个字符串被转换为一个码点切片时，此字符串中存储的字节序列将被解读为一个一个码点的UTF-8编码序列。 非法的UTF-8编码字节序列将被转化为Unicode替换字符值0xFFFD。</p><p>当一个字符串被转换为一个字节切片时，结果切片中的底层字节序列是此字符串中存储的字节序列的一 份深复制。</p></blockquote><p>所以这个转化过程还是有复制的，TiDB 用这个特点写了个 <code>hack.String</code>, 挺有意思的：<a href="https://github.com/pingcap/tidb/blob/master/util/hack/hack.go">https://github.com/pingcap/tidb/blob/master/util/hack/hack.go</a></p><p>但是实际上，上述情景存在一些编译器的优化（我吐了），这是标准库中的优化</p><blockquote><ul><li>一个 for-range 循环中跟随 range 关键字的从字符串到字节切片的转换; <code>for i, v := range []byte(s) &#123;&#125;</code></li><li>一个在映射元素索引语法中被用做键值的从字节切片到字符串的转换; <code>v[string(bytes)]</code></li><li>一个字符串比较表达式中被用做比较值的从字节切片到字符串的转换; <code>if s &lt; string(bytes)</code></li><li>一个(至少有一个被衔接的字符串值为非空字符串常量的)字符串衔接表达式中的从字节切片到 字符串的转换。<code>s  += string(bytes)</code></li></ul></blockquote><p>for-range 遍历字符串的时候 key 是 byte start index, value 是 rune. 所以其实很好玩：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>  &#123;</span><br><span class="line">s := <span class="string">&quot;你妈死了，我是你哥哥，我们俩都是你妈的儿子&quot;</span></span><br><span class="line"><span class="keyword">for</span> i, rn := <span class="keyword">range</span> s &#123;</span><br><span class="line">fmt.Println(i, rn, <span class="type">string</span>(rn))</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以试着运行一下这个，至于遍历 bytes, 你可以：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, v := <span class="keyword">range</span> []<span class="type">byte</span>(s) &#123;&#125;</span><br></pre></td></tr></table></figure><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><p>函数我其实不是很想介绍，但是我们需要注意一下 builtin 的这种内置函数，这种往往靠开洞之类的方法，在 这些函数声明在 <code>builtin</code> 􏰀 和 <code>unsafe</code> 􏰀 标准库中, 可以支持泛型甚至类型作为参数，其中 <code>len</code> <code>cap</code> 这些也有可能编译期获得值。</p><p>另外，很多时候 Go 编译器会希望你定义完整个函数，但是写个 <code>panic(“unimplemented”)</code> 其实也可以，实际上Go 有个 <a href="https://golang.org/ref/spec#Terminating_statements">https://golang.org/ref/spec#Terminating_statements</a> ，满足这个标准的可以当函数的结尾。</p><h4 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h4><p>channel 是个 mpmc 的模型，一些 goroutine可以向 此通道发送数据，另外一些goroutine可以从此通道接收数据。</p><blockquote><p>随着一个数据值的传递(发送和接收)，一些数据值的所有权从一个协程转移到了另一个协程。 当一 个协程发送一个值到一个通道，我们可以认为此协程释放了一些值的所有权。 当一个协程从一个通道 接收到一个值，我们可以认为此协程获取了一些值的所有权。</p></blockquote><p>(突然想到 Send 和 Sync 这俩 trait)</p><h4 id="channel-的类型"><a href="#channel-的类型" class="headerlink" title="channel 的类型"></a>channel 的类型</h4><blockquote><p>字面形式chan T表示一个元素类型为T的双向通道类型。 编译器允许从此类型的值中接收和向此 类型的值中发送数据。<br> 字面形式chan&lt;- T表示一个元素类型为T的单向发送通道类型。 编译器不允许从此类型的值中 接收数据。</p><p>字面形式&lt;-chan T表示一个元素类型为T的单向接收通道类型。 编译器不允许向此类型的值中 发送数据。</p></blockquote><p>双向通道chan T的值可以被隐式转换为单向通道类型chan&lt;- T和&lt;-chan T，但反之不行(即使显式 也不行)。 类型chan&lt;- T和&lt;-chan T的值也不能相互转换。</p><blockquote><p>一个容量为0的通道值称为一个非 缓冲通道(unbuffered channel)，一个容量不为0的通道值称为一个缓冲通道(buffered channel)。</p><p>通道类型的零值也使用预声明的nil来表示。 一个非零通道值必须通过内置的make函数来创建。 </p></blockquote><p>所以 channel 比较是靠“内部成员是不是同一个”来判断的。</p><h5 id="channel-操作和语义"><a href="#channel-操作和语义" class="headerlink" title="channel 操作和语义"></a>channel 操作和语义</h5><ol><li><code>close(ch)</code> 关闭非 <code>&lt;-chan</code></li><li><code>ch &lt;- v</code> 给 ch 发送 v</li><li><code>&lt;-ch</code> 接收一个值</li><li><code>cap(ch)</code> 查询容量</li><li><code>len(ch)</code> 查询内部已有元素的长度</li></ol><blockquote><p>Go中大多数的基本操作都是未同步的。换句话说，它们都不是并发安全的。 这些操作包括赋值、传 参、和各种容器值操作等。 但是，除了并发地关闭一个通道和向此通道发送数据这种情形，上面这些 所有列出的操作都已经同步过了，因此它们可以在并发协程中安全运行而无需其它同步操作。 我们在 编程中应该避免并发地关闭一个通道和向此通道发送数据这种情形， 因为这种情形属于不良设计(原 因将在下面解释)。</p></blockquote><p>所以 close 和 send 逻辑应该合理的拆分。</p><blockquote><p>注意:通道的赋值和其它类型值的赋值一样，是未同步的。 同样，将刚从一个通道接收出来的值赋给 另一个值也是未同步的。</p><p>如果被查询的通道为一个nil零值通道，则cap和len函数调用都返回0。 这两个操作是如此简单，所 以后面将不再对它们进行详解。 事实上，这两个操作在实践中很少使用。</p></blockquote><div class="table-container"><table><thead><tr><th style="text-align:center">操作</th><th style="text-align:center">nil channel</th><th style="text-align:center">closed channel</th><th style="text-align:center">channel</th></tr></thead><tbody><tr><td style="text-align:center">close</td><td style="text-align:center">panic</td><td style="text-align:center">panic</td><td style="text-align:center">close it</td></tr><tr><td style="text-align:center">ch &lt;-</td><td style="text-align:center">blocking forever</td><td style="text-align:center">panic</td><td style="text-align:center">blocking or send success</td></tr><tr><td style="text-align:center">&lt;-ch</td><td style="text-align:center">blocking forever</td><td style="text-align:center">never panic</td><td style="text-align:center">blocking or recv success</td></tr></tbody></table></div><p>其实根据我理解，我总结了一下：</p><ul><li>Golang 的 close 是“不可重复调用” 的，close nil, 被 close 的 channel 都会产生 panic</li><li>sender 应该知道 channel 的情况，给 nil 发送会 blocking forever, 给 closed 发送会 panic</li><li>receiver 某种情况下不知道，所以它从 nil 接收会 block forever, 从 closed 接收消息必定不会 blocking</li></ul><p>channel 此外还需要维护 FIFO 的语义，这其实暗示很麻烦的实现，实际上很多内存 channel 都不想做这一点。</p><p>可以认为一个 channel 维护了3个 queue:</p><blockquote><ol><li>接收数据协程队列。此队列是一个没有长度限制的链表。 此队列中的协程均处于阻塞状态，它们 正等待着从此通道接收数据。</li><li>发送数据协程队列。此队列也是一个没有长度限制的链表。 此队列中的协程亦均处于阻塞状态， 它们正等待着向此通道发送数据。 此队列中的每个协程将要发送的值(或者此值的指针，取决于 具体编译器实现)和此协程一起存储在此队列中。</li><li>数据缓冲队列。这是一个循环队列，它的长度为此通道的容量。此队列中存放的值的类型都为此 通道的元素类型。 如果此队列中当前存放的值的个数已经达到此通道的容量，则我们说此通道已 经处于满槽状态。 如果此队列中当前存放的值的个数为零，则我们说此通道处于空槽状态。 对 于一个非缓冲通道(容量为零)，它总是同时处于满槽状态和空槽状态。</li></ol></blockquote><p>注意其中的 blocking 行为，在 select 的时候你会需要它们的。此外：</p><blockquote><p>一个非零通道被关闭之后，此通道上的后续数据接收操作将永不会阻塞。 此通道的 缓冲队列中存储数据仍然可以被接收出来。 伴随着这些接收出来的缓冲数据的第二个可选返回(类型 不确定布尔)值仍然是true。 一旦此缓冲队列变为空，后续的数据接收操作将永不阻塞并且总会返回 此通道的元素类型的零值和值为false的第二个可选返回结果。 </p><p>通道操作情形C: 当一个协程成功获取到一个非零且尚未关闭的通道的锁并且准备关闭此通道时，下面 两步将依次执行:</p><ol><li>如果此通道的接收数据协程队列不为空(这种情况下，缓冲队列必为空)，此队列中的所有协程 将被依个弹出，并且每个协程将接收到此通道的元素类型的一个零值，然后恢复至运行状态。</li><li>如果此通道的发送数据协程队列不为空，此队列中的所有协程将被依个弹出，并且每个协程中都将产生一个panic(因为向已关闭的通道发送数据)。 这就是我们在上面说并发地关闭一个通道和 向此通道发送数据这种情形属于不良设计的原因。 事实上，并发地关闭一个通道和向此通道发送 数据将产生数据竞争。</li></ol></blockquote><p>其他几个 case 也可以看看。</p><p>此外需要注意：</p><ul><li><code>&lt;-</code> 接收到的元素全是值复制（我个人感觉传指针怪怪的？不知有没有什么 例子）</li><li>goroutine 和 channel 中， channel 只有没有 goroutine 引用才会被 gc, goroutine 同理。所以要小心 leak.</li><li>goroutine 允许你从 nil 和 closed 中 recv, 返回一个 ok 的 bool。这也允许你 for-range 使用</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">  <span class="keyword">for</span> v, ok &lt;- ch </span><br><span class="line">  <span class="keyword">if</span> !ok &#123;</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> v := <span class="keyword">range</span> ch &#123;</span><br><span class="line">  <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="select-channel"><a href="#select-channel" class="headerlink" title="select channel"></a>select channel</h5><blockquote><p>所有的非阻塞 case 操作中将有一个被随机选择执行(而不是按照从上到下的顺序)，然后执行此 操作对应的 case 分支代码块。</p><p>在所有的 case 操作均为阻塞的情况下，如果 default 分支存在，则 default 分支代码块将得到执 行; 否则，当前协程将被推入所有阻塞操作中相关的通道的发送数据协程队列或者接收数据协程 队列中，并进入阻塞状态。</p></blockquote><p>一种很常用的模式是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">select &#123;</span><br><span class="line">case &lt;-ch:</span><br><span class="line">// do something</span><br><span class="line">default:</span><br><span class="line">// 跳过</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>select 会评估所有的 arm, 给 channel lock 并且尝试是否是 non-blocking 的</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>  &#123;</span><br><span class="line">ch := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> ch&lt;- <span class="number">114514</span>:</span><br><span class="line">fmt.Println(<span class="string">&quot;Send done&quot;</span>)</span><br><span class="line"><span class="keyword">case</span> v := &lt;- ch:</span><br><span class="line">fmt.Printf(<span class="string">&quot;Receive %d\n&quot;</span>, v)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Println(<span class="string">&quot;done&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上操作会得到：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fatal error: all goroutines are asleep - deadlock!</span><br><span class="line"></span><br><span class="line">goroutine 1 [select]:</span><br><span class="line">main.main()</span><br><span class="line">        .../cmd/chan_example.go:7 +0xe3</span><br></pre></td></tr></table></figure><h3 id="method"><a href="#method" class="headerlink" title="method"></a>method</h3><p>有 method 需要有几个限制：</p><blockquote><ol><li>T 必须是一个定义类型(第14章);</li><li>T 必须和此方法声明定义在同一个代码包中;</li><li>T 不能是一个指针类型;</li><li>T 不能是一个接口类型。</li></ol></blockquote><p>method 会 implict 生成函数，让 go 编译器去 mangling。</p><blockquote><p>对每一个为值类型属主 T 声明的方法，编译器将自动隐式地为其对应的指针类型属主 <em>T 声明一个相应的 同名方法。 以上面的为类型Book声明的Pages方法为例，编译器将自动为类型</em>Book声明一个同名方 法:</p></blockquote><p>也就是说 <code>(T) call()</code> 被声明后，<code>(*T) call</code> 会被 implicit 的定义，传 <code>(*v)</code> 作为参数，而生成的函数 function call，会是一个值复制。类型T的方法集总是类型<em>T的方法集的子集。上述第一个括号里的被称为 </em>receiver type*。</p><p>这点可以在 Go-FAQ 找到：<a href="https://golang.org/doc/faq#different_method_sets">https://golang.org/doc/faq#different_method_sets</a></p><p>所以我们需要考虑是<code>(*T)</code> 还是 <code>(T)</code> 实现：</p><blockquote><p>对于值类型属主还是指针类型属主都可以接受的方法声明，下面列出了一些考虑因素:</p><ul><li>太多的指针可能会增加垃圾回收器的负担。 如果一个值类型的尺寸太大，那么属主参数在传参的时候的复制成本将不可忽略。 指针类型都是 小尺寸类型。 关于各种不同类型的尺寸，请阅读值复制代价(第34章)一文。</li><li>在并发场合下，同时调用为值类型属主和指针类型属主方法比较易于产生数据竞争。</li><li>sync 标准库包中的类型的值不应该被复制，所以如果一个结构体类型内嵌(第24章)了这些类 型，则不应该为这个结构体类型声明值类型属主的方法。</li></ul><p>如果实在拿不定主意在一个方法声明中应该使用值类型属主还是指针类型属主，那么请使用指针类型属 主。</p></blockquote><h3 id="interface"><a href="#interface" class="headerlink" title="interface"></a>interface</h3><p>interface 是一个很常用，但是用起来大家其实很模糊的东西。我们需要实际上脑袋想清楚：</p><ul><li><code>i = v</code> 会不会产生复制，还是引用的 copy</li><li><code>i1 = i2</code> 会有如何影响</li><li>interface 内部如何维护具体类型，完整信息。</li></ul><blockquote><p>在Go中，如果类型T实现了一个接口类型I，则类型T的值都可以隐式转换到类型I。 换句话说，类型 T的值可以赋给类型I的可修改值。 当一个T值被转换到类型I(或者赋给一个I值)的时候，</p><ul><li>如果类型T是一个非接口类型，则此T值的<strong>一个复制</strong>将被包裹在结果(或者目标)I值中。 此操作 的时间复杂度为 <em>O</em>(n) ，其中 n 为 T 值的尺寸。</li><li>如果类型 T 也为一个接口类型，则此 T 值中当前包裹的(非接口)值将被复制一份到结果(或者目 标)I值中。 官方标准编译器为此操作做了优化，使得此操作的时间复杂度为<em>O</em>(1)，而不 是<em>O</em>(n)。</li></ul></blockquote><p>也就是说，本身会发生一个 copy 过程。</p><p>可以看一段比较有趣的代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Book <span class="keyword">struct</span> &#123;</span><br><span class="line">name <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b Book)</span></span> About() <span class="type">string</span> &#123;</span><br><span class="line"><span class="keyword">return</span> fmt.Sprintf(<span class="string">&quot;Book(name:%s)&quot;</span>, b.name)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Aboutable <span class="keyword">interface</span> &#123;</span><br><span class="line">About() <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>  &#123;</span><br><span class="line"><span class="keyword">var</span> aboutable Aboutable</span><br><span class="line"><span class="keyword">if</span> aboutable == <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(<span class="string">&quot;aboutable is nil&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(aboutable) <span class="comment">// &lt;nil&gt;</span></span><br><span class="line"><span class="keyword">var</span> bookPtr *Book</span><br><span class="line">aboutable = bookPtr</span><br><span class="line"><span class="keyword">if</span> aboutable == <span class="literal">nil</span> &#123;</span><br><span class="line">fmt.Println(<span class="string">&quot;aboutable is nil&quot;</span>)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">fmt.Println(<span class="string">&quot;aboutable is not nil&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Println(aboutable) <span class="comment">// &lt;nil&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// panic: value method main.Book.About called using nil *Book pointer</span></span><br><span class="line"><span class="comment">//aboutable.About()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">b := Book&#123;name: <span class="string">&quot;卡拉马佐夫兄弟&quot;</span>&#125;</span><br><span class="line">aboutable = b</span><br><span class="line"></span><br><span class="line">fmt.Println(aboutable.About()) <span class="comment">// Book(name:卡拉马佐夫兄弟)</span></span><br><span class="line"><span class="comment">//aboutableBook := aboutable.(Book)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>对于一个非接口类型和接口类型对，它们的实现关系信息包括两部分的内容:</p><ol><li>动态类型(即此非接口类型)的信息。</li><li>一个方法表(切片类型)，其中存储了所有此接口类型指定的并且为此非接口类型(动态类型)声明的方法。</li></ol></blockquote><p>可以实现 Golang 的多态：</p><blockquote><p>比如，当方法i.m被调用时，其实被调用的是方法t.m。 一个接口值可以通过包裹不同动态类型的动态值来表现出各种不同的行为，这称为多态。</p></blockquote><p>但我觉得还是很鸡肋的，对不同类型需要一堆 builtin 或者写很多遍, 感觉很蛋疼。</p><h3 id="反射与类型"><a href="#反射与类型" class="headerlink" title="反射与类型"></a>反射与类型</h3><p>我们可以注意到之前的：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">b := Book&#123;name: <span class="string">&quot;卡拉马佐夫兄弟&quot;</span>&#125;</span><br><span class="line">aboutable = b</span><br><span class="line"></span><br><span class="line">fmt.Println(aboutable.About()) <span class="comment">// Book(name:卡拉马佐夫兄弟)</span></span><br><span class="line">aboutableBook := aboutable.(Book)</span><br></pre></td></tr></table></figure><p>类比起来，我们已经拥有了对一定的底层类型的转换，可以理解成<code>static_cast</code>,可能需要类似 C++ 的 <code>dynamic_cast&lt;&gt;</code> 的转换，也就是：</p><blockquote><ol><li><p>将一个接口值转换为一个非接口类型(此非接口类型必须实现了此接口值的接口类型)。</p></li><li><p>将一个接口值转换为另一个接口类型(前者接口值的类型可以实现了也可以未实现后者目标接口</p><p>类型)。</p></li></ol></blockquote><p>以上依靠：</p><blockquote><p>在一个类型断言表达式i.(T)中，i称为断言值，T称为断言类型。 一个断言可能成功或者失败。</p></blockquote><p>还是有一些不同的，实际上 <code>dynamic_cast</code> 对象是指针，而这里很难拿到<code>interface</code> 中原对象的引用：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">b := Book&#123;name: <span class="string">&quot;卡拉马佐夫兄弟&quot;</span>&#125;</span><br><span class="line">aboutable = b</span><br><span class="line"></span><br><span class="line">fmt.Println(aboutable.About()) <span class="comment">// Book(name:卡拉马佐夫兄弟)</span></span><br><span class="line">aboutableBook := aboutable.(Book)</span><br><span class="line">fmt.Println(aboutableBook.About()) <span class="comment">// Book(name:卡拉马佐夫兄弟)</span></span><br><span class="line"></span><br><span class="line">aboutableBook.name = <span class="string">&quot;罪与罚&quot;</span></span><br><span class="line">fmt.Println(aboutable.About()) <span class="comment">// Book(name:卡拉马佐夫兄弟)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//bptr, ok := (aboutable).(*Book)</span></span><br><span class="line"><span class="comment">//if !ok &#123;</span></span><br><span class="line"><span class="comment">//fmt.Println(&quot;cast error&quot;)</span></span><br><span class="line"><span class="comment">//&#125; else &#123;</span></span><br><span class="line"><span class="comment">//fmt.Println(bptr.About())</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br></pre></td></tr></table></figure><p>下面是编译不通过的, 除非你一开始放的就是 <code>*Book</code>, 可以转回来。否则这仍然是一个 copy 行为。</p><p>此外还有个很神秘的语法：switch type:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span> x.(<span class="keyword">type</span>) &#123;</span><br><span class="line"><span class="keyword">case</span> []<span class="type">int</span>:</span><br><span class="line">  <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我真的觉得这个语法太神秘了，这似乎是个 builtin。</p><p>此外，类似 Java 逆变，协变的概念：</p><blockquote><p>一个 <strong>[]T</strong> 类型的值不能直接被转换为类型 <strong>[]I</strong> ，即使类型 <strong>T</strong> 实现了接口类型<strong>I</strong></p></blockquote><h3 id="类型内嵌"><a href="#类型内嵌" class="headerlink" title="类型内嵌"></a>类型内嵌</h3><p>似乎是由于 Go 组合优于继承的哲学，Go 允许类型内嵌，它的规则有点奇怪：</p><blockquote><ol><li>一个类型名 T 只有在它既不表示一个定义的指针类型也不表示一个基类型为指针类型或者接口类型 的指针类型的情况下在可以被用作内嵌字段。</li><li>一个指针类型 *T 只有在 T 为一个类型名并且 T 既不表示一个指针类型也不表示一个接口类型的时 候才能被用作内嵌字段。</li></ol></blockquote><ul><li>T 本身要求不是 pointer/基类型不是 pointer/interface</li><li>*T 要求 T 是类型名 基类型不是 pointer/interface</li><li>（我以前不知道的是，类型竟然能内嵌 interface, 神了）</li></ul><p>被内嵌类型的方法会被提升，这是一个语法糖，如果重复定义，可以参考以下逻辑：</p><blockquote><p>只有深度最浅的一个完整形式的选择器(并且最浅者只有一个)可以被缩写为x.y。 换句话说， x.y 表示深度最浅的一个选择器。其它完整形式的选择器被此最浅者所遮挡(压制)。 如果有多个完整形式的选择器同时拥有最浅深度，则任何完整形式的选择器都不能被缩写为 x.y 。 我们称这些同时拥有最浅深度的完整形式的选择器发生了碰撞。</p></blockquote><p>而外层类型也会 implicit 实现这些方法。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Types In Golang: part1</title>
      <link href="/2020/05/01/Types-In-Golang/"/>
      <url>/2020/05/01/Types-In-Golang/</url>
      
        <content type="html"><![CDATA[<p>Golang 的类型分为：</p><ul><li>basic type:<ul><li>string</li><li>bool</li><li>int/uint/float</li><li>byte and rune is uint8 and int32</li><li>complex</li></ul></li><li>composite type<ul><li>pointer</li><li>struct</li><li>function</li><li>container<ul><li>slice</li><li>array</li><li>map</li></ul></li><li>channel</li><li>interface</li></ul></li></ul><p>每种 type 都有一个 kind</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">type A B  // A is an another type</span><br><span class="line">type A = B // A is an alias of B</span><br></pre></td></tr></table></figure><h4 id="underlying-type"><a href="#underlying-type" class="headerlink" title="underlying type"></a>underlying type</h4><ul><li>每个 type 都有 underlying type</li><li>内置类型 underlying type 为自身</li><li>unsafe.Pointer undefined</li><li>一个 undefined type 即 <code>=</code> 构成的 composite type</li><li>一个类型声明中，两个类型共享 underlying type</li></ul><p>上面的内容4/5写的很乱，其实就是下面：</p><ul><li><code>AgeSlice</code> 底层类型是 <code>[]Age</code></li><li><code>Age</code> 的底层类型是 <code>MyInt</code>, <code>MyInt</code> 底层类型是 <code>int</code>, <code>int</code> 底层类型是自己</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> typesys</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> (</span><br><span class="line">MyInt <span class="type">int</span></span><br><span class="line">Age MyInt</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> (</span><br><span class="line">IntSlice []<span class="type">int</span></span><br><span class="line">MyIntSlice []MyInt</span><br><span class="line">AgeSlice []Age</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Ages []Age</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f1</span><span class="params">(v <span class="type">int</span>)</span></span>  &#123;</span><br><span class="line"><span class="built_in">panic</span>(<span class="string">&quot;implement me&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f2</span><span class="params">([]Age)</span></span>  &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f3</span><span class="params">([]<span class="type">int</span>)</span></span>  &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Call1</span><span class="params">()</span></span>  &#123;</span><br><span class="line"><span class="keyword">var</span> v MyInt = <span class="number">114514</span></span><br><span class="line"><span class="comment">//cannot call</span></span><br><span class="line"><span class="comment">//f1(v)</span></span><br><span class="line">f1(<span class="type">int</span>(v))</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> s []Age</span><br><span class="line">f2(s)</span><br><span class="line"><span class="keyword">var</span> s2 AgeSlice</span><br><span class="line">f2(s2)</span><br><span class="line"></span><br><span class="line"><span class="comment">// cannot call</span></span><br><span class="line"><span class="comment">//f3(s)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意，类型别名中</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> A = B</span><br><span class="line"><span class="keyword">type</span> C = B</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> AA = <span class="keyword">struct</span> &#123;&#125;</span><br><span class="line"><span class="keyword">type</span> BB = <span class="keyword">struct</span> &#123;&#125;</span><br></pre></td></tr></table></figure><p>AA, BB 都是同一种类型</p><h4 id="value"><a href="#value" class="headerlink" title="value"></a>value</h4><p>一个类型有：</p><ul><li>不同的 value</li><li>一个零值</li></ul><p>我们可以用 unsafe 标准库包中的 Sizeof 函数来取得任何一个值的 memory size。</p><blockquote><p>裹在一个接口值中的非接口 值称为此接口值的动态值。此动态值的类型称为此接口值的动态类型。 一个什么也没包裹的接口值为 一个零值接口值。零值接口值的动态值和动态类型均为不存在。</p><p>一个接口类型可以指定若干个(可以是零个)方法，这些方法形成了此接口类型的方法集。</p></blockquote><h3 id="指针"><a href="#指针" class="headerlink" title="指针"></a>指针</h3><p>这个概念类似 C 的 pointer, 但是有 gc 兜底，所以我总觉得 Go 里面指针怪怪的</p><h5 id="可寻址"><a href="#可寻址" class="headerlink" title="可寻址"></a>可寻址</h5><p><code>return &amp;func()</code> 可能会给你报错 “不可寻址”，这一点我总觉得很离谱… 但是我们总得搞明白为什么。</p><blockquote><p>一个可寻址的值是指被放置在内存中某固定位置处的一个值(但放置在某固定位置处的一个 值并非一定是可寻址的)。 目前，我们只需知道所有变量都是可以寻址的;但是所有常量、函数返回 值和强制转换结果都是不可寻址的。 当一个变量被声明的时候，Go运行时将为此变量开辟一段内存。 此内存的起始地址即为此变量的地址。</p></blockquote><p><code>*p</code> 类似 C，对 <code>nil</code> deref 会 panic.</p><p><img src="/Users/fuasahi/Downloads/47D191C9293076F9A6775E0FA2546192.png" alt="47D191C9293076F9A6775E0FA2546192"></p><p>这个写的比较迷，我个人理解是：</p><ul><li>如果是 underline type 相同，可以 implicit 转</li><li>如果关系多层，需要 explict 的转</li></ul><p>指针只能与 nil 比较</p><p>（unsafe.Pointer 类似 C Pointer, 可以让我们大展宏图）</p><h4 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h4><ul><li>当一个(源)结构体值被赋值给另外一个(目标)结构体值时，其效果和逐个将源结构体值的各个字段 赋值给目标结构体值的各个对应字段的效果是一样的。</li><li><code>&amp;Struct&#123;&#125;</code> 是一个语法糖，<code>(&amp;Struct&#123;&#125;.field)</code> 不可以，但是 <code>&amp;Struct&#123;&#125;</code> 本身的 field 是可以续命的（想起 C++ 用 <code>&amp;&amp;</code> 续命了）</li></ul><h4 id="值与引用"><a href="#值与引用" class="headerlink" title="值与引用"></a>值与引用</h4><p>Go 里面有两种指针：</p><ul><li>类型安全的 pointer</li><li>不安全的 unsafe.Pointer</li></ul><blockquote><p>一个指针值存储着另一个值的地址，除非此指针值是一个nil空指针。 我们可以说此指针引用着(第15 章)另外一个值，或者说另外一个值正被此指针所引用。 </p></blockquote><p>实际上，如果传参，参数是 slice/map/string, 然后你把整个 对象 copy 了一遍，显然是不合理的。很显然这需要 pass 一个 pointer/引用一样的对象进去。</p><p>实际上我们可以找到一些对象定义：</p><ol><li>slice: <a href="https://github.com/golang/go/blob/master/src/runtime/slice.go">https://github.com/golang/go/blob/master/src/runtime/slice.go</a></li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> slice <span class="keyword">struct</span> &#123;</span><br><span class="line">array unsafe.Pointer</span><br><span class="line"><span class="built_in">len</span>   <span class="type">int</span></span><br><span class="line"><span class="built_in">cap</span>   <span class="type">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>map: <a href="https://github.com/golang/go/blob/master/src/runtime/map.go">https://github.com/golang/go/blob/master/src/runtime/map.go</a></li><li>…</li></ol><p>这些具体 parse 的时候都是类似：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">type _map *hashtableImpl</span><br></pre></td></tr></table></figure><p>这样的引用对象。</p><p>比较需要注意的是 interface</p><blockquote><p>一个非空接口类型的值的dynamicTypeInfo字段的methods字段引用着一个方法列表。 此列表中的每 一项为此接口值的动态类型上定义的一个方法，此方法对应着此接口类型所指定的一个的同原型的方 法。</p></blockquote><p>所以：</p><blockquote><ul><li>在赋值中，底层间接值部将不会被复制</li><li>在使用 unsafe.Sizeof 函数计算一个值的尺寸的 时候，此值的间接部分所占内存空间未被计算在内。</li></ul></blockquote><p>需要理解引用这个词，在 Go 里面实际上没有很好的 context</p><blockquote><p>在Go中，只有切片、映射、通道和函数类型属于引用类型。 (如果我们确实需要引用类型这个术 语，那么我们不应把其它指针持有者类型排除在引用类型之外。) 一些函数调用的参数是通过引用来传递的。 (对不起，在Go中，所有的函数调用的参数都是通过 值复制的方式来传递的。)</p></blockquote><h3 id="array-slice-map"><a href="#array-slice-map" class="headerlink" title="array slice map"></a>array slice map</h3><ul><li>一个映射类型的键值类型必须为一个可比较类型</li><li>数组和切片类型的键类型均为内 置类型int。 一个数组或切片的一个元素对应的键值总是一个非负整数下标，此非负整数表示该元素在 该数组或切片所有元素中的顺序位置。此非负整数下标亦常称为一个元素索引(index)。</li><li>每个容器值有一个长度属性</li><li>每个数组值仅由一个直接部分组成，而一个切片或者映射值是由一个直接 部分和一个可能的被此直接部分引用着的间接部分组成。</li></ul><blockquote><p>一个数组或者切片的所有元素紧挨着存放在一块连续的内存中。一个数组中的所有元素均存放在此数组 值的直接部分，一个切片中的所元素均存放在此切片值的间接部分。 在官方标准编译器和运行时中， 映射是使用哈希表算法来实现的。所以一个映射中的所有元素也均存放在一块连续的内存中，但是映射 中的元素并不一定紧挨着存放。</p><p>对于这三种容器，元素访问的时间复杂度均为<em>O</em>(1)。</p></blockquote><h4 id="零值"><a href="#零值" class="headerlink" title="零值"></a>零值</h4><ol><li><p><code>A&#123;&#125;</code> —&gt; <code>[]int&#123;&#125;</code></p></li><li><p>和指针一样，所有切片和映射类型的零值均用预声明的标识符 nil 来表示。</p></li><li><p>即使一个数组变量在声明的时候未指定初始值，它的元素所占的内存空间也已经被开辟出</p><p>来。 但是一个nil切片或者映射值的元素的内存空间尚未被开辟出来。</p></li><li><p><code>[]T&#123;&#125;</code>表示类型<code>[]T</code>的一个空切片值，它和<code>[]T(nil)</code>是不等价的。 同样，<code>map[K]T&#123;&#125;</code>和</p><p><code>map[K]T(nil)</code> 也是不等价的。</p></li></ol><p>以上内容是很显然的，但是实际使用的时候，因为 slice 我们通常和 append 联用，所以<code>var v []int</code> 然后再对它不断 append</p><h5 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h5><ul><li>同类型数组是可比较的，类似 C 里面 strcmp</li><li>slice map 可以同 nil 比较</li></ul><h5 id="len-cap"><a href="#len-cap" class="headerlink" title="len cap"></a>len cap</h5><ul><li>slice: len cap</li><li>map: len, 它的 cap 是无限大</li><li>array: len cap 都是自身的 size</li></ul><h5 id="元素的-r-w"><a href="#元素的-r-w" class="headerlink" title="元素的 r/w"></a>元素的 r/w</h5><p>在 C++ 中，我们可以想象：</p><ul><li><code>const T&amp; operator[](int v)</code> 和  <code>T&amp; operator[](int v)</code> , 保证你拿出来是个 ref</li></ul><p>在 Go 的 <code>v[k]</code> 中：</p><p>如果是个 slice/array</p><ul><li>v 是一个 nil slice: panic</li><li>slice/array 中必须有长度的限制</li></ul><p>如果是个 map</p><ul><li>如果 k 是一个动态类型为不可比较类型的接口值，则 v[k] 在运行时刻将造成一个 Panic （比如你定义了一个 map[interface{}]xxx, 然后传了一个不可以 cmp 的 key, 它会 panic 说这玩意不是 hashable 的）</li><li>如果 <code>v[k] = xxx</code> ，且 <code>v</code> is nil, 会 panic</li><li><code>v[k]</code> 读取时，<strong>无论如何不会 panic</strong>, 如果不存在会返回 Value 类型的 零值</li></ul><h4 id="Slice-的结构与操作语义"><a href="#Slice-的结构与操作语义" class="headerlink" title="Slice 的结构与操作语义"></a>Slice 的结构与操作语义</h4><p>了解了 slice 的语义，我们才能不瞎几把用。首先要知道 Slice 并不是 immutable + Persistent 的结构，也就是说，实际上这些操作是很可能有副作用的</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> slice <span class="keyword">struct</span> &#123;</span><br><span class="line">array unsafe.Pointer</span><br><span class="line"><span class="built_in">len</span>   <span class="type">int</span></span><br><span class="line"><span class="built_in">cap</span>   <span class="type">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>当一个切片被用做一个 append 函数调用中的基础切片，</p><p>如果添加的元素数量大于此(基础)切片的冗余元素槽位的数量，则一个新的底层内存片段将被 开辟出来并用来存放结果切片的元素。 这时，基础切片和结果切片不共享任何底层元素。 否则，不会有底层内存片段被开辟出来。这时，基础切片中的所有元素也同时属于结果切片。两 个切片的元素都存放于同一个内存片段上。</p></blockquote><p>实际上，如果不注意的话，很容易发生多个 slice 共享底层内存的情况，请注意。</p><ul><li>slice 赋值改变 slice 的引用对象</li><li>array 赋值 copy 全部元素</li></ul><p>对于 map 来说，增改/删分别是：</p><ul><li><code>v[k] = s</code></li><li><code>delete(v, k)</code></li></ul><p>map 上操作似乎都是泛型的，（Go 没有泛型就是sb，哎）。</p><blockquote><p>注意，在Go 1.12之前，映射打印结果中的条目顺序并不固定，两次打印结果可能并不相同。</p></blockquote><p>至于 slice, 通常靠 append, 但是 slice 又不是 immutable 的，所以实际上 <code>append()</code> 可能会返回一个改变 len 而不改变 cap 的：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span>  &#123;</span><br><span class="line">s1 := []<span class="type">int</span> &#123; <span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">4</span>&#125;</span><br><span class="line">fmt.Printf(<span class="string">&quot;len: %d cap: %d\n&quot;</span>, <span class="built_in">len</span>(s1), <span class="built_in">cap</span>(s1))</span><br><span class="line">s1 = <span class="built_in">append</span>(s1, <span class="number">4</span>)</span><br><span class="line">fmt.Printf(<span class="string">&quot;len: %d cap: %d\n&quot;</span>, <span class="built_in">len</span>(s1), <span class="built_in">cap</span>(s1))</span><br><span class="line">s2 := <span class="built_in">append</span>(s1, <span class="number">5</span>)</span><br><span class="line">fmt.Printf(<span class="string">&quot;len: %d cap: %d\n&quot;</span>, <span class="built_in">len</span>(s1), <span class="built_in">cap</span>(s1))</span><br><span class="line">fmt.Printf(<span class="string">&quot;len: %d cap: %d\n&quot;</span>, <span class="built_in">len</span>(s2), <span class="built_in">cap</span>(s2))</span><br><span class="line"></span><br><span class="line">s1[<span class="number">2</span>] = <span class="number">5</span></span><br><span class="line"><span class="comment">// s1: 5 s2: 5</span></span><br><span class="line">fmt.Printf(<span class="string">&quot;s1: %d s2: %d\n&quot;</span>, s1[<span class="number">2</span>], s2[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">s3 := <span class="built_in">append</span>(s1, <span class="number">6</span>)</span><br><span class="line"><span class="comment">// s2: 6 s3: 6</span></span><br><span class="line">fmt.Printf(<span class="string">&quot;s2: %d s3: %d\n&quot;</span>, s2[<span class="built_in">len</span>(s2) - <span class="number">1</span>], s3[<span class="built_in">len</span>(s3) - <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">sptr := &amp;s1[<span class="number">5</span>]</span><br><span class="line">*sptr = <span class="number">114514</span></span><br><span class="line"><span class="comment">// s2: 114514 s3: 114514</span></span><br><span class="line">fmt.Printf(<span class="string">&quot;s2: %d s3: %d\n&quot;</span>, s2[<span class="number">5</span>], s3[<span class="number">5</span>])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以我个人觉得，还是把 slice 当成“有内部所有权的指针”吧</p><p>（我局的挺傻逼的，真的）</p><p>创建容器可以：</p><ul><li><code>new</code></li><li><code>make</code></li><li>字面量</li></ul><h4 id="容器元素：寻址"><a href="#容器元素：寻址" class="headerlink" title="容器元素：寻址"></a>容器元素：寻址</h4><blockquote><p>可寻址的数组的元素也是可寻址的。</p><p>不可寻址的数组的元素也是不可寻址的。 原因很简单，因为 一个数组中的所有元素均处于此数组的直接部分。 </p><p>一个切片值的任何元素都是可寻址的，即使此切片本身是不可寻址的。 这是因为一个切片的底层 元素总是存储在一个被开辟出来的内存片段上。 任何映射元素都是不可寻址的。原因详见此条问答(第51章)。</p><p>如果一个映射类型的元素类型为一个结构体类型，则我们无法修改此映射类型的值中的每个结构 体元素的单个字段。 我们必须整体地同时修改所有结构体字段。 </p><p>如果一个映射类型的元素类型为一个数组类型，则我们无法修改此映射类型的值中的每个数组元 素的单个元素。 我们必须整体地同时修改所有数组元素。</p></blockquote><h4 id="slice-copy"><a href="#slice-copy" class="headerlink" title="slice copy"></a>slice copy</h4><p><code>copy</code> 函数形式是 <code>copy(dest, src)</code>. 在 dest 拷贝到 len 为止，返回拷贝的长度。</p><h4 id="for-loop"><a href="#for-loop" class="headerlink" title="for-loop"></a>for-loop</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> key, element = <span class="keyword">range</span> aContainer &#123; </span><br><span class="line"><span class="comment">// 使用key和element ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 cpp 中，我们会有（实际上加入 range 之后会更好使）：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span>&amp; p: container) &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; p: container) &#123;&#125;</span><br></pre></td></tr></table></figure><p>感觉 Go 的 loop 功能孱弱很多：</p><ul><li>如果你需要修改值，其实还是要借助 key</li></ul><blockquote><ol><li>如果 aContainer 是一个数组，那么在遍历过程中对此数组元素的修改不会体现到循环变量 中。 原因是此数组的副本(被真正遍历的容器)和此数组不共享任何元素。</li><li>如果 aContainer 是一个切片(或者映射)，那么在遍历过程中对此切片(或者映射)元素 的修改将体现到循环变量中。 原因是此切片(或者映射)的副本和此切片(或者映射)共 享元素(或条目)。</li><li>在遍历中的每个循环步， aContainer 副本中的一个键值元素对将被赋值(复制)给循环变量。 所以对循环变量的直接部分的修改将不会体现在aContainer中的对应元素中。 (因为这个原 因，并且 for-range 循环是遍历映射条目的唯一途径，所以最好不要使用大尺寸的映射键值和元 素类型，以避免较大的复制负担。)</li></ol></blockquote><p>这里有一些细节：</p><blockquote><p>映射中的条目的遍历顺序是不确定的(可以认为是随机的)。或者说，同一个映射中的条目的两 次遍历中，条目的顺序很可能是不一致的，即使在这两次遍历之间，此映射并未发生任何改变。</p><p> 如果在一个映射中的条目的遍历过程中，一个还没有被遍历到的条目被删除了，则此条目保证不 会被遍历出来。</p><p>如果在一个映射中的条目的遍历过程中，一个新的条目被添加入此映射，则此条目并不保证将在 此遍历过程中被遍历出来。</p></blockquote><p>循环变量是单个的，实际上你可以试试：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// 可以使用 persons[:] 或者 &amp;persons 避免开销</span></span><br><span class="line"><span class="keyword">for</span> i, p := <span class="keyword">range</span> persons &#123;</span><br><span class="line">fmt.Println(i, p)</span><br><span class="line"><span class="comment">// Note: 不改变遍历过程中的值</span></span><br><span class="line">persons[<span class="number">1</span>].name = <span class="string">&quot;Jack&quot;</span></span><br><span class="line">p.age = <span class="number">31</span></span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(<span class="string">&quot;persons:&quot;</span>, &amp;persons)</span><br><span class="line"></span><br><span class="line">persons[<span class="number">1</span>].name = <span class="string">&quot;nmsl.xt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> personSlice []Person</span><br><span class="line">personSlice = persons[:]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, p := <span class="keyword">range</span> personSlice &#123;</span><br><span class="line">fmt.Println(i, p)</span><br><span class="line"><span class="comment">// Note: 不改变遍历过程中的值</span></span><br><span class="line">personSlice[<span class="number">1</span>].name = <span class="string">&quot;Jack&quot;</span></span><br><span class="line">p.age = <span class="number">31</span></span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(<span class="string">&quot;persons:&quot;</span>, &amp;personSlice)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Person <span class="keyword">struct</span> &#123;</span><br><span class="line">name <span class="type">string</span></span><br><span class="line">age <span class="type">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>请注意，上述所有各种容器操作的内部实现都未进行同步。如果不使用今后将要介绍的各种并发同步技 术，在没有协程修改一个容器值和它的元素的时候，多个协程并发读取此容器值和它的元素是安全的。 但是并发修改同一个容器值则是不安全的。</p></blockquote><p>需要注意的一点是：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> k, v := <span class="keyword">range</span> container &#123;</span><br><span class="line">slice = <span class="built_in">append</span>(slice, &amp;v)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你会发现，如同那个经典的并发错误一样，你 append 了同一个值。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Distribute Transaction: basic of 2PC</title>
      <link href="/2020/04/06/Distribute-Transaction-basic-of-2PC/"/>
      <url>/2020/04/06/Distribute-Transaction-basic-of-2PC/</url>
      
        <content type="html"><![CDATA[<h1 id="Distributed-Transaction"><a href="#Distributed-Transaction" class="headerlink" title="Distributed Transaction"></a>Distributed Transaction</h1><p>需求：要么全部提交，要么全都不提交。事务的各个成分都是原子的。</p><p>假设：</p><ol><li>每个 Node 记录 Log，但是得不到全局的 Log</li><li>允许 <em>coordinator process</em> 的存在，它可能是事务的发起者，其他的 Node 被视为 participants.</li><li>发送消息的时候，可能需要记录到日志中</li></ol><p>2PC 有两个阶段：</p><ul><li>The <em>commit-request phase</em> (or <em>voting phase</em>)<ul><li>这个阶段<em>coordinator</em> 试图 prepare. 结果有以下两种</li><li>“Yes”: commit (if the transaction participant’s local portion execution has ended properly)</li><li>“No”: abort (if a problem has been detected with the local portion)</li></ul></li><li>The <em>commit phase</em> 根据之前收集到的结果来决定是否进行最终的 Commit 或者 abort, 并且把这个消息 broadcast.</li></ul><p>上面是 2PC 的初级印象，但是细想起来其实问题蛮多的：</p><ul><li>participants “可以提交” 是一个什么样的状态？</li><li>对于 abort 2PC 应该如何处理这个日志？</li><li>并行的 2PC 是什么样子的？对 Lock Manager 有什么影响？</li></ul><p>下面详细解释一下。</p><h2 id="2PC-的结构"><a href="#2PC-的结构" class="headerlink" title="2PC 的结构"></a>2PC 的结构</h2><p><img src="https://image.mwish.me/blog-image/3149FDE05902E361F776579665A3F442.png" alt="3149FDE05902E361F776579665A3F442"></p><ol><li><code>coordinator</code> <ol><li>写<code>&lt;prepare TXN&gt;</code>  WAL</li><li>broadcast <code>prepare</code></li></ol></li><li><code>participants</code> 收到 <code>prepare</code><ol><li>执行事务，写 undo log 和 redo log</li><li>如果操作是成功的，那么事务进入一个 <code>pre-commit</code> 的状态：<ol><li>即使 abort 了也能够恢复这个状态</li><li>事务会写入一个 <code>&lt;prepare TXN&gt;</code> 的 log</li></ol></li><li>如果操作是失败的，那么写入 <code>&lt;don&#39;t commit TXN&gt;</code> 并且 abort</li><li>如果以上操作都成功，返回一个 <code>agreement</code>, 否则返回 <code>abort</code></li></ol></li></ol><p>对于 commit 阶段，实际上逻辑如下</p><ol><li><code>coordinator</code><ol><li>如果都是 <code>agreement</code>, 那么写 <code>&lt;Commit Txn&gt;</code> 的 Log, 否则写 <code>&lt;Abort Txn&gt;</code></li><li>广播</li></ol></li><li><code>participants</code> 收到后，执行对应逻辑，完成后返回 <code>ACK</code></li></ol><p><img src="https://image.mwish.me/blog-image/14B5C5E1-CB99-4552-A969-A5A88D95D6F3.png" alt="14B5C5E1-CB99-4552-A969-A5A88D95D6F3"></p><h3 id="2PC-的恢复"><a href="#2PC-的恢复" class="headerlink" title="2PC 的恢复"></a>2PC 的恢复</h3><ol><li>如果 Txn 有 <code>&lt;don&#39;t commit TXN&gt;</code> <code>&lt;commit TXN&gt;</code> <code>&lt;abort TXN&gt;</code> 的 Log, 情况应该非常明显了。</li><li>如果是 <code>&lt;ready&gt;</code> 的 log, 需要和其他节点一起决定状况（这意味着协调者的状态是 <code>wait</code>, 而各个节点都是 <code>ready</code>）</li><li>如果没有相关的状态，那么至少 <code>abort</code> 它是安全的。</li></ol><p>在 wiki 上也可以找到：</p><blockquote><p><em>Presumed abort</em> or <em>Presumed commit</em> are common such optimizations.<a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol#cite_note-weikum2001-2">[2]</a><a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol#cite_note-Bern2009-3">[3]</a><a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol#cite_note-mohan1983-5">[5]</a> An assumption about the outcome of transactions, either commit, or abort, can save both messages and logging operations by the participants during the 2PC protocol’s execution. For example, when presumed abort, if during system recovery from failure no logged evidence for commit of some transaction is found by the recovery procedure, then it assumes that the transaction has been aborted, and acts accordingly. This means that it does not matter if aborts are logged at all, and such logging can be saved under this assumption. Typically a penalty of additional operations is paid during recovery from failure, depending on optimization type. Thus the best variant of optimization, if any, is chosen according to failure and transaction outcome statistics.</p></blockquote><h3 id="Timeout"><a href="#Timeout" class="headerlink" title="Timeout"></a>Timeout</h3><blockquote><p>The greatest disadvantage of the two-phase commit protocol is that it is a blocking protocol. If the coordinator fails permanently, some participants will never resolve their transactions: After a participant has sent an <strong>agreement</strong> message to the coordinator, it will block until a <strong>commit</strong> or <strong>rollback</strong> is received.</p></blockquote><p>如果协调者收到了一个 <code>abort</code>, 其实还蛮欢喜的：那肯定大家一起 abort 。但是如果哪个机器憋着没消息了，哦豁，你得一直 block 着。</p><p>所以 2PC 一定程度上可能需要引入 timeout：</p><blockquote><p>对于协调者来说如果在指定时间内没有收到所有参与者的应答，则可以自动退出 WAIT 状态，并向所有参与者发送 rollback 通知。对于参与者来说如果位于 READY 状态，但是在指定时间内没有收到协调者的第二阶段通知，则不能武断地执行 rollback 操作，因为协调者可能发送的是 commit 通知，这个时候执行 rollback 就会导致数据不一致。</p><p>此时，我们可以介入互询机制，让参与者 A 去询问其他参与者 B 的执行情况。如果 B 执行了 rollback 或 commit 操作，则 A 可以大胆的与 B 执行相同的操作；如果 B 此时还没有到达 READY 状态，则可以推断出协调者发出的肯定是 rollback 通知；如果 B 同样位于 READY 状态，则 A 可以继续询问另外的参与者。只有当所有的参与者都位于 READY 状态时，此时两阶段提交协议无法处理，将陷入长时间的阻塞状态。</p></blockquote><h3 id="3PC-和-Pre-Commit"><a href="#3PC-和-Pre-Commit" class="headerlink" title="3PC 和 Pre Commit"></a>3PC 和 Pre Commit</h3><p>我们之前说到，全是<code>ready log</code> 是一个奇怪的状态。这个时候一定程度上可以引入 3PC：</p><p><a href="https://en.wikipedia.org/wiki/Three-phase_commit_protocol">https://en.wikipedia.org/wiki/Three-phase_commit_protocol</a></p><blockquote><p>A <a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol">two-phase commit protocol</a> cannot dependably recover from a failure of both the coordinator and a cohort member during the <strong>Commit phase</strong>. If only the coordinator had failed, and no cohort members had received a commit message, it could safely be inferred that no commit had happened. If, however, both the coordinator and a cohort member failed, it is possible that the failed cohort member was the first to be notified, and had actually done the commit. Even if a new coordinator is selected, it cannot confidently proceed with the operation until it has received an agreement from all cohort members, and hence must block until all cohort members respond.</p><p>The three-phase commit protocol eliminates this problem by introducing the Prepared to commit state. If the coordinator fails before sending preCommit messages, the cohort will unanimously agree that the operation was aborted. The coordinator will not send out a doCommit message until all cohort members have <strong>ACK</strong>ed that they are <strong>Prepared to commit</strong>. This eliminates the possibility that any cohort member actually completed the transaction before all cohort members were aware of the decision to do so (an ambiguity that necessitated indefinite blocking in the <a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol">two-phase commit protocol</a>).</p></blockquote><p><strong>Prepared to commit</strong> 这个状态表示, precommit 成功了就只能 commit 了，否则是应该 abort 的。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://segmentfault.com/a/1190000012534071">https://segmentfault.com/a/1190000012534071</a></li><li><a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol">https://en.wikipedia.org/wiki/Two-phase_commit_protocol</a></li><li><a href="https://en.wikipedia.org/wiki/Three-phase_commit_protocol">https://en.wikipedia.org/wiki/Three-phase_commit_protocol</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CALL: libc 和 C++ 标准库</title>
      <link href="/2020/04/04/CALL-libc-%E5%92%8C-C-%E6%A0%87%E5%87%86%E5%BA%93/"/>
      <url>/2020/04/04/CALL-libc-%E5%92%8C-C-%E6%A0%87%E5%87%86%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<p>CALL 是 <strong>(Compiler/Assembler/Linker/Loader)</strong>的简称。如果你和 C/C++ 打过交道的话，没有理由会对这几个词太陌生。所以今天这是一篇水文。</p><h2 id="Levels-of-Representation-Interpretation"><a href="#Levels-of-Representation-Interpretation" class="headerlink" title="Levels of Representation/Interpretation"></a>Levels of Representation/Interpretation</h2><p><img src="https://image.mwish.me/blog-image/level.png" alt="level"></p><ul><li>“XX 是一门 解释型语言”</li><li>“XX 是编译型语言”</li></ul><p>抛开正确性，一定程度上我们可以尝试填空（Python / C++、Go）并且知道：</p><ul><li>Python 可能会运行一个解释器（官方是 CPython, 可能有 Pypy 这样的），然后解释 Python 的字节码</li><li>C++、Go 会编译成 binary, 就我理解，这是“机器上的字节码”(这是跟 Python 字节码对应的，实际情况可能手是反过来的), 然后执行。这其中 Go 可能会有 Runtime、GC 这样的开销。</li></ul><p>但是同时，Python 也能通过一些方式打包成 exe （虽然很巨大），同时 LLVM 这些层次的引入让我们的理解模糊了起来。所以我们要明确一下这个 Level。</p><p><img src="https://image.mwish.me/blog-image/A6642C36-5B8D-4168-877C-9D3FCCD84A44.png" alt="A6642C36-5B8D-4168-877C-9D3FCCD84A44"></p><blockquote><ul><li>Language translation gives us another option</li><li>In general, we interpret a high-level language when efficiency is not critical and translate to a lower-level language to increase performance</li><li>Although this is becoming a “distinction without a difference”  Many intepreters do a “just in time” runtime compilation to bytecode that either is emulated or directly compiled to machine code (e.g. LLVM)</li></ul></blockquote><p>所以这个问题实际上是很含糊不清的，第三点里面 JIT 等的引入更让事情扑朔迷离了起来。具体其实可以参考这个链接里的说法：<a href="https://www.zhihu.com/question/19608553。">https://www.zhihu.com/question/19608553。</a></p><blockquote><p>一般被称为“解释型语言”的是主流实现为解释器的语言，但并不是说它就无法编译。例如说经常被认为是“解释型语言”的<a href="http://schemers.org/">Scheme</a>就有好几种编译器实现，其中率先支持<a href="http://www.r6rs.org/">R6RS</a>规范的大部分内容的是<a href="http://ikarus-scheme.org/">Ikarus</a>，支持在x86上编译Scheme；它最终不是生成某种虚拟机的字节码，而是直接生成x86机器码。</p></blockquote><p>实际上解释器的性能劣势也不一定是一种坏事，像我去年去 PyCon 听的“慢解释是一种优势”，虽然有点破罐子破摔的味道，但是如果你在 C/C++ 下开 asan/valgrind 或者带 <code>gcc -g</code>, 和 Go 这种带 Runtime 的、V8这些可以提供的debug比较，难免会有羡慕的想法。</p><blockquote><p>Interpreter provides instruction set independence: run on any machine</p></blockquote><p>就是这样。</p><h2 id="CALL-chain"><a href="#CALL-chain" class="headerlink" title="CALL chain"></a>CALL chain</h2><p><img src="https://image.mwish.me/blog-image/8009A6B1-A4E5-46A4-A40F-BD41F4E01D34.png" alt="8009A6B1-A4E5-46A4-A40F-BD41F4E01D34"></p><p>这是一张水图。可能还要处理一下预处理之类的过程，但是大概流程是这样没错。</p><h3 id="Compile"><a href="#Compile" class="headerlink" title="Compile"></a>Compile</h3><p>Compile 的过程大概是</p><ul><li>Lexer</li><li>Parser</li><li>Semantic Analysis and Optimization</li><li>Code generation</li></ul><p>不过看上面转的那篇文章，似乎形式有变，这方面我不是很了解。Lexer/Parser 的部分可以参考我之前的 Lex/Yacc 入门。总之，我们现在把源代码编译后可以转化为一种对应的 IR, 即 <code>nmsl.c</code> -&gt; <code>nmsl.S</code>.</p><h3 id="Assembler"><a href="#Assembler" class="headerlink" title="Assembler"></a>Assembler</h3><p>Assembler 接下来会<code>nmsl.s</code> -&gt; <code>nmsl.o</code>.</p><ul><li>Reads and Uses Directives</li><li>Replace Pseudo-instructions</li><li>Produce <strong>Machine Language</strong> rather than just <strong>Assembly Language</strong></li><li>Creates Object File</li></ul><p>顺便给出这个 part 一个很有意思的 slide:</p><p><img src="https://image.mwish.me/blog-image/顺便.png" alt="顺便"></p><h4 id="ELF"><a href="#ELF" class="headerlink" title="ELF"></a>ELF</h4><blockquote><ul><li>object file header: size and position of the other pieces of the object file</li><li>text segment: the machine code</li><li>data segment: binary representation of the static data in the source file</li><li><p>relocation information: identifies lines of code that need to be fixed up later</p></li><li><p>symbol table: list of this file’s labels and static data that can be referenced</p></li><li>debugging information</li><li>A standard format is ELF (except Microsoft)  <a href="http://www.skyfree.org/linux/references/ELF_Format.pdf">http://www.skyfree.org/linux/references/ELF_Format.pdf</a></li></ul></blockquote><p>这个我觉得还是 csapp 写得好…总之生成的目标文件会满足这样的形式。</p><h3 id="Linker"><a href="#Linker" class="headerlink" title="Linker"></a>Linker</h3><blockquote><p> Combines several object (.o) files into a single executable (“linking”)</p></blockquote><p><img src="https://image.mwish.me/blog-image/5B0267D5-78CF-4CB7-97B7-69D4D5D1DF88.png" alt="5B0267D5-78CF-4CB7-97B7-69D4D5D1DF88"></p><blockquote><ul><li>Step 1: Take text segment from each .o file and put them together</li><li>Step 2: Take data segment from each .o file, put them together, and concatenate this onto end of text segments</li><li>Step 3: Resolve references<ul><li>Go through Relocation Table; handle each entry</li><li>That is, fill in all absolute addresses</li></ul></li></ul></blockquote><p>这段我感觉 CSAPP 讲的稍微详细一些。</p><p>在应用层面上，这里其实还涉及（不一定是这里引入的）name mangling，calling convention这种 C/C++ 相关的问题，所以可能 <code>extern &quot;C&quot;</code> 在这种情况下就相对很好理解了。</p><h3 id="Loader"><a href="#Loader" class="headerlink" title="Loader"></a>Loader</h3><blockquote><p>When one is run, loader’s job is to load it into memory and start it running</p><p>In reality, loader is the operating system (OS)</p><ul><li>loading is one of the OS tasks</li><li>And these days, the loader actually does a lot of the linking:  Linker’s ‘executable’ is actually only partially linked, instead still having external references</li></ul></blockquote><p>这里可以参考 CSAPP 里面链接的时机相关的概念。</p><h3 id="libc-libc"><a href="#libc-libc" class="headerlink" title="libc/libc++"></a>libc/libc++</h3><p><code>qsort</code> 是一个 <code>&lt;cstdlib&gt;</code> 下的函数，如果你去 libc++ 找的话，会发现事情好像不太对：</p><p><a href="https://github.com/llvm-mirror/libcxx/blob/7c3769df62c0b3820130aa868397a80a042e0232/include/cstdlib">https://github.com/llvm-mirror/libcxx/blob/7c3769df62c0b3820130aa868397a80a042e0232/include/cstdlib</a></p><p>这里只有 <code>using</code> 和函数声明，没有对应的实现。</p><p>实际上 C++ 的标准库（以 libc++） 为例，可能会根据模版生成需要的函数/类。所以我们可以看到对应的一些源代码。</p><p>C语言的库函数实际上通常以链接库的形式在 libc 中提供，链接的时候我们找到：<a href="https://stackoverflow.com/questions/26277283/gcc-linking-libc-static-and-some-other-library-dynamically-revisited">https://stackoverflow.com/questions/26277283/gcc-linking-libc-static-and-some-other-library-dynamically-revisited</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> system </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RISC-V GetStart</title>
      <link href="/2020/03/28/RISC-V-GetStart/"/>
      <url>/2020/03/28/RISC-V-GetStart/</url>
      
        <content type="html"><![CDATA[<h1 id="RISC-V-and-C-Toolchains"><a href="#RISC-V-and-C-Toolchains" class="headerlink" title="RISC-V and C Toolchains"></a>RISC-V and C Toolchains</h1><h2 id="ISA-amp-amp-RISC-V"><a href="#ISA-amp-amp-RISC-V" class="headerlink" title="ISA &amp;&amp; RISC-V"></a>ISA &amp;&amp; RISC-V</h2><p>指令(Instruction) 是 CPU 的 primitives operations, 我们可以知道有这样的保障：</p><ul><li>指令顺序执行</li><li>每条指令完成很轻量的、基本的操作</li><li>每条指令会作用在 operand 上，甚至可能变更指令的顺序。</li></ul><p>CPU 会有某个 “family”, 实现了它自己的 instruction set。这个独特的 instruction set 又实现了某个具体的 ISA，例如：</p><ol><li>ARM, Intel x86, MIPS, RISC-V, IBM/Motorola PowerPC (old Mac), Intel IA64</li></ol><p>RISC-V 希望保证简洁的特性(以下摘自 RISC-V v2p1)：</p><blockquote><p>RISC-V的不同寻常之处，除了在于它是最近诞生的和开源的以外，还在于:和几乎所 有以往的ISA不同，它是模块化的。它的核心是一个名为<em>RV32I</em>的基础ISA，运行一个完整 的软件栈。RV32I是固定的，永远不会改变。这为编译器编写者，操作系统开发人员和汇 编语言程序员提供了稳定的目标。模块化来源于可选的标准扩展，根据应用程序的需要， 硬件可以包含或不包含这些扩展。这种模块化特性使得RISC-V具有了袖珍化、低能耗的特 点，而这对于嵌入式应用可能至关重要。RISC-V编译器得知当前硬件包含哪些扩展后，便 可以生成当前硬件条件下的最佳代码。惯例是把代表扩展的字母附加到指令集名称之后作 为指示。例如，RV32IMFD将乘法(RV32M)，单精度浮点(RV32F)和双精度浮点 (RV32D)的扩展添加到了基础指令集(RV32I)中。</p></blockquote><h2 id="RISC-V-basic-RV32I"><a href="#RISC-V-basic-RV32I" class="headerlink" title="RISC-V basic: RV32I"></a>RISC-V basic: RV32I</h2><p><img src="https://image.mwish.me/blog-image/寄存器模型.png" alt="寄存器模型"></p><ul><li>Registers: 32 words，每个长度是 32bits。（非基础的有16bit的压缩指令和 64bit 甚至更大的指令）</li><li>Memory: Huge</li></ul><p>访问 registers 和 memory 的速度大概差距 100-500倍</p><p>RISC-V 有 32个 <strong>RV32I</strong> 寄存器, 名称是 <code>x0</code>-<code>x31</code></p><blockquote><p>x0 is special, always holds the value zero<br> • So really only 31 registers able to hold variable values</p></blockquote><p>注意 6.828 可能会有对应的 name, 下面对原因有一定的解释</p><blockquote><p>Registers are also given symbolic names: <br> These will be described later and are a “convention”/“ABI” (Application Binary Interface):   Not actually enforced in hardware but needed to follow to keep things consistent</p></blockquote><p>Register 本身是没有类型的（废话）。</p><ul><li>RISC-V does not <strong>require</strong> that integers be word aligned</li><li>但是，如果不 align，对 atomicity 支持缺乏，同时 load 操作会慢上很多。</li></ul><p>So in <strong>practice</strong>, RISC-V requires integers to be aligned on 4-byte boundaries</p><h3 id="RISC-V-Instructions"><a href="#RISC-V-Instructions" class="headerlink" title="RISC-V Instructions"></a>RISC-V Instructions</h3><p>Instructions are fixed, 32b long （话说似乎 b 是 bit, B 是 Byte）</p><p><img src="https://image.mwish.me/blog-image/8C6F3A35-2220-475D-A75B-C1E09A1E6B69.png" alt="8C6F3A35-2220-475D-A75B-C1E09A1E6B69"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add x1, x2, x3</span><br></pre></td></tr></table></figure><p><code>x1 = x2 + x3</code> 与上面等价. add 是 operation code (opcode), x1 是 destination register, <code>x2</code> <code>x3</code> 是第一、第二个 operand register。以上的格式被称为 assembly comment syntax</p><p><code>x0</code> 在 RISC-V 中代表 no-op, 就是“读是0，什么都不写”。实际上，RISC-V 核心的指令很精简，它依靠 <code>x0</code> 来实现很多伪指令。</p><h4 id="立即数-immediates-和常量构建"><a href="#立即数-immediates-和常量构建" class="headerlink" title="立即数(immediates) 和常量构建"></a>立即数(immediates) 和常量构建</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">addi x3, x4, -10</span><br></pre></td></tr></table></figure><p>相当于 <code>f = g - 10</code>，当然这里有个问题就是这个立即数能有多大呢？ RISC-V 32 中指令是定长的，虽然我们有压缩指令之类的支持，但是 <code>imm</code> 占用的 bytes 仍然是受限的，显然，它没有能力表示 32 位长度的数据：一个 I-type 的指令只有 12bits 来保存立即数。</p><p>那肯定我们还需要构建一个 32bit 的数吧！可以看看如下：</p><blockquote><p>图 2.1 剩下的两条整数计算指令主要用于构造大的常量数值和链接。加载立即数到高 位(lui)将 20 位常量加载到寄存器的高 20 位。接着便可以使用标准的立即指令来创建 32 位常量。这样子，仅使用 2 条 32 位 RV32I 指令，便可构造一个 32 位常量。向 PC 高位加 上立即数(auipc)让我们仅用两条指令，便可以基于当前 PC 以任意偏移量转移控制流或 者访问数据。将 auipc 中的 20 位立即数与 jalr(参见下面)中 12 位立即数的组合，我们 可以将执行流转移到任何 32 位 PC 相对地址。而 auipc 加上普通加载或存储指令中的 12 位立即数偏移量，使我们可以访问任何 32 位 PC 相对地址的数据。</p></blockquote><h3 id="data-transfer"><a href="#data-transfer" class="headerlink" title="data transfer"></a>data transfer</h3><p><img src="https://image.mwish.me/blog-image/853BC117-2DE0-49B5-AD9C-B3D24C18BE16.png" alt="853BC117-2DE0-49B5-AD9C-B3D24C18BE16"></p><p>很正常的思路是，要从内存 — 寄存器读写数据，而且地址是 32位的 （肯定不能给立即数了）</p><ul><li>1 word = 4bytes</li><li>Data typically smaller than 32 bits, but rarely smaller than 8 bits</li><li>Memory addresses are really  in bytes, not words</li></ul><p>下面的<code>lw</code> <code>sw</code> 表示 <code>load</code> <code>store</code> 单位为 <code>word</code> 的数据</p><p>注意，这里提到 RISC-V 是 Little-Endian 的，这意味着我们从下头读 <code>0x000408012</code></p><p><img src="https://image.mwish.me/blog-image/9BB275BA-B363-4E42-B421-7A75C4D0F1CC.png" alt="9BB275BA-B363-4E42-B421-7A75C4D0F1CC"></p><p>随便从知乎找的图</p><p><img src="https://image.mwish.me/blog-image/随便从知乎找的图.jpg" alt="随便从知乎找的图"></p><p>也就是说，一个 int 0x03f5</p><p>是：</p><ul><li>f5 : 0</li><li>03 : 1</li><li>00 : 2</li><li>00 : 3</li></ul><p>实际上 BigEndian LittleEndian 可以看之前 Post 的那篇文章: <a href="https://zhuanlan.zhihu.com/p/254144597">https://zhuanlan.zhihu.com/p/254144597</a></p><p><img src="https://image.mwish.me/blog-image/1D6C494E-FAEE-4D74-ACD9-F9FD987A591B.png" alt="1D6C494E-FAEE-4D74-ACD9-F9FD987A591B"></p><p><code>int</code> 如果是 32 bit 的，那么 1word = 4byte, 显然合理对吧，上面这段也很好懂。</p><ul><li>lw 是 reg &lt;- memory on address</li><li>sw 是 reg value -&gt; memory on address</li></ul><p>还有 <code>lb</code> <code>sb</code> , 很好懂对吧，就不多解释了。</p><blockquote><p>RISC-V also has “unsigned byte” loads (<strong>lbu</strong>) which zero extend to fill register. Why no unsigned store byte <strong>sbu</strong>?</p></blockquote><h3 id="Logical-Instruction"><a href="#Logical-Instruction" class="headerlink" title="Logical Instruction"></a>Logical Instruction</h3><p><img src="https://image.mwish.me/blog-image/7FFBD3D3-88CB-43F5-BB70-F069403DC8CC.png" alt="7FFBD3D3-88CB-43F5-BB70-F069403DC8CC"></p><p>注意算数移位和逻辑移位：对于signed, 算数移位会把符号位移动下来。</p><p>然后在 RISC-V 里面，可以把它们最后一个字母当成区分 <code>logical</code> 和 <code>arithmetic</code> 的标志</p><h3 id="分支指令"><a href="#分支指令" class="headerlink" title="分支指令"></a>分支指令</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">beq register1,register2,L1</span><br></pre></td></tr></table></figure><p><code>if (x1 == x2) goto L1</code>, 其中 L1 是一个 Label.</p><h3 id="分支指令-1"><a href="#分支指令-1" class="headerlink" title="分支指令"></a>分支指令</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">beq register1,register2,L1</span><br></pre></td></tr></table></figure><p>if (x1 == x2) goto L1, 其中 L1 是一个 Label. S</p><p>beq 这种 b 开头的指令中，b 是 branch 的缩写，beq 就是 Branch on EQual，同理可以推测：</p><ul><li>blt: branch on less than </li><li>bne: branch on not equal</li><li>bltu Branch on Greater Than Unsigned </li></ul><p>值得玩味的是，RISC-V 里面不存在greater ，它会被转成 less  。</p><p>上面的代码可以被视为 conditional branch, 此外我们还可以关注 unconditional branch. 也就是 always jump 的 case，这里有语句 j，即 jump。jal 和 jalr 这两个指令，jal 是 jump and link。它的形式大概是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">jal rd offset</span><br><span class="line">jalr rd rs (offset)</span><br></pre></td></tr></table></figure><ul><li>jal 会把 PC+4 写入到 rd 寄存器中，作为保存“调用者” ，然后把内容跳转到 offset </li></ul><p>所以它可能的使用场景是：</p><ol><li>无条件的跳转（代码里写 goto）</li><li>调用别的函数（上下文写到rd里面）</li></ol><p>如果是 jalr 就是 <code>PC + imm</code> 变成 <code>rs + imm</code></p><h3 id="再论计算"><a href="#再论计算" class="headerlink" title="再论计算"></a>再论计算</h3><blockquote><p>有什么不同之处?首先，RISC-V 中没有字节或半字宽度的整数计算操作。操作始终 是以完整的寄存器宽度。内存访问需要的能量比算术运算高几个数量级。因此低宽度的数 据访问可以节省大量的能量，但低宽度的运算不会。ARM-32 具有一个不寻常的功能，对 于大多数算术逻辑运算中的一个操作数，你可以选择对它进行移位。尽管这些指令的使用 频率很低，但它使数据路径和数据通路更加复杂。与此相对的是，RV32I 提供了单独的移位指令。</p><p>RV32I 也不包含乘法和除法，它们包含在可选的 RV32M 扩展中(参见第 4 章)。与 ARM-32 和 x86-32 不同，即使处理器没有添加乘除法扩展，完整的 RISC-V 软件栈也可以 运行，这可以缩小嵌入式芯片的面积。MIPS-32 汇编程序可能用一系列移位以及加法指令 来替换乘法，以提高性能，这可能会使程序员看到处理器执行了汇编程序中没有的指令， 进而造成混淆。RV32I 可以忽略了这些特性:循环移位指令和整数算术溢出检测，这两个 特性都可以用若干条 RV32I 指令来实现(参见第 2.6 节)。</p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>The Go Memory Model</title>
      <link href="/2020/02/29/The-Go-Memory-Model/"/>
      <url>/2020/02/29/The-Go-Memory-Model/</url>
      
        <content type="html"><![CDATA[<p>memory model 其实各大语言似乎都有，所以看到下面的代码你大概不会陌生</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="type">string</span></span><br><span class="line"><span class="keyword">var</span> done <span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">setup</span><span class="params">()</span></span> &#123;</span><br><span class="line">a = <span class="string">&quot;hello, world&quot;</span></span><br><span class="line">done = <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">go</span> setup()</span><br><span class="line"><span class="keyword">for</span> !done &#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>相信你可以用经验判断上面的例子哪里有问题，实际上，一个程序面临着：</p><ul><li>编译器可能把无关的代码乱序以提高效率</li><li>CPU 可能会产生执行上的乱序（比如 Intel 的 Store-Load 乱序）</li><li>多核内存上有各种各样的麻烦<ul><li>虽说内存和并发关系暧昧不清，但是毫无疑问，前者对写代码是存在影响的。有的时候甚至会给人带来奇怪的印象和吊诡的设计，比如 C 和 Java 不同含义的 volatile.</li></ul></li></ul><p>那么 Go 同样要面临这样的问题，下面的代码能够很好的运作。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">xxx := <span class="literal">nil</span></span><br><span class="line">wg.Add(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">defer</span> wg.Done()</span><br><span class="line"><span class="comment">// logic..</span></span><br><span class="line">xxx = val</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">wg.Done()</span><br><span class="line"><span class="comment">// read xxx</span></span><br></pre></td></tr></table></figure><p>还有：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">xChan = <span class="built_in">make</span>(<span class="keyword">chan</span> X)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">xChan &lt;- val</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">xxx := &lt;- xChan</span><br><span class="line"><span class="comment">// read xxx</span></span><br></pre></td></tr></table></figure><p>为什么呢？我们来看看这个 blog 吧：<a href="https://golang.org/ref/mem">https://golang.org/ref/mem</a></p><h2 id="Happens-Before"><a href="#Happens-Before" class="headerlink" title="Happens Before"></a>Happens Before</h2><blockquote><p>Within a single goroutine, the happens-before order is the order expressed by the program.</p><p>A read <em>r</em> of a variable <code>v</code> is <em>allowed</em> to observe a write <em>w</em> to <code>v</code> if both of the following hold:</p><ol><li><em>r</em> does not happen before <em>w</em>.</li><li>There is no other write <em>w’</em> to <code>v</code> that happens after <em>w</em> but before <em>r</em>.</li></ol><p>To guarantee that a read <em>r</em> of a variable <code>v</code> observes a particular write <em>w</em> to <code>v</code>, ensure that <em>w</em> is the only write <em>r</em> is allowed to observe. That is, <em>r</em> is <em>guaranteed</em> to observe <em>w</em> if both of the following hold:</p><ol><li><em>w</em> happens before <em>r</em>.</li><li>Any other write to the shared variable <code>v</code> either happens before <em>w</em> or after <em>r</em>.</li></ol><p>This pair of conditions is stronger than the first pair; it requires that there are no other writes happening concurrently with <em>w</em> or <em>r</em>.</p></blockquote><p>原文还是比较精炼的，我就直接翻译了。目前的 happens before 针对的对象是单个变量。注意</p><blockquote><p>Reads and writes of values larger than a single machine word behave as multiple machine-word-sized operations in an unspecified order.</p></blockquote><p>关于 happens before, Go 语言的介绍还是很简单的，我倾向于阅读一下 C++ Concurrency In Action, 摘录下面关于 happens-before 的一段</p><blockquote><p>At the basic level, inter-thread happens-before is relatively simple and relies on the synchronizes-with relationship introduced in section 5.3.1: if operation A in one thread synchronizes-with operation B in another thread, then A inter-thread happens- before B. It’s also a transitive relation: if A inter-thread happens-before B and B inter- thread happens-before C, then A inter-thread happens-before C. You saw this in listing 5.2 as well.</p><p>Inter-thread happens-before also combines with the sequenced-before relation: if operation A is sequenced before operation B, and operation B inter-thread happens- before operation C, then A inter-thread happens-before C. Similarly, if A synchronizes- with B and B is sequenced before C, then A inter-thread happens-before C. These two together mean that if you make a series of changes to data in a single thread, you need only one synchronizes-with relationship for the data to be visible to subsequent opera- tions on the thread that executed C.</p></blockquote><p>以上你就有了关于 happens before 的基本认知。</p><h3 id="黑暗面"><a href="#黑暗面" class="headerlink" title="黑暗面"></a>黑暗面</h3><p>下面内容是我胡扯的</p><blockquote><p>This hardware must obey the following ordering constraints [McK05a, McK05b]:</p><ol><li>Each CPU will always perceive its own memory accesses as occurring in program order.</li><li>CPUs will reorder a given operation with a store only if the two operations are referencing different locations.</li><li>All of a given CPU’s loads preceding a read memory barrier (smp_rmb()) will be perceived by all CPUs to precede any loads following that read memory barrier.</li><li>All of a given CPU’s stores preceding a write mem- ory barrier (smp_wmb()) will be perceived by all CPUs to precede any stores following that write memory barrier.</li><li>All of a given CPU’s accesses (loads and stores) preceding a full memory barrier (smp_mb()) will be perceived by all CPUs to precede any accesses following that memory barrier.</li></ol></blockquote><h2 id="Synchronization"><a href="#Synchronization" class="headerlink" title="Synchronization"></a>Synchronization</h2><h3 id="Initialization"><a href="#Initialization" class="headerlink" title="Initialization"></a>Initialization</h3><blockquote><p>Program initialization runs in a single goroutine, but that goroutine may create other goroutines, which run concurrently.</p><p>If a package <code>p</code> imports package <code>q</code>, the completion of <code>q</code>‘s <code>init</code> functions happens before the start of any of <code>p</code>‘s.</p><p>The start of the function <code>main.main</code> happens after all <code>init</code> functions have finished.</p></blockquote><p>就是 <code>init</code> 阶段形成一棵树或者DAG，后被 import 的先被初始化。</p><h3 id="Goroutine-creation"><a href="#Goroutine-creation" class="headerlink" title="Goroutine creation"></a>Goroutine creation</h3><blockquote><p> The <code>go</code> statement that starts a new goroutine happens before the goroutine’s execution begins.</p></blockquote><p>官方文档的例子很好，一字不易</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">hello</span><span class="params">()</span></span> &#123;</span><br><span class="line">a = <span class="string">&quot;hello, world&quot;</span></span><br><span class="line"><span class="keyword">go</span> f()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><code>go</code> before goroutine’s begin</li><li><code>a</code> 会先被初始化</li></ol><h3 id="Goroutine-destruction"><a href="#Goroutine-destruction" class="headerlink" title="Goroutine destruction"></a>Goroutine destruction</h3><blockquote><p>The exit of a goroutine is not guaranteed to happen before any event in the program. For example, in this program:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">var a string</span><br><span class="line"></span><br><span class="line">func hello() &#123;</span><br><span class="line">go func() &#123; a = &quot;hello&quot; &#125;()</span><br><span class="line">print(a)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>the assignment to <code>a</code> is not followed by any synchronization event, so it is not guaranteed to be observed by any other goroutine. In fact, an aggressive compiler might delete the entire <code>go</code> statement.</p><p>If the effects of a goroutine must be observed by another goroutine, use a synchronization mechanism such as a lock or channel communication to establish a relative ordering.</p></blockquote><p>（其实我很好奇，这一段能不能过编译）</p><h3 id="Channel-communication"><a href="#Channel-communication" class="headerlink" title="Channel communication"></a>Channel communication</h3><blockquote><p><em>A send on a channel happens before the corresponding receive from that channel completes.</em></p><p><em>A receive from an unbuffered channel happens before the send on that channel completes.</em></p></blockquote><p>回想起开头的代码，不难理解为什么下列代码是合理的</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">xChan = <span class="built_in">make</span>(<span class="keyword">chan</span> X)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">xChan &lt;- val</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">xxx := &lt;- xChan</span><br><span class="line"><span class="comment">// read xxx</span></span><br></pre></td></tr></table></figure><p>代码还有个比较有意思的地方是限流</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> limit = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> _, w := <span class="keyword">range</span> work &#123;</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(w <span class="keyword">func</span>()</span></span>) &#123;</span><br><span class="line">limit &lt;- <span class="number">1</span></span><br><span class="line">w()</span><br><span class="line">&lt;-limit</span><br><span class="line">&#125;(w)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">select</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="sync-库"><a href="#sync-库" class="headerlink" title="sync 库"></a>sync 库</h3><blockquote><p><em>A single call of</em> <code>f()</code> <em>from</em> <code>once.Do(f)</code> <em>happens (returns) before any call of</em> <code>once.Do(f)</code> <em>returns.</em></p><p><em>For any call to</em> <code>l.RLock</code> <em>on a</em> <code>sync.RWMutex</code> <em>variable</em> <code>l</code><em>, there is an</em> <em>n</em> <em>such that the</em> <code>l.RLock</code> <em>happens (returns) after call</em> <em>n</em> <em>to</em> <code>l.Unlock</code> <em>and the matching</em> <code>l.RUnlock</code> <em>happens before call</em> <em>n**+1 to</em> <code>l.Lock</code><em>.</em></p></blockquote><p>如果 <code>Lock</code> <code>Once</code> 有问题，那我们的程序真应该出毛病了！实际上，程序最早的 <code>wg.Done</code> 也有 happens-before 语义！</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>GFS 简读</title>
      <link href="/2020/02/25/GFS-%E7%AE%80%E8%AF%BB/"/>
      <url>/2020/02/25/GFS-%E7%AE%80%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h2 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h2><p>由于有多份副本，GFS 面临着一致性的问题。</p><p>当数据被进行 replicated 的时候，一致性是很重要的。你读一个副本的时候，先写了但是数据还没过来呢</p><p>关于一致性，有强一致性和弱一致性，又派生出最终一致性这些意义不明的狗东西</p><p>这篇文章 写得不错，另外 ddia 关于这个也有简单讨论。</p><p><a href="https://zhuanlan.zhihu.com/p/48782892">https://zhuanlan.zhihu.com/p/48782892</a></p><blockquote><p> General tension between these:<br>     strong consistency is easy for application writers<br>     strong consistency is bad for performance<br>     weak consistency has good performance and is easy to scale to many servers<br>     weak consistency is complex to reason about</p></blockquote><h2 id="GFS-的特性-我相信读者们读过一万遍了"><a href="#GFS-的特性-我相信读者们读过一万遍了" class="headerlink" title="GFS 的特性(我相信读者们读过一万遍了)"></a>GFS 的特性(我相信读者们读过一万遍了)</h2><ol><li><p>失效是常态，而非意外事件：这点同 mapreduce, 我们需要处理失效等问题，来保证程序能够稳步的运行</p></li><li><p>文件“非常巨大”</p><blockquote><p>我们经常需要处理快速增长的、并且由数亿个对象构成的、数以 TB 的数据<br>集时，采用管理数亿个 KB 大小的小文件的方式是非常不明智的</p><p>(都用tb, 数个gb算, 好强啊，我什么时候能买的起这么多存储)</p></blockquote></li><li><p>文件的修改采取 append 形式，很少会实际的把数据弄掉。写完之后尽量只进行“顺序读”，而非 RandomAccess. 同时提供 atomic 的 append 调用。</p></li><li><p>GFS 提供了快照操作，能够对文件/目录下的文件取 Snapshot</p></li><li><p>没用 POSIX API，但是仍然有弱化的相似 API</p></li></ol><h2 id="GFS"><a href="#GFS" class="headerlink" title="GFS"></a>GFS</h2><p><img src="/Users/fuasahi/Downloads/C7442FCD-3FDB-4930-8EEB-8CA54E3E396D.png" alt="C7442FCD-3FDB-4930-8EEB-8CA54E3E396D"></p><blockquote><p>GFS 存储的文件都被分割成固定大小的 Chunk。在 Chunk 创建的时候，Master 服务器会给每个 Chunk 分 配一个不变的、全球唯一的 64 位的 Chunk 标识。Chunk 服务器把 Chunk 以 Linux 文件的形式保存在本地硬盘 上，并且根据指定的 Chunk 标识和字节范围来读写块数据。出于可靠性的考虑，每个块都会复制到多个块服 务器上。缺省情况下，我们使用 3 个存储复制节点，不过用户可以为不同的文件命名空间设定不同的复制级别。</p><p>Master 节点管理所有的文件系统元数据。这些元数据包括名字空间、访问控制信息、文件和 Chunk 的映 射信息、以及当前 Chunk 的位置信息。Master 节点还管理着系统范围内的活动，比如，Chunk Lease、孤儿 Chunk的回收、以及 Chunk 在 Chunk 服务器之间的迁移。</p></blockquote><p>GFS 的代码跑在 user-space 上，同时被链接到库里。</p><p>论文提到 GFS 客户端和服务端都不用写缓存：</p><blockquote><p>客户端缓存数据几乎没有什么用处，因为大部 分程序要么以流的方式读取一个巨大文件，要么工作集太大根本无法被缓存。</p><p>Chunk 服务器不需要缓存文件数据的原因是，Chunk 以本地文件的方式保存，Linux 操作系统的文件系统缓存会把经常访问的数据缓存在内存中。</p></blockquote><h3 id="Master’s-metadata"><a href="#Master’s-metadata" class="headerlink" title="Master’s metadata"></a>Master’s metadata</h3><p><img src="/Users/fuasahi/Downloads/14BB9EEE-7E8F-4EB4-9752-BF22671DFEB4.png" alt="14BB9EEE-7E8F-4EB4-9752-BF22671DFEB4"></p><ul><li><code>map(filename --&gt; [chunk-servers])</code>, ns tree</li><li>chunk handler, lease <code>map(handle --&gt; ([cs, version, primary, lease expiration]))</code></li><li>Chunk 的 信息</li><li>LOG, CKPT</li></ul><blockquote><p>Master 服务器不会持久保存 Chunk 位置信息。Master 服务器在启动时，或者有新的 Chunk 服务器加入时，向各个 Chunk 服务器轮询它们所存储的 Chunk 的信息。</p><p>同样的，每个文件的在命名空间中的数据大小通常在 64 字节以下，因为保存的文件名是用前缀压缩算法压缩过的。</p></blockquote><h4 id="操作日志"><a href="#操作日志" class="headerlink" title="操作日志"></a>操作日志</h4><ul><li>log 复制到 remote 多台机器，全部完成之后，才会响应客户端</li><li>chunk保证log持久化之后，对客户端是可见的</li><li>master 能够 replay log 和构建 ckpt</li></ul><h3 id="Read"><a href="#Read" class="headerlink" title="Read"></a>Read</h3><p><img src="/Users/fuasahi/Downloads/EC865399-2D30-4FF9-B84A-02D81A237714.png" alt="EC865399-2D30-4FF9-B84A-02D81A237714"></p><blockquote><p>客户端并不通过 Master 节点读写文件数据。反之，客户端向 Master 节点询问它应该联系的 Chunk 服务器。 客户端将这些 metadata 缓存一段时间，后续的操作将直接和 Chunk 服务器进行数据读写操作。</p></blockquote><ul><li>Client 把 <code>(filename, offset)</code> 发送给 Master</li><li>Master 发送 <code>(u64_chunk_id, [chunk_servers])</code> 回去，客户端有一定的对这个结果的缓存</li><li>Client 从 Chunk Server 读数据，一般会选取 <code>[chunk_server]</code> 里面最近的机器去读取。</li></ul><p>这个其实和文件系统 inode 和 block 的设计有一定相似性，逻辑上一定程度上可以按照那个理解。目前 GFS 的默认 Chunk Size 是 64M，这个值似乎在 HDFS 里面是可以调的。64M 减轻了 Master 的内存开销和 Client 的 metadata 缓存开销。但是其实这样也会造成很大的 internal fragments, 不适合小文件的处理，所以还是用户自己看情况 trade-off 把。</p><p>论文提到了：</p><blockquote><p>在实际应用中，由于我们的程序通常是连续的读取包含多个 Chunk 的大文件，热点还不是主要的问题。</p><p>然而，当我们第一次把 GFS 用于批处理队列系统的时候，热点的问题还是产生了:一个可执行文件在GFS 上保存为 single-chunk 文件，之后这个可执行文件在数百台机器上同时启动。存放这个可执行文件的几 个 Chunk 服务器被数百个客户端的并发请求访问导致系统局部过载。我们通过使用更大的复制参数来保存可 执行文件，以及错开批处理队列系统程序的启动时间的方法解决了这个问题。一个可能的长效解决方案是， 在这种的情况下，允许客户端从其它客户端读取数据。</p></blockquote><h2 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h2><p>GFS 对 file namespace 的修改，包括创建文件，是 atomic 的。 file namespace 只在 master 节点上操作。</p><blockquote><p>the master’s operation log defines a <strong>global total order</strong> of these operations</p></blockquote><p>但是并行的client写入是危险的，可以参考截图和对下面 phenomena 的定义</p><blockquote><p>When a mutation succeeds without interference from concurrent writers, the affected region is defined (and by implication consistent): all clients will always see what the mutation has written. Concurrent successful mutations leave the region undefined but consistent: all clients see the same data, but it may not reflect what any one mutation has written. Typically, it consists of mingled fragments from multiple mutations. A failed mutation makes the region in- consistent (hence also undefined): different clients may see different data at different times. We describe below how our applications can distinguish defined regions from undefined</p></blockquote><p>通俗的讲，需要辨别“一致”和”已定义”, 前者是多个副本内容的一致，后者是针对写/append 语义的。</p><p>GFS 保证写入的文件是“一致的”，这包括：</p><blockquote><p>(a) 对 Chunk 的所有副本的修改操作顺序一致(3.1 章)，</p><p>(b)使用 Chunk 的版本号<strong>（这个值是跟 Lease 挂钩的，不理解的话可以看后面）</strong>来检测副本是否因为它所在的 Chunk 服务器宕机(4.5 章)而错过了修改操作 而导致其失效。失效的副本不会再进行任何修改操作，Master 服务器也不再返回这个 Chunk 副本的位置信息 给客户端。它们会被垃圾收集系统尽快回收。</p></blockquote><p>a 很好理解，b 相对难理解很多, 所以我贴原文：</p><blockquote><p>using chunk version numbers to detect any replica that has become stale because it has missed mu- tations while its chunkserver was down </p></blockquote><p>然后注意 refresh</p><blockquote><p>Since clients cache chunk locations, they may read from a stale replica before that information is refreshed. This win- dow is limited by the cache entry’s timeout and the next open of the file, which purges from the cache all chunk in- formation for that file. Moreover, as most of our files are append-only, a stale replica usually returns a premature end of chunk rather than outdated data. When a reader retries and contacts the master, it will immediately get current chunk locations.</p></blockquote><p>所以我认为上面这段含义是，GFS 可能给客户端返回非最新但一致的数据，然后等待从客户端读取/刷新</p><blockquote><p>在实际应用中，我们所有的应用程序对文件的写入操作都是尽量采用数据追加方式，而不是覆盖方式。 一种典型的应用，应用程序从头到尾写入数据，生成了一个文件。写入所有数据之后，应用程序自动将文件 改名为一个永久保存的文件名，或者周期性的作 Checkpoint，记录成功写入了多少数据。Checkpoint 文件可以 包含程序级别的校验和。Readers 仅校验并处理上个 Checkpoint 之后产生的文件 region，这些文件 region 的状 态一定是已定义的。这个方法满足了我们一致性和并发处理的要求。追加写入比随机位置写入更加有效率， 对应用程序的失败处理更具有弹性。Checkpoint 可以让 Writer 以渐进的方式重新开始，并且可以防止 Reader 处理已经被成功写入，但是从应用程序的角度来看还并未完成的数据。</p></blockquote><h2 id="Atomic-Append"><a href="#Atomic-Append" class="headerlink" title="Atomic Append"></a>Atomic Append</h2><ol><li>client 想 append, 所以 ask for last chunk, 有可能是 master 上 no primary 的。</li><li>master 寻找版本号等于 master 的数据，然后如果没有 primary 分配 primary 和 lease。注意，只有认为没有 primary 的时候，master 才会 increase version<ol><li>如果联系不上，master 需要 wait for the lease, generate new primary</li><li>写顺序由 Primary 决定，是 chunk 内确定的, 具体参考论文3.2</li></ol></li><li>给客户端返回 (P, S, #V + Lease)</li><li>Master 持久化这个 version number</li></ol><blockquote><p>GFS 􏰂供了一种原子的数据追加操作–记录追加。传统方式的写入操作，客户程序会指定数据写入的偏 移量。对同一个region的并行写入操作不是串行的:region尾部可能会包含多个不同客户机写入的数据片段。 使用记录追加，客户机只需要指定要写入的数据。GFS 保证至少有一次原子的写入操作成功执行(即写入一 个顺序的 byte 流)，写入的数据追加到 GFS 指定的偏移位置上，之后 GFS 返回这个偏移量给客户机。这类似 于在 Unix 操作系统编程环境中，对以 O_APPEND 模式打开的文件，多个并发写操作在没有竞态条件时的行 为。</p></blockquote><p>所以，你仍然可能有各种各样的问题，虽然它是指定顺序运行的。所以论文在2最后写了，应该在应用层做一定的决定（不知道这个部分有没有被封装成库）</p><blockquote><p>在实际应用中，我们所有的应用程序对文件的写入操作都是尽量采用数据追加方式，而不是覆盖方式。 一种典型的应用，应用程序从头到尾写入数据，生成了一个文件。写入所有数据之后，应用程序自动将文件 改名为一个永久保存的文件名，或者周期性的作 Checkpoint，记录成功写入了多少数据。Checkpoint 文件可以 包含程序级别的校验和。Readers 仅校验并处理上个 Checkpoint 之后产生的文件 region，这些文件 region 的状 态一定是已定义的。这个方法满足了我们一致性和并发处理的要求。追加写入比随机位置写入更加有效率， 对应用程序的失败处理更具有弹性。Checkpoint 可以让 Writer 以渐进的方式重新开始，并且可以防止 Reader 处理已经被成功写入，但是从应用程序的角度来看还并未完成的数据。</p><p>我们再来分析另一种典型的应用。许多应用程序并行的追加数据到同一个文件，比如进行结果的合并或 者是一个生产者-消费者队列。记录追加方式的“至少一次追加”的特性保证了 Writer 的输出。Readers 使用 下面的方法来处理偶然性的填充数据和重复内容。Writers 在每条写入的记录中都包含了额外的信息，例如 Checksum，用来验证它的有效性。Reader 可以利用 Checksum 识别和抛弃额外的填充数据和记录片段。如果 应用不能容忍偶尔的重复内容(比如，如果这些重复数据触发了非幂等操作)，可以用记录的唯一标识符来过滤 它们，这些唯一标识符通常用于命名程序中处理的实体对象，例如 web 文档。这些记录 I/O 功能18都包含在我 们的程序共享的库中，并且适用于 Google 内部的其它的文件接口实现。所以，相同序列的记录，加上一些偶 尔出现的重复数据，都被分发到 Reader 了。</p></blockquote><p>而系统只能保证：</p><blockquote><p>如果操作成功执行，数据一定已经写入到 Chunk 的所有副本的相同偏移位置上</p></blockquote><h2 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h2><p>你可以把这个 GFS 系统当成是允许 cow 的，当你请求 snapshot 的时候：</p><ol><li>取消所有现有的 Lease, 并写 wal</li><li>copy metadata, 并且记录 rc, 拷贝有同样的 metadata</li><li>处理写 chunk 的时候，如果是快照写 C，Master 会 copy 一份新 chunk C’</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Go Concurrency Patterns</title>
      <link href="/2020/02/19/Go-Concurrency-Patterns-Pipeline/"/>
      <url>/2020/02/19/Go-Concurrency-Patterns-Pipeline/</url>
      
        <content type="html"><![CDATA[<h2 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h2><blockquote><p> Informally, a pipeline is a series of <em>stages</em> connected by channels, where each stage is a group of goroutines running the same function. In each stage, the goroutines</p><ul><li>receive values from <em>upstream</em> via <em>inbound</em> channels</li><li>perform some function on that data, usually producing new values</li><li>send values <em>downstream</em> via <em>outbound</em> channels</li></ul></blockquote><p>你可能对 OS 里面的 pipeline 相当熟悉，每天都用。实际上甚至在 6.828 2019 作业里面还实现了一个类似的模式实现 prime: <a href="https://pdos.csail.mit.edu/6.828/2019/labs/util.html">https://pdos.csail.mit.edu/6.828/2019/labs/util.html</a></p><p>这个 pipeline 意思是通过 <code>fn(in chan) out chan</code> 这样的模式不停套 channel 链，最后提供给一个消费者：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">chan1 := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">2</span>; i &lt; <span class="number">100</span>; i++ &#123;</span><br><span class="line">chan1 &lt;- i</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">close</span>(chan1)</span><br><span class="line">&#125;()</span><br><span class="line">primeChan := Filter(chan1, IsPrime)</span><br><span class="line"><span class="keyword">for</span> prime := <span class="keyword">range</span> primeChan &#123;</span><br><span class="line">fmt.Println(<span class="string">&quot;Recv prime: &quot;</span>, prime)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样甚至能很函数式(bushi)的套圈：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="comment">// Set up the pipeline and consume the output.</span></span><br><span class="line">    <span class="keyword">for</span> n := <span class="keyword">range</span> sq(sq(gen(<span class="number">2</span>, <span class="number">3</span>))) &#123;</span><br><span class="line">        fmt.Println(n) <span class="comment">// 16 then 81</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Fan-in-fan-out"><a href="#Fan-in-fan-out" class="headerlink" title="Fan-in/fan-out"></a>Fan-in/fan-out</h3><blockquote><p>Multiple functions can read from the same channel until that channel is closed; this is called <em>fan-out</em>. This provides a way to distribute work amongst a group of workers to parallelize CPU use and I/O.</p><p>A function can read from multiple inputs and proceed until all are closed by multiplexing the input channels onto a single channel that’s closed when all the inputs are closed. This is called <em>fan-in</em>.</p></blockquote><p>chan 其实类似一个很诡异(niubi)的 mpms 的 queue。上述的 <code>sq</code> , <code>gen</code> 都是：</p><ul><li>接受一个/零个 in channel</li><li>apply 一系列操作</li><li>吐出一个 out channel</li></ul><p>博客中提供了一个 <code>merge</code> 函数的例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    in := gen(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Distribute the sq work across two goroutines that both read from in.</span></span><br><span class="line">    c1 := sq(in)</span><br><span class="line">    c2 := sq(in)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Consume the merged output from c1 and c2.</span></span><br><span class="line">    <span class="keyword">for</span> n := <span class="keyword">range</span> merge(c1, c2) &#123;</span><br><span class="line">        fmt.Println(n) <span class="comment">// 4 then 9, or 9 then 4</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数同时做了 fan-in 和 fan-out:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">merge</span><span class="params">(cs ...&lt;-<span class="keyword">chan</span> <span class="type">int</span>)</span></span> &lt;-<span class="keyword">chan</span> <span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">    out := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Start an output goroutine for each input channel in cs.  output</span></span><br><span class="line">    <span class="comment">// copies values from c to out until c is closed, then calls wg.Done.</span></span><br><span class="line">    output := <span class="function"><span class="keyword">func</span><span class="params">(c &lt;-<span class="keyword">chan</span> <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">        <span class="keyword">for</span> n := <span class="keyword">range</span> c &#123;</span><br><span class="line">            out &lt;- n</span><br><span class="line">        &#125;</span><br><span class="line">        wg.Done()</span><br><span class="line">    &#125;</span><br><span class="line">    wg.Add(<span class="built_in">len</span>(cs))</span><br><span class="line">    <span class="keyword">for</span> _, c := <span class="keyword">range</span> cs &#123;</span><br><span class="line">        <span class="keyword">go</span> output(c)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Start a goroutine to close out once all the output goroutines are</span></span><br><span class="line">    <span class="comment">// done.  This must start after the wg.Add call.</span></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        wg.Wait()</span><br><span class="line">        <span class="built_in">close</span>(out)</span><br><span class="line">    &#125;()</span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意到我们前一篇博客提到的一些问题，比如 errors 的处理和 goroutine 泄漏：</p><blockquote><p>There is a pattern to our pipeline functions:</p><ul><li>stages close their outbound channels when all the send operations are done.</li><li>stages keep receiving values from inbound channels until those channels are closed.</li></ul><p>This pattern allows each receiving stage to be written as a <code>range</code> loop and ensures that all goroutines exit once all values have been successfully sent downstream.</p><p>But in real pipelines, stages don’t always receive all the inbound values. Sometimes this is by design: the receiver may only need a subset of values to make progress. More often, a stage exits early because an inbound value represents an error in an earlier stage. In either case the receiver should not have to wait for the remaining values to arrive, and we want earlier stages to stop producing values that later stages don’t need.</p></blockquote><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">// Consume the first value from the output.</span></span><br><span class="line">    out := merge(c1, c2)</span><br><span class="line">    fmt.Println(&lt;-out) <span class="comment">// 4 or 9</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">    <span class="comment">// Since we didn&#x27;t receive the second value from out,</span></span><br><span class="line">    <span class="comment">// one of the output goroutines is hung attempting to send it.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于这样的消费者，生产的 goroutine 会卡住 —&gt; 泄漏。一定程度上，可以用 buffer + close 解决这个问题。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">gen</span><span class="params">(nums ...<span class="type">int</span>)</span></span> &lt;-<span class="keyword">chan</span> <span class="type">int</span> &#123;</span><br><span class="line">    out := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>, <span class="built_in">len</span>(nums))</span><br><span class="line">    <span class="keyword">for</span> _, n := <span class="keyword">range</span> nums &#123;</span><br><span class="line">        out &lt;- n</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">close</span>(out)</span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="插入一段-goroutine-知识"><a href="#插入一段-goroutine-知识" class="headerlink" title="插入一段 goroutine 知识"></a>插入一段 goroutine 知识</h3><p>我们的 channel 和 close 有什么规则呢：</p><ul><li>channel 是 FIFO 的</li><li>如果去 close, Channel 是一个空指针或者已经被关闭时，Go 语言运行时都会直接 <code>panic</code> 并抛出异常</li><li>close 的时候不能是<code>&lt;-chan</code>, 即单向接受的 channel</li><li>Channel 和 goroutine 的 GC：一边有数据就不能 gc.</li></ul><p>具体参考 Detailed Explanations for Channel Operations 一节，可以看到：</p><blockquote><p>To make the explanations for channel operations simple and clear, in the remaining of this article, channels will be classified into three categories:</p><ol><li>nil channels.</li><li>non-nil but closed channels.</li><li>not-closed non-nil channels.</li></ol><p>The following table simply summarizes the behaviors for all kinds of operations applying on nil, closed and not-closed non-nil channels.</p><div class="table-container"><table><thead><tr><th style="text-align:center">Operation</th><th style="text-align:center">A Nil Channel</th><th style="text-align:center">A Closed Channel</th><th style="text-align:center">A Not-Closed Non-Nil Channel</th></tr></thead><tbody><tr><td style="text-align:center">Close</td><td style="text-align:center">panic</td><td style="text-align:center">panic</td><td style="text-align:center">succeed to close (C)</td></tr><tr><td style="text-align:center">Send Value To</td><td style="text-align:center">block for ever</td><td style="text-align:center">panic</td><td style="text-align:center">block or succeed to send (B)</td></tr><tr><td style="text-align:center">Receive Value From</td><td style="text-align:center">block for ever</td><td style="text-align:center">never block (D)</td><td style="text-align:center">block or succeed to receive (A)</td></tr></tbody></table></div></blockquote><p>其实我挺好奇的， Rust 区分了 sender receiver, 这里为啥不…</p><h3 id="Explicit-cancellation"><a href="#Explicit-cancellation" class="headerlink" title="Explicit cancellation"></a>Explicit cancellation</h3><blockquote><p>When <code>main</code> decides to exit without receiving all the values from <code>out</code>, it must tell the goroutines in the upstream stages to abandon the values they’re trying to send. It does so by sending values on a channel called <code>done</code>. It sends two values since there are potentially two blocked senders:</p></blockquote><p>具体来说，下游已经拿到了数据或者出现了 err, 需要告诉上游这样的消息。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    in := gen(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Distribute the sq work across two goroutines that both read from in.</span></span><br><span class="line">    c1 := sq(in)</span><br><span class="line">    c2 := sq(in)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Consume the first value from output.</span></span><br><span class="line">    done := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line">    <span class="keyword">defer</span> <span class="built_in">close</span>(done)</span><br><span class="line">    out := merge(done, c1, c2)</span><br><span class="line">    fmt.Println(&lt;-out) <span class="comment">// 4 or 9</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>加入了 done 这个 flag 后，这里只需要一个值，同时有两个 input channel. 那么，merge 我们可以实现：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">merge</span><span class="params">(done &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;, cs ...&lt;-<span class="keyword">chan</span> <span class="type">int</span>)</span></span> &lt;-<span class="keyword">chan</span> <span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">    out := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Start an output goroutine for each input channel in cs.  output</span></span><br><span class="line">    <span class="comment">// copies values from c to out until c is closed or it receives a value</span></span><br><span class="line">    <span class="comment">// from done, then output calls wg.Done.</span></span><br><span class="line">    output := <span class="function"><span class="keyword">func</span><span class="params">(c &lt;-<span class="keyword">chan</span> <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">        <span class="keyword">defer</span> wg.Done()</span><br><span class="line">        <span class="keyword">for</span> n := <span class="keyword">range</span> c &#123;</span><br><span class="line">            <span class="keyword">select</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> out &lt;- n:</span><br><span class="line">            <span class="keyword">case</span> &lt;-done:</span><br><span class="line">               <span class="keyword">return</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    wg.Add(<span class="built_in">len</span>(cs))</span><br><span class="line">    <span class="keyword">for</span> _, c := <span class="keyword">range</span> cs &#123;</span><br><span class="line">        <span class="keyword">go</span> output(c)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Start a goroutine to close out once all the output goroutines are</span></span><br><span class="line">    <span class="comment">// done.  This must start after the wg.Add call.</span></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        wg.Wait()</span><br><span class="line">        <span class="built_in">close</span>(out)</span><br><span class="line">    &#125;()</span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>bitcoin</title>
      <link href="/2020/01/31/bitcoin/"/>
      <url>/2020/01/31/bitcoin/</url>
      
        <content type="html"><![CDATA[<h2 id="Bitcoin"><a href="#Bitcoin" class="headerlink" title="Bitcoin"></a>Bitcoin</h2><p>bitcoin 主要解决的问题（我相信你们在各种地方看过一万遍了）：</p><ul><li>forgery: 伪造</li><li>double spending </li><li>theft</li></ul><p>我们需要考量的问题是：</p><ul><li>区块链是怎么存储的，Transaction Block 这些结构的关系是什么</li><li>如何防止错误</li><li>如何防止distributed system 经常出现的问题</li></ul><h3 id="Transaction"><a href="#Transaction" class="headerlink" title="Transaction"></a>Transaction</h3><p>Bitcoin 的 idea 是把数据当成是 signed sequence of transactions</p><blockquote><p>every coin has a sequence of transaction records one for each time this coin was transferred as payment a coin’s latest transaction indicates who owns it now</p></blockquote><p>在论文中， txn 格式是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pub(user1): public key of new owner</span><br><span class="line">hash(prev): hash of this coin&#x27;s previous transaction record</span><br><span class="line">sig(user2): signature over transaction by previous owner&#x27;s private key</span><br><span class="line">(BitCoin is much more complex: amount (fractional), multiple in/out, ...)</span><br></pre></td></tr></table></figure><p>可以看看他的 Transaction Example</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Y owns a coin, previously given to it by X: </span><br><span class="line">// X-&gt;Y coin, T7: pub(Y), hash(T6) 前一次交易, sig(X) X 用 private key 签名出的唯一值</span><br><span class="line">    T7: pub(Y), hash(T6), sig(X)</span><br></pre></td></tr></table></figure><p>跟着上面的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Y buys a hamburger from Z and pays with this coin</span><br><span class="line">// Y 拿到 Z 的 pub key</span><br><span class="line">  Z sends public key to Y</span><br><span class="line">  // pub key 可以用于加密，Y 创建记录</span><br><span class="line">  Y creates a new transaction and signs it</span><br><span class="line">  T8: pub(Z), hash(T7), sig(Y)</span><br></pre></td></tr></table></figure><p>验证：T8 的 sig 和 T7 的 pub 是一样的</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Y sends transaction record to Z</span><br><span class="line">Z verifies:</span><br><span class="line">  T8&#x27;s sig() corresponds to T7&#x27;s pub()</span><br><span class="line">Z gives hamburger to Y</span><br></pre></td></tr></table></figure><p>Z 的余额是 Z 知道的没有花费的 transaction 记录（感觉这个过程类似于从 log 中读）</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Z &quot;owns&quot; a coin = Z knows private key for &quot;new owner&quot; public key in latest xaction</span><br></pre></td></tr></table></figure></blockquote><p>也就是说，Z 有一个币，表示 Z 知道 T8 的 pub(Z) 可以解析出来多少 （xaction == Transaction）</p><p>如何防止一个签名的 double-spending</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">what do we need?</span><br><span class="line">  publish log of all transactions to everyone, in same order</span><br><span class="line">    so Q knows about Y-&gt;Z, and will reject Y-&gt;Q</span><br><span class="line">    a &quot;public ledger&quot;</span><br><span class="line">  ensure Y can&#x27;t un-publish a transaction</span><br></pre></td></tr></table></figure></blockquote><p>在事实上要求对方广播 下面这段介绍了和 raft 之类 consensus 的区别</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">why not publish transactions like this:</span><br><span class="line">  1000s of peers, run by anybody, no trust required in any one peer</span><br><span class="line">  peers flood new transactions over &quot;overlay&quot;</span><br><span class="line">  transaction Y-&gt;Z only acceptable if majority of peers think it is valid</span><br><span class="line">    i.e. they don&#x27;t know of any Y-&gt;Q</span><br><span class="line">    hopefully majority overlap ensures double-spend is detected</span><br><span class="line">  how to count votes?</span><br><span class="line">    how to even count peers so you know what a majority is?</span><br><span class="line">    perhaps distinct IP addresses?</span><br><span class="line">  problem: &quot;sybil attack&quot; // 女巫攻击，制造大量节点加入系统</span><br><span class="line">    IP addresses are not secure -- easy to forge</span><br><span class="line">    attacker pretends to have 10,000 computers -- majority</span><br><span class="line">    when Z asks, attacker&#x27;s majority says &quot;we only know of Y-&gt;Z&quot;</span><br><span class="line">    when Q asks, attacker&#x27;s majority says &quot;we only know of Y-&gt;Q&quot;</span><br><span class="line">  voting is hard in &quot;open&quot; p2p schemes</span><br></pre></td></tr></table></figure></blockquote><h3 id="Block-Chain"><a href="#Block-Chain" class="headerlink" title="Block Chain"></a>Block Chain</h3><p>是一个 agreement on transaction log to prevent double-spending</p><p>包含了 transaction 的整个记录，然后有很多 replica (论文中叫 peers, 这里指的是别的区块链系统，叫 replica 也不太合适)</p><ul><li>每个包含完整的备份（太 tm 浪费了吧）</li><li>new block / transaction 需要广播给其他的 peers</li></ul><p>每个 block 包含：</p><ul><li>hash(prev_block) // 注意是 block</li><li>一个 transaction 的顺序集合 </li><li>“nonce” (not quite a nonce in the usual cryptographic sense)</li><li>current time: 现在的时间戳</li></ul><p>尽量每10分钟产生一个 block chain, 同时记录只有被放在 block chain 上才会被信任</p><blockquote><p>在进行随机散列运算时，工作量证明机制引入了对某一个特定值的扫描工作，比方说 SHA‐256 下，随机散列值以一个或多个 0 开始。那么随着 0 的数目的上升, 找到这个解所需要的工作量 将呈指数增长，而对结果进行检验则仅需要一次随机散列运算。</p></blockquote><p>block 的创建是由 mining 来做的，多个 cpu 尝试很多次，来挖出新的 block. 在这个系统中可能会有几个问题，我记得我们在 Raft 中也有类似的问题</p><ul><li>顺序提交：消息的提交要求是顺序的，这个在 Raft 中由单个 master 来处理</li><li>blockchain fork: 由于网络分区或者两个peer 同时算出了新的block等原因， blockchain 被分成没有共识的多个。</li></ul><p>先介绍第二个问题，bitcoin 解决的方案是：</p><ul><li>同样长度、新 block 不同的 chain 都会被保持, 直到新的最长纪录覆盖</li><li>假设新产生了 BZ/BQ 两条链，有更多被观测到的一方，有更多机器，<em>更大概率</em>找到新的节点，然后更长的 block-chain 会被 apply</li><li>在一个系统（分区内部）会下载被 apply 的区块链</li></ul><p>第二个问题还会有变体：Y 用同一个 hash 给不同 block chain 发送，会造成分裂；给同一个发送的时候，不会容许这种顺序出现。</p><h3 id="激励"><a href="#激励" class="headerlink" title="激励"></a>激励</h3><p>前文介绍了 mining, 挖矿的过程中, 新区块会附带一个由创造者拥有的电子货币。</p><p>同时，也有交易费。输出小于输入时，差额是交易费</p><h3 id="Reclaiming-Disk-Space"><a href="#Reclaiming-Disk-Space" class="headerlink" title="Reclaiming Disk Space"></a><strong>Reclaiming Disk Space</strong></h3><p>Once the latest transaction in a coin is buried under enough blocks, the spent transactions before it can be discarded to save disk space.</p><h2 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h2><h4 id="是不是-signature-就足够了"><a href="#是不是-signature-就足够了" class="headerlink" title="是不是 signature 就足够了"></a>是不是 signature 就足够了</h4><p>答：不是，可能会有人把这个 signature copy 一份，然后重复转账交易行为</p><h4 id="Proof-of-work-的-purpose"><a href="#Proof-of-work-的-purpose" class="headerlink" title="Proof-of-work 的 purpose"></a>Proof-of-work 的 purpose</h4><p>攻击者需要 51% 攻击</p><h4 id="有比-pow-更节省资源的算法么"><a href="#有比-pow-更节省资源的算法么" class="headerlink" title="有比 pow 更节省资源的算法么"></a>有比 pow 更节省资源的算法么</h4><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">A: Proof-of-work is hard to fake or simulate, a nice property in a</span><br><span class="line">totally open system like Bitcoin where you cannot trust anyone to</span><br><span class="line">follow rules. There are some alternate schemes; search the web for</span><br><span class="line">proof-of-stake or look at Algorand and Byzcoin, for example. In a</span><br><span class="line">smallish closed system, in which the participants are known though</span><br><span class="line">not entirely trusted, Byzantine agreement protocols could be used, as</span><br><span class="line">in Hyperledger.</span><br></pre></td></tr></table></figure></blockquote><h4 id="传播很多消息的处理"><a href="#传播很多消息的处理" class="headerlink" title="传播很多消息的处理"></a>传播很多消息的处理</h4><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">There&#x27;s a small chance that two miners find blocks at the same time,</span><br><span class="line">perhaps B50&#x27; containing &quot;pay Bob&quot; and B50&#x27;&#x27; containing &quot;pay Charlie&quot;. At</span><br><span class="line">this point there&#x27;s a fork in the block chain. These two blocks will be</span><br><span class="line">flooded to all the nodes. Each node will start mining a successor to one</span><br><span class="line">of them (the first it hears). Again the most likely outcome is that a</span><br><span class="line">single miner will finish significantly before any other miner, and flood</span><br><span class="line">the successor, and most peers will switch that winning fork. The chance</span><br><span class="line">of repeatedly having two miners simultaneously find blocks gets very</span><br><span class="line">small as the forks get longer. So eventually all the peers will switch</span><br><span class="line">to the same fork, and in fork there will be only one spend of the coin.</span><br><span class="line"></span><br><span class="line">The possibility of accidentally having a short-lived fork is the reason</span><br><span class="line">that careful clients will wait until there are a few successor blocks</span><br><span class="line">before believing a transaction.</span><br></pre></td></tr></table></figure></blockquote><h4 id="随着区块链的增长，新加入一个节点会不会耗时很久"><a href="#随着区块链的增长，新加入一个节点会不会耗时很久" class="headerlink" title="随着区块链的增长，新加入一个节点会不会耗时很久"></a>随着区块链的增长，新加入一个节点会不会耗时很久</h4><ul><li>一旦下载完了就不再需要了</li><li>一些 user 可以信任身边有完整的 chain 的用户（或者矿工？）</li></ul><h4 id="51-攻击"><a href="#51-攻击" class="headerlink" title="51 攻击"></a>51 攻击</h4><p>对于 51% 攻击：<a href="https://www.coindesk.com/51-attacks-real-threat-bitcoin">https://www.coindesk.com/51-attacks-real-threat-bitcoin</a> 实际上出现 51% 这个系统就 GG 了</p><h4 id="SHA-256-之外的方案"><a href="#SHA-256-之外的方案" class="headerlink" title="SHA-256 之外的方案"></a>SHA-256 之外的方案</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Q: Are there any ways for Bitcoin mining to do useful work, beyond simply</span><br><span class="line">brute-force calculating SHA-256 hashes?</span><br><span class="line"></span><br><span class="line">A: Maybe -- here are two attempts to do what you suggest:</span><br><span class="line">https://www.cs.umd.edu/~elaine/docs/permacoin.pdf</span><br><span class="line">http://primecoin.io/</span><br></pre></td></tr></table></figure><p>阅读比特币论文有感：</p><ul><li>嗯，每个区块会存所有的信息…所有信息？什么几把？哦有个 merkle tree, 等等你又没有 snapshot 或者 compaction, 在这有鬼用啊，难道你跟 buddy 算法一样 coin 有新纪录就 mark as delete 然后把 sibling 一起删掉么</li><li>嗯，处理脑裂…哦这个叫 fork… 等会儿，也就是说这个系统只有最终一致性，不能保证读到正确的数据？网络分区怎么办？哦多等几个 block 验证…什么几把</li><li>嗯，一个链要保证所有的记录是有序的…fuck…这代价太高了吧</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> distributed </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MapReduce 简读</title>
      <link href="/2020/01/28/MapReduce-%E7%AE%80%E8%AF%BB/"/>
      <url>/2020/01/28/MapReduce-%E7%AE%80%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="MapReduce-论文阅读"><a href="#MapReduce-论文阅读" class="headerlink" title="MapReduce 论文阅读"></a>MapReduce 论文阅读</h1><blockquote><p>本文主要介绍了 MapReduce 论文的第三章。第四章等内容最好自行再去阅读。</p></blockquote><h2 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h2><p>MapReduce 使用类似 fp 的原语来描述一个计算：</p><blockquote><p>Map(k, v) =&gt; list(k2, v2)</p><p>Reduce(k2, list(v2)) =&gt; list(v2)</p><p>输入的k, v != 中间的 k2, v2 == 输出的k2, v2.</p></blockquote><p>可以做倒排索引、wordcount、分布式排序等事情，前提是你能把你的任务描述成map – reduce 形式。</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="机器"><a href="#机器" class="headerlink" title="机器"></a>机器</h3><blockquote><ol><li><p>x86 架构、运行 Linux 操作系统、双处理器、2-4GB 内存的机器。</p></li><li><p>普通的网络硬件设备，每个机器的带宽为百兆或者千兆，但是远小于网络的平均带宽的一半。</p></li><li><p>集群中包含成百上千的机器，因此，机器故障是常态。</p></li><li><p>存储为廉价的内置 IDE 硬盘。一个内部分布式文件系统用来管理存储在这些磁盘上的数据。文件系</p><p>统通过数据复制来在不可靠的硬件上保证数据的可靠性和有效性。</p></li><li><p>用户􏰂交工作(job)给调度系统。每个工作(job)都包含一系列的任务(task)，调度系统将这些任</p><p>务调度到集群中多台可用的机器上。</p></li></ol></blockquote><p>在原始论文中，提到了上述的环境，但是不知道如果用内存计算并写存取都在内存的话，会不会对机器性能要求高很多。</p><h3 id="主要流程"><a href="#主要流程" class="headerlink" title="主要流程"></a>主要流程</h3><p><img src="https://nmsl.maplewish.cn/blog:/Users/fuasahi/Desktop/writing/MapReduce.md:mapreduce%E6%B5%81%E7%A8%8B.png" alt="mapreduce流程"></p><p>可以看到，这里有 map-worker 和 reduce-worker. Map Reduce 分区数量由用户定义。</p><p>操作按论文说有一些流程，照搬不太好，我就说下自己的理解：</p><ol><li>将输入文件分 M 段，定义一定的数据段大小(原始论文给16-64MB)</li><li>用户程序创建大量的 map reduce 工作副本, 有 workers 和 master。论文里面只有一个 master, 似乎 Hadoop MapReduce 允许你配置备用的 Master.</li><li>master 分配任务给空闲 worker，有M和R个 map 和 reduce 任务</li><li><strong>Map worker</strong> 完成计算，并且把数据<strong>缓存</strong>在<strong>内存</strong>中， <code>k2, v2</code> 对自动分区成 R 个，写在 <strong>本地文件</strong> 中，消息被传给master, master 把这个信息传给 reducer.</li><li>reducer 接收到 master 的消息后：<ol><li>用 rpc 读取这些数据</li><li>把数据按照 k2 聚合，似乎要排序？</li><li>处理这些数据，按照分区<strong>追加</strong>写到输出文件</li></ol></li><li>完成后，R个分区有<strong>追加</strong> 的 map-reduce 文件。</li></ol><h3 id="故障处理"><a href="#故障处理" class="headerlink" title="故障处理"></a>故障处理</h3><h4 id="worker-故障"><a href="#worker-故障" class="headerlink" title="worker 故障"></a>worker 故障</h4><p>worker 故障的主要解决方案是标记成错误，如果是 map-worker 则通知 reduce-worker ，把任务交给别人执行。</p><p>我很弟弟，看的是论文中文翻译，但是感觉这段写的比我能总结的好很多:</p><blockquote><p>master 周期性的 ping 每个 worker。如果在一个约定的时间范围内没有收到 worker 返回的信息，master 将<br>把这个 worker 标记为失效。所有由这个失效的 worker 完成的 Map 任务被重设为初始的空闲状态，之后这些<br>任务就可以被安排给其他的 worker。同样的，worker 失效时正在运行的 Map 或 Reduce 任务也将被重新置为<br>空闲状态，等待重新调度。</p></blockquote><ol><li>总的来说， master 会跟 worker 保持 heaet beat</li><li>没有返回的话，任务从 类似 <em>执行中</em> 的状态被更改为 <em>未知性</em></li><li>等待任务被调度给别的 worker</li></ol><h4 id="master-故障"><a href="#master-故障" class="headerlink" title="master 故障"></a>master 故障</h4><p>类似内存备份吧，写wal／周期性写入磁盘什么的 … 主要是写入 ckpt, 然后让系统能够 recover</p><h3 id="任务粒度"><a href="#任务粒度" class="headerlink" title="任务粒度"></a>任务粒度</h3><blockquote><p>理想情况下，M 和 R 应当 比集群中 worker 的机器数量要多得多。在每台 worker 机器都执行大量的不同任务能够 高集群的动态的负载 均衡能力，并且能够加快故障恢复的速度:失效机器上执行的大量 Map 任务都可以分布到所有其他的 worker 机器上去执行。</p><p>但是实际上，在我们的具体实现中对 M 和 R 的取值都有一定的客观限制，因为 master 必须执行 O(M+R) 次调度，并且在内存中保存 O(M<em>R)个状态(对影响内存使用的因素还是比较小的:O(M</em>R)块状态，大概每 对 Map 任务/Reduce 任务 1 个字节就可以了)。</p></blockquote><h3 id="备用任务"><a href="#备用任务" class="headerlink" title="备用任务"></a>备用任务</h3><p>有的任务执行的很慢，我们有的时候会调度 backup 机器 (备份) 来处理剩下的、处理中的任务。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>隔离级别</title>
      <link href="/2020/01/13/%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"/>
      <url>/2020/01/13/%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h1><ul><li>A: Abortability</li><li>C 用户层面定义的 invariant</li><li>Isolation: 隔离性</li><li>Durability: 持久性</li></ul><h2 id="单对象写入的实现"><a href="#单对象写入的实现" class="headerlink" title="单对象写入的实现"></a>单对象写入的实现</h2><p>希望对单个机器的单个节点，能提供原子性和隔离性</p><p>如果是大文件/覆盖的时候不 atomic(写到一半了) / 客户会不会看到部分更新的值</p><p>通过日志来实现崩溃回复，用锁实现隔离</p><p>单个对象实际上也有一些奇葩操作，比如 CAS 操作，一般直接由 CAS 类指令支持。</p><h2 id="弱隔离级别"><a href="#弱隔离级别" class="headerlink" title="弱隔离级别"></a>弱隔离级别</h2><h3 id="Read-Committed"><a href="#Read-Committed" class="headerlink" title="Read Committed"></a>Read Committed</h3><ul><li>读数据库：只能看到已经提交的数据，没有脏读</li><li>写数据库：只会覆盖已经写入的数据，没有脏写</li></ul><blockquote><p>读未提交(Read uncommitted)。它可以防止脏写，但不防止脏读。</p></blockquote><p>读：不会看到部分更新的值。</p><p>写：没有脏写</p><p>可能的实现：</p><p>实际上这个级别可以通过 row-level-lock 实现：</p><p>修改特定 object 的时候，只有说，直到 abort/commit</p><p>读可以拿到对应的锁，实际上也可以保留一份 old value, 以操作。</p><h2 id="SI-和-Repeatable-Read"><a href="#SI-和-Repeatable-Read" class="headerlink" title="SI 和 Repeatable Read"></a>SI 和 Repeatable Read</h2><p>这个时候需要说 Read Committed 的问题：它读到的可能是自己的 Write 和别人 Committed 的 write 的混合物</p><p>这种异常被称为不可重复读/读偏差（read skew）</p><p>实现的方法相对来说可能要备份/SI</p><h3 id="SI"><a href="#SI" class="headerlink" title="SI"></a>SI</h3><ul><li>写需要写锁，读从 Snapshot 读</li></ul><p>Txn 从一致性快照读取</p><p>在 PostgreSQL 中</p><ul><li>事务会有一个严格递增的 ID</li><li>字段有 createBy deleteBy 的语义，实现上是 xmin, xmax.</li></ul><p>SI 有可见性的规则：</p><ul><li>每次事务开始的时候，列出其他所有的Txn, 并 ignore 这些</li><li>被 abort 的事务执行的写入被忽略</li><li>被较晚事务 id(产生第一次读/读之前获取的)事务所做的任何写入都会被忽略，不管是否已经提交</li></ul><p>所以可见性规则是：</p><ul><li>txn 开始的时候，创建对象的事务已经提交了</li><li>对象没有被被标记为 deleted </li></ul><h3 id="SI-amp-amp-Index"><a href="#SI-amp-amp-Index" class="headerlink" title="SI &amp;&amp; Index"></a>SI &amp;&amp; Index</h3><ul><li>PostgreSQL 避免更新</li><li>TiDB Index 类型会一起更新</li><li>有的数据库会创建 Copy-on-write 结构</li></ul><ul><li>PostgreSQL: SI —&gt; repeatable read</li><li>Oracle: Serializable</li></ul><h2 id="Lost-Update"><a href="#Lost-Update" class="headerlink" title="Lost Update"></a>Lost Update</h2><ul><li>TXN1 readX writeX commit</li><li>TXN2 readX writeX                commit</li></ul><p>Txn1 有可能会被 Overwrite.</p><p>可以实现原子写，也可以 LOCK FOR XXX 显示锁定。</p><h2 id="SI-可能发生的问题"><a href="#SI-可能发生的问题" class="headerlink" title="SI 可能发生的问题"></a>SI 可能发生的问题</h2><ul><li>3个 txn 互相依赖</li><li>2个之间的 phantom</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Docker review: Linux Namespace</title>
      <link href="/2020/01/11/Docker-review-Linux-Namespace/"/>
      <url>/2020/01/11/Docker-review-Linux-Namespace/</url>
      
        <content type="html"><![CDATA[<h2 id="docker的简单实现原理"><a href="#docker的简单实现原理" class="headerlink" title="docker的简单实现原理"></a>docker的简单实现原理</h2><p>参考的书编写于2017年，本人会将书上相关的内容先过一遍，然后把现在比较具体的实现贴出来。</p><h3 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h3><p>以下内容是对 Linux Man namespace(7) 的一个整理，建议有空闲去阅读官方的文档，不要吸收二手知识。</p><p>如果你跑下面的话：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ ls -l /proc/$$/ns</span><br><span class="line">总用量 0</span><br><span class="line">lrwxrwxrwx 1 mwish mwish 0  1月 11 04:10 cgroup -&gt; &#x27;cgroup:[4026531835]&#x27;</span><br><span class="line">lrwxrwxrwx 1 mwish mwish 0  1月 11 04:10 ipc -&gt; &#x27;ipc:[4026531839]&#x27;</span><br><span class="line">lrwxrwxrwx 1 mwish mwish 0  1月 11 04:10 mnt -&gt; &#x27;mnt:[4026531840]&#x27;</span><br><span class="line">lrwxrwxrwx 1 mwish mwish 0  1月 11 04:10 net -&gt; &#x27;net:[4026531992]&#x27;</span><br><span class="line">lrwxrwxrwx 1 mwish mwish 0  1月 11 04:10 pid -&gt; &#x27;pid:[4026531836]&#x27;</span><br><span class="line">lrwxrwxrwx 1 mwish mwish 0  1月 11 04:10 pid_for_children -&gt; &#x27;pid:[4026531836]&#x27;</span><br><span class="line">lrwxrwxrwx 1 mwish mwish 0  1月 11 04:10 user -&gt; &#x27;user:[4026531837]&#x27;</span><br><span class="line">lrwxrwxrwx 1 mwish mwish 0  1月 11 04:10 uts -&gt; &#x27;uts:[4026531838]&#x27;</span><br></pre></td></tr></table></figure><p>实际上你可以在 man 里头找到 namespace</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">A namespace wraps a global system resource in an abstraction that</span><br><span class="line">makes it appear to the processes within the namespace that they have</span><br><span class="line">their own isolated instance of the global resource.  Changes to the</span><br><span class="line">global resource are visible to other processes that are members of</span><br><span class="line">the namespace, but are invisible to other processes.  One use of</span><br><span class="line">namespaces is to implement containers.</span><br><span class="line"></span><br><span class="line">This page provides pointers to information on the various namespace</span><br><span class="line">types, describes the associated /proc files, and summarizes the APIs</span><br><span class="line">for working with namespaces.</span><br></pre></td></tr></table></figure></blockquote><p>种类也可以：</p><blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Namespace types</span><br><span class="line">    The following table shows the namespace types available on Linux.</span><br><span class="line">    The second column of the table shows the flag value that is used to</span><br><span class="line">    specify the namespace type in various APIs.  The third column</span><br><span class="line">    identifies the manual page that provides details on the namespace</span><br><span class="line">    type.  The last column is a summary of the resources that are</span><br><span class="line">    isolated by the namespace type.</span><br><span class="line"></span><br><span class="line">    Namespace Flag            Page                  Isolates</span><br><span class="line">    Cgroup    CLONE_NEWCGROUP cgroup_namespaces(7)  Cgroup root directory</span><br><span class="line">    IPC       CLONE_NEWIPC    ipc_namespaces(7)     System V IPC,</span><br><span class="line">                                                    POSIX message queues</span><br><span class="line">    Network   CLONE_NEWNET    network_namespaces(7) Network devices,</span><br><span class="line">                                                    stacks, ports, etc.</span><br><span class="line">    Mount     CLONE_NEWNS     mount_namespaces(7)   Mount points</span><br><span class="line">    PID       CLONE_NEWPID    pid_namespaces(7)     Process IDs</span><br><span class="line">    User      CLONE_NEWUSER   user_namespaces(7)    User and group IDs</span><br><span class="line">    UTS       CLONE_NEWUTS    uts_namespaces(7)     Hostname and NIS</span><br><span class="line">                                                    domain name</span><br></pre></td></tr></table></figure></blockquote><p>通俗的说，就是：</p><ul><li><code>Mount</code>: 隔离文件系统挂载点</li><li><code>UTS</code>: 隔离主机名和域名信息</li><li><code>IPC</code>: 隔离进程间通信</li><li><code>PID</code>: 隔离进程的ID</li><li><code>Network</code>: 隔离网络资源</li><li><code>User</code>: 隔离用户和用户组的ID</li></ul><p>此外，在一些地方你可以注意限制</p><blockquote><p>Note that namespaces <em>do not</em> restrict access to physical resources such as CPU, memory and disk. That access is metered and restricted by a kernel feature called ‘cgroups’.</p></blockquote><p>嗯这个名词我们稍后再介绍吧。</p><p>实际上可以读完 namespace(7) 对应的 man 手册：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Each process has a /proc/[pid]/ns/ subdirectory containing one entry</span><br><span class="line">       for each namespace that supports being manipulated by setns(2):</span><br></pre></td></tr></table></figure><p>刚刚 <code>cat /proc/$$/ns</code> 实际上就是这样读取信息的。同时我们留意一下之前的 namespace , 他是有一个 id 的。如果多个 process 的 namespace 有着同一个 id, 我们有理由认为它们在一个 namespace 下头。那么以下方法可以保留自己（或者我们渴望的进程 id 的） uts namespace. 这些内容可以参考 man 的 <em>namespace lifetime</em> 这个 part.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ <span class="built_in">touch</span> uts</span><br><span class="line">➜  ~ mount --<span class="built_in">bind</span> /proc/$$/ns/uts uts</span><br></pre></td></tr></table></figure><p>假设我们之前 mount 了 uts, 这个时候我们知道他是能：<strong>隔离主机名和域名信息</strong></p><p>接下来我们介绍几个 syscall:</p><ul><li>setns(2): allows the calling process to join an existing namespace.  The namespace to join is specified via a file descriptor that refers to one of the /proc/[pid]/ns files described below.</li><li>unshare(2): <a href="http://man7.org/linux/man-pages/man2/unshare.2.html">http://man7.org/linux/man-pages/man2/unshare.2.html</a></li><li>clone(2): <a href="http://man7.org/linux/man-pages/man2/clone.2.html">http://man7.org/linux/man-pages/man2/clone.2.html</a></li><li>ioctl(2): (吐槽: 这玩意万能啊…) <a href="http://man7.org/linux/man-pages/man2/ioctl.2.html">http://man7.org/linux/man-pages/man2/ioctl.2.html</a></li></ul><p>你可以当成是添加 namespace 和 切换 namespace。</p><p>以下部分介绍的是各种 namespace, 代码很多 sample 来自于这个地方：<a href="http://crosbymichael.com/creating-containers-part-1.html">http://crosbymichael.com/creating-containers-part-1.html</a> </p><h2 id="Skeleton"><a href="#Skeleton" class="headerlink" title="Skeleton"></a>Skeleton</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> _GNU_SOURCE</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> STACKSIZE (1024*1024)</span></span><br><span class="line"><span class="type">static</span> <span class="type">char</span> child_stack[STACKSIZE];</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">clone_args</span> &#123;</span></span><br><span class="line">        <span class="type">char</span> **argv;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// child_exec is the func that will be executed as the result of clone</span></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">child_exec</span><span class="params">(<span class="type">void</span> *stuff)</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">clone_args</span> *<span class="title">args</span> =</span> (<span class="keyword">struct</span> clone_args *)stuff;</span><br><span class="line">        <span class="keyword">if</span> (execvp(args-&gt;argv[<span class="number">0</span>], args-&gt;argv) != <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;failed to execvp argments %s\n&quot;</span>,</span><br><span class="line">                        strerror(errno));</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// we should never reach here!</span></span><br><span class="line">        <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span></span><br><span class="line">&#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">clone_args</span> <span class="title">args</span>;</span></span><br><span class="line">        args.argv = &amp;argv[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> clone_flags = SIGCHLD;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// the result of this call is that our child_exec will be run in another</span></span><br><span class="line">        <span class="comment">// process returning it&#x27;s pid</span></span><br><span class="line">        <span class="type">pid_t</span> pid =</span><br><span class="line">            clone(child_exec, child_stack + STACKSIZE, clone_flags, &amp;args;</span><br><span class="line">        <span class="keyword">if</span> (pid &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;clone failed WTF!!!! %s\n&quot;</span>, strerror(errno));</span><br><span class="line">                <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// lets wait on our child process here before we, the parent, exits</span></span><br><span class="line">        <span class="keyword">if</span> (waitpid(pid, <span class="literal">NULL</span>, <span class="number">0</span>) == <span class="number">-1</span>) &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;failed to wait pid %d\n&quot;</span>, pid);</span><br><span class="line">                <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">exit</span>(EXIT_SUCCESS);</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p> 我们需要一个 skeleton 来填充逻辑</p><h4 id="Unix-Time-sharing-Namespace"><a href="#Unix-Time-sharing-Namespace" class="headerlink" title="Unix Time-sharing Namespace"></a>Unix Time-sharing Namespace</h4><p>UTS 隔离主机名和域名信息, 我在自己的 manjaro 上仿照代码写了一个</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> _GNU_SOURC</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;signal.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> STACK_SIZE (1024 * 1024)</span></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">char</span> child_stack[STACK_SIZE];</span><br><span class="line"><span class="type">char</span>* <span class="type">const</span> child_args[] = &#123;</span><br><span class="line"><span class="string">&quot;/bin/bash&quot;</span>,</span><br><span class="line"><span class="literal">NULL</span>,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">child_main</span><span class="params">(<span class="type">void</span>* args)</span> &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;in sub process\n&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (sethostname(<span class="string">&quot;mname&quot;</span>, <span class="built_in">strlen</span>(<span class="string">&quot;mname&quot;</span>)) != <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;failed to execvp argments %s\n&quot;</span>,</span><br><span class="line">                        strerror(errno));</span><br><span class="line">                <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">execv(child_args[<span class="number">0</span>], child_args);</span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;start\n&quot;</span>);</span><br><span class="line"><span class="type">int</span> child_pid = clone(child_main, child_stack + STACK_SIZE, SIGCHLD, <span class="literal">NULL</span>);</span><br><span class="line">waitpid(child_pid, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;exit\n&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你需要 sudo 以运行这个程序。</p><h2 id="IPC-Namespace"><a href="#IPC-Namespace" class="headerlink" title="IPC Namespace"></a>IPC Namespace</h2><p>The IPC namespace is used for isolating interprocess communication, things like SysV message queues. Let’s make a copy of <code>skeleton.c</code> for this namespace.</p><h2 id="PID-Namespace"><a href="#PID-Namespace" class="headerlink" title="PID Namespace"></a>PID Namespace</h2><blockquote><p>This one is fun. The PID namespace is a way to carve up the PIDs that one process can view and interact with. When we create a new PID namespace the first process will get to be the loved PID 1. If this process exits the kernel kills everyone else within the namespace. Let’s start by making a copy of <code>skeleton.c</code> for our changes.</p></blockquote><p>他会对进程 PID 重新标号，每个 PID namespace 有自己的 wx, 内核为 PID ns 维护了一个树状结构，从 root ns 到 child ns，其中：</p><ul><li>父节点可以看到子ns进程</li><li>子不能看到父 ns</li><li>PID 1 有 init 特权</li><li>不能 kill/ptrace 父/兄 ns</li><li>如果重新挂载 <code>/proc</code> 文件系统</li></ul><p>一个进程 1 可以屏蔽一定的信号，但是四种杀掉程序的 SIG 中，对于父级 ns 进程的 SIGKILL, SIGSTOP 会被杀掉。</p><p>同时，用 ps, 因为看到的是内存的 <code>/proc</code> 虚拟文件系统，所以可能需要重新 mount.</p><h2 id="mount-Namespace"><a href="#mount-Namespace" class="headerlink" title="mount Namespace"></a>mount Namespace</h2><p>(历史上第一个实现的 ns)</p><p><code>CLONE_NEWNS</code></p><p> 挂载的形式有：</p><ul><li>share</li><li>slave</li><li>share and slave</li><li>primary</li><li>unbindable</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Rust std::sync::Arc</title>
      <link href="/2020/01/09/Rust-std-sync-Arc/"/>
      <url>/2020/01/09/Rust-std-sync-Arc/</url>
      
        <content type="html"><![CDATA[<h2 id="水文-Rust-std-sync-Arc"><a href="#水文-Rust-std-sync-Arc" class="headerlink" title="[水文] Rust std::sync::Arc"></a>[水文] Rust std::sync::Arc</h2><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[cfg_attr(not(test), lang = <span class="string">&quot;arc&quot;</span>)]</span></span><br><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Arc</span>&lt;T: ?<span class="built_in">Sized</span>&gt; &#123;</span><br><span class="line">    ptr: NonNull&lt;ArcInner&lt;T&gt;&gt;,</span><br><span class="line">    phantom: PhantomData&lt;T&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>内部是：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">ArcInner</span>&lt;T: ?<span class="built_in">Sized</span>&gt; &#123;</span><br><span class="line">    strong: atomic::AtomicUsize,</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the value usize::MAX acts as a sentinel for temporarily &quot;locking&quot; the</span></span><br><span class="line">    <span class="comment">// ability to upgrade weak pointers or downgrade strong ones; this is used</span></span><br><span class="line">    <span class="comment">// to avoid races in `make_mut` and `get_mut`.</span></span><br><span class="line">    weak: atomic::AtomicUsize,</span><br><span class="line"></span><br><span class="line">    data: T,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Comparing-with-std-rc-Rc"><a href="#Comparing-with-std-rc-Rc" class="headerlink" title="Comparing with std::rc::Rc"></a>Comparing with <code>std::rc::Rc</code></h2><h3 id="内部可变形"><a href="#内部可变形" class="headerlink" title="内部可变形"></a>内部可变形</h3><p>其实你应该记得 Rc 实现用了一堆 <code>Cell</code> 来表示 counter, </p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[cfg_attr(not(test), lang = <span class="string">&quot;rc&quot;</span>)]</span></span><br><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Rc</span>&lt;T: ?<span class="built_in">Sized</span>&gt; &#123;</span><br><span class="line">    ptr: NonNull&lt;RcBox&lt;T&gt;&gt;,</span><br><span class="line">    phantom: PhantomData&lt;T&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">RcBox</span>&lt;T: ?<span class="built_in">Sized</span>&gt; &#123;</span><br><span class="line">    strong: Cell&lt;<span class="type">usize</span>&gt;,</span><br><span class="line">    weak: Cell&lt;<span class="type">usize</span>&gt;,</span><br><span class="line">    value: T,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里内部可变形中， ArcInner 靠的是 <code>Atomic</code> 来实现</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>如果是 <code>new</code> 的话：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[inline]</span></span><br><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">new</span>(data: T) <span class="punctuation">-&gt;</span> Arc&lt;T&gt; &#123;</span><br><span class="line">    <span class="comment">// Start the weak pointer count as 1 which is the weak pointer that&#x27;s</span></span><br><span class="line">    <span class="comment">// held by all the strong pointers (kinda), see std/rc.rs for more info</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">x</span>: <span class="type">Box</span>&lt;_&gt; = <span class="keyword">box</span> ArcInner &#123;</span><br><span class="line">        strong: atomic::AtomicUsize::<span class="title function_ invoke__">new</span>(<span class="number">1</span>),</span><br><span class="line">        weak: atomic::AtomicUsize::<span class="title function_ invoke__">new</span>(<span class="number">1</span>),</span><br><span class="line">        data,</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">Self</span>::<span class="title function_ invoke__">from_inner</span>(Box::<span class="title function_ invoke__">into_raw_non_null</span>(x))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于 clone 来说，注释非常详细：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[inline]</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">clone</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> Arc&lt;T&gt; &#123;</span><br><span class="line">    <span class="comment">// Using a relaxed ordering is alright here, as knowledge of the</span></span><br><span class="line">    <span class="comment">// original reference prevents other threads from erroneously deleting</span></span><br><span class="line">    <span class="comment">// the object.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// As explained in the [Boost documentation][1], Increasing the</span></span><br><span class="line">    <span class="comment">// reference counter can always be done with memory_order_relaxed: New</span></span><br><span class="line">    <span class="comment">// references to an object can only be formed from an existing</span></span><br><span class="line">    <span class="comment">// reference, and passing an existing reference from one thread to</span></span><br><span class="line">    <span class="comment">// another must already provide any required synchronization.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// [1]: (www.boost.org/doc/libs/1_55_0/doc/html/atomic/usage_examples.html)</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">old_size</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">inner</span>().strong.<span class="title function_ invoke__">fetch_add</span>(<span class="number">1</span>, Relaxed);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// However we need to guard against massive refcounts in case someone</span></span><br><span class="line">    <span class="comment">// is `mem::forget`ing Arcs. If we don&#x27;t do this the count can overflow</span></span><br><span class="line">    <span class="comment">// and users will use-after free. We racily saturate to `isize::MAX` on</span></span><br><span class="line">    <span class="comment">// the assumption that there aren&#x27;t ~2 billion threads incrementing</span></span><br><span class="line">    <span class="comment">// the reference count at once. This branch will never be taken in</span></span><br><span class="line">    <span class="comment">// any realistic program.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// We abort because such a program is incredibly degenerate, and we</span></span><br><span class="line">    <span class="comment">// don&#x27;t care to support it.</span></span><br><span class="line">    <span class="keyword">if</span> old_size &gt; MAX_REFCOUNT &#123;</span><br><span class="line">        <span class="keyword">unsafe</span> &#123;</span><br><span class="line">            <span class="title function_ invoke__">abort</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">Self</span>::<span class="title function_ invoke__">from_inner</span>(<span class="keyword">self</span>.ptr)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><code>Relaxed</code> 的 <code>fetch_add</code> 是原子的</li><li>如果有 <code>old_size &gt; MAX_REFCOUNT</code> ，这里认为你一般出了 <code>mem::forget</code> 的 奇怪 bug</li></ol><p>对于 Drop 来说：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[inline]</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">    <span class="comment">// Because `fetch_sub` is already atomic, we do not need to synchronize</span></span><br><span class="line">    <span class="comment">// with other threads unless we are going to delete the object. This</span></span><br><span class="line">    <span class="comment">// same logic applies to the below `fetch_sub` to the `weak` count.</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">self</span>.<span class="title function_ invoke__">inner</span>().strong.<span class="title function_ invoke__">fetch_sub</span>(<span class="number">1</span>, Release) != <span class="number">1</span> &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// This fence is needed to prevent reordering of use of the data and</span></span><br><span class="line">    <span class="comment">// deletion of the data.  Because it is marked `Release`, the decreasing</span></span><br><span class="line">    <span class="comment">// of the reference count synchronizes with this `Acquire` fence. This</span></span><br><span class="line">    <span class="comment">// means that use of the data happens before decreasing the reference</span></span><br><span class="line">    <span class="comment">// count, which happens before this fence, which happens before the</span></span><br><span class="line">    <span class="comment">// deletion of the data.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// As explained in the [Boost documentation][1],</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// &gt; It is important to enforce any possible access to the object in one</span></span><br><span class="line">    <span class="comment">// &gt; thread (through an existing reference) to *happen before* deleting</span></span><br><span class="line">    <span class="comment">// &gt; the object in a different thread. This is achieved by a &quot;release&quot;</span></span><br><span class="line">    <span class="comment">// &gt; operation after dropping a reference (any access to the object</span></span><br><span class="line">    <span class="comment">// &gt; through this reference must obviously happened before), and an</span></span><br><span class="line">    <span class="comment">// &gt; &quot;acquire&quot; operation before deleting the object.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// In particular, while the contents of an Arc are usually immutable, it&#x27;s</span></span><br><span class="line">    <span class="comment">// possible to have interior writes to something like a Mutex&lt;T&gt;. Since a</span></span><br><span class="line">    <span class="comment">// Mutex is not acquired when it is deleted, we can&#x27;t rely on its</span></span><br><span class="line">    <span class="comment">// synchronization logic to make writes in thread A visible to a destructor</span></span><br><span class="line">    <span class="comment">// running in thread B.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Also note that the Acquire fence here could probably be replaced with an</span></span><br><span class="line">    <span class="comment">// Acquire load, which could improve performance in highly-contended</span></span><br><span class="line">    <span class="comment">// situations. See [2].</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// [1]: (www.boost.org/doc/libs/1_55_0/doc/html/atomic/usage_examples.html)</span></span><br><span class="line">    <span class="comment">// [2]: (https://github.com/rust-lang/rust/pull/41714)</span></span><br><span class="line">    atomic::<span class="title function_ invoke__">fence</span>(Acquire);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">unsafe</span> &#123;</span><br><span class="line">        <span class="keyword">self</span>.<span class="title function_ invoke__">drop_slow</span>();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>考虑一下这段代码：</p><blockquote><p>deletion of the data.  Because it is marked <code>Release</code>, the decreasing of the reference count synchronizes with this <code>Acquire</code> fence. This means that use of the data happens before decreasing the reference count, which happens before this fence, which happens before the deletion of the data.</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">atomic::fence(Acquire);</span><br></pre></td></tr></table></figure><ol><li><code>self.inner().strong.fetch_sub(1, Release)</code> 本身是原子的</li><li><code>atomic::fence(Acquire);</code> 保证 <code>self.drop_slow</code> 不会被重排序到 <code>fetch_sub</code> 之前</li></ol><p>然后 <code>drop_slow</code> 也包含了一段这样的逻辑：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Non-inlined part of `drop`.</span></span><br><span class="line"><span class="meta">#[inline(never)]</span></span><br><span class="line"><span class="keyword">unsafe</span> <span class="keyword">fn</span> <span class="title function_">drop_slow</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">    <span class="comment">// Destroy the data at this time, even though we may not free the box</span></span><br><span class="line">    <span class="comment">// allocation itself (there may still be weak pointers lying around).</span></span><br><span class="line">    ptr::<span class="title function_ invoke__">drop_in_place</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>.ptr.<span class="title function_ invoke__">as_mut</span>().data);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">self</span>.<span class="title function_ invoke__">inner</span>().weak.<span class="title function_ invoke__">fetch_sub</span>(<span class="number">1</span>, Release) == <span class="number">1</span> &#123;</span><br><span class="line">        atomic::<span class="title function_ invoke__">fence</span>(Acquire);</span><br><span class="line">        Global.<span class="title function_ invoke__">dealloc</span>(<span class="keyword">self</span>.ptr.<span class="title function_ invoke__">cast</span>(), Layout::<span class="title function_ invoke__">for_value</span>(<span class="keyword">self</span>.ptr.<span class="title function_ invoke__">as_ref</span>()))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>fetch_sub</code> 也有同样逻辑。详细内容可以参考这个解答：</p><ul><li><a href="https://stackoverflow.com/questions/48124031/stdmemory-order-relaxed-atomicity-with-respect-to-the-same-atomic-variable#comment83225530_48124031">https://stackoverflow.com/questions/48124031/stdmemory-order-relaxed-atomicity-with-respect-to-the-same-atomic-variable#comment83225530_48124031</a></li><li>同时其实在 CppReference 的 Relaxed 一节也有内容的提示，声称 <code>shared_ptr</code> 的 <code>inc</code> 适合 <code>relaxed</code> ，而 <code>dec</code> 需要<code>release</code> +  <code>acquire</code> .</li></ul><h3 id="count"><a href="#count" class="headerlink" title="count"></a>count</h3><p><code>Arc</code> 实现了：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  <span class="meta">#[inline]</span></span><br><span class="line">  <span class="meta">#[stable(feature = <span class="string">&quot;arc_counts&quot;</span>, since = <span class="string">&quot;1.15.0&quot;</span>)]</span></span><br><span class="line">  <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">weak_count</span>(this: &amp;<span class="keyword">Self</span>) <span class="punctuation">-&gt;</span> <span class="type">usize</span> &#123;</span><br><span class="line">      <span class="keyword">let</span> <span class="variable">cnt</span> = this.<span class="title function_ invoke__">inner</span>().weak.<span class="title function_ invoke__">load</span>(SeqCst);</span><br><span class="line">      <span class="comment">// If the weak count is currently locked, the value of the</span></span><br><span class="line">      <span class="comment">// count was 0 just before taking the lock.</span></span><br><span class="line">      <span class="keyword">if</span> cnt == usize::MAX &#123; <span class="number">0</span> &#125; <span class="keyword">else</span> &#123; cnt - <span class="number">1</span> &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line"><span class="meta">#[inline]</span></span><br><span class="line">  <span class="meta">#[stable(feature = <span class="string">&quot;arc_counts&quot;</span>, since = <span class="string">&quot;1.15.0&quot;</span>)]</span></span><br><span class="line">  <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">strong_count</span>(this: &amp;<span class="keyword">Self</span>) <span class="punctuation">-&gt;</span> <span class="type">usize</span> &#123;</span><br><span class="line">      this.<span class="title function_ invoke__">inner</span>().strong.<span class="title function_ invoke__">load</span>(SeqCst)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>其实可以看看 <code>Weak</code> 实现的</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[unstable(feature = <span class="string">&quot;weak_counts&quot;</span>, issue = <span class="string">&quot;57977&quot;</span>)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">weak_count</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;<span class="type">usize</span>&gt; &#123;</span><br><span class="line">    <span class="comment">// Due to the implicit weak pointer added when any strong pointers are</span></span><br><span class="line">    <span class="comment">// around, we cannot implement `weak_count` correctly since it</span></span><br><span class="line">    <span class="comment">// necessarily requires accessing the strong count and weak count in an</span></span><br><span class="line">    <span class="comment">// unsynchronized fashion. So this version is a bit racy.</span></span><br><span class="line">    <span class="keyword">self</span>.<span class="title function_ invoke__">inner</span>().<span class="title function_ invoke__">map</span>(|inner| &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">strong</span> = inner.strong.<span class="title function_ invoke__">load</span>(SeqCst);</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">weak</span> = inner.weak.<span class="title function_ invoke__">load</span>(SeqCst);</span><br><span class="line">        <span class="keyword">if</span> strong == <span class="number">0</span> &#123;</span><br><span class="line">            <span class="comment">// If the last `Arc` has *just* been dropped, it might not yet</span></span><br><span class="line">            <span class="comment">// have removed the implicit weak count, so the value we get</span></span><br><span class="line">            <span class="comment">// here might be 1 too high.</span></span><br><span class="line">            weak</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// As long as there&#x27;s still at least 1 `Arc` around, subtract</span></span><br><span class="line">            <span class="comment">// the implicit weak pointer.</span></span><br><span class="line">            <span class="comment">// Note that the last `Arc` might get dropped between the 2</span></span><br><span class="line">            <span class="comment">// loads we do above, removing the implicit weak pointer. This</span></span><br><span class="line">            <span class="comment">// means that the value might be 1 too low here. In order to not</span></span><br><span class="line">            <span class="comment">// return 0 here (which would happen if we&#x27;re the only weak</span></span><br><span class="line">            <span class="comment">// pointer), we guard against that specifically.</span></span><br><span class="line">            cmp::<span class="title function_ invoke__">max</span>(<span class="number">1</span>, weak - <span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的 SeqCst 可以看看：<a href="https://stackoverflow.com/questions/12340773/how-do-memory-order-seq-cst-and-memory-order-acq-rel-differ">https://stackoverflow.com/questions/12340773/how-do-memory-order-seq-cst-and-memory-order-acq-rel-differ</a></p><p>而 is_unique 又不同了：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Determine whether this is the unique reference (including weak refs) to</span></span><br><span class="line"><span class="comment">/// the underlying data.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// Note that this requires locking the weak ref count.</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">is_unique</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">bool</span> &#123;</span><br><span class="line">    <span class="comment">// lock the weak pointer count if we appear to be the sole weak pointer</span></span><br><span class="line">    <span class="comment">// holder.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// The acquire label here ensures a happens-before relationship with any</span></span><br><span class="line">    <span class="comment">// writes to `strong` (in particular in `Weak::upgrade`) prior to decrements</span></span><br><span class="line">    <span class="comment">// of the `weak` count (via `Weak::drop`, which uses release).  If the upgraded</span></span><br><span class="line">    <span class="comment">// weak ref was never dropped, the CAS here will fail so we do not care to synchronize.</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">self</span>.<span class="title function_ invoke__">inner</span>().weak.<span class="title function_ invoke__">compare_exchange</span>(<span class="number">1</span>, usize::MAX, Acquire, Relaxed).<span class="title function_ invoke__">is_ok</span>() &#123;</span><br><span class="line">        <span class="comment">// This needs to be an `Acquire` to synchronize with the decrement of the `strong`</span></span><br><span class="line">        <span class="comment">// counter in `drop` -- the only access that happens when any but the last reference</span></span><br><span class="line">        <span class="comment">// is being dropped.</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">unique</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">inner</span>().strong.<span class="title function_ invoke__">load</span>(Acquire) == <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// The release write here synchronizes with a read in `downgrade`,</span></span><br><span class="line">        <span class="comment">// effectively preventing the above read of `strong` from happening</span></span><br><span class="line">        <span class="comment">// after the write.</span></span><br><span class="line">        <span class="keyword">self</span>.<span class="title function_ invoke__">inner</span>().weak.<span class="title function_ invoke__">store</span>(<span class="number">1</span>, Release); <span class="comment">// release the lock</span></span><br><span class="line">        unique</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>deque in Rust</title>
      <link href="/2020/01/01/deque-in-Rust-and-C/"/>
      <url>/2020/01/01/deque-in-Rust-and-C/</url>
      
        <content type="html"><![CDATA[<h1 id="std-collections-VecDeque"><a href="#std-collections-VecDeque" class="headerlink" title="std::collections::VecDeque"></a>std::collections::VecDeque</h1><p>Rust 的 <code>VecDeque</code> 采取的是 ring buffer 的方式来实现的。我们首先看看它的结构：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// A double-ended queue implemented with a growable ring buffer.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// The &quot;default&quot; usage of this type as a queue is to use [`push_back`] to add to</span></span><br><span class="line"><span class="comment">/// the queue, and [`pop_front`] to remove from the queue. [`extend`] and [`append`]</span></span><br><span class="line"><span class="comment">/// push onto the back in this manner, and iterating over `VecDeque` goes front</span></span><br><span class="line"><span class="comment">/// to back.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// [`push_back`]: #method.push_back</span></span><br><span class="line"><span class="comment">/// [`pop_front`]: #method.pop_front</span></span><br><span class="line"><span class="comment">/// [`extend`]: #method.extend</span></span><br><span class="line"><span class="comment">/// [`append`]: #method.append</span></span><br><span class="line">#[<span class="built_in">stable</span>(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span><br><span class="line">pub <span class="keyword">struct</span> <span class="title class_">VecDeque</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="comment">// tail and head are pointers into the buffer. Tail always points</span></span><br><span class="line">    <span class="comment">// to the first element that could be read, Head always points</span></span><br><span class="line">    <span class="comment">// to where data should be written.</span></span><br><span class="line">    <span class="comment">// If tail == head the buffer is empty. The length of the ringbuffer</span></span><br><span class="line">    <span class="comment">// is defined as the distance between the two.</span></span><br><span class="line">    tail: usize,</span><br><span class="line">    head: usize,</span><br><span class="line">    buf: RawVec&lt;T&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><em>RawVec</em> 我们稍后去看，目前可以理解成一段分配的、连续的 Unininitialize Memory</li></ul><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[allow(missing_debug_implementations)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">RawVec</span>&lt;T, A: Alloc = Global&gt; &#123;</span><br><span class="line">    ptr: Unique&lt;T&gt;,</span><br><span class="line">    cap: <span class="type">usize</span>,</span><br><span class="line">    a: A,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>他们具体结构可以看看我随手弄的图：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">buftailhead buf(end)</span><br><span class="line">|     |     |    |</span><br></pre></td></tr></table></figure><p>写入的时候向 head 写入，tail 是 可读的头（老实说我看代码之前总觉得是反过来的）。</p><p>当 <code>new</code> 的时候会 call <code>with_capacity</code></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">with_capacity</span>(capacity: <span class="type">usize</span>) <span class="punctuation">-&gt;</span> VecDeque&lt;T&gt; &#123;</span><br><span class="line">    <span class="comment">// +1 since the ringbuffer always leaves one space empty</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">cap</span> = cmp::<span class="title function_ invoke__">max</span>(capacity + <span class="number">1</span>, MINIMUM_CAPACITY + <span class="number">1</span>).<span class="title function_ invoke__">next_power_of_two</span>();</span><br><span class="line">    <span class="built_in">assert!</span>(cap &gt; capacity, <span class="string">&quot;capacity overflow&quot;</span>);</span><br><span class="line"></span><br><span class="line">    VecDeque &#123;</span><br><span class="line">        tail: <span class="number">0</span>,</span><br><span class="line">        head: <span class="number">0</span>,</span><br><span class="line">        buf: RawVec::<span class="title function_ invoke__">with_capacity</span>(cap),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>cap 会让大小成为 2 的倍数。因为 head == tail 是 empty 的表示，所以需要 <code>capacity + 1</code></p><p>对于 <code>push_back</code>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">push_back</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, value: T) &#123;</span><br><span class="line">    <span class="keyword">self</span>.<span class="title function_ invoke__">grow_if_necessary</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">head</span> = <span class="keyword">self</span>.head;</span><br><span class="line">    <span class="keyword">self</span>.head = <span class="keyword">self</span>.<span class="title function_ invoke__">wrap_add</span>(<span class="keyword">self</span>.head, <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">unsafe</span> &#123; <span class="keyword">self</span>.<span class="title function_ invoke__">buffer_write</span>(head, value) &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>grow_if_necessary</code> 比较重要，我们后面介绍</p><h3 id="Index-Wrap"><a href="#Index-Wrap" class="headerlink" title="Index Wrap"></a>Index Wrap</h3><p><code>wrap</code> 其实想一想很清晰，这个不是直接去取地址，而是在 ring buffer 里面拿到一个相对的地址。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/// Returns the index in the underlying buffer for a given logical element</span></span><br><span class="line"><span class="comment">/// index + addend.</span></span><br><span class="line"><span class="meta">#[inline]</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">wrap_add</span>(&amp;<span class="keyword">self</span>, idx: <span class="type">usize</span>, addend: <span class="type">usize</span>) <span class="punctuation">-&gt;</span> <span class="type">usize</span> &#123;</span><br><span class="line">    <span class="title function_ invoke__">wrap_index</span>(idx.<span class="title function_ invoke__">wrapping_add</span>(addend), <span class="keyword">self</span>.<span class="title function_ invoke__">cap</span>())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>wrap_index</code>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Returns the index in the underlying buffer for a given logical element index.</span></span><br><span class="line"><span class="meta">#[inline]</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">wrap_index</span>(index: <span class="type">usize</span>, size: <span class="type">usize</span>) <span class="punctuation">-&gt;</span> <span class="type">usize</span> &#123;</span><br><span class="line">    <span class="comment">// size is always a power of 2</span></span><br><span class="line">    <span class="built_in">debug_assert!</span>(size.<span class="title function_ invoke__">is_power_of_two</span>());</span><br><span class="line">    index &amp; (size - <span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个 size 其实是 <code>RawVec</code> 的 cap. 我们之前看到了 cap 会保证自己是 2 的倍数, 这里也有 <code>debug_assert</code>。所以 <code>index &amp; (size - 1)</code> 相当于 <code>index % size</code>. 拿到这里对应的 index。迭代器、<code>index</code> 都是用这一套的。</p><p>所以之前的 <code>push_back</code> ：</p><ul><li>检查是否要 grow, 如果要的话肯定会先 grow, grow 方法一会儿介绍。</li><li>拿到 old head (可写入的)</li><li>head 在 ringbuffer 里面前进</li><li>写入 old head</li></ul><p>然后可以看看 <code>push_front</code> , 很类似</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">push_front</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, value: T) &#123;</span><br><span class="line">    <span class="keyword">self</span>.<span class="title function_ invoke__">grow_if_necessary</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">self</span>.tail = <span class="keyword">self</span>.<span class="title function_ invoke__">wrap_sub</span>(<span class="keyword">self</span>.tail, <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">tail</span> = <span class="keyword">self</span>.tail;</span><br><span class="line">    <span class="keyword">unsafe</span> &#123;</span><br><span class="line">        <span class="keyword">self</span>.<span class="title function_ invoke__">buffer_write</span>(tail, value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不需要我过多解释，你肯定知道：</p><ul><li>检查是否要 grow, 如果要的话肯定会先 grow, grow 方法一会儿介绍。</li><li>拿到 old tail </li><li>tail 在 ringbuffer 里面后退</li><li>写入 old tail</li></ul><h2 id="Pop"><a href="#Pop" class="headerlink" title="Pop"></a>Pop</h2><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">pop_front</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">self</span>.<span class="title function_ invoke__">is_empty</span>() &#123;</span><br><span class="line">        <span class="literal">None</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">tail</span> = <span class="keyword">self</span>.tail;</span><br><span class="line">        <span class="keyword">self</span>.tail = <span class="keyword">self</span>.<span class="title function_ invoke__">wrap_add</span>(<span class="keyword">self</span>.tail, <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">unsafe</span> &#123; <span class="title function_ invoke__">Some</span>(<span class="keyword">self</span>.<span class="title function_ invoke__">buffer_read</span>(tail)) &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="grow-if-neccessary"><a href="#grow-if-neccessary" class="headerlink" title="grow_if_neccessary"></a><code>grow_if_neccessary</code></h2><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// This may panic or abort</span></span><br><span class="line"><span class="meta">#[inline]</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">grow_if_necessary</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">self</span>.<span class="title function_ invoke__">is_full</span>() &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">old_cap</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">cap</span>();</span><br><span class="line">        <span class="keyword">self</span>.buf.<span class="title function_ invoke__">double</span>();</span><br><span class="line">        <span class="keyword">unsafe</span> &#123;</span><br><span class="line">            <span class="keyword">self</span>.<span class="title function_ invoke__">handle_capacity_increase</span>(old_cap);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">debug_assert!</span>(!<span class="keyword">self</span>.<span class="title function_ invoke__">is_full</span>());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>double</code> 是 raw_vec 的一个方法：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[inline(never)]</span></span><br><span class="line">   <span class="meta">#[cold]</span></span><br><span class="line">   <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">double</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">       <span class="keyword">unsafe</span> &#123;</span><br><span class="line">           <span class="keyword">let</span> <span class="variable">elem_size</span> = mem::size_of::&lt;T&gt;();</span><br><span class="line"></span><br><span class="line">           <span class="comment">// since we set the capacity to usize::MAX when elem_size is</span></span><br><span class="line">           <span class="comment">// 0, getting to here necessarily means the RawVec is overfull.</span></span><br><span class="line">           <span class="built_in">assert!</span>(elem_size != <span class="number">0</span>, <span class="string">&quot;capacity overflow&quot;</span>);</span><br><span class="line"></span><br><span class="line">           <span class="keyword">let</span> (new_cap, uniq) = <span class="keyword">match</span> <span class="keyword">self</span>.<span class="title function_ invoke__">current_layout</span>() &#123;</span><br><span class="line">               <span class="title function_ invoke__">Some</span>(cur) =&gt; &#123;</span><br><span class="line">                   <span class="comment">// Since we guarantee that we never allocate more than</span></span><br><span class="line">                   <span class="comment">// isize::MAX bytes, `elem_size * self.cap &lt;= isize::MAX` as</span></span><br><span class="line">                   <span class="comment">// a precondition, so this can&#x27;t overflow. Additionally the</span></span><br><span class="line">                   <span class="comment">// alignment will never be too large as to &quot;not be</span></span><br><span class="line">                   <span class="comment">// satisfiable&quot;, so `Layout::from_size_align` will always</span></span><br><span class="line">                   <span class="comment">// return `Some`.</span></span><br><span class="line">                   <span class="comment">//</span></span><br><span class="line">                   <span class="comment">// tl;dr; we bypass runtime checks due to dynamic assertions</span></span><br><span class="line">                   <span class="comment">// in this module, allowing us to use</span></span><br><span class="line">                   <span class="comment">// `from_size_align_unchecked`.</span></span><br><span class="line">                   <span class="keyword">let</span> <span class="variable">new_cap</span> = <span class="number">2</span> * <span class="keyword">self</span>.cap;</span><br><span class="line">                   <span class="keyword">let</span> <span class="variable">new_size</span> = new_cap * elem_size;</span><br><span class="line">                   <span class="title function_ invoke__">alloc_guard</span>(new_size).<span class="title function_ invoke__">unwrap_or_else</span>(|_| <span class="title function_ invoke__">capacity_overflow</span>());</span><br><span class="line">                   <span class="keyword">let</span> <span class="variable">ptr_res</span> = <span class="keyword">self</span>.a.<span class="title function_ invoke__">realloc</span>(NonNull::<span class="title function_ invoke__">from</span>(<span class="keyword">self</span>.ptr).<span class="title function_ invoke__">cast</span>(),</span><br><span class="line">                                                cur,</span><br><span class="line">                                                new_size);</span><br><span class="line">                   <span class="keyword">match</span> ptr_res &#123;</span><br><span class="line">                       <span class="title function_ invoke__">Ok</span>(ptr) =&gt; (new_cap, ptr.<span class="title function_ invoke__">cast</span>().<span class="title function_ invoke__">into</span>()),</span><br><span class="line">                       <span class="title function_ invoke__">Err</span>(_) =&gt; <span class="title function_ invoke__">handle_alloc_error</span>(</span><br><span class="line">                           Layout::<span class="title function_ invoke__">from_size_align_unchecked</span>(new_size, cur.<span class="title function_ invoke__">align</span>())</span><br><span class="line">                       ),</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="literal">None</span> =&gt; &#123;</span><br><span class="line">                   <span class="comment">// skip to 4 because tiny Vec&#x27;s are dumb; but not if that</span></span><br><span class="line">                   <span class="comment">// would cause overflow</span></span><br><span class="line">                   <span class="keyword">let</span> <span class="variable">new_cap</span> = <span class="keyword">if</span> elem_size &gt; (!<span class="number">0</span>) / <span class="number">8</span> &#123; <span class="number">1</span> &#125; <span class="keyword">else</span> &#123; <span class="number">4</span> &#125;;</span><br><span class="line">                   <span class="keyword">match</span> <span class="keyword">self</span>.a.alloc_array::&lt;T&gt;(new_cap) &#123;</span><br><span class="line">                       <span class="title function_ invoke__">Ok</span>(ptr) =&gt; (new_cap, ptr.<span class="title function_ invoke__">into</span>()),</span><br><span class="line">                       <span class="title function_ invoke__">Err</span>(_) =&gt; <span class="title function_ invoke__">handle_alloc_error</span>(Layout::array::&lt;T&gt;(new_cap).<span class="title function_ invoke__">unwrap</span>()),</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;;</span><br><span class="line">           <span class="keyword">self</span>.ptr = uniq;</span><br><span class="line">           <span class="keyword">self</span>.cap = new_cap;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>调用 <code>realloc</code> ，<em>不改变现有布局</em>的情况下 buffer 倍扩，所以接下来需要：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">unsafe</span> &#123;</span><br><span class="line"><span class="keyword">self</span>.<span class="title function_ invoke__">handle_capacity_increase</span>(old_cap);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现上代码写的很清晰：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Frobs the head and tail sections around to handle the fact that we</span></span><br><span class="line"><span class="comment">/// just reallocated. Unsafe because it trusts old_capacity.</span></span><br><span class="line"><span class="meta">#[inline]</span></span><br><span class="line"><span class="keyword">unsafe</span> <span class="keyword">fn</span> <span class="title function_">handle_capacity_increase</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>, old_capacity: <span class="type">usize</span>) &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">new_capacity</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">cap</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Move the shortest contiguous section of the ring buffer</span></span><br><span class="line">    <span class="comment">//    T             H</span></span><br><span class="line">    <span class="comment">//   [o o o o o o o . ]</span></span><br><span class="line">    <span class="comment">//    T             H</span></span><br><span class="line">    <span class="comment">// A [o o o o o o o . . . . . . . . . ]</span></span><br><span class="line">    <span class="comment">//        H T</span></span><br><span class="line">    <span class="comment">//   [o o . o o o o o ]</span></span><br><span class="line">    <span class="comment">//          T             H</span></span><br><span class="line">    <span class="comment">// B [. . . o o o o o o o . . . . . . ]</span></span><br><span class="line">    <span class="comment">//              H T</span></span><br><span class="line">    <span class="comment">//   [o o o o o . o o ]</span></span><br><span class="line">    <span class="comment">//              H                 T</span></span><br><span class="line">    <span class="comment">// C [o o o o o . . . . . . . . . o o ]</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">self</span>.tail &lt;= <span class="keyword">self</span>.head &#123;</span><br><span class="line">        <span class="comment">// A</span></span><br><span class="line">        <span class="comment">// Nop</span></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> <span class="keyword">self</span>.head &lt; old_capacity - <span class="keyword">self</span>.tail &#123;</span><br><span class="line">        <span class="comment">// B</span></span><br><span class="line">        <span class="keyword">self</span>.<span class="title function_ invoke__">copy_nonoverlapping</span>(old_capacity, <span class="number">0</span>, <span class="keyword">self</span>.head);</span><br><span class="line">        <span class="keyword">self</span>.head += old_capacity;</span><br><span class="line">        <span class="built_in">debug_assert!</span>(<span class="keyword">self</span>.head &gt; <span class="keyword">self</span>.tail);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// C</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">new_tail</span> = new_capacity - (old_capacity - <span class="keyword">self</span>.tail);</span><br><span class="line">        <span class="keyword">self</span>.<span class="title function_ invoke__">copy_nonoverlapping</span>(new_tail, <span class="keyword">self</span>.tail, old_capacity - <span class="keyword">self</span>.tail);</span><br><span class="line">        <span class="keyword">self</span>.tail = new_tail;</span><br><span class="line">        <span class="built_in">debug_assert!</span>(<span class="keyword">self</span>.head &lt; <span class="keyword">self</span>.tail);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">debug_assert!</span>(<span class="keyword">self</span>.head &lt; <span class="keyword">self</span>.<span class="title function_ invoke__">cap</span>());</span><br><span class="line">    <span class="built_in">debug_assert!</span>(<span class="keyword">self</span>.tail &lt; <span class="keyword">self</span>.<span class="title function_ invoke__">cap</span>());</span><br><span class="line">    <span class="built_in">debug_assert!</span>(<span class="keyword">self</span>.<span class="title function_ invoke__">cap</span>().<span class="title function_ invoke__">count_ones</span>() == <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个算法会保证尽量移动最少的元素。</p><ul><li>A: 不需要调整. 刚好 tail 完全在开头，可以想象成只有 push_back。(front push pop 同样也有可能啦，准确的说)</li><li>B: <code>self.head &lt; old_capacity - self.tail</code> 保证移动前段元素</li><li>C: 否则 移动后段元素。</li></ul><h2 id="Drop"><a href="#Drop" class="headerlink" title="Drop"></a>Drop</h2><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">unsafe</span> <span class="keyword">impl</span>&lt;<span class="meta">#[may_dangle]</span> T&gt; <span class="built_in">Drop</span> <span class="keyword">for</span> <span class="title class_">VecDeque</span>&lt;T&gt; &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> (front, back) = <span class="keyword">self</span>.<span class="title function_ invoke__">as_mut_slices</span>();</span><br><span class="line">        <span class="keyword">unsafe</span> &#123;</span><br><span class="line">            <span class="comment">// use drop for [T]</span></span><br><span class="line">            ptr::<span class="title function_ invoke__">drop_in_place</span>(front);</span><br><span class="line">            ptr::<span class="title function_ invoke__">drop_in_place</span>(back);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// RawVec handles deallocation</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个 front back 是 [start, head) 到 [tail, end) 的 slice</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[inline]</span></span><br><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;deque_extras_15&quot;</span>, since = <span class="string">&quot;1.5.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">as_mut_slices</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) <span class="punctuation">-&gt;</span> (&amp;<span class="keyword">mut</span> [T], &amp;<span class="keyword">mut</span> [T]) &#123;</span><br><span class="line">    <span class="keyword">unsafe</span> &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">head</span> = <span class="keyword">self</span>.head;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">tail</span> = <span class="keyword">self</span>.tail;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">buf</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">buffer_as_mut_slice</span>();</span><br><span class="line">        RingSlices::<span class="title function_ invoke__">ring_slices</span>(buf, head, tail)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个 <code>ring_slice</code> 实现是：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Returns the two slices that cover the `VecDeque`&#x27;s valid range</span></span><br><span class="line"><span class="keyword">trait</span> <span class="title class_">RingSlices</span>: <span class="built_in">Sized</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">slice</span>(<span class="keyword">self</span>, from: <span class="type">usize</span>, to: <span class="type">usize</span>) <span class="punctuation">-&gt;</span> <span class="keyword">Self</span>;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">split_at</span>(<span class="keyword">self</span>, i: <span class="type">usize</span>) <span class="punctuation">-&gt;</span> (<span class="keyword">Self</span>, <span class="keyword">Self</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">ring_slices</span>(buf: <span class="keyword">Self</span>, head: <span class="type">usize</span>, tail: <span class="type">usize</span>) <span class="punctuation">-&gt;</span> (<span class="keyword">Self</span>, <span class="keyword">Self</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">contiguous</span> = tail &lt;= head;</span><br><span class="line">        <span class="keyword">if</span> contiguous &#123;</span><br><span class="line">            <span class="keyword">let</span> (empty, buf) = buf.<span class="title function_ invoke__">split_at</span>(<span class="number">0</span>);</span><br><span class="line">            (buf.<span class="title function_ invoke__">slice</span>(tail, head), empty)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">let</span> (mid, right) = buf.<span class="title function_ invoke__">split_at</span>(tail);</span><br><span class="line">            <span class="keyword">let</span> (left, _) = mid.<span class="title function_ invoke__">split_at</span>(head);</span><br><span class="line">            (right, left)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个 contiguous 类似我们之前扩容 的时候。</p><p>而内存的回收交给 <code>RawVec</code>.</p><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><ul><li><code>push_front</code> <code>push_back</code>: 均摊复杂度和 <code>Vec</code> 的 <code>push_back</code>一样，不过可能扩容的时候需要 1.5 倍 size 的复制</li></ul><p>下面这段从官方文档复制过来的</p><div class="table-container"><table><thead><tr><th style="text-align:left"></th><th style="text-align:left">get(i)</th><th style="text-align:left">insert(i)</th><th style="text-align:left">remove(i)</th><th style="text-align:left">append</th><th style="text-align:left">split_off(i)</th></tr></thead><tbody><tr><td style="text-align:left"><a href="https://doc.rust-lang.org/std/vec/struct.Vec.html"><code>Vec</code></a></td><td style="text-align:left">O(1)</td><td style="text-align:left">O(n-i)*</td><td style="text-align:left">O(n-i)</td><td style="text-align:left">O(m)*</td><td style="text-align:left">O(n-i)</td></tr><tr><td style="text-align:left"><a href="https://doc.rust-lang.org/std/collections/struct.VecDeque.html"><code>VecDeque</code></a></td><td style="text-align:left">O(1)</td><td style="text-align:left">O(min(i, n-i))*</td><td style="text-align:left">O(min(i, n-i))</td><td style="text-align:left">O(m)*</td><td style="text-align:left">O(min(i, n-i))</td></tr><tr><td style="text-align:left"><a href="https://doc.rust-lang.org/std/collections/struct.LinkedList.html"><code>LinkedList</code></a></td><td style="text-align:left">O(min(i, n-i))</td><td style="text-align:left">O(min(i, n-i))</td><td style="text-align:left">O(min(i, n-i))</td><td style="text-align:left">O(1)</td><td style="text-align:left">O(min(i, n-i))</td></tr></tbody></table></div><p>Note that where ties occur, <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html"><code>Vec</code></a> is generally going to be faster than <a href="https://doc.rust-lang.org/std/collections/struct.VecDeque.html"><code>VecDeque</code></a>, and <a href="https://doc.rust-lang.org/std/collections/struct.VecDeque.html"><code>VecDeque</code></a> is generally going to be faster than</p>]]></content>
      
      
      
        <tags>
            
            <tag> language </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Naive C++ STL: searching and copying</title>
      <link href="/2019/12/27/Naive-C-STL-searching-and-copying/"/>
      <url>/2019/12/27/Naive-C-STL-searching-and-copying/</url>
      
        <content type="html"><![CDATA[<h1 id="Naive-C-STL-searching-and-copying"><a href="#Naive-C-STL-searching-and-copying" class="headerlink" title="Naive C++ STL: searching and copying"></a>Naive C++ STL: searching and copying</h1><p>因为本人不会写 C++，所以很多地方是很 naive 的手动复制和查找的，十分傻逼。现在我们用 STL 来改造弱智代码吧。</p><h2 id="Tools-about-copying"><a href="#Tools-about-copying" class="headerlink" title="Tools about copying"></a>Tools about copying</h2><h3 id="memcpy"><a href="#memcpy" class="headerlink" title="memcpy"></a><code>memcpy</code></h3><blockquote><div class="table-container"><table><thead><tr><th>dest</th><th>-</th><th>pointer to the memory location to copy to</th></tr></thead><tbody><tr><td>src</td><td>-</td><td>pointer to the memory location to copy from</td></tr><tr><td>count</td><td>-</td><td>number of bytes to copy</td></tr></tbody></table></div><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span>* <span class="title function_">memcpy</span><span class="params">( <span class="type">void</span>* dest, <span class="type">const</span> <span class="type">void</span>* src, <span class="built_in">std</span>::<span class="type">size_t</span> count )</span>;</span><br></pre></td></tr></table></figure></blockquote><p>关于它的效率：</p><blockquote><p>memcpy比循环赋值快吗？为什么？ - 海枫的回答 - 知乎 <a href="https://www.zhihu.com/question/356017800/answer/907232343">https://www.zhihu.com/question/356017800/answer/907232343</a></p></blockquote><p>需要注意的是：</p><blockquote><p>If the objects overlap, the behavior is undefined.</p><p>If either <code>dest</code> or <code>src</code> is a null pointer, the behavior is undefined, even if <code>count</code> is zero.</p></blockquote><p>我个人觉得这可能基于一些实现上的优化，如果不想要的话，可以跳到下一个工具</p><h3 id="memmove"><a href="#memmove" class="headerlink" title="memmove"></a><code>memmove</code></h3><blockquote><p>The objects may overlap: copying takes place as if the characters were copied to a temporary character array and then the characters were copied from the array to <code>dest</code>.</p></blockquote><p>似乎多一条检查边界的指令，这个 sample code 说明了一切：</p><blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"> <span class="type">char</span> str[] = <span class="string">&quot;1234567890&quot;</span>;</span><br><span class="line"> <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; str &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line"> <span class="built_in">std</span>::memmove(str + <span class="number">4</span>, str + <span class="number">3</span>, <span class="number">3</span>); <span class="comment">// copies from [4, 5, 6] to [5, 6, 7]</span></span><br><span class="line"> <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; str &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></blockquote><h3 id="std-copy-std-copy-if"><a href="#std-copy-std-copy-if" class="headerlink" title="std::copy std::copy_if"></a><code>std::copy</code> <code>std::copy_if</code></h3><p>同上：</p><blockquote><p>Copies all elements in the range <code>[first, last)</code> starting from first and proceeding to last - 1. The behavior is undefined if <code>d_first</code> is within the range <code>[first, last)</code>. In this case, <a href="https://en.cppreference.com/w/cpp/algorithm/copy_backward">std::copy_backward</a> may be used instead.</p><p>Only copies the elements for which the predicate <code>pred</code> returns true. The relative order of the elements that are copied is preserved. The behavior is undefined if the source and the destination ranges overlap.</p></blockquote><p>可以指定 execute_policy.</p><p>其实可能你听过 <code>std::uninitialized_copy</code>, 实际上这部分内容在下面 StackoverFlow 里有：</p><p><a href="https://stackoverflow.com/questions/30158192/difference-between-stduninitialized-copy-stdcopy">https://stackoverflow.com/questions/30158192/difference-between-stduninitialized-copy-stdcopy</a></p><p>实际上很简单，<code>uninitialized_copy</code> 用 construct, 调用 constructor.</p><p>此外 cppreference 上认为这些会尽量用 <code>memmove</code> 实现</p><h3 id="std-copy-backward"><a href="#std-copy-backward" class="headerlink" title="std::copy_backward"></a><code>std::copy_backward</code></h3><blockquote><p>When copying overlapping ranges, <code>std::copy</code> is appropriate when copying to the left (beginning of the destination range is outside the source range) while <code>std::copy_backward</code> is appropriate when copying to the right (end of the destination range is outside the source range).</p></blockquote><p>注意别和下面的搞混了</p><h3 id="std-reversed-copy"><a href="#std-reversed-copy" class="headerlink" title="std::reversed_copy"></a><code>std::reversed_copy</code></h3><blockquote><p>Copies the elements from the range <code>[first, last)</code> to another range beginning at <code>d_first</code> in such a way that the elements in the new range are in reverse order.</p><p>Behaves as if by executing the assignment <em>(d_first + (last - first) - 1 - i) = </em>(first + i) once for each non-negative <code>i &lt; (last - first)</code></p><p>If the source and destination ranges (that is, <code>[first, last)</code> and <code>[d_first, d_first+(last-first))</code> respectively) overlap, the behavior is undefined.</p></blockquote><p>BidirIt 需要满足：<a href="https://en.cppreference.com/w/cpp/named_req/BidirectionalIterator"><em>LegacyBidirectionalIterator</em></a></p><p>区别很大：<a href="https://stackoverflow.com/questions/34049447/difference-between-copy-backward-and-reverse-copy">https://stackoverflow.com/questions/34049447/difference-between-copy-backward-and-reverse-copy</a></p><h3 id="std-uninitialized-xxx"><a href="#std-uninitialized-xxx" class="headerlink" title="std::uninitialized_xxx"></a><code>std::uninitialized_xxx</code></h3><p>相当于在 MayUninitMem 上 placement new, 然后调用 copy constructor.</p><h2 id="Tools-about-searching"><a href="#Tools-about-searching" class="headerlink" title="Tools about searching"></a>Tools about searching</h2><h3 id="on-unsorted-ranges"><a href="#on-unsorted-ranges" class="headerlink" title="on unsorted ranges"></a>on unsorted ranges</h3><h4 id="find-find-if-find-first-of"><a href="#find-find-if-find-first-of" class="headerlink" title="find find_if find_first_of"></a><code>find</code> <code>find_if</code> <code>find_first_of</code></h4><ul><li>根据条件 find</li><li>找到“首个”符合条件的，否则返回尾部</li></ul><h4 id="std-adjacent-find"><a href="#std-adjacent-find" class="headerlink" title="std::adjacent_find"></a><code>std::adjacent_find</code></h4><p>找到两个连续相同元素</p><h4 id="std-search"><a href="#std-search" class="headerlink" title="std::search"></a><code>std::search</code></h4><p>类似字符串查找，在顺序容器中查找子顺序容器</p><h3 id="on-sorted-ranges"><a href="#on-sorted-ranges" class="headerlink" title="on sorted ranges"></a>on sorted ranges</h3><h4 id="std-lower-bound-std-upper-bound"><a href="#std-lower-bound-std-upper-bound" class="headerlink" title="std::lower_bound std::upper_bound"></a><code>std::lower_bound</code> <code>std::upper_bound</code></h4><p>分别是：</p><blockquote><p>Returns an iterator pointing to the first element in the range <code>[first, last)</code> that is <em>not less</em> than (i.e. greater or equal to) <code>value</code>, or <code>last</code> if no such element is found.</p><p>Returns an iterator pointing to the first element in the range <code>[first, last)</code> that is <em>greater</em> than <code>value</code>, or <code>last</code> if no such element is found.</p></blockquote><p>注意都是 last</p><p>注意 comp:</p><blockquote><p>binary predicate which returns true if the first argument is <em>less</em> than (i.e. is ordered before) the second.</p></blockquote><h4 id="std-equal-range"><a href="#std-equal-range" class="headerlink" title="std::equal_range"></a><code>std::equal_range</code></h4><p>可能实现成这样：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> ForwardIt, <span class="keyword">class</span> T&gt;</span></span><br><span class="line"><span class="function">std::pair&lt;ForwardIt,ForwardIt&gt; </span></span><br><span class="line"><span class="function">    <span class="title">equal_range</span><span class="params">(ForwardIt first, ForwardIt last,</span></span></span><br><span class="line"><span class="params"><span class="function">                <span class="type">const</span> T&amp; value)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> std::<span class="built_in">make_pair</span>(std::<span class="built_in">lower_bound</span>(first, last, value),</span><br><span class="line">                          std::<span class="built_in">upper_bound</span>(first, last, value));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Migration"><a href="#Migration" class="headerlink" title="Migration"></a>Migration</h2><p>以上是我写的废物代码，现在考虑把之前 proj 的代码迁移到这些上去。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">INDEX_TEMPLATE_ARGUMENTS</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">B_PLUS_TREE_INTERNAL_PAGE_TYPE::ValueIndex</span><span class="params">(<span class="type">const</span> ValueType &amp;value)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>-&gt;<span class="built_in">GetSize</span>(); ++i) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">ValueAt</span>(i) == value) &#123;</span><br><span class="line">            <span class="keyword">return</span> i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">GetSize</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>B+ 树的 internal page 是无序的，所以仍然需要一个线性的查找</li><li>目标是不会重复的</li></ul><p>所以我改成了一个很 naive 的 code:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">INDEX_TEMPLATE_ARGUMENTS</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">B_PLUS_TREE_INTERNAL_PAGE_TYPE::ValueIndex</span><span class="params">(<span class="type">const</span> ValueType &amp;value)</span> <span class="type">const</span> </span>&#123;</span><br><span class="line"><span class="keyword">auto</span> iter =</span><br><span class="line">        std::<span class="built_in">lower_bound</span>(<span class="keyword">this</span>-&gt;array, <span class="keyword">this</span>-&gt;array + <span class="built_in">GetSize</span>(), value,</span><br><span class="line">                         [](<span class="type">const</span> MappingType &amp;mp, <span class="type">const</span> ValueType &amp;vl) &#123;</span><br><span class="line">                             <span class="keyword">return</span> mp.second &lt; vl;</span><br><span class="line">                         &#125;);</span><br><span class="line">    <span class="keyword">if</span> (iter == <span class="keyword">this</span>-&gt;array + <span class="built_in">GetSize</span>() || iter-&gt;second != value) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">GetSize</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> iter - <span class="keyword">this</span>-&gt;array;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>copying:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// <span class="doctag">TODO:</span> select a STL function like `copy_backward` to help us to move</span></span><br><span class="line"><span class="comment">// memory.</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="built_in">GetSize</span>(); i &gt; to_insert_pos; --i) &#123;</span><br><span class="line">    <span class="keyword">this</span>-&gt;array[i] = <span class="keyword">this</span>-&gt;array[i - <span class="number">1</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个实际上肯定可以切换成 copy_backward, 但是写的时候大脑得清晰一些：</p><ul><li>实际上数据范围类似 [src_start, src_end) 和 [target_end - (src_end - src_start), target_end)</li><li>注意拷贝</li></ul><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">std::<span class="built_in">copy_backward</span>(<span class="keyword">this</span>-&gt;array + to_insert_pos, <span class="keyword">this</span>-&gt;array + <span class="built_in">GetSize</span>(),</span><br><span class="line">                       <span class="keyword">this</span>-&gt;array + <span class="built_in">GetSize</span>() + <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p>binary_search:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (; i &lt; <span class="built_in">GetSize</span>(); ++i) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">comparator</span>(<span class="keyword">this</span>-&gt;array[i].first, key) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> i;</span><br></pre></td></tr></table></figure><p>这个实际上 key 是有序的，可以利用 stl 的二分，这里我写了个 lower_bound:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> iter =</span><br><span class="line">    std::<span class="built_in">lower_bound</span>(<span class="keyword">this</span>-&gt;array, <span class="keyword">this</span>-&gt;array + <span class="built_in">GetSize</span>(), key,</span><br><span class="line">                     [&amp;](<span class="type">const</span> MappingType &amp;mp, <span class="type">const</span> KeyType &amp;key) &#123;</span><br><span class="line">                         <span class="keyword">return</span> <span class="built_in">comparator</span>(mp.first, key) &lt; <span class="number">0</span>;</span><br><span class="line">                     &#125;);</span><br><span class="line"><span class="keyword">return</span> iter - <span class="keyword">this</span>-&gt;array;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Rust std::cell</title>
      <link href="/2019/11/27/Rust-std-cell/"/>
      <url>/2019/11/27/Rust-std-cell/</url>
      
        <content type="html"><![CDATA[<h1 id="std-cell"><a href="#std-cell" class="headerlink" title="std::cell"></a>std::cell</h1><p>今天病终于好了，不用上腹下泄了，来写点水文庆祝一下🎉</p><h2 id="UnsafeCell"><a href="#UnsafeCell" class="headerlink" title="UnsafeCell"></a>UnsafeCell</h2><p><code>UnsafeCell</code> 的动机在 F001 大佬的 <a href="https://zhuanlan.zhihu.com/p/22243054">这篇文章</a> 里面提及了，提一下作者写的书还是很不错的，对我帮助很大。</p><p><code>UnsafeCell</code> 结构如下所示：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[lang = <span class="string">&quot;unsafe_cell&quot;</span>]</span></span><br><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="meta">#[repr(transparent)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">UnsafeCell</span>&lt;T: ?<span class="built_in">Sized</span>&gt; &#123;</span><br><span class="line">    value: T,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意一下 marker:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">impl</span>&lt;T: ?<span class="built_in">Sized</span>&gt; !<span class="built_in">Sync</span> <span class="keyword">for</span> <span class="title class_">UnsafeCell</span>&lt;T&gt; &#123;&#125;</span><br></pre></td></tr></table></figure><p>比较重要的方法是 <code>get</code>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;T: ?<span class="built_in">Sized</span>&gt; UnsafeCell&lt;T&gt; &#123;</span><br><span class="line">    <span class="comment">/// Gets a mutable pointer to the wrapped value.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// This can be cast to a pointer of any kind.</span></span><br><span class="line">    <span class="comment">/// Ensure that the access is unique (no active references, mutable or not)</span></span><br><span class="line">    <span class="comment">/// when casting to `&amp;mut T`, and ensure that there are no mutations</span></span><br><span class="line">    <span class="comment">/// or mutable aliases going on when casting to `&amp;T`</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// # Examples</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// ```</span></span><br><span class="line">    <span class="comment">/// use std::cell::UnsafeCell;</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// let uc = UnsafeCell::new(5);</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// let five = uc.get();</span></span><br><span class="line">    <span class="comment">/// ```</span></span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">const</span> <span class="keyword">fn</span> <span class="title function_">get</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> *<span class="keyword">mut</span> T &#123;</span><br><span class="line">        <span class="comment">// We can just cast the pointer from `UnsafeCell&lt;T&gt;` to `T` because of</span></span><br><span class="line">        <span class="comment">// #[repr(transparent)]</span></span><br><span class="line">        <span class="keyword">self</span> <span class="keyword">as</span> *<span class="keyword">const</span> UnsafeCell&lt;T&gt; <span class="keyword">as</span> *<span class="keyword">const</span> T <span class="keyword">as</span> *<span class="keyword">mut</span> T</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>repr(transparent)</code> 资料在：</p><ul><li><a href="https://github.com/rust-lang/rust/issues/43036">https://github.com/rust-lang/rust/issues/43036</a></li><li><a href="https://github.com/rust-lang/rfcs/pull/1758">https://github.com/rust-lang/rfcs/pull/1758</a></li><li><a href="https://github.com/rust-lang/rfcs/blob/master/text/1758-repr-transparent.md">https://github.com/rust-lang/rfcs/blob/master/text/1758-repr-transparent.md</a></li></ul><blockquote><p>On some ABIs, structures with one field aren’t handled the same way as values of the same type as the single field. For example on ARM64, functions returning a structure with a single <code>f64</code> field return nothing and take a pointer to be filled with the return value, whereas functions returning a <code>f64</code> return the floating-point number directly.</p><p>This means that if someone wants to wrap a <code>f64</code> value in a struct tuple wrapper and use that wrapper as the return type of a FFI function that actually returns a bare <code>f64</code>, the calls to this function will be compiled incorrectly by Rust and the execution of the program will segfault.</p><p>This also means that <code>UnsafeCell</code> cannot be soundly used in place of a bare <code>T</code> in FFI context, which might be necessary to signal to the Rust side of things that this <code>T</code> value may unexpectedly be mutated.</p></blockquote><h2 id="std-cell-Cell"><a href="#std-cell-Cell" class="headerlink" title="std::cell::Cell"></a>std::cell::Cell</h2><blockquote><p><code>Cell</code> implements interior mutability by moving values in and out of the <code>Cell</code>. To use references instead of values, one must use the <code>RefCell</code> type, acquiring a write lock before mutating. <code>Cell</code> provides methods to retrieve and change the current interior value:</p><ul><li>For types that implement <code>Copy</code>, the <code>get</code> method retrieves the current interior value.</li><li>For types that implement <code>Default</code>, the <code>take</code> method replaces the current interior value with <code>Default::default()</code> and returns the replaced value.</li><li>For all types, the <code>replace</code> method replaces the current interior value and returns the replaced value and the <code>into_inner</code> method consumes the <code>Cell</code> and returns the interior value. Additionally, the <code>set</code> method replaces the interior value, dropping the replaced value.</li></ul></blockquote><p>对于 <code>Cell</code> 而言，不一定完全需要你实现 Copy 才能用，<code>get</code> 需要你实现 <code>Copy</code>, <code>set</code> 会移除原先内部的</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="meta">#[repr(transparent)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">Cell</span>&lt;T: ?<span class="built_in">Sized</span>&gt; &#123;</span><br><span class="line">    value: UnsafeCell&lt;T&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对应的几个 marker</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">unsafe</span> <span class="keyword">impl</span>&lt;T: ?<span class="built_in">Sized</span>&gt; <span class="built_in">Send</span> <span class="keyword">for</span> <span class="title class_">Cell</span>&lt;T&gt; <span class="keyword">where</span> T: <span class="built_in">Send</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">impl</span>&lt;T: ?<span class="built_in">Sized</span>&gt; !<span class="built_in">Sync</span> <span class="keyword">for</span> <span class="title class_">Cell</span>&lt;T&gt; &#123;&#125;</span><br></pre></td></tr></table></figure><p>可以看到，从结构设计来看, <code>Cell</code> 相对来说额外开销小一些。</p><p>Get/Set:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;T:<span class="built_in">Copy</span>&gt; Cell&lt;T&gt; &#123;</span><br><span class="line">    <span class="comment">/// Returns a copy of the contained value.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// # Examples</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// ```</span></span><br><span class="line">    <span class="comment">/// use std::cell::Cell;</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// let c = Cell::new(5);</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// let five = c.get();</span></span><br><span class="line">    <span class="comment">/// ```</span></span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">get</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> T &#123;</span><br><span class="line">        <span class="keyword">unsafe</span>&#123; *<span class="keyword">self</span>.value.<span class="title function_ invoke__">get</span>() &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 省略</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个 <code>get</code> 需要实现 copy trait, 拿到 <code>UnsafeCell</code> 内部的数值。然后把这个旧值 <code>drop</code> 掉。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">impl</span>&lt;T&gt; Cell&lt;T&gt; &#123;</span><br><span class="line">    <span class="comment">/// Sets the contained value.</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// # Examples</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// ```</span></span><br><span class="line">    <span class="comment">/// use std::cell::Cell;</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// let c = Cell::new(5);</span></span><br><span class="line">    <span class="comment">///</span></span><br><span class="line">    <span class="comment">/// c.set(10);</span></span><br><span class="line">    <span class="comment">/// ```</span></span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line">    <span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">set</span>(&amp;<span class="keyword">self</span>, val: T) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">old</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">replace</span>(val);</span><br><span class="line">        <span class="title function_ invoke__">drop</span>(old);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看来我们需要看看 <code>replace</code>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;move_cell&quot;</span>, since = <span class="string">&quot;1.17.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">replace</span>(&amp;<span class="keyword">self</span>, val: T) <span class="punctuation">-&gt;</span> T &#123;</span><br><span class="line">    mem::<span class="title function_ invoke__">replace</span>(<span class="keyword">unsafe</span> &#123; &amp;<span class="keyword">mut</span> *<span class="keyword">self</span>.value.<span class="title function_ invoke__">get</span>() &#125;, val)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>mem::replace</code> 的文档如下：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">replace</span>&lt;T&gt;(dest: &amp;<span class="keyword">mut</span> T, src: T) <span class="punctuation">-&gt;</span> T</span><br></pre></td></tr></table></figure><blockquote><p>Moves <code>src</code> into the referenced <code>dest</code>, returning the previous <code>dest</code> value.</p><p>Neither value is dropped.</p></blockquote><p>返回 <code>UnsafeCell</code> 保存的值，同时写入 <code>UnsafeCell</code>.</p><h2 id="std-cell-RefCell"><a href="#std-cell-RefCell" class="headerlink" title="std::cell::RefCell"></a>std::cell::RefCell</h2><blockquote><p><code>RefCell</code> uses Rust’s lifetimes to implement ‘dynamic borrowing’, a process whereby one can claim temporary, exclusive, mutable access to the inner value. Borrows for <code>RefCell</code>s are tracked ‘at runtime’, unlike Rust’s native reference types which are entirely tracked statically, at compile time. Because <code>RefCell</code> borrows are dynamic it is possible to attempt to borrow a value that is already mutably borrowed; when this happens it results in thread panic.</p></blockquote><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// A mutable memory location with dynamically checked borrow rules</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// See the [module-level documentation](index.html) for more.</span></span><br><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">RefCell</span>&lt;T: ?<span class="built_in">Sized</span>&gt; &#123;</span><br><span class="line">    borrow: Cell&lt;BorrowFlag&gt;,</span><br><span class="line">    value: UnsafeCell&lt;T&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>它相对 <code>Cell</code> 多维护了一个 <code>borrow</code> 字段：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Positive values represent the number of `Ref` active. Negative values</span></span><br><span class="line"><span class="comment">// represent the number of `RefMut` active. Multiple `RefMut`s can only be</span></span><br><span class="line"><span class="comment">// active at a time if they refer to distinct, nonoverlapping components of a</span></span><br><span class="line"><span class="comment">// `RefCell` (e.g., different ranges of a slice).</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// `Ref` and `RefMut` are both two words in size, and so there will likely never</span></span><br><span class="line"><span class="comment">// be enough `Ref`s or `RefMut`s in existence to overflow half of the `usize`</span></span><br><span class="line"><span class="comment">// range. Thus, a `BorrowFlag` will probably never overflow or underflow.</span></span><br><span class="line"><span class="comment">// However, this is not a guarantee, as a pathological program could repeatedly</span></span><br><span class="line"><span class="comment">// create and then mem::forget `Ref`s or `RefMut`s. Thus, all code must</span></span><br><span class="line"><span class="comment">// explicitly check for overflow and underflow in order to avoid unsafety, or at</span></span><br><span class="line"><span class="comment">// least behave correctly in the event that overflow or underflow happens (e.g.,</span></span><br><span class="line"><span class="comment">// see BorrowRef::new).</span></span><br><span class="line"><span class="keyword">type</span> <span class="title class_">BorrowFlag</span> = <span class="type">isize</span>;</span><br><span class="line"><span class="keyword">const</span> UNUSED: BorrowFlag = <span class="number">0</span>;</span><br></pre></td></tr></table></figure><p>可以看到：</p><ul><li><code>UNUSED</code> 表示这个 <code>RefCell</code> 并没有任何借用</li><li>Positive value: 表示 <code>Ref</code>, 这里可以推测是 <code>&amp;T</code> 模式的借用存在</li><li>Nagative value: 表示 <code>RefMut</code>, 这里可以推测是 <code>&amp;mut T</code> 模式的借用存在</li></ul><p>让我们看看 <code>try_borrow_mut</code>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// Mutably borrows the wrapped value, returning an error if the value is currently borrowed.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// The borrow lasts until the returned `RefMut` or all `RefMut`s derived</span></span><br><span class="line"><span class="comment">/// from it exit scope. The value cannot be borrowed while this borrow is</span></span><br><span class="line"><span class="comment">/// active.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// This is the non-panicking variant of [`borrow_mut`](#method.borrow_mut).</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// # Examples</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// ```</span></span><br><span class="line"><span class="comment">/// use std::cell::RefCell;</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// let c = RefCell::new(5);</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// &#123;</span></span><br><span class="line"><span class="comment">///     let m = c.borrow();</span></span><br><span class="line"><span class="comment">///     assert!(c.try_borrow_mut().is_err());</span></span><br><span class="line"><span class="comment">/// &#125;</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// assert!(c.try_borrow_mut().is_ok());</span></span><br><span class="line"><span class="comment">/// ```</span></span><br><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;try_borrow&quot;</span>, since = <span class="string">&quot;1.13.0&quot;</span>)]</span></span><br><span class="line"><span class="meta">#[inline]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">try_borrow_mut</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;RefMut&lt;<span class="symbol">&#x27;_</span>, T&gt;, BorrowMutError&gt; &#123;</span><br><span class="line">    <span class="keyword">match</span> BorrowRefMut::<span class="title function_ invoke__">new</span>(&amp;<span class="keyword">self</span>.borrow) &#123;</span><br><span class="line">        <span class="title function_ invoke__">Some</span>(b) =&gt; <span class="title function_ invoke__">Ok</span>(RefMut &#123;</span><br><span class="line">            value: <span class="keyword">unsafe</span> &#123; &amp;<span class="keyword">mut</span> *<span class="keyword">self</span>.value.<span class="title function_ invoke__">get</span>() &#125;,</span><br><span class="line">            borrow: b,</span><br><span class="line">        &#125;),</span><br><span class="line">        <span class="literal">None</span> =&gt; <span class="title function_ invoke__">Err</span>(BorrowMutError &#123; _private: () &#125;),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里有相当重要的 <code>BorrowRefMut</code>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">BorrowRefMut</span>&lt;<span class="symbol">&#x27;b</span>&gt; &#123;</span><br><span class="line">    borrow: &amp;<span class="symbol">&#x27;b</span> Cell&lt;BorrowFlag&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Drop</span> <span class="keyword">for</span> <span class="title class_">BorrowRefMut</span>&lt;<span class="symbol">&#x27;_</span>&gt; &#123;</span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">borrow</span> = <span class="keyword">self</span>.borrow.<span class="title function_ invoke__">get</span>();</span><br><span class="line">        <span class="built_in">debug_assert!</span>(<span class="title function_ invoke__">is_writing</span>(borrow));</span><br><span class="line">        <span class="keyword">self</span>.borrow.<span class="title function_ invoke__">set</span>(borrow + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">&#x27;b</span>&gt; BorrowRefMut&lt;<span class="symbol">&#x27;b</span>&gt; &#123;</span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">new</span>(borrow: &amp;<span class="symbol">&#x27;b</span> Cell&lt;BorrowFlag&gt;) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;BorrowRefMut&lt;<span class="symbol">&#x27;b</span>&gt;&gt; &#123;</span><br><span class="line">        <span class="comment">// <span class="doctag">NOTE:</span> Unlike BorrowRefMut::clone, new is called to create the initial</span></span><br><span class="line">        <span class="comment">// mutable reference, and so there must currently be no existing</span></span><br><span class="line">        <span class="comment">// references. Thus, while clone increments the mutable refcount, here</span></span><br><span class="line">        <span class="comment">// we explicitly only allow going from UNUSED to UNUSED - 1.</span></span><br><span class="line">        <span class="keyword">match</span> borrow.<span class="title function_ invoke__">get</span>() &#123;</span><br><span class="line">            UNUSED =&gt; &#123;</span><br><span class="line">                borrow.<span class="title function_ invoke__">set</span>(UNUSED - <span class="number">1</span>);</span><br><span class="line">                <span class="title function_ invoke__">Some</span>(BorrowRefMut &#123; borrow &#125;)</span><br><span class="line">            &#125;,</span><br><span class="line">            _ =&gt; <span class="literal">None</span>,</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Clones a `BorrowRefMut`.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// This is only valid if each `BorrowRefMut` is used to track a mutable</span></span><br><span class="line">    <span class="comment">// reference to a distinct, nonoverlapping range of the original object.</span></span><br><span class="line">    <span class="comment">// This isn&#x27;t in a Clone impl so that code doesn&#x27;t call this implicitly.</span></span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">clone</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> BorrowRefMut&lt;<span class="symbol">&#x27;b</span>&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">borrow</span> = <span class="keyword">self</span>.borrow.<span class="title function_ invoke__">get</span>();</span><br><span class="line">        <span class="built_in">debug_assert!</span>(<span class="title function_ invoke__">is_writing</span>(borrow));</span><br><span class="line">        <span class="comment">// Prevent the borrow counter from underflowing.</span></span><br><span class="line">        <span class="built_in">assert!</span>(borrow != isize::<span class="title function_ invoke__">min_value</span>());</span><br><span class="line">        <span class="keyword">self</span>.borrow.<span class="title function_ invoke__">set</span>(borrow - <span class="number">1</span>);</span><br><span class="line">        BorrowRefMut &#123; borrow: <span class="keyword">self</span>.borrow &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[inline(always)]</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">is_writing</span>(x: BorrowFlag) <span class="punctuation">-&gt;</span> <span class="type">bool</span> &#123;</span><br><span class="line">    x &lt; UNUSED</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回的是一个 <code>RefMut</code>, 带有值和 <code>BorrowRefMut&lt;&#39;b&gt;</code></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/// A wrapper type for a mutably borrowed value from a `RefCell&lt;T&gt;`.</span></span><br><span class="line"><span class="comment">///</span></span><br><span class="line"><span class="comment">/// See the [module-level documentation](index.html) for more.</span></span><br><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;rust1&quot;</span>, since = <span class="string">&quot;1.0.0&quot;</span>)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">struct</span> <span class="title class_">RefMut</span>&lt;<span class="symbol">&#x27;b</span>, T: ?<span class="built_in">Sized</span> + <span class="symbol">&#x27;b</span>&gt; &#123;</span><br><span class="line">    value: &amp;<span class="symbol">&#x27;b</span> <span class="keyword">mut</span> T,</span><br><span class="line">    borrow: BorrowRefMut&lt;<span class="symbol">&#x27;b</span>&gt;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以按照之前的规则，来大致明白这段逻辑：</p><ol><li><code>new</code> 的时候，这里是个 <code>RefMut</code>, 必须没有 <code>Ref</code>, 即 unused 才是合法的，它的状态改为 <code>UNUSED - 1</code>. 即一个 <code>RefMut</code>.</li><li><code>drop</code> 的时候，增加 <code>BorrowFlag</code> 的值.</li><li><code>BorrowRefMut</code> 持有 <code>&amp; Cell&lt;BorrowFlag&gt;</code></li></ol><p><code>try_borrow</code> 类似：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[stable(feature = <span class="string">&quot;try_borrow&quot;</span>, since = <span class="string">&quot;1.13.0&quot;</span>)]</span></span><br><span class="line"><span class="meta">#[inline]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">try_borrow</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">Result</span>&lt;Ref&lt;<span class="symbol">&#x27;_</span>, T&gt;, BorrowError&gt; &#123;</span><br><span class="line">    <span class="keyword">match</span> BorrowRef::<span class="title function_ invoke__">new</span>(&amp;<span class="keyword">self</span>.borrow) &#123;</span><br><span class="line">        <span class="title function_ invoke__">Some</span>(b) =&gt; <span class="title function_ invoke__">Ok</span>(Ref &#123;</span><br><span class="line">            value: <span class="keyword">unsafe</span> &#123; &amp;*<span class="keyword">self</span>.value.<span class="title function_ invoke__">get</span>() &#125;,</span><br><span class="line">            borrow: b,</span><br><span class="line">        &#125;),</span><br><span class="line">        <span class="literal">None</span> =&gt; <span class="title function_ invoke__">Err</span>(BorrowError &#123; _private: () &#125;),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">BorrowRef</span>&lt;<span class="symbol">&#x27;b</span>&gt; &#123;</span><br><span class="line">    borrow: &amp;<span class="symbol">&#x27;b</span> Cell&lt;BorrowFlag&gt;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span>&lt;<span class="symbol">&#x27;b</span>&gt; BorrowRef&lt;<span class="symbol">&#x27;b</span>&gt; &#123;</span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">new</span>(borrow: &amp;<span class="symbol">&#x27;b</span> Cell&lt;BorrowFlag&gt;) <span class="punctuation">-&gt;</span> <span class="type">Option</span>&lt;BorrowRef&lt;<span class="symbol">&#x27;b</span>&gt;&gt; &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">b</span> = borrow.<span class="title function_ invoke__">get</span>().<span class="title function_ invoke__">wrapping_add</span>(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span> !<span class="title function_ invoke__">is_reading</span>(b) &#123;</span><br><span class="line">            <span class="comment">// Incrementing borrow can result in a non-reading value (&lt;= 0) in these cases:</span></span><br><span class="line">            <span class="comment">// 1. It was &lt; 0, i.e. there are writing borrows, so we can&#x27;t allow a read borrow</span></span><br><span class="line">            <span class="comment">//    due to Rust&#x27;s reference aliasing rules</span></span><br><span class="line">            <span class="comment">// 2. It was isize::max_value() (the max amount of reading borrows) and it overflowed</span></span><br><span class="line">            <span class="comment">//    into isize::min_value() (the max amount of writing borrows) so we can&#x27;t allow</span></span><br><span class="line">            <span class="comment">//    an additional read borrow because isize can&#x27;t represent so many read borrows</span></span><br><span class="line">            <span class="comment">//    (this can only happen if you mem::forget more than a small constant amount of</span></span><br><span class="line">            <span class="comment">//    `Ref`s, which is not good practice)</span></span><br><span class="line">            <span class="literal">None</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// Incrementing borrow can result in a reading value (&gt; 0) in these cases:</span></span><br><span class="line">            <span class="comment">// 1. It was = 0, i.e. it wasn&#x27;t borrowed, and we are taking the first read borrow</span></span><br><span class="line">            <span class="comment">// 2. It was &gt; 0 and &lt; isize::max_value(), i.e. there were read borrows, and isize</span></span><br><span class="line">            <span class="comment">//    is large enough to represent having one more read borrow</span></span><br><span class="line">            borrow.<span class="title function_ invoke__">set</span>(b);</span><br><span class="line">            <span class="title function_ invoke__">Some</span>(BorrowRef &#123; borrow &#125;)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Drop</span> <span class="keyword">for</span> <span class="title class_">BorrowRef</span>&lt;<span class="symbol">&#x27;_</span>&gt; &#123;</span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">drop</span>(&amp;<span class="keyword">mut</span> <span class="keyword">self</span>) &#123;</span><br><span class="line">        <span class="keyword">let</span> <span class="variable">borrow</span> = <span class="keyword">self</span>.borrow.<span class="title function_ invoke__">get</span>();</span><br><span class="line">        <span class="built_in">debug_assert!</span>(<span class="title function_ invoke__">is_reading</span>(borrow));</span><br><span class="line">        <span class="keyword">self</span>.borrow.<span class="title function_ invoke__">set</span>(borrow - <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">impl</span> <span class="title class_">Clone</span> <span class="keyword">for</span> <span class="title class_">BorrowRef</span>&lt;<span class="symbol">&#x27;_</span>&gt; &#123;</span><br><span class="line">    <span class="meta">#[inline]</span></span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">clone</span>(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="keyword">Self</span> &#123;</span><br><span class="line">        <span class="comment">// Since this Ref exists, we know the borrow flag</span></span><br><span class="line">        <span class="comment">// is a reading borrow.</span></span><br><span class="line">        <span class="keyword">let</span> <span class="variable">borrow</span> = <span class="keyword">self</span>.borrow.<span class="title function_ invoke__">get</span>();</span><br><span class="line">        <span class="built_in">debug_assert!</span>(<span class="title function_ invoke__">is_reading</span>(borrow));</span><br><span class="line">        <span class="comment">// Prevent the borrow counter from overflowing into</span></span><br><span class="line">        <span class="comment">// a writing borrow.</span></span><br><span class="line">        <span class="built_in">assert!</span>(borrow != isize::<span class="title function_ invoke__">max_value</span>());</span><br><span class="line">        <span class="keyword">self</span>.borrow.<span class="title function_ invoke__">set</span>(borrow + <span class="number">1</span>);</span><br><span class="line">        BorrowRef &#123; borrow: <span class="keyword">self</span>.borrow &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li><code>new</code> 的时候 <code>+1</code> 并检查，如果之前是 <code>&lt; 0</code> 的 writing 状态，返回 None. 否则返回 <code>BorrowRef</code></li><li><code>drop</code> 的时候 <code>borrow</code> 减少</li><li><code>clone</code> 的时候 <code>++borrow</code></li></ol>]]></content>
      
      
      <categories>
          
          <category> Rust </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Vector 的 C++ 和 Rust 实现</title>
      <link href="/2019/10/15/Vector-%E7%9A%84-C-%E5%92%8C-Rust-%E5%AE%9E%E7%8E%B0/"/>
      <url>/2019/10/15/Vector-%E7%9A%84-C-%E5%92%8C-Rust-%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>MapReduce Paper &amp; Lab Report</title>
      <link href="/2019/10/09/MapReduce-Paper-Lab-Report/"/>
      <url>/2019/10/09/MapReduce-Paper-Lab-Report/</url>
      
        <content type="html"><![CDATA[<h1 id="MapReduce-论文阅读"><a href="#MapReduce-论文阅读" class="headerlink" title="MapReduce 论文阅读"></a>MapReduce 论文阅读</h1><h2 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h2><p>MapReduce 使用类似 fp 的原语来描述一个计算：</p><blockquote><p>Map(k, v) =&gt; list(k2, v2)</p><p>Reduce(k2, list(v2)) =&gt; list(v2)</p><p>输入的k, v != 中间的 k2, v2 == 输出的k2, v2.</p></blockquote><p>可以做倒排索引、wordcount、分布式排序等事情，前提是你能把你的任务描述成map – reduce 形式。</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="主要流程"><a href="#主要流程" class="headerlink" title="主要流程"></a>主要流程</h3><p><img src="https://nmsl.maplewish.cn/blog:/Users/fuasahi/Desktop/writing/MapReduce.md:mapreduce%E6%B5%81%E7%A8%8B.png" alt="mapreduce流程"></p><p>可以看到，这里有 map-worker 和 reduce-worker. Map Reduce 分区数量由用户定义。</p><p>操作按论文说有一些流程，照搬不太好，我就说下自己的理解：</p><ol><li>将输入文件分段，定义一定的数据段大小(原始论文给16-64MB)</li><li>用户程序创建大量的 map reduce 工作副本</li><li>master 分配任务给空闲 worker，有M和R个任务</li><li><strong>Map worker</strong> 完成计算，并且把数据<strong>缓存</strong>在<strong>内存</strong>中， <code>k2, v2</code> 对自动分区成 R 个，写在 <strong>本地文件</strong> 中，消息被传给master, master 把这个信息传给 reducer.</li><li>reducer 接收到 master 的消息后：<ol><li>用 rpc 读取这些数据</li><li>把数据按照 k2 聚合，似乎要排序？</li><li>处理这些数据，按照分区<strong>追加</strong>写到输出文件</li></ol></li><li>完成后，R个分区有<strong>追加</strong> 的 map-reduce 文件。</li></ol><h3 id="故障处理"><a href="#故障处理" class="headerlink" title="故障处理"></a>故障处理</h3><h4 id="worker-故障"><a href="#worker-故障" class="headerlink" title="worker 故障"></a>worker 故障</h4><p>worker 故障的主要解决方案是标记成错误，如果是 map-worker 则通知 reduce-worker ，把任务交给别人执行。</p><p>我很弟弟，看的是论文中文翻译，但是感觉这段写的比我能总结的好很多：</p><blockquote><p>master 周期性的 ping 每个 worker。如果在一个约定的时间范围内没有收到 worker 返回的信息，master 将<br>把这个 worker 标记为失效。所有由这个失效的 worker 完成的 Map 任务被重设为初始的空闲状态，之后这些<br>任务就可以被安排给其他的 worker。同样的，worker 失效时正在运行的 Map 或 Reduce 任务也将被重新置为<br>空闲状态，等待重新调度。</p></blockquote><h4 id="master-故障"><a href="#master-故障" class="headerlink" title="master 故障"></a>master 故障</h4><p>类似内存备份吧，写wal／周期性写入磁盘什么的 …</p><h3 id="任务粒度"><a href="#任务粒度" class="headerlink" title="任务粒度"></a>任务粒度</h3><blockquote><p>理想情况下，M 和 R 应当 比集群中 worker 的机器数量要多得多。在每台 worker 机器都执行大量的不同任务能够 高集群的动态的负载 均衡能力，并且能够加快故障恢复的速度:失效机器上执行的大量 Map 任务都可以分布到所有其他的 worker 机器上去执行。</p><p>但是实际上，在我们的具体实现中对 M 和 R 的取值都有一定的客观限制，因为 master 必须执行 O(M+R) 次调度，并且在内存中保存 O(M<em>R)个状态(对影响内存使用的因素还是比较小的:O(M</em>R)块状态，大概每 对 Map 任务/Reduce 任务 1 个字节就可以了)。</p></blockquote><h3 id="备用任务"><a href="#备用任务" class="headerlink" title="备用任务"></a>备用任务</h3><p>有的任务执行的很慢，我们有的时候会调度 backup (备份) 来处理剩下的、处理中的任务。</p>]]></content>
      
      
      <categories>
          
          <category> Lab Report </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Paper Reading </tag>
            
            <tag> Lab Report </tag>
            
            <tag> Distributed </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyConCn2019</title>
      <link href="/2019/09/29/PyConCn2019/"/>
      <url>/2019/09/29/PyConCn2019/</url>
      
        <content type="html"><![CDATA[<p>翘了一天公司 TB 来 PyCon, 也不说想法了，就说下自己听的一些。由于自己水平不够，说的东西可能有很多问题，欢迎各路大佬指出：</p><h3 id="ARMIN-RONACHER-调试是一种新的发布：慢语言的意外优势"><a href="#ARMIN-RONACHER-调试是一种新的发布：慢语言的意外优势" class="headerlink" title="ARMIN RONACHER: 调试是一种新的发布：慢语言的意外优势"></a>ARMIN RONACHER: 调试是一种新的发布：慢语言的意外优势</h3><p>作者对比了 Python, V8, 还有 Cpp 这些语言的 debug/release 下的性能比较和 debug 可提供的信息，得出 Python 编译不能像有 JIT/AOT 编译器一样，提供很高的优化，但是这也让在生产环境中用 debug mode（或者说提供更多的 debug 信息）的性能损耗、代价更小。</p><h3 id="LAIKE9M-Python-调试新思路"><a href="#LAIKE9M-Python-调试新思路" class="headerlink" title="LAIKE9M: Python 调试新思路"></a>LAIKE9M: Python 调试新思路</h3><p><a href="https://github.com/laike9m/Cyberbraingithub.com">https://github.com/laike9m/Cyberbraingithub.com</a></p><p>介绍了下 Python debug 的思路，同时引出这个 repo, 看上去很不错= =不过我尚且没有体验过，不好做出评价。感觉做题可以用用，不过目前生产环境用这个估计不是很方便？</p><h3 id="张佳圆-GIL-的过去和未来"><a href="#张佳圆-GIL-的过去和未来" class="headerlink" title="张佳圆: GIL 的过去和未来"></a>张佳圆: GIL 的过去和未来</h3><p><a href="https://www.python.org/dev/peps/pep-0554/www.python.org">https://www.python.org/dev/peps/pep-0554/www.python.org</a></p><p>介绍了一下 GIL 的历史和一些绕过 GIL 的方案，也介绍了上面这个 PEP，不过感觉提问环节质量不是很高= =</p><h3 id="GIAMPAOLO-RODOLA-使用-Python-加速文件传输和文件复制"><a href="#GIAMPAOLO-RODOLA-使用-Python-加速文件传输和文件复制" class="headerlink" title="GIAMPAOLO RODOLA: 使用 Python 加速文件传输和文件复制"></a>GIAMPAOLO RODOLA: 使用 Python 加速文件传输和文件复制</h3><p>psutil 这个库的作者介绍一下用 sendfile 代替 read + write 减少用户态内核跳来跳去的方法。同时也简短介绍了下 psutil 这个库。（我本人也用这个库，所以听得很开心）</p><p><a href="https://pic3.zhimg.com/v2-ea5c21e251004d639b624aaae78294ae_ipico.jpg">giampaolo/psutilgithub.com</a></p><h3 id="THAUTWARM-Python-语法扩展框架-Moshmosh-和其上-CPython-兼容的-JIT-实现"><a href="#THAUTWARM-Python-语法扩展框架-Moshmosh-和其上-CPython-兼容的-JIT-实现" class="headerlink" title="THAUTWARM: Python 语法扩展框架 Moshmosh 和其上 CPython 兼容的 JIT 实现"></a>THAUTWARM: Python 语法扩展框架 Moshmosh 和其上 CPython 兼容的 JIT 实现</h3><p>Moshmosh 似乎没介绍？主要内容是后者，期待大佬开发者填坑。</p><h3 id="张汝家-从-thriftpy-中学习-rpc-协议"><a href="#张汝家-从-thriftpy-中学习-rpc-协议" class="headerlink" title="张汝家: 从 thriftpy 中学习 rpc 协议"></a>张汝家: 从 thriftpy 中学习 rpc 协议</h3><p>简单介绍了一下 thrift 和 thriftpy，似乎没有讲很深。</p><hr><p>参会体验还是很不错的，很多比较实用的建议，期待下次再玩</p>]]></content>
      
      
      <categories>
          
          <category> life </category>
          
      </categories>
      
      
        <tags>
            
            <tag> talks </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
